"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[7943],{6903:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"rag-recommendations/retrieval-system","title":"Retrieval System Implementation","description":"This section focuses on building a robust retrieval system that efficiently finds relevant products based on user queries, preferences, and context. The retrieval system is the core component that bridges user intent with relevant products using vector similarity search.","source":"@site/docs/rag-recommendations/retrieval-system.md","sourceDirName":"rag-recommendations","slug":"/rag-recommendations/retrieval-system","permalink":"/fullstack-dev/docs/rag-recommendations/retrieval-system","draft":false,"unlisted":false,"editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/docs/rag-recommendations/retrieval-system.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Data Pipeline and Vector Embeddings","permalink":"/fullstack-dev/docs/rag-recommendations/data-pipeline"},"next":{"title":"Generation and Personalization Engine","permalink":"/fullstack-dev/docs/rag-recommendations/generation-engine"}}');var s=r(5813),i=r(7814);const a={},o="Retrieval System Implementation",l={},c=[{value:"Retrieval Architecture",id:"retrieval-architecture",level:2},{value:"Vector Database Implementation",id:"vector-database-implementation",level:2},{value:"Qdrant Integration",id:"qdrant-integration",level:3},{value:"Query Processing Engine",id:"query-processing-engine",level:3},{value:"Retrieval Engine",id:"retrieval-engine",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Caching Strategy",id:"caching-strategy",level:3},{value:"Search API Implementation",id:"search-api-implementation",level:2},{value:"REST API Service",id:"rest-api-service",level:3},{value:"Next Steps",id:"next-steps",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"retrieval-system-implementation",children:"Retrieval System Implementation"})}),"\n",(0,s.jsx)(n.p,{children:"This section focuses on building a robust retrieval system that efficiently finds relevant products based on user queries, preferences, and context. The retrieval system is the core component that bridges user intent with relevant products using vector similarity search."}),"\n",(0,s.jsx)(n.h2,{id:"retrieval-architecture",children:"Retrieval Architecture"}),"\n",(0,s.jsx)(n.p,{children:"Our retrieval system uses a multi-stage approach to ensure both relevance and performance:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   User Query    \u2502    \u2502   Query         \u2502    \u2502   Retrieval     \u2502\n\u2502   + Context     \u2502\u2500\u2500\u2500\u25b6\u2502   Processing    \u2502\u2500\u2500\u2500\u25b6\u2502   Engine        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502                      \u2502                      \u2502                 \u2502\n\u251c\u2500 Search Query        \u251c\u2500 Query Expansion     \u251c\u2500 Vector Search   \u2502\n\u251c\u2500 User Profile        \u251c\u2500 Intent Detection    \u251c\u2500 Hybrid Filtering\u2502\n\u251c\u2500 Session Context     \u251c\u2500 Embedding Gen.     \u251c\u2500 Re-ranking      \u2502\n\u251c\u2500 Behavioral Data     \u251c\u2500 Filter Extraction  \u251c\u2500 Diversity       \u2502\n\u2514\u2500 Product Context     \u2514\u2500 Query Enhancement  \u2514\u2500 Post-processing \u2502\n"})}),"\n",(0,s.jsx)(n.h2,{id:"vector-database-implementation",children:"Vector Database Implementation"}),"\n",(0,s.jsx)(n.h3,{id:"qdrant-integration",children:"Qdrant Integration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# retrieval/vector_db.py\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.models import Distance, VectorParams, PointStruct\nfrom qdrant_client.models import Filter, FieldCondition, Range, MatchValue\nimport numpy as np\nfrom typing import List, Dict, Any, Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass QdrantVectorDB:\n    """Qdrant vector database implementation for product retrieval"""\n    \n    def __init__(self, host: str = "localhost", port: int = 6333):\n        self.client = QdrantClient(host=host, port=port)\n        self.collections = {}\n        \n    async def setup_collection(self, \n                              collection_name: str, \n                              vector_size: int, \n                              distance: Distance = Distance.COSINE) -> bool:\n        """Setup a new collection for vector storage"""\n        try:\n            # Check if collection exists\n            collections = self.client.get_collections()\n            existing_names = [c.name for c in collections.collections]\n            \n            if collection_name not in existing_names:\n                self.client.create_collection(\n                    collection_name=collection_name,\n                    vectors_config=VectorParams(size=vector_size, distance=distance)\n                )\n                logger.info(f"Created collection: {collection_name}")\n            else:\n                logger.info(f"Collection already exists: {collection_name}")\n            \n            self.collections[collection_name] = {\n                \'vector_size\': vector_size,\n                \'distance\': distance\n            }\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f"Failed to setup collection {collection_name}: {e}")\n            return False\n    \n    async def upsert_vectors(self, \n                            collection_name: str, \n                            vectors_data: List[Dict[str, Any]]) -> bool:\n        """Insert or update vectors in the collection"""\n        try:\n            points = []\n            \n            for data in vectors_data:\n                point = PointStruct(\n                    id=data[\'id\'],\n                    vector=data[\'vector\'].tolist() if isinstance(data[\'vector\'], np.ndarray) else data[\'vector\'],\n                    payload=data[\'payload\']\n                )\n                points.append(point)\n            \n            # Batch upsert\n            batch_size = 100\n            for i in range(0, len(points), batch_size):\n                batch = points[i:i + batch_size]\n                self.client.upsert(\n                    collection_name=collection_name,\n                    points=batch\n                )\n            \n            logger.info(f"Upserted {len(points)} vectors to {collection_name}")\n            return True\n            \n        except Exception as e:\n            logger.error(f"Failed to upsert vectors: {e}")\n            return False\n    \n    async def search_vectors(self, \n                            collection_name: str,\n                            query_vector: np.ndarray,\n                            limit: int = 10,\n                            filters: Optional[Filter] = None) -> List[Dict[str, Any]]:\n        """Search for similar vectors"""\n        try:\n            results = self.client.search(\n                collection_name=collection_name,\n                query_vector=query_vector.tolist() if isinstance(query_vector, np.ndarray) else query_vector,\n                query_filter=filters,\n                limit=limit,\n                with_payload=True,\n                with_vectors=False\n            )\n            \n            search_results = []\n            for result in results:\n                search_results.append({\n                    \'id\': result.id,\n                    \'score\': result.score,\n                    \'payload\': result.payload\n                })\n            \n            return search_results\n            \n        except Exception as e:\n            logger.error(f"Search failed: {e}")\n            return []\n    \n    def create_filter(self, filter_conditions: Dict[str, Any]) -> Filter:\n        """Create Qdrant filter from conditions"""\n        conditions = []\n        \n        for field, value in filter_conditions.items():\n            if isinstance(value, list):\n                # Multiple values - use should condition\n                should_conditions = [\n                    FieldCondition(key=field, match=MatchValue(value=v))\n                    for v in value\n                ]\n                conditions.extend(should_conditions)\n            elif isinstance(value, dict) and \'range\' in value:\n                # Range condition\n                range_filter = value[\'range\']\n                conditions.append(\n                    FieldCondition(\n                        key=field,\n                        range=Range(\n                            gte=range_filter.get(\'gte\'),\n                            lte=range_filter.get(\'lte\')\n                        )\n                    )\n                )\n            else:\n                # Exact match\n                conditions.append(\n                    FieldCondition(key=field, match=MatchValue(value=value))\n                )\n        \n        return Filter(must=conditions) if conditions else None\n'})}),"\n",(0,s.jsx)(n.h3,{id:"query-processing-engine",children:"Query Processing Engine"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# retrieval/query_processor.py\nimport re\nimport spacy\nfrom typing import List, Dict, Any, Optional, Set\nimport logging\nfrom datetime import datetime\n\nlogger = logging.getLogger(__name__)\n\nclass QueryProcessor:\n    \"\"\"Advanced query processing for e-commerce search\"\"\"\n    \n    def __init__(self):\n        # Load spaCy model for NLP processing\n        try:\n            self.nlp = spacy.load(\"en_core_web_sm\")\n        except OSError:\n            logger.warning(\"spaCy model not found. Install with: python -m spacy download en_core_web_sm\")\n            self.nlp = None\n        \n        # Product categories and attributes\n        self.categories = {\n            'electronics': ['phone', 'laptop', 'computer', 'tablet', 'camera', 'headphones'],\n            'clothing': ['shirt', 'pants', 'dress', 'shoes', 'jacket', 'jeans'],\n            'home': ['furniture', 'decor', 'kitchen', 'bedroom', 'bathroom'],\n            'books': ['novel', 'textbook', 'fiction', 'non-fiction', 'cookbook'],\n            'sports': ['fitness', 'outdoor', 'gym', 'running', 'cycling']\n        }\n        \n        # Price keywords\n        self.price_keywords = {\n            'cheap': {'range': {'lte': 50}},\n            'affordable': {'range': {'lte': 100}},\n            'budget': {'range': {'lte': 75}},\n            'expensive': {'range': {'gte': 500}},\n            'premium': {'range': {'gte': 300}},\n            'luxury': {'range': {'gte': 1000}}\n        }\n        \n        # Brand extraction patterns\n        self.brand_patterns = [\n            r'\\b(apple|samsung|nike|adidas|sony|microsoft|google)\\b',\n            r'\\b(amazon|dell|hp|lenovo|asus|lg)\\b'\n        ]\n    \n    def process_query(self, query: str, user_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        \"\"\"Process user query and extract structured information\"\"\"\n        logger.info(f\"Processing query: {query}\")\n        \n        # Basic preprocessing\n        query_lower = query.lower().strip()\n        \n        # Extract components\n        processed_query = {\n            'original_query': query,\n            'cleaned_query': self._clean_query(query_lower),\n            'intent': self._detect_intent(query_lower),\n            'entities': self._extract_entities(query_lower),\n            'filters': self._extract_filters(query_lower),\n            'keywords': self._extract_keywords(query_lower),\n            'embedding_text': self._create_embedding_text(query_lower, user_context),\n            'query_expansion': self._expand_query(query_lower),\n            'priority_terms': self._identify_priority_terms(query_lower)\n        }\n        \n        logger.info(f\"Processed query structure: {processed_query}\")\n        return processed_query\n    \n    def _clean_query(self, query: str) -> str:\n        \"\"\"Clean and normalize the query\"\"\"\n        # Remove special characters but keep important ones\n        query = re.sub(r'[^\\w\\s\\-\\$\\.]', ' ', query)\n        \n        # Normalize whitespace\n        query = re.sub(r'\\s+', ' ', query)\n        \n        # Remove common stop words that don't add value\n        stop_words = {'a', 'an', 'the', 'is', 'are', 'was', 'were', 'for', 'with'}\n        words = query.split()\n        words = [word for word in words if word not in stop_words]\n        \n        return ' '.join(words)\n    \n    def _detect_intent(self, query: str) -> str:\n        \"\"\"Detect user intent from query\"\"\"\n        # Define intent patterns\n        intent_patterns = {\n            'specific_product': [r'\\b(buy|purchase|order)\\b', r'\\b(specific|exact)\\b'],\n            'browse_category': [r'\\b(show|browse|look|find)\\b.*\\b(category|type)\\b'],\n            'compare_products': [r'\\b(compare|vs|versus|difference)\\b'],\n            'price_search': [r'\\b(cheap|expensive|price|cost|budget)\\b'],\n            'brand_search': [r'\\b(brand|manufacturer|make)\\b'],\n            'feature_search': [r'\\b(with|having|feature|specification)\\b'],\n            'general_search': [r'.*']  # Default fallback\n        }\n        \n        for intent, patterns in intent_patterns.items():\n            if any(re.search(pattern, query) for pattern in patterns):\n                return intent\n        \n        return 'general_search'\n    \n    def _extract_entities(self, query: str) -> Dict[str, List[str]]:\n        \"\"\"Extract named entities from the query\"\"\"\n        entities = {\n            'products': [],\n            'brands': [],\n            'categories': [],\n            'attributes': [],\n            'price_terms': []\n        }\n        \n        # Extract brands\n        for pattern in self.brand_patterns:\n            matches = re.findall(pattern, query, re.IGNORECASE)\n            entities['brands'].extend(matches)\n        \n        # Extract categories\n        for category, keywords in self.categories.items():\n            if any(keyword in query for keyword in keywords):\n                entities['categories'].append(category)\n                entities['products'].extend([kw for kw in keywords if kw in query])\n        \n        # Extract price terms\n        for price_term in self.price_keywords.keys():\n            if price_term in query:\n                entities['price_terms'].append(price_term)\n        \n        # Use spaCy for additional entity extraction if available\n        if self.nlp:\n            doc = self.nlp(query)\n            for ent in doc.ents:\n                if ent.label_ in ['PRODUCT', 'ORG']:\n                    entities['brands'].append(ent.text)\n        \n        return entities\n    \n    def _extract_filters(self, query: str) -> Dict[str, Any]:\n        \"\"\"Extract filter conditions from query\"\"\"\n        filters = {}\n        \n        # Price filters\n        for price_term, condition in self.price_keywords.items():\n            if price_term in query:\n                filters['price'] = condition\n                break\n        \n        # Extract specific price mentions\n        price_match = re.search(r'\\$?(\\d+(?:\\.\\d{2})?)', query)\n        if price_match:\n            price = float(price_match.group(1))\n            if 'under' in query or 'below' in query:\n                filters['price'] = {'range': {'lte': price}}\n            elif 'over' in query or 'above' in query:\n                filters['price'] = {'range': {'gte': price}}\n            else:\n                # Approximate range around the mentioned price\n                filters['price'] = {'range': {'gte': price * 0.8, 'lte': price * 1.2}}\n        \n        # Category filters\n        entities = self._extract_entities(query)\n        if entities['categories']:\n            filters['category'] = entities['categories']\n        \n        # Brand filters\n        if entities['brands']:\n            filters['brand'] = entities['brands']\n        \n        # Availability filters\n        if any(term in query for term in ['available', 'in stock', 'ready']):\n            filters['is_available'] = True\n        \n        # Rating filters\n        if 'high rated' in query or 'top rated' in query:\n            filters['rating'] = {'range': {'gte': 4.0}}\n        elif 'highly rated' in query:\n            filters['rating'] = {'range': {'gte': 4.5}}\n        \n        return filters\n    \n    def _extract_keywords(self, query: str) -> List[str]:\n        \"\"\"Extract important keywords for search\"\"\"\n        # Basic keyword extraction\n        words = query.split()\n        \n        # Remove common words\n        stop_words = {'for', 'with', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'from'}\n        keywords = [word for word in words if word not in stop_words and len(word) > 2]\n        \n        # Add entity-based keywords\n        entities = self._extract_entities(query)\n        keywords.extend(entities['products'])\n        keywords.extend(entities['brands'])\n        \n        return list(set(keywords))  # Remove duplicates\n    \n    def _create_embedding_text(self, query: str, user_context: Optional[Dict[str, Any]] = None) -> str:\n        \"\"\"Create optimized text for embedding generation\"\"\"\n        text_components = [query]\n        \n        # Add user context if available\n        if user_context:\n            if user_context.get('preferred_categories'):\n                text_components.append(f\"Categories: {', '.join(user_context['preferred_categories'])}\")\n            \n            if user_context.get('preferred_brands'):\n                text_components.append(f\"Brands: {', '.join(user_context['preferred_brands'])}\")\n            \n            if user_context.get('recent_searches'):\n                recent = user_context['recent_searches'][:3]  # Last 3 searches\n                text_components.append(f\"Recent interests: {', '.join(recent)}\")\n        \n        return ' '.join(text_components)\n    \n    def _expand_query(self, query: str) -> List[str]:\n        \"\"\"Expand query with synonyms and related terms\"\"\"\n        # Simple synonym expansion\n        synonyms = {\n            'phone': ['smartphone', 'mobile', 'cellphone'],\n            'laptop': ['notebook', 'computer', 'pc'],\n            'cheap': ['affordable', 'budget', 'inexpensive'],\n            'expensive': ['premium', 'luxury', 'high-end'],\n            'good': ['quality', 'excellent', 'top', 'best']\n        }\n        \n        expanded_terms = [query]\n        words = query.split()\n        \n        for word in words:\n            if word in synonyms:\n                expanded_terms.extend(synonyms[word])\n        \n        return expanded_terms\n    \n    def _identify_priority_terms(self, query: str) -> List[str]:\n        \"\"\"Identify high-priority terms that should have higher weight\"\"\"\n        priority_patterns = [\n            r'\\b(best|top|premium|quality)\\b',\n            r'\\b(need|want|looking for)\\b',\n            r'\\b(brand new|latest|newest)\\b'\n        ]\n        \n        priority_terms = []\n        for pattern in priority_patterns:\n            matches = re.findall(pattern, query)\n            priority_terms.extend(matches)\n        \n        return priority_terms\n"})}),"\n",(0,s.jsx)(n.h3,{id:"retrieval-engine",children:"Retrieval Engine"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# retrieval/retrieval_engine.py\nimport numpy as np\nfrom typing import List, Dict, Any, Optional\nimport logging\nfrom dataclasses import dataclass\nimport asyncio\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass RetrievalResult:\n    \"\"\"Structure for retrieval results\"\"\"\n    product_id: str\n    score: float\n    payload: Dict[str, Any]\n    retrieval_method: str\n    ranking_factors: Dict[str, float]\n\nclass RetrievalEngine:\n    \"\"\"Advanced retrieval engine with multiple search strategies\"\"\"\n    \n    def __init__(self, \n                 vector_db: QdrantVectorDB,\n                 embedding_generator,\n                 query_processor: QueryProcessor):\n        self.vector_db = vector_db\n        self.embedding_generator = embedding_generator\n        self.query_processor = query_processor\n        \n        # Retrieval weights\n        self.retrieval_weights = {\n            'semantic_similarity': 0.6,\n            'category_match': 0.2,\n            'brand_match': 0.1,\n            'price_relevance': 0.05,\n            'popularity': 0.05\n        }\n    \n    async def search(self, \n                    query: str,\n                    user_context: Optional[Dict[str, Any]] = None,\n                    limit: int = 20,\n                    include_filters: bool = True) -> List[RetrievalResult]:\n        \"\"\"Main search interface\"\"\"\n        logger.info(f\"Searching for: {query}\")\n        \n        # Process query\n        processed_query = self.query_processor.process_query(query, user_context)\n        \n        # Multiple retrieval strategies\n        results = await self._multi_stage_retrieval(processed_query, user_context, limit)\n        \n        # Re-rank results\n        ranked_results = self._rerank_results(results, processed_query, user_context)\n        \n        # Apply diversity\n        diverse_results = self._apply_diversity(ranked_results[:limit * 2])\n        \n        return diverse_results[:limit]\n    \n    async def _multi_stage_retrieval(self, \n                                   processed_query: Dict[str, Any],\n                                   user_context: Optional[Dict[str, Any]],\n                                   limit: int) -> List[RetrievalResult]:\n        \"\"\"Multi-stage retrieval with different strategies\"\"\"\n        all_results = []\n        \n        # Stage 1: Semantic vector search\n        semantic_results = await self._semantic_search(processed_query, limit)\n        all_results.extend(semantic_results)\n        \n        # Stage 2: Filtered search (if filters exist)\n        if processed_query['filters']:\n            filtered_results = await self._filtered_search(processed_query, limit)\n            all_results.extend(filtered_results)\n        \n        # Stage 3: User preference-based search\n        if user_context:\n            preference_results = await self._preference_search(processed_query, user_context, limit)\n            all_results.extend(preference_results)\n        \n        # Deduplicate results\n        seen_ids = set()\n        unique_results = []\n        for result in all_results:\n            if result.product_id not in seen_ids:\n                unique_results.append(result)\n                seen_ids.add(result.product_id)\n        \n        return unique_results\n    \n    async def _semantic_search(self, processed_query: Dict[str, Any], limit: int) -> List[RetrievalResult]:\n        \"\"\"Semantic similarity search using vector embeddings\"\"\"\n        try:\n            # Generate query embedding\n            query_text = processed_query['embedding_text']\n            query_embedding = await self.embedding_generator.generate_embeddings([query_text])\n            \n            if len(query_embedding) == 0:\n                return []\n            \n            # Search in vector database\n            search_results = await self.vector_db.search_vectors(\n                collection_name='products',\n                query_vector=query_embedding[0],\n                limit=limit * 2  # Get more results for re-ranking\n            )\n            \n            # Convert to RetrievalResult objects\n            results = []\n            for result in search_results:\n                retrieval_result = RetrievalResult(\n                    product_id=result['id'],\n                    score=result['score'],\n                    payload=result['payload'],\n                    retrieval_method='semantic',\n                    ranking_factors={'semantic_similarity': result['score']}\n                )\n                results.append(retrieval_result)\n            \n            logger.info(f\"Semantic search returned {len(results)} results\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"Semantic search failed: {e}\")\n            return []\n    \n    async def _filtered_search(self, processed_query: Dict[str, Any], limit: int) -> List[RetrievalResult]:\n        \"\"\"Search with specific filters\"\"\"\n        try:\n            filters = self.vector_db.create_filter(processed_query['filters'])\n            \n            # Generate query embedding\n            query_text = processed_query['embedding_text']\n            query_embedding = await self.embedding_generator.generate_embeddings([query_text])\n            \n            if len(query_embedding) == 0:\n                return []\n            \n            # Search with filters\n            search_results = await self.vector_db.search_vectors(\n                collection_name='products',\n                query_vector=query_embedding[0],\n                limit=limit,\n                filters=filters\n            )\n            \n            # Convert to RetrievalResult objects\n            results = []\n            for result in search_results:\n                ranking_factors = {\n                    'semantic_similarity': result['score'],\n                    'filter_match': 1.0  # Perfect filter match\n                }\n                \n                retrieval_result = RetrievalResult(\n                    product_id=result['id'],\n                    score=result['score'],\n                    payload=result['payload'],\n                    retrieval_method='filtered',\n                    ranking_factors=ranking_factors\n                )\n                results.append(retrieval_result)\n            \n            logger.info(f\"Filtered search returned {len(results)} results\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"Filtered search failed: {e}\")\n            return []\n    \n    async def _preference_search(self, \n                               processed_query: Dict[str, Any],\n                               user_context: Dict[str, Any],\n                               limit: int) -> List[RetrievalResult]:\n        \"\"\"Search based on user preferences\"\"\"\n        try:\n            # Create preference-enhanced query\n            preference_filters = {}\n            \n            if user_context.get('preferred_categories'):\n                preference_filters['category'] = user_context['preferred_categories']\n            \n            if user_context.get('preferred_brands'):\n                preference_filters['brand'] = user_context['preferred_brands']\n            \n            if user_context.get('price_range'):\n                preference_filters['price'] = user_context['price_range']\n            \n            if not preference_filters:\n                return []\n            \n            filters = self.vector_db.create_filter(preference_filters)\n            \n            # Generate query embedding\n            query_text = processed_query['embedding_text']\n            query_embedding = await self.embedding_generator.generate_embeddings([query_text])\n            \n            if len(query_embedding) == 0:\n                return []\n            \n            # Search with preference filters\n            search_results = await self.vector_db.search_vectors(\n                collection_name='products',\n                query_vector=query_embedding[0],\n                limit=limit,\n                filters=filters\n            )\n            \n            # Convert to RetrievalResult objects\n            results = []\n            for result in search_results:\n                ranking_factors = {\n                    'semantic_similarity': result['score'],\n                    'preference_match': 0.8  # High preference match\n                }\n                \n                retrieval_result = RetrievalResult(\n                    product_id=result['id'],\n                    score=result['score'],\n                    payload=result['payload'],\n                    retrieval_method='preference',\n                    ranking_factors=ranking_factors\n                )\n                results.append(retrieval_result)\n            \n            logger.info(f\"Preference search returned {len(results)} results\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"Preference search failed: {e}\")\n            return []\n    \n    def _rerank_results(self, \n                       results: List[RetrievalResult],\n                       processed_query: Dict[str, Any],\n                       user_context: Optional[Dict[str, Any]]) -> List[RetrievalResult]:\n        \"\"\"Re-rank results using multiple factors\"\"\"\n        logger.info(f\"Re-ranking {len(results)} results\")\n        \n        for result in results:\n            # Calculate composite score\n            composite_score = 0.0\n            \n            # Semantic similarity\n            semantic_score = result.ranking_factors.get('semantic_similarity', 0.0)\n            composite_score += semantic_score * self.retrieval_weights['semantic_similarity']\n            \n            # Category match\n            category_score = self._calculate_category_score(result, processed_query)\n            composite_score += category_score * self.retrieval_weights['category_match']\n            result.ranking_factors['category_match'] = category_score\n            \n            # Brand match\n            brand_score = self._calculate_brand_score(result, processed_query)\n            composite_score += brand_score * self.retrieval_weights['brand_match']\n            result.ranking_factors['brand_match'] = brand_score\n            \n            # Price relevance\n            price_score = self._calculate_price_score(result, processed_query)\n            composite_score += price_score * self.retrieval_weights['price_relevance']\n            result.ranking_factors['price_relevance'] = price_score\n            \n            # Popularity score\n            popularity_score = self._calculate_popularity_score(result)\n            composite_score += popularity_score * self.retrieval_weights['popularity']\n            result.ranking_factors['popularity'] = popularity_score\n            \n            # User context boost\n            if user_context:\n                context_score = self._calculate_context_score(result, user_context)\n                composite_score += context_score * 0.1\n                result.ranking_factors['context_match'] = context_score\n            \n            result.score = composite_score\n        \n        # Sort by composite score\n        ranked_results = sorted(results, key=lambda x: x.score, reverse=True)\n        \n        logger.info(\"Re-ranking completed\")\n        return ranked_results\n    \n    def _calculate_category_score(self, result: RetrievalResult, processed_query: Dict[str, Any]) -> float:\n        \"\"\"Calculate category match score\"\"\"\n        query_categories = processed_query['entities'].get('categories', [])\n        if not query_categories:\n            return 0.0\n        \n        product_category = result.payload.get('category', '')\n        if product_category in query_categories:\n            return 1.0\n        \n        # Partial match for subcategories\n        product_subcategory = result.payload.get('subcategory', '')\n        if any(cat in product_subcategory.lower() for cat in query_categories):\n            return 0.5\n        \n        return 0.0\n    \n    def _calculate_brand_score(self, result: RetrievalResult, processed_query: Dict[str, Any]) -> float:\n        \"\"\"Calculate brand match score\"\"\"\n        query_brands = processed_query['entities'].get('brands', [])\n        if not query_brands:\n            return 0.0\n        \n        product_brand = result.payload.get('brand', '').lower()\n        for brand in query_brands:\n            if brand.lower() in product_brand:\n                return 1.0\n        \n        return 0.0\n    \n    def _calculate_price_score(self, result: RetrievalResult, processed_query: Dict[str, Any]) -> float:\n        \"\"\"Calculate price relevance score\"\"\"\n        price_filters = processed_query['filters'].get('price')\n        if not price_filters:\n            return 0.5  # Neutral score\n        \n        product_price = result.payload.get('price', 0)\n        \n        if 'range' in price_filters:\n            price_range = price_filters['range']\n            min_price = price_range.get('gte', 0)\n            max_price = price_range.get('lte', float('inf'))\n            \n            if min_price <= product_price <= max_price:\n                return 1.0\n            else:\n                # Calculate how far outside the range\n                if product_price < min_price:\n                    ratio = product_price / min_price\n                elif product_price > max_price:\n                    ratio = max_price / product_price\n                else:\n                    ratio = 1.0\n                \n                return max(0.0, ratio)\n        \n        return 0.5\n    \n    def _calculate_popularity_score(self, result: RetrievalResult) -> float:\n        \"\"\"Calculate product popularity score\"\"\"\n        # Normalize popularity metrics\n        review_count = result.payload.get('review_count', 0)\n        rating = result.payload.get('rating', 0.0)\n        popularity = result.payload.get('popularity_score', 0.0)\n        \n        # Combine metrics\n        review_score = min(1.0, review_count / 100)  # Normalize to 0-1\n        rating_score = rating / 5.0 if rating > 0 else 0\n        popularity_score = min(1.0, popularity / 100)  # Normalize to 0-1\n        \n        return (review_score + rating_score + popularity_score) / 3\n    \n    def _calculate_context_score(self, result: RetrievalResult, user_context: Dict[str, Any]) -> float:\n        \"\"\"Calculate user context match score\"\"\"\n        score = 0.0\n        \n        # Preferred categories\n        preferred_categories = user_context.get('preferred_categories', [])\n        product_category = result.payload.get('category', '')\n        if product_category in preferred_categories:\n            score += 0.5\n        \n        # Preferred brands\n        preferred_brands = user_context.get('preferred_brands', [])\n        product_brand = result.payload.get('brand', '')\n        if product_brand in preferred_brands:\n            score += 0.3\n        \n        # Price range preference\n        preferred_price_range = user_context.get('price_range')\n        if preferred_price_range:\n            product_price = result.payload.get('price', 0)\n            min_price = preferred_price_range.get('min', 0)\n            max_price = preferred_price_range.get('max', float('inf'))\n            \n            if min_price <= product_price <= max_price:\n                score += 0.2\n        \n        return min(1.0, score)\n    \n    def _apply_diversity(self, results: List[RetrievalResult]) -> List[RetrievalResult]:\n        \"\"\"Apply diversity to results to avoid showing too similar products\"\"\"\n        if len(results) <= 5:\n            return results\n        \n        diverse_results = [results[0]]  # Always include top result\n        \n        for result in results[1:]:\n            # Check if result is diverse enough\n            is_diverse = True\n            \n            for existing_result in diverse_results:\n                # Check category diversity\n                if (result.payload.get('category') == existing_result.payload.get('category') and\n                    result.payload.get('subcategory') == existing_result.payload.get('subcategory')):\n                    \n                    # Check if from same brand\n                    if result.payload.get('brand') == existing_result.payload.get('brand'):\n                        is_diverse = False\n                        break\n            \n            if is_diverse:\n                diverse_results.append(result)\n            \n            # Limit diversity checking to avoid performance issues\n            if len(diverse_results) >= 10:\n                break\n        \n        # Fill remaining slots with best remaining results\n        remaining_slots = len(results) - len(diverse_results)\n        if remaining_slots > 0:\n            remaining_results = [r for r in results if r not in diverse_results]\n            diverse_results.extend(remaining_results[:remaining_slots])\n        \n        logger.info(f\"Applied diversity: {len(diverse_results)} results\")\n        return diverse_results\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"caching-strategy",children:"Caching Strategy"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# retrieval/cache_manager.py\nimport redis\nimport json\nimport hashlib\nfrom typing import Dict, Any, Optional, List\nimport logging\nimport pickle\n\nlogger = logging.getLogger(__name__)\n\nclass RetrievalCache:\n    """Cache for retrieval results to improve performance"""\n    \n    def __init__(self, redis_client: redis.Redis):\n        self.redis = redis_client\n        self.cache_ttl = 3600  # 1 hour\n        self.query_cache_ttl = 1800  # 30 minutes\n    \n    def _create_cache_key(self, query: str, filters: Dict[str, Any], user_id: Optional[str] = None) -> str:\n        """Create a unique cache key for the query"""\n        key_data = {\n            \'query\': query,\n            \'filters\': filters,\n            \'user_id\': user_id\n        }\n        \n        key_string = json.dumps(key_data, sort_keys=True)\n        key_hash = hashlib.md5(key_string.encode()).hexdigest()\n        \n        return f"retrieval_cache:{key_hash}"\n    \n    async def get_cached_results(self, \n                               query: str, \n                               filters: Dict[str, Any],\n                               user_id: Optional[str] = None) -> Optional[List[RetrievalResult]]:\n        """Get cached retrieval results"""\n        try:\n            cache_key = self._create_cache_key(query, filters, user_id)\n            cached_data = self.redis.get(cache_key)\n            \n            if cached_data:\n                results_data = pickle.loads(cached_data)\n                logger.info(f"Cache hit for query: {query}")\n                return results_data\n            \n            return None\n            \n        except Exception as e:\n            logger.error(f"Cache retrieval error: {e}")\n            return None\n    \n    async def cache_results(self, \n                          query: str,\n                          filters: Dict[str, Any],\n                          results: List[RetrievalResult],\n                          user_id: Optional[str] = None):\n        """Cache retrieval results"""\n        try:\n            cache_key = self._create_cache_key(query, filters, user_id)\n            results_data = pickle.dumps(results)\n            \n            self.redis.setex(cache_key, self.cache_ttl, results_data)\n            logger.info(f"Cached results for query: {query}")\n            \n        except Exception as e:\n            logger.error(f"Cache storage error: {e}")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"search-api-implementation",children:"Search API Implementation"}),"\n",(0,s.jsx)(n.h3,{id:"rest-api-service",children:"REST API Service"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# api/search_api.py\nfrom fastapi import FastAPI, HTTPException, Depends\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict, Any, Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\napp = FastAPI(title="RAG E-commerce Search API")\n\nclass SearchRequest(BaseModel):\n    query: str = Field(..., description="Search query")\n    limit: int = Field(default=20, ge=1, le=100, description="Number of results")\n    filters: Optional[Dict[str, Any]] = Field(default=None, description="Search filters")\n    user_id: Optional[str] = Field(default=None, description="User ID for personalization")\n\nclass SearchResponse(BaseModel):\n    query: str\n    results: List[Dict[str, Any]]\n    total_results: int\n    search_time: float\n    filters_applied: Dict[str, Any]\n\n# Global retrieval engine instance\nretrieval_engine: Optional[RetrievalEngine] = None\n\ndef get_retrieval_engine() -> RetrievalEngine:\n    """Dependency to get retrieval engine"""\n    if retrieval_engine is None:\n        raise HTTPException(status_code=500, detail="Retrieval engine not initialized")\n    return retrieval_engine\n\n@app.post("/search", response_model=SearchResponse)\nasync def search_products(\n    request: SearchRequest,\n    engine: RetrievalEngine = Depends(get_retrieval_engine)\n) -> SearchResponse:\n    """Search for products using the RAG retrieval system"""\n    try:\n        import time\n        start_time = time.time()\n        \n        # Get user context if user_id provided\n        user_context = None\n        if request.user_id:\n            user_context = await get_user_context(request.user_id)\n        \n        # Perform search\n        results = await engine.search(\n            query=request.query,\n            user_context=user_context,\n            limit=request.limit,\n            include_filters=True\n        )\n        \n        search_time = time.time() - start_time\n        \n        # Format results\n        formatted_results = []\n        for result in results:\n            formatted_result = {\n                \'product_id\': result.product_id,\n                \'score\': result.score,\n                \'product_data\': result.payload,\n                \'retrieval_method\': result.retrieval_method,\n                \'ranking_factors\': result.ranking_factors\n            }\n            formatted_results.append(formatted_result)\n        \n        return SearchResponse(\n            query=request.query,\n            results=formatted_results,\n            total_results=len(formatted_results),\n            search_time=search_time,\n            filters_applied=request.filters or {}\n        )\n        \n    except Exception as e:\n        logger.error(f"Search error: {e}")\n        raise HTTPException(status_code=500, detail=str(e))\n\nasync def get_user_context(user_id: str) -> Optional[Dict[str, Any]]:\n    """Get user context for personalization"""\n    # This would typically fetch from user service or database\n    # Placeholder implementation\n    return {\n        \'preferred_categories\': [\'electronics\', \'books\'],\n        \'preferred_brands\': [\'apple\', \'samsung\'],\n        \'price_range\': {\'min\': 0, \'max\': 1000},\n        \'recent_searches\': [\'laptop\', \'phone case\', \'wireless headphones\']\n    }\n\n@app.get("/health")\nasync def health_check():\n    """Health check endpoint"""\n    return {"status": "healthy", "service": "rag-search-api"}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.p,{children:["Continue to the ",(0,s.jsx)(n.a,{href:"./generation-engine",children:"Generation and Personalization Engine"})," section to build LLM-powered recommendation explanations and personalized content generation."]}),"\n",(0,s.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multi-stage Retrieval"}),": Combine semantic search with filtered and preference-based retrieval"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Query Processing"}),": Advanced NLP processing extracts intent, entities, and filters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Re-ranking"}),": Use multiple factors to improve result relevance"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Diversity"}),": Apply diversity algorithms to avoid repetitive results"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Caching"}),": Implement smart caching to improve performance"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Performance"}),": Optimize vector search and use efficient data structures"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},7814:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>o});var t=r(9729);const s={},i=t.createContext(s);function a(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);