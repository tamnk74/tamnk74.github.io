"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[2679],{5741:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>i});var r=t(9729);const s={},o=r.createContext(s);function a(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(o.Provider,{value:n},e.children)}},9552:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>l,frontMatter:()=>a,metadata:()=>r,toc:()=>u});const r=JSON.parse('{"id":"architecture-practices/architecture-execution/performance-testing","title":"Performance Testing Guide","description":"This guide provides comprehensive performance testing strategies for NestJS microservices and Next.js microfrontend applications, covering load testing, stress testing, performance benchmarking, and automated performance validation in CI/CD pipelines.","source":"@site/docs/architecture-practices/architecture-execution/performance-testing.md","sourceDirName":"architecture-practices/architecture-execution","slug":"/architecture-practices/architecture-execution/performance-testing","permalink":"/fullstack-dev/docs/architecture-practices/architecture-execution/performance-testing","draft":false,"unlisted":false,"editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/docs/architecture-practices/architecture-execution/performance-testing.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Database Migration Management Guide","permalink":"/fullstack-dev/docs/architecture-practices/architecture-execution/database-migrations"},"next":{"title":"Environment Promotion Guide","permalink":"/fullstack-dev/docs/architecture-practices/architecture-execution/environment-promotion"}}');var s=t(5813),o=t(5741);const a={},i="Performance Testing Guide",c={},u=[{value:"Overview",id:"overview",level:2},{value:"Performance Testing Architecture",id:"performance-testing-architecture",level:2},{value:"Complete Testing Pipeline",id:"complete-testing-pipeline",level:3},{value:"Load Testing with K6",id:"load-testing-with-k6",level:2},{value:"K6 Test Scripts",id:"k6-test-scripts",level:3},{value:"Stress Testing Script",id:"stress-testing-script",level:3},{value:"Spike Testing Script",id:"spike-testing-script",level:3},{value:"Frontend Performance Testing",id:"frontend-performance-testing",level:2},{value:"Lighthouse Performance Testing",id:"lighthouse-performance-testing",level:3},{value:"Playwright Performance Testing",id:"playwright-performance-testing",level:3},{value:"Database Performance Testing",id:"database-performance-testing",level:2},{value:"Database Load Testing",id:"database-load-testing",level:3},{value:"CI/CD Integration",id:"cicd-integration",level:2},{value:"Performance Testing Pipeline",id:"performance-testing-pipeline",level:3},{value:"Performance Monitoring Integration",id:"performance-monitoring-integration",level:2},{value:"Performance Metrics Collection",id:"performance-metrics-collection",level:3},{value:"Related Documentation",id:"related-documentation",level:2}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"performance-testing-guide",children:"Performance Testing Guide"})}),"\n",(0,s.jsx)(n.p,{children:"This guide provides comprehensive performance testing strategies for NestJS microservices and Next.js microfrontend applications, covering load testing, stress testing, performance benchmarking, and automated performance validation in CI/CD pipelines."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"Performance testing ensures applications meet performance requirements under various load conditions. This guide covers different types of performance testing, automation strategies, and performance optimization techniques for microservices and microfrontend architectures."}),"\n",(0,s.jsx)(n.h2,{id:"performance-testing-architecture",children:"Performance Testing Architecture"}),"\n",(0,s.jsx)(n.h3,{id:"complete-testing-pipeline",children:"Complete Testing Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    A[Performance Requirements] --\x3e B[Test Planning]\n    B --\x3e C[Test Environment Setup]\n    C --\x3e D[Test Data Preparation]\n    \n    D --\x3e E[Unit Performance Tests]\n    D --\x3e F[Integration Performance Tests]\n    D --\x3e G[Load Tests]\n    D --\x3e H[Stress Tests]\n    D --\x3e I[Spike Tests]\n    D --\x3e J[Volume Tests]\n    \n    E --\x3e K[CI/CD Pipeline]\n    F --\x3e K\n    G --\x3e L[Performance Monitoring]\n    H --\x3e L\n    I --\x3e L\n    J --\x3e L\n    \n    L --\x3e M[Results Analysis]\n    M --\x3e N[Performance Reports]\n    N --\x3e O[Optimization Decisions]\n    O --\x3e P[Performance Tuning]\n    \n    Q[Baseline Establishment] --\x3e R[Performance Comparison]\n    R --\x3e S[Regression Detection]\n    S --\x3e T[Alert Generation]\n    \n    K --\x3e Q\n    N --\x3e R\n"})}),"\n",(0,s.jsx)(n.h2,{id:"load-testing-with-k6",children:"Load Testing with K6"}),"\n",(0,s.jsx)(n.h3,{id:"k6-test-scripts",children:"K6 Test Scripts"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// tests/performance/load-test.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nimport { Rate, Trend, Counter } from 'k6/metrics';\n\n// Custom metrics\nconst errorRate = new Rate('error_rate');\nconst responseTimeP95 = new Trend('response_time_p95');\nconst successfulRequests = new Counter('successful_requests');\nconst failedRequests = new Counter('failed_requests');\n\n// Test configuration\nexport const options = {\n  stages: [\n    { duration: '2m', target: 10 },   // Ramp up to 10 users\n    { duration: '5m', target: 10 },   // Stay at 10 users\n    { duration: '2m', target: 20 },   // Ramp up to 20 users\n    { duration: '5m', target: 20 },   // Stay at 20 users\n    { duration: '2m', target: 50 },   // Ramp up to 50 users\n    { duration: '5m', target: 50 },   // Stay at 50 users\n    { duration: '2m', target: 0 },    // Ramp down to 0 users\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)<2000'], // 95% of requests must be below 2s\n    http_req_failed: ['rate<0.01'],    // Error rate must be below 1%\n    error_rate: ['rate<0.01'],         // Custom error rate\n    response_time_p95: ['p(95)<2000'], // Custom P95 response time\n  },\n};\n\n// Test data\nconst testUsers = [\n  { email: 'user1@example.com', password: 'password123' },\n  { email: 'user2@example.com', password: 'password123' },\n  { email: 'user3@example.com', password: 'password123' },\n];\n\nconst baseUrl = __ENV.BASE_URL || 'http://localhost:3001';\n\n// Authentication helper\nfunction authenticate() {\n  const user = testUsers[Math.floor(Math.random() * testUsers.length)];\n  \n  const loginResponse = http.post(`${baseUrl}/auth/login`, {\n    email: user.email,\n    password: user.password,\n  }, {\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  });\n\n  const loginSuccess = check(loginResponse, {\n    'login status is 200': (r) => r.status === 200,\n    'login response has token': (r) => r.json('access_token') !== undefined,\n  });\n\n  if (loginSuccess) {\n    successfulRequests.add(1);\n    return loginResponse.json('access_token');\n  } else {\n    failedRequests.add(1);\n    errorRate.add(1);\n    return null;\n  }\n}\n\n// Main test scenario\nexport default function () {\n  // Authentication\n  const token = authenticate();\n  if (!token) {\n    return;\n  }\n\n  const headers = {\n    'Authorization': `Bearer ${token}`,\n    'Content-Type': 'application/json',\n  };\n\n  // Test user profile endpoint\n  const profileResponse = http.get(`${baseUrl}/users/profile`, { headers });\n  \n  const profileCheck = check(profileResponse, {\n    'profile status is 200': (r) => r.status === 200,\n    'profile response time < 500ms': (r) => r.timings.duration < 500,\n    'profile has user data': (r) => r.json('id') !== undefined,\n  });\n\n  if (profileCheck) {\n    successfulRequests.add(1);\n    responseTimeP95.add(profileResponse.timings.duration);\n  } else {\n    failedRequests.add(1);\n    errorRate.add(1);\n  }\n\n  // Test product listing endpoint\n  const productsResponse = http.get(`${baseUrl}/products?page=1&limit=20`, { headers });\n  \n  check(productsResponse, {\n    'products status is 200': (r) => r.status === 200,\n    'products response time < 1000ms': (r) => r.timings.duration < 1000,\n    'products has data': (r) => r.json('data') !== undefined,\n  });\n\n  // Test product creation\n  const newProduct = {\n    name: `Test Product ${Math.random()}`,\n    description: 'Test product description',\n    price: Math.floor(Math.random() * 1000) + 10,\n    categoryId: '123e4567-e89b-12d3-a456-426614174000',\n  };\n\n  const createResponse = http.post(`${baseUrl}/products`, JSON.stringify(newProduct), { headers });\n  \n  const createCheck = check(createResponse, {\n    'product creation status is 201': (r) => r.status === 201,\n    'product creation response time < 1500ms': (r) => r.timings.duration < 1500,\n    'created product has id': (r) => r.json('id') !== undefined,\n  });\n\n  if (createCheck) {\n    const productId = createResponse.json('id');\n    \n    // Test product update\n    const updateData = { name: `Updated ${newProduct.name}` };\n    const updateResponse = http.put(`${baseUrl}/products/${productId}`, JSON.stringify(updateData), { headers });\n    \n    check(updateResponse, {\n      'product update status is 200': (r) => r.status === 200,\n      'product update response time < 1000ms': (r) => r.timings.duration < 1000,\n    });\n\n    // Test product deletion\n    const deleteResponse = http.del(`${baseUrl}/products/${productId}`, null, { headers });\n    \n    check(deleteResponse, {\n      'product deletion status is 204': (r) => r.status === 204,\n      'product deletion response time < 500ms': (r) => r.timings.duration < 500,\n    });\n  }\n\n  sleep(1); // Wait 1 second between iterations\n}\n\n// Setup function (runs once before the test)\nexport function setup() {\n  console.log('Starting performance test setup...');\n  \n  // Health check\n  const healthResponse = http.get(`${baseUrl}/health`);\n  if (healthResponse.status !== 200) {\n    throw new Error('Service is not healthy');\n  }\n  \n  console.log('Service health check passed');\n  return { timestamp: new Date().toISOString() };\n}\n\n// Teardown function (runs once after the test)\nexport function teardown(data) {\n  console.log(`Performance test completed at ${new Date().toISOString()}`);\n  console.log(`Test started at ${data.timestamp}`);\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"stress-testing-script",children:"Stress Testing Script"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// tests/performance/stress-test.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nimport { Rate, Trend } from 'k6/metrics';\n\nconst errorRate = new Rate('error_rate');\nconst responseTime = new Trend('response_time');\n\nexport const options = {\n  stages: [\n    { duration: '1m', target: 50 },   // Ramp up to 50 users\n    { duration: '3m', target: 100 },  // Ramp up to 100 users\n    { duration: '3m', target: 200 },  // Ramp up to 200 users\n    { duration: '3m', target: 300 },  // Ramp up to 300 users (stress point)\n    { duration: '5m', target: 300 },  // Stay at 300 users\n    { duration: '3m', target: 400 },  // Push to 400 users (breaking point)\n    { duration: '5m', target: 400 },  // Stay at 400 users\n    { duration: '2m', target: 0 },    // Ramp down\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)<5000'], // Allow higher response times during stress\n    http_req_failed: ['rate<0.05'],    // Allow higher error rate during stress\n    error_rate: ['rate<0.05'],\n  },\n};\n\nconst baseUrl = __ENV.BASE_URL || 'http://localhost:3001';\n\nexport default function () {\n  const response = http.get(`${baseUrl}/products?page=1&limit=50`);\n  \n  const success = check(response, {\n    'status is 200': (r) => r.status === 200,\n    'response time < 5000ms': (r) => r.timings.duration < 5000,\n  });\n\n  if (!success) {\n    errorRate.add(1);\n  }\n  \n  responseTime.add(response.timings.duration);\n  \n  sleep(Math.random() * 2 + 1); // Random sleep between 1-3 seconds\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"spike-testing-script",children:"Spike Testing Script"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// tests/performance/spike-test.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\n\nexport const options = {\n  stages: [\n    { duration: '2m', target: 10 },   // Normal load\n    { duration: '30s', target: 100 }, // Spike to 100 users\n    { duration: '1m', target: 100 },  // Stay at spike\n    { duration: '30s', target: 10 },  // Return to normal\n    { duration: '2m', target: 10 },   // Normal load\n    { duration: '30s', target: 200 }, // Larger spike\n    { duration: '1m', target: 200 },  // Stay at larger spike\n    { duration: '30s', target: 10 },  // Return to normal\n    { duration: '2m', target: 10 },   // Normal load\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)<3000'],\n    http_req_failed: ['rate<0.02'],\n  },\n};\n\nconst baseUrl = __ENV.BASE_URL || 'http://localhost:3001';\n\nexport default function () {\n  const responses = http.batch([\n    ['GET', `${baseUrl}/products`],\n    ['GET', `${baseUrl}/categories`],\n    ['GET', `${baseUrl}/health`],\n  ]);\n\n  for (let i = 0; i < responses.length; i++) {\n    check(responses[i], {\n      'status is 200': (r) => r.status === 200,\n      'response time < 3000ms': (r) => r.timings.duration < 3000,\n    });\n  }\n\n  sleep(1);\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"frontend-performance-testing",children:"Frontend Performance Testing"}),"\n",(0,s.jsx)(n.h3,{id:"lighthouse-performance-testing",children:"Lighthouse Performance Testing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// tests/performance/lighthouse-performance.ts\nimport lighthouse from 'lighthouse';\nimport * as chromeLauncher from 'chrome-launcher';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\ninterface PerformanceMetrics {\n  url: string;\n  timestamp: Date;\n  scores: {\n    performance: number;\n    accessibility: number;\n    bestPractices: number;\n    seo: number;\n  };\n  metrics: {\n    firstContentfulPaint: number;\n    largestContentfulPaint: number;\n    firstInputDelay: number;\n    cumulativeLayoutShift: number;\n    speedIndex: number;\n    timeToInteractive: number;\n  };\n  opportunities: Array<{\n    id: string;\n    title: string;\n    score: number;\n    details: any;\n  }>;\n}\n\nclass LighthousePerformanceTester {\n  private chrome?: chromeLauncher.LaunchedChrome;\n\n  async initialize(): Promise<void> {\n    this.chrome = await chromeLauncher.launch({\n      chromeFlags: ['--headless', '--disable-gpu', '--no-sandbox'],\n    });\n  }\n\n  async runPerformanceTest(url: string): Promise<PerformanceMetrics> {\n    if (!this.chrome) {\n      await this.initialize();\n    }\n\n    const options = {\n      logLevel: 'info' as const,\n      output: 'json' as const,\n      onlyCategories: ['performance', 'accessibility', 'best-practices', 'seo'],\n      port: this.chrome!.port,\n      settings: {\n        preset: 'desktop',\n        throttlingMethod: 'simulate',\n        throttling: {\n          rttMs: 40,\n          throughputKbps: 10240,\n          cpuSlowdownMultiplier: 1,\n        },\n      },\n    };\n\n    const result = await lighthouse(url, options);\n    const lhr = result!.lhr;\n\n    return {\n      url,\n      timestamp: new Date(),\n      scores: {\n        performance: Math.round((lhr.categories.performance?.score || 0) * 100),\n        accessibility: Math.round((lhr.categories.accessibility?.score || 0) * 100),\n        bestPractices: Math.round((lhr.categories['best-practices']?.score || 0) * 100),\n        seo: Math.round((lhr.categories.seo?.score || 0) * 100),\n      },\n      metrics: {\n        firstContentfulPaint: lhr.audits['first-contentful-paint']?.numericValue || 0,\n        largestContentfulPaint: lhr.audits['largest-contentful-paint']?.numericValue || 0,\n        firstInputDelay: lhr.audits['max-potential-fid']?.numericValue || 0,\n        cumulativeLayoutShift: lhr.audits['cumulative-layout-shift']?.numericValue || 0,\n        speedIndex: lhr.audits['speed-index']?.numericValue || 0,\n        timeToInteractive: lhr.audits['interactive']?.numericValue || 0,\n      },\n      opportunities: Object.values(lhr.audits)\n        .filter(audit => audit.scoreDisplayMode === 'numeric' && audit.score !== null && audit.score < 0.9)\n        .map(audit => ({\n          id: audit.id,\n          title: audit.title,\n          score: audit.score || 0,\n          details: audit.details,\n        }))\n        .sort((a, b) => a.score - b.score),\n    };\n  }\n\n  async runPageSpeedTest(urls: string[]): Promise<PerformanceMetrics[]> {\n    const results: PerformanceMetrics[] = [];\n\n    for (const url of urls) {\n      console.log(`Testing ${url}...`);\n      try {\n        const metrics = await this.runPerformanceTest(url);\n        results.push(metrics);\n        \n        // Log key metrics\n        console.log(`Performance Score: ${metrics.scores.performance}`);\n        console.log(`LCP: ${metrics.metrics.largestContentfulPaint}ms`);\n        console.log(`FID: ${metrics.metrics.firstInputDelay}ms`);\n        console.log(`CLS: ${metrics.metrics.cumulativeLayoutShift}`);\n        \n        // Wait between tests\n        await new Promise(resolve => setTimeout(resolve, 2000));\n      } catch (error) {\n        console.error(`Failed to test ${url}:`, error);\n      }\n    }\n\n    return results;\n  }\n\n  async generateReport(results: PerformanceMetrics[], outputPath: string): Promise<void> {\n    const report = {\n      timestamp: new Date().toISOString(),\n      summary: {\n        totalPages: results.length,\n        averagePerformanceScore: results.reduce((sum, r) => sum + r.scores.performance, 0) / results.length,\n        averageAccessibilityScore: results.reduce((sum, r) => sum + r.scores.accessibility, 0) / results.length,\n        pagesBelow90Performance: results.filter(r => r.scores.performance < 90).length,\n        slowestPage: results.reduce((slowest, current) => \n          current.metrics.largestContentfulPaint > slowest.metrics.largestContentfulPaint ? current : slowest\n        ),\n      },\n      details: results,\n      recommendations: this.generateRecommendations(results),\n    };\n\n    await fs.writeFile(outputPath, JSON.stringify(report, null, 2));\n    console.log(`Performance report saved to ${outputPath}`);\n  }\n\n  private generateRecommendations(results: PerformanceMetrics[]): string[] {\n    const recommendations: string[] = [];\n    \n    // Analyze common issues\n    const commonOpportunities = new Map<string, number>();\n    \n    results.forEach(result => {\n      result.opportunities.forEach(opp => {\n        commonOpportunities.set(opp.id, (commonOpportunities.get(opp.id) || 0) + 1);\n      });\n    });\n\n    // Generate recommendations based on frequency\n    const sortedOpportunities = Array.from(commonOpportunities.entries())\n      .sort((a, b) => b[1] - a[1])\n      .slice(0, 5);\n\n    sortedOpportunities.forEach(([opportunityId, count]) => {\n      const percentage = Math.round((count / results.length) * 100);\n      recommendations.push(`${opportunityId} affects ${percentage}% of tested pages`);\n    });\n\n    return recommendations;\n  }\n\n  async cleanup(): Promise<void> {\n    if (this.chrome) {\n      await this.chrome.kill();\n    }\n  }\n}\n\n// Usage example\nexport async function runLighthouseTests(): Promise<void> {\n  const tester = new LighthousePerformanceTester();\n  \n  const urls = [\n    'http://localhost:3000',\n    'http://localhost:3000/products',\n    'http://localhost:3000/profile',\n    'http://localhost:3000/dashboard',\n  ];\n\n  try {\n    const results = await tester.runPageSpeedTest(urls);\n    await tester.generateReport(results, 'lighthouse-report.json');\n    \n    // Check performance thresholds\n    const failedPages = results.filter(r => r.scores.performance < 90);\n    if (failedPages.length > 0) {\n      console.error(`${failedPages.length} pages failed performance threshold`);\n      process.exit(1);\n    }\n  } finally {\n    await tester.cleanup();\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"playwright-performance-testing",children:"Playwright Performance Testing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// tests/performance/playwright-performance.ts\nimport { test, expect, Page } from '@playwright/test';\n\ninterface PerformanceMetrics {\n  navigation: number;\n  firstContentfulPaint: number;\n  largestContentfulPaint: number;\n  domContentLoaded: number;\n  loadComplete: number;\n  resources: Array<{\n    name: string;\n    duration: number;\n    size: number;\n  }>;\n}\n\nasync function collectPerformanceMetrics(page: Page): Promise<PerformanceMetrics> {\n  const performanceData = await page.evaluate(() => {\n    const navigation = performance.getEntriesByType('navigation')[0] as PerformanceNavigationTiming;\n    const paintEntries = performance.getEntriesByType('paint');\n    const resourceEntries = performance.getEntriesByType('resource') as PerformanceResourceTiming[];\n\n    const fcp = paintEntries.find(entry => entry.name === 'first-contentful-paint')?.startTime || 0;\n    const lcp = paintEntries.find(entry => entry.name === 'largest-contentful-paint')?.startTime || 0;\n\n    return {\n      navigation: navigation.loadEventEnd - navigation.navigationStart,\n      firstContentfulPaint: fcp,\n      largestContentfulPaint: lcp,\n      domContentLoaded: navigation.domContentLoadedEventEnd - navigation.navigationStart,\n      loadComplete: navigation.loadEventEnd - navigation.navigationStart,\n      resources: resourceEntries.map(resource => ({\n        name: resource.name,\n        duration: resource.responseEnd - resource.requestStart,\n        size: resource.transferSize || 0,\n      })),\n    };\n  });\n\n  return performanceData;\n}\n\ntest.describe('Frontend Performance Tests', () => {\n  test('Home page should load within performance budget', async ({ page }) => {\n    await page.goto('http://localhost:3000');\n    \n    const metrics = await collectPerformanceMetrics(page);\n    \n    // Performance assertions\n    expect(metrics.navigation).toBeLessThan(3000); // 3 seconds max\n    expect(metrics.firstContentfulPaint).toBeLessThan(1500); // 1.5 seconds max\n    expect(metrics.domContentLoaded).toBeLessThan(2000); // 2 seconds max\n    \n    console.log('Performance Metrics:', metrics);\n  });\n\n  test('Product listing should handle large datasets efficiently', async ({ page }) => {\n    // Navigate to products page\n    await page.goto('http://localhost:3000/products');\n    \n    // Wait for products to load\n    await page.waitForSelector('[data-testid=\"product-list\"]');\n    \n    const metrics = await collectPerformanceMetrics(page);\n    \n    // Check that rendering large lists doesn't block UI\n    expect(metrics.navigation).toBeLessThan(4000);\n    \n    // Test scrolling performance\n    const scrollStart = Date.now();\n    await page.evaluate(() => {\n      window.scrollTo(0, document.body.scrollHeight);\n    });\n    const scrollDuration = Date.now() - scrollStart;\n    \n    expect(scrollDuration).toBeLessThan(100); // Smooth scrolling\n  });\n\n  test('Form submission should be responsive', async ({ page }) => {\n    await page.goto('http://localhost:3000/login');\n    \n    // Measure form interaction performance\n    const interactionStart = Date.now();\n    \n    await page.fill('[data-testid=\"email-input\"]', 'test@example.com');\n    await page.fill('[data-testid=\"password-input\"]', 'password123');\n    \n    const fillDuration = Date.now() - interactionStart;\n    expect(fillDuration).toBeLessThan(500); // Responsive input\n    \n    // Measure form submission\n    const submitStart = Date.now();\n    await page.click('[data-testid=\"submit-button\"]');\n    \n    // Wait for navigation or response\n    await page.waitForURL('**/dashboard');\n    const submitDuration = Date.now() - submitStart;\n    \n    expect(submitDuration).toBeLessThan(2000); // Quick submission\n  });\n\n  test('Bundle size should be within limits', async ({ page }) => {\n    await page.goto('http://localhost:3000');\n    \n    const metrics = await collectPerformanceMetrics(page);\n    \n    // Check JavaScript bundle size\n    const jsResources = metrics.resources.filter(r => r.name.includes('.js'));\n    const totalJSSize = jsResources.reduce((sum, r) => sum + r.size, 0);\n    \n    expect(totalJSSize).toBeLessThan(1024 * 1024); // 1MB max for JS\n    \n    // Check CSS bundle size\n    const cssResources = metrics.resources.filter(r => r.name.includes('.css'));\n    const totalCSSSize = cssResources.reduce((sum, r) => sum + r.size, 0);\n    \n    expect(totalCSSSize).toBeLessThan(256 * 1024); // 256KB max for CSS\n  });\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"database-performance-testing",children:"Database Performance Testing"}),"\n",(0,s.jsx)(n.h3,{id:"database-load-testing",children:"Database Load Testing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// tests/performance/database-performance.ts\nimport { Test } from '@nestjs/testing';\nimport { DataSource } from 'typeorm';\nimport { Performance } from 'perf_hooks';\n\ninterface DatabaseMetrics {\n  operationType: string;\n  duration: number;\n  rowsAffected: number;\n  connectionCount: number;\n  timestamp: Date;\n}\n\nclass DatabasePerformanceTester {\n  private dataSource: DataSource;\n  private metrics: DatabaseMetrics[] = [];\n\n  constructor(dataSource: DataSource) {\n    this.dataSource = dataSource;\n  }\n\n  async testConnectionPool(): Promise<void> {\n    console.log('Testing database connection pool...');\n    \n    const promises: Promise<any>[] = [];\n    const startTime = performance.now();\n    \n    // Simulate concurrent connections\n    for (let i = 0; i < 50; i++) {\n      promises.push(this.performDatabaseOperation('SELECT 1'));\n    }\n    \n    await Promise.all(promises);\n    const duration = performance.now() - startTime;\n    \n    console.log(`50 concurrent connections completed in ${duration}ms`);\n    \n    if (duration > 5000) {\n      throw new Error('Connection pool performance degraded');\n    }\n  }\n\n  async testQueryPerformance(): Promise<void> {\n    console.log('Testing query performance...');\n    \n    // Test simple SELECT\n    await this.performDatabaseOperation('SELECT COUNT(*) FROM users', 'count_users');\n    \n    // Test complex JOIN\n    await this.performDatabaseOperation(`\n      SELECT u.id, u.name, p.title, c.name as category \n      FROM users u \n      LEFT JOIN products p ON u.id = p.created_by \n      LEFT JOIN categories c ON p.category_id = c.id \n      WHERE u.created_at > NOW() - INTERVAL '30 days'\n      ORDER BY u.created_at DESC \n      LIMIT 100\n    `, 'complex_join');\n    \n    // Test aggregation\n    await this.performDatabaseOperation(`\n      SELECT DATE(created_at) as date, COUNT(*) as count \n      FROM products \n      WHERE created_at > NOW() - INTERVAL '30 days' \n      GROUP BY DATE(created_at) \n      ORDER BY date DESC\n    `, 'aggregation');\n    \n    // Analyze results\n    this.metrics.forEach(metric => {\n      console.log(`${metric.operationType}: ${metric.duration}ms`);\n      \n      if (metric.duration > 1000) {\n        console.warn(`Slow query detected: ${metric.operationType}`);\n      }\n    });\n  }\n\n  async testInsertPerformance(): Promise<void> {\n    console.log('Testing bulk insert performance...');\n    \n    const batchSizes = [100, 500, 1000, 2000];\n    \n    for (const batchSize of batchSizes) {\n      const startTime = performance.now();\n      \n      // Generate test data\n      const testData = Array.from({ length: batchSize }, (_, i) => ({\n        name: `Test Product ${i}`,\n        description: `Description for test product ${i}`,\n        price: Math.floor(Math.random() * 1000) + 10,\n        category_id: '123e4567-e89b-12d3-a456-426614174000',\n      }));\n      \n      // Bulk insert\n      await this.dataSource.query(`\n        INSERT INTO products (name, description, price, category_id) \n        VALUES ${testData.map(() => '(?, ?, ?, ?)').join(', ')}\n      `, testData.flatMap(item => [item.name, item.description, item.price, item.category_id]));\n      \n      const duration = performance.now() - startTime;\n      \n      console.log(`Batch insert ${batchSize} records: ${duration}ms (${(batchSize / (duration / 1000)).toFixed(0)} records/sec)`);\n      \n      // Clean up test data\n      await this.dataSource.query('DELETE FROM products WHERE name LIKE ?', ['Test Product %']);\n    }\n  }\n\n  async testUpdatePerformance(): Promise<void> {\n    console.log('Testing update performance...');\n    \n    // Create test data\n    const testProductIds: string[] = [];\n    for (let i = 0; i < 1000; i++) {\n      const result = await this.dataSource.query(`\n        INSERT INTO products (name, description, price, category_id) \n        VALUES (?, ?, ?, ?) \n        RETURNING id\n      `, [`Test Product ${i}`, `Description ${i}`, 100, '123e4567-e89b-12d3-a456-426614174000']);\n      \n      testProductIds.push(result[0].id);\n    }\n    \n    // Test single record updates\n    const singleUpdateStart = performance.now();\n    for (let i = 0; i < 100; i++) {\n      await this.dataSource.query('UPDATE products SET price = ? WHERE id = ?', [200, testProductIds[i]]);\n    }\n    const singleUpdateDuration = performance.now() - singleUpdateStart;\n    console.log(`100 single updates: ${singleUpdateDuration}ms`);\n    \n    // Test bulk update\n    const bulkUpdateStart = performance.now();\n    await this.dataSource.query(`\n      UPDATE products \n      SET price = 300 \n      WHERE id IN (${testProductIds.slice(100, 200).map(() => '?').join(', ')})\n    `, testProductIds.slice(100, 200));\n    const bulkUpdateDuration = performance.now() - bulkUpdateStart;\n    console.log(`100 bulk update: ${bulkUpdateDuration}ms`);\n    \n    // Clean up\n    await this.dataSource.query(`\n      DELETE FROM products \n      WHERE id IN (${testProductIds.map(() => '?').join(', ')})\n    `, testProductIds);\n  }\n\n  private async performDatabaseOperation(query: string, operationType = 'generic'): Promise<void> {\n    const startTime = performance.now();\n    const connectionsBefore = await this.getConnectionCount();\n    \n    try {\n      const result = await this.dataSource.query(query);\n      const duration = performance.now() - startTime;\n      const connectionsAfter = await this.getConnectionCount();\n      \n      this.metrics.push({\n        operationType,\n        duration,\n        rowsAffected: Array.isArray(result) ? result.length : 1,\n        connectionCount: connectionsAfter,\n        timestamp: new Date(),\n      });\n    } catch (error) {\n      console.error(`Database operation failed: ${operationType}`, error);\n      throw error;\n    }\n  }\n\n  private async getConnectionCount(): Promise<number> {\n    try {\n      const result = await this.dataSource.query(`\n        SELECT count(*) as count \n        FROM pg_stat_activity \n        WHERE state = 'active'\n      `);\n      return parseInt(result[0].count);\n    } catch {\n      return 0;\n    }\n  }\n\n  generateReport(): any {\n    const report = {\n      timestamp: new Date().toISOString(),\n      totalOperations: this.metrics.length,\n      averageDuration: this.metrics.reduce((sum, m) => sum + m.duration, 0) / this.metrics.length,\n      slowestOperation: this.metrics.reduce((slowest, current) => \n        current.duration > slowest.duration ? current : slowest\n      ),\n      operationBreakdown: this.metrics.reduce((breakdown, metric) => {\n        if (!breakdown[metric.operationType]) {\n          breakdown[metric.operationType] = {\n            count: 0,\n            totalDuration: 0,\n            averageDuration: 0,\n          };\n        }\n        breakdown[metric.operationType].count++;\n        breakdown[metric.operationType].totalDuration += metric.duration;\n        breakdown[metric.operationType].averageDuration = \n          breakdown[metric.operationType].totalDuration / breakdown[metric.operationType].count;\n        return breakdown;\n      }, {} as any),\n    };\n\n    return report;\n  }\n}\n\n// Usage in tests\ndescribe('Database Performance', () => {\n  let tester: DatabasePerformanceTester;\n  let dataSource: DataSource;\n\n  beforeAll(async () => {\n    // Setup test database connection\n    dataSource = new DataSource({\n      type: 'postgres',\n      host: process.env.TEST_DB_HOST,\n      port: parseInt(process.env.TEST_DB_PORT || '5432'),\n      username: process.env.TEST_DB_USER,\n      password: process.env.TEST_DB_PASS,\n      database: process.env.TEST_DB_NAME,\n      synchronize: true,\n      entities: ['src/**/*.entity.ts'],\n    });\n    \n    await dataSource.initialize();\n    tester = new DatabasePerformanceTester(dataSource);\n  });\n\n  afterAll(async () => {\n    await dataSource.destroy();\n  });\n\n  test('Connection pool performance', async () => {\n    await tester.testConnectionPool();\n  });\n\n  test('Query performance', async () => {\n    await tester.testQueryPerformance();\n  });\n\n  test('Insert performance', async () => {\n    await tester.testInsertPerformance();\n  });\n\n  test('Update performance', async () => {\n    await tester.testUpdatePerformance();\n  });\n\n  test('Generate performance report', () => {\n    const report = tester.generateReport();\n    console.log('Database Performance Report:', JSON.stringify(report, null, 2));\n    \n    // Assert performance thresholds\n    expect(report.averageDuration).toBeLessThan(500); // 500ms average\n    expect(report.slowestOperation.duration).toBeLessThan(2000); // 2s max\n  });\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"cicd-integration",children:"CI/CD Integration"}),"\n",(0,s.jsx)(n.h3,{id:"performance-testing-pipeline",children:"Performance Testing Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"# .github/workflows/performance-tests.yml\nname: Performance Tests\n\non:\n  schedule:\n    - cron: '0 2 * * *' # Daily at 2 AM\n  workflow_dispatch:\n    inputs:\n      test_type:\n        description: 'Type of performance test'\n        required: true\n        default: 'load'\n        type: choice\n        options:\n        - load\n        - stress\n        - spike\n        - endurance\n\njobs:\n  performance-tests:\n    runs-on: ubuntu-latest\n    \n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: testdb\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n      \n      redis:\n        image: redis:7\n        options: >-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n    - name: Checkout\n      uses: actions/checkout@v4\n\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '18'\n        cache: 'npm'\n\n    - name: Install dependencies\n      run: npm ci\n\n    - name: Build application\n      run: npm run build\n\n    - name: Start application\n      run: |\n        npm run start:prod &\n        sleep 30 # Wait for application to start\n      env:\n        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb\n        REDIS_URL: redis://localhost:6379\n\n    - name: Wait for application to be ready\n      run: |\n        timeout 60 bash -c 'until curl -f http://localhost:3000/health; do sleep 2; done'\n\n    - name: Install K6\n      run: |\n        sudo gpg -k\n        sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69\n        echo \"deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main\" | sudo tee /etc/apt/sources.list.d/k6.list\n        sudo apt-get update\n        sudo apt-get install k6\n\n    - name: Run load tests\n      if: ${{ github.event.inputs.test_type == 'load' || github.event.inputs.test_type == '' }}\n      run: k6 run tests/performance/load-test.js\n      env:\n        BASE_URL: http://localhost:3000\n\n    - name: Run stress tests\n      if: ${{ github.event.inputs.test_type == 'stress' }}\n      run: k6 run tests/performance/stress-test.js\n      env:\n        BASE_URL: http://localhost:3000\n\n    - name: Run spike tests\n      if: ${{ github.event.inputs.test_type == 'spike' }}\n      run: k6 run tests/performance/spike-test.js\n      env:\n        BASE_URL: http://localhost:3000\n\n    - name: Run frontend performance tests\n      run: npm run test:performance:frontend\n\n    - name: Run database performance tests\n      run: npm run test:performance:database\n      env:\n        TEST_DB_HOST: localhost\n        TEST_DB_PORT: 5432\n        TEST_DB_USER: postgres\n        TEST_DB_PASS: postgres\n        TEST_DB_NAME: testdb\n\n    - name: Generate performance report\n      run: |\n        node scripts/generate-performance-report.js\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n    - name: Upload performance results\n      uses: actions/upload-artifact@v3\n      with:\n        name: performance-results\n        path: |\n          performance-report.json\n          lighthouse-report.json\n          k6-results.json\n\n    - name: Comment PR with results\n      if: github.event_name == 'pull_request'\n      uses: actions/github-script@v6\n      with:\n        script: |\n          const fs = require('fs');\n          const report = JSON.parse(fs.readFileSync('performance-report.json', 'utf8'));\n          \n          const comment = `\n          ## \ud83d\udcca Performance Test Results\n          \n          **Load Test Summary:**\n          - Average Response Time: ${report.averageResponseTime}ms\n          - 95th Percentile: ${report.p95ResponseTime}ms\n          - Error Rate: ${report.errorRate}%\n          - Requests/Second: ${report.requestsPerSecond}\n          \n          **Frontend Performance:**\n          - Performance Score: ${report.lighthouseScore}/100\n          - Largest Contentful Paint: ${report.lcp}ms\n          - First Input Delay: ${report.fid}ms\n          \n          ${report.hasRegressions ? '\u26a0\ufe0f Performance regressions detected!' : '\u2705 All performance thresholds met'}\n          `;\n          \n          github.rest.issues.createComment({\n            issue_number: context.issue.number,\n            owner: context.repo.owner,\n            repo: context.repo.repo,\n            body: comment\n          });\n\n    - name: Fail if performance thresholds not met\n      run: |\n        if [ -f performance-failures.txt ]; then\n          echo \"Performance thresholds not met:\"\n          cat performance-failures.txt\n          exit 1\n        fi\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-monitoring-integration",children:"Performance Monitoring Integration"}),"\n",(0,s.jsx)(n.h3,{id:"performance-metrics-collection",children:"Performance Metrics Collection"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// src/monitoring/performance-monitoring.service.ts\nimport { Injectable, Logger } from '@nestjs/common';\nimport { Interval } from '@nestjs/schedule';\nimport { PrometheusService } from './prometheus.service';\nimport { Histogram, Counter, Gauge } from 'prom-client';\n\n@Injectable()\nexport class PerformanceMonitoringService {\n  private readonly logger = new Logger(PerformanceMonitoringService.name);\n  \n  private readonly responseTimeHistogram: Histogram<string>;\n  private readonly throughputCounter: Counter<string>;\n  private readonly activeUsersGauge: Gauge<string>;\n  private readonly errorRateCounter: Counter<string>;\n\n  constructor(private readonly prometheusService: PrometheusService) {\n    this.responseTimeHistogram = new Histogram({\n      name: 'http_request_duration_seconds',\n      help: 'Duration of HTTP requests in seconds',\n      labelNames: ['method', 'route', 'status_code'],\n      buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10],\n      registers: [this.prometheusService.getRegistry()],\n    });\n\n    this.throughputCounter = new Counter({\n      name: 'http_requests_total',\n      help: 'Total number of HTTP requests',\n      labelNames: ['method', 'route', 'status_code'],\n      registers: [this.prometheusService.getRegistry()],\n    });\n\n    this.activeUsersGauge = new Gauge({\n      name: 'active_users_total',\n      help: 'Number of active users',\n      registers: [this.prometheusService.getRegistry()],\n    });\n\n    this.errorRateCounter = new Counter({\n      name: 'http_request_errors_total',\n      help: 'Total number of HTTP request errors',\n      labelNames: ['method', 'route', 'error_type'],\n      registers: [this.prometheusService.getRegistry()],\n    });\n  }\n\n  recordRequestMetrics(\n    method: string,\n    route: string,\n    statusCode: number,\n    duration: number\n  ): void {\n    this.responseTimeHistogram\n      .labels(method, route, statusCode.toString())\n      .observe(duration / 1000); // Convert to seconds\n\n    this.throughputCounter\n      .labels(method, route, statusCode.toString())\n      .inc();\n\n    if (statusCode >= 400) {\n      this.errorRateCounter\n        .labels(method, route, statusCode >= 500 ? 'server_error' : 'client_error')\n        .inc();\n    }\n  }\n\n  @Interval(60000) // Every minute\n  async collectSystemMetrics(): Promise<void> {\n    try {\n      // Collect active users (example implementation)\n      const activeUsers = await this.getActiveUsersCount();\n      this.activeUsersGauge.set(activeUsers);\n\n      // Additional metrics collection can be added here\n    } catch (error) {\n      this.logger.error('Failed to collect system metrics', error);\n    }\n  }\n\n  private async getActiveUsersCount(): Promise<number> {\n    // Implementation would depend on your authentication system\n    // This is a placeholder\n    return Math.floor(Math.random() * 100);\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"related-documentation",children:"Related Documentation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/fullstack-dev/docs/architecture-practices/architecture-execution/application-monitoring",children:"Application Performance Monitoring"})})," - Real-time performance monitoring"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/fullstack-dev/docs/architecture-practices/architecture-execution/infrastructure-monitoring",children:"Infrastructure Monitoring"})})," - System-level performance metrics"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/fullstack-dev/docs/architecture-practices/architecture-execution/cicd-pipeline",children:"CI/CD Pipeline"})})," - Integration with deployment pipeline"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:"This performance testing guide should be regularly updated to incorporate new testing tools and methodologies."})]})}function l(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}}}]);