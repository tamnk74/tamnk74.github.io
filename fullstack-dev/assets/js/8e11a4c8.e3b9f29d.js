"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[9270],{9718:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"rag-ecommerce-recommendations-part1-introduction","metadata":{"permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part1-introduction","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-08-rag-ecommerce-recommendations-part1-introduction.md","source":"@site/blog/2025-10-08-rag-ecommerce-recommendations-part1-introduction.md","title":"Building Intelligent E-commerce Recommendations with RAG: Part 1 - Introduction and Architecture Overview","description":"Modern e-commerce platforms generate billions of interactions daily, creating vast amounts of unstructured data including product descriptions, user reviews, browsing patterns, and purchase histories. Traditional recommendation systems, while effective, often struggle to understand the nuanced context and semantic relationships within this data. Enter Retrieval-Augmented Generation (RAG) - a revolutionary approach that combines the power of large language models with dynamic information retrieval to create more intelligent, context-aware recommendation systems.","date":"2025-10-08T00:00:00.000Z","tags":[{"inline":false,"label":"RAG","permalink":"/fullstack-dev/blog/tags/rag","description":"Retrieval-Augmented Generation"},{"inline":false,"label":"E-commerce","permalink":"/fullstack-dev/blog/tags/ecommerce","description":"E-commerce development and strategies"},{"inline":false,"label":"Recommendations","permalink":"/fullstack-dev/blog/tags/recommendations","description":"Recommendation systems and algorithms"},{"inline":false,"label":"Artificial Intelligence","permalink":"/fullstack-dev/blog/tags/ai","description":"Artificial intelligence and AI applications"},{"inline":false,"label":"Machine Learning","permalink":"/fullstack-dev/blog/tags/machine-learning","description":"Machine learning and AI applications"},{"inline":false,"label":"Vector Databases","permalink":"/fullstack-dev/blog/tags/vector-databases","description":"Vector database systems"},{"inline":false,"label":"Large Language Models","permalink":"/fullstack-dev/blog/tags/llm","description":"Large language models and applications"},{"inline":false,"label":"Architecture","permalink":"/fullstack-dev/blog/tags/architecture","description":"Software architecture and design patterns"}],"readingTime":7.82,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"rag-ecommerce-recommendations-part1-introduction","title":"Building Intelligent E-commerce Recommendations with RAG: Part 1 - Introduction and Architecture Overview","authors":["tam"],"tags":["rag","ecommerce","recommendations","ai","machine-learning","vector-databases","llm","architecture"],"date":"2025-10-08T00:00:00.000Z"},"unlisted":false,"nextItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 2 - Data Pipeline and Vector Embeddings","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part2-data-pipeline-embeddings"}},"content":"Modern e-commerce platforms generate billions of interactions daily, creating vast amounts of unstructured data including product descriptions, user reviews, browsing patterns, and purchase histories. Traditional recommendation systems, while effective, often struggle to understand the nuanced context and semantic relationships within this data. Enter Retrieval-Augmented Generation (RAG) - a revolutionary approach that combines the power of large language models with dynamic information retrieval to create more intelligent, context-aware recommendation systems.\\n\\nThis comprehensive series will guide you through building a sophisticated e-commerce recommendation system using RAG technology, covering everything from architectural design to production deployment.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why RAG for E-commerce Recommendations?\\n\\n### \ud83e\udde0 **Understanding Context and Intent**\\nTraditional collaborative filtering and content-based systems analyze patterns and similarities but often miss the subtle nuances of user intent. RAG systems can:\\n\\n- **Understand natural language queries**: \\"Show me comfortable running shoes for winter marathons\\"\\n- **Process complex product relationships**: Understanding that \\"wireless earbuds with noise cancellation\\" relates to \\"productivity\\" and \\"commuting\\"\\n- **Capture seasonal and temporal context**: Recommending products based on current trends and seasonal relevance\\n\\n### \ud83c\udfaf **Personalization at Scale**\\nRAG enables unprecedented personalization by:\\n\\n- **Dynamic content generation**: Creating personalized product descriptions and recommendations\\n- **Multi-modal understanding**: Processing text, images, and user behavior simultaneously\\n- **Real-time adaptation**: Adjusting recommendations based on immediate context and user feedback\\n\\n### \ud83d\udd04 **Continuous Learning**\\nUnlike static models, RAG systems continuously improve by:\\n\\n- **Incorporating fresh data**: New products, reviews, and trends are immediately available\\n- **Learning from interactions**: User feedback directly improves future recommendations\\n- **Adapting to market changes**: Seasonal trends, new categories, and emerging products\\n\\n## Series Overview\\n\\nThis 5-part series will take you from concept to production:\\n\\n### **Part 1: Introduction and Architecture Overview** (This Post)\\n- RAG fundamentals for e-commerce\\n- System architecture and components\\n- Technology stack selection\\n- Data flow and processing pipeline\\n\\n### **Part 2: Data Pipeline and Vector Embeddings**\\n- Product catalog processing\\n- User behavior tracking\\n- Vector embedding generation\\n- Database design and optimization\\n\\n### **Part 3: Retrieval System Implementation**\\n- Vector database setup (Pinecone, Weaviate, Qdrant)\\n- Semantic search implementation\\n- Hybrid search strategies\\n- Performance optimization\\n\\n### **Part 4: Generation and Personalization Engine**\\n- LLM integration (OpenAI, Anthropic, Local models)\\n- Prompt engineering for recommendations\\n- Personalization algorithms\\n- A/B testing framework\\n\\n### **Part 5: Production Deployment and Monitoring**\\n- Scaling strategies\\n- Performance monitoring\\n- Cost optimization\\n- Continuous improvement\\n\\n## Architecture Overview\\n\\nLet\'s explore the high-level architecture of our RAG-powered recommendation system:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                           User Interface Layer                      \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   Web App   \u2502  \u2502 Mobile App  \u2502  \u2502   API      \u2502  \u2502   Admin     \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                       API Gateway & Load Balancer                   \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                     Recommendation Engine                           \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\\n\u2502  \u2502   Query         \u2502  \u2502   Retrieval     \u2502  \u2502   Generation    \u2502     \u2502\\n\u2502  \u2502   Processing    \u2502  \u2502   Engine        \u2502  \u2502   Engine        \u2502     \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                         Data Layer                                  \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   Vector    \u2502  \u2502 Product     \u2502  \u2502   User      \u2502  \u2502   Cache     \u2502 \u2502\\n\u2502  \u2502  Database   \u2502  \u2502 Database    \u2502  \u2502  Database   \u2502  \u2502   Layer     \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                     Data Processing Pipeline                        \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   Data      \u2502  \u2502 Embedding   \u2502  \u2502   Feature   \u2502  \u2502   Model     \u2502 \u2502\\n\u2502  \u2502 Ingestion   \u2502  \u2502 Generation  \u2502  \u2502 Engineering \u2502  \u2502  Training   \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## Core Components Deep Dive\\n\\n### 1. **Query Processing Layer**\\n\\nThe entry point for all recommendation requests, responsible for:\\n\\n```typescript\\ninterface QueryProcessor {\\n  // Parse and understand user intent\\n  parseUserQuery(query: string): ParsedQuery;\\n  \\n  // Extract contextual information\\n  extractContext(userId: string, sessionData: SessionContext): UserContext;\\n  \\n  // Generate search parameters\\n  generateSearchParams(query: ParsedQuery, context: UserContext): SearchParams;\\n}\\n\\ninterface ParsedQuery {\\n  intent: \'browse\' | \'search\' | \'compare\' | \'recommendation\';\\n  categories: string[];\\n  filters: ProductFilter[];\\n  sentiment: \'positive\' | \'neutral\' | \'negative\';\\n  urgency: \'low\' | \'medium\' | \'high\';\\n}\\n\\ninterface UserContext {\\n  userId: string;\\n  demographics: UserDemographics;\\n  purchaseHistory: Purchase[];\\n  browsingBehavior: BrowsingSession[];\\n  preferences: UserPreferences;\\n  currentSession: SessionContext;\\n}\\n```\\n\\n**Key Responsibilities:**\\n- Natural language query understanding\\n- Intent classification and entity extraction\\n- Context enrichment with user data\\n- Query optimization for downstream components\\n\\n### 2. **Retrieval Engine**\\n\\nThe core of our RAG system, implementing hybrid search strategies:\\n\\n```typescript\\ninterface RetrievalEngine {\\n  // Semantic search using vector embeddings\\n  semanticSearch(query: string, filters: SearchFilters): Promise<Product[]>;\\n  \\n  // Traditional keyword-based search\\n  keywordSearch(query: string, filters: SearchFilters): Promise<Product[]>;\\n  \\n  // Hybrid search combining both approaches\\n  hybridSearch(params: SearchParams): Promise<SearchResult[]>;\\n  \\n  // Collaborative filtering recommendations\\n  collaborativeFilter(userId: string, context: UserContext): Promise<Product[]>;\\n}\\n\\ninterface SearchResult {\\n  product: Product;\\n  relevanceScore: number;\\n  searchType: \'semantic\' | \'keyword\' | \'collaborative\';\\n  explanation: string;\\n}\\n```\\n\\n**Search Strategies:**\\n- **Semantic Search**: Vector similarity using embeddings\\n- **Keyword Search**: Traditional full-text search with BM25\\n- **Collaborative Filtering**: User-based and item-based recommendations\\n- **Hybrid Ranking**: Combining multiple signals for optimal results\\n\\n### 3. **Generation Engine**\\n\\nTransforms retrieved products into personalized recommendations:\\n\\n```typescript\\ninterface GenerationEngine {\\n  // Generate personalized recommendations\\n  generateRecommendations(\\n    products: Product[], \\n    userContext: UserContext,\\n    generationParams: GenerationParams\\n  ): Promise<Recommendation[]>;\\n  \\n  // Create explanations for recommendations\\n  generateExplanations(\\n    recommendation: Recommendation,\\n    userContext: UserContext\\n  ): Promise<string>;\\n  \\n  // Generate product comparisons\\n  generateComparison(\\n    products: Product[],\\n    comparisonCriteria: string[]\\n  ): Promise<ProductComparison>;\\n}\\n\\ninterface Recommendation {\\n  product: Product;\\n  score: number;\\n  reasoning: string;\\n  personalizationFactors: PersonalizationFactor[];\\n  confidence: number;\\n}\\n\\ninterface PersonalizationFactor {\\n  type: \'purchase_history\' | \'browsing_behavior\' | \'demographics\' | \'seasonal\';\\n  weight: number;\\n  explanation: string;\\n}\\n```\\n\\n## Technology Stack Selection\\n\\n### **Vector Databases**\\n\\n| Database | Best For | Pros | Cons |\\n|----------|----------|------|------|\\n| **Pinecone** | Production scale | Managed service, excellent performance | Cost, vendor lock-in |\\n| **Weaviate** | Complex schemas | GraphQL API, multi-modal support | Learning curve |\\n| **Qdrant** | Self-hosted | Open source, Rust performance | Operational overhead |\\n| **Chroma** | Development | Easy setup, Python native | Limited production features |\\n\\n**Recommendation**: Start with **Qdrant** for development and **Pinecone** for production.\\n\\n### **Language Models**\\n\\n| Model | Best For | Pros | Cons |\\n|-------|----------|------|------|\\n| **OpenAI GPT-4** | High-quality generation | Excellent reasoning, API ease | Cost, latency |\\n| **Anthropic Claude** | Safety-focused | Strong reasoning, less hallucination | Rate limits |\\n| **Local Models** | Privacy/cost | Data control, no API costs | Infrastructure complexity |\\n| **Azure OpenAI** | Enterprise | Enterprise features, compliance | Microsoft ecosystem |\\n\\n**Recommendation**: **OpenAI GPT-4** for prototyping, **Local models** for production scale.\\n\\n### **Embedding Models**\\n\\n```typescript\\ninterface EmbeddingService {\\n  generateProductEmbedding(product: Product): Promise<number[]>;\\n  generateQueryEmbedding(query: string): Promise<number[]>;\\n  generateUserEmbedding(userContext: UserContext): Promise<number[]>;\\n}\\n\\n// Popular embedding models\\nconst EMBEDDING_MODELS = {\\n  \'text-embedding-ada-002\': {\\n    dimensions: 1536,\\n    cost: \'low\',\\n    quality: \'high\',\\n    provider: \'openai\'\\n  },\\n  \'all-MiniLM-L6-v2\': {\\n    dimensions: 384,\\n    cost: \'free\',\\n    quality: \'medium\',\\n    provider: \'sentence-transformers\'\\n  },\\n  \'text-embedding-3-large\': {\\n    dimensions: 3072,\\n    cost: \'medium\',\\n    quality: \'highest\',\\n    provider: \'openai\'\\n  }\\n};\\n```\\n\\n## Data Flow Architecture\\n\\n### **Real-time Recommendation Flow**\\n\\n```mermaid\\nsequenceDiagram\\n    participant User\\n    participant API\\n    participant QueryProcessor\\n    participant RetrievalEngine\\n    participant VectorDB\\n    participant GenerationEngine\\n    participant LLM\\n    participant Cache\\n\\n    User->>API: Request recommendations\\n    API->>QueryProcessor: Parse query + context\\n    QueryProcessor->>RetrievalEngine: Search parameters\\n    RetrievalEngine->>VectorDB: Vector similarity search\\n    VectorDB--\x3e>RetrievalEngine: Candidate products\\n    RetrievalEngine->>GenerationEngine: Retrieved products\\n    GenerationEngine->>LLM: Generate personalized recommendations\\n    LLM--\x3e>GenerationEngine: Recommendation content\\n    GenerationEngine->>Cache: Store results\\n    GenerationEngine--\x3e>API: Personalized recommendations\\n    API--\x3e>User: Recommendation response\\n```\\n\\n### **Batch Processing Pipeline**\\n\\n```typescript\\ninterface BatchProcessor {\\n  // Daily product catalog updates\\n  processProductUpdates(): Promise<void>;\\n  \\n  // Weekly user behavior analysis\\n  updateUserProfiles(): Promise<void>;\\n  \\n  // Monthly model retraining\\n  retrainModels(): Promise<void>;\\n  \\n  // Real-time event processing\\n  processUserEvent(event: UserEvent): Promise<void>;\\n}\\n\\ninterface UserEvent {\\n  userId: string;\\n  eventType: \'view\' | \'click\' | \'purchase\' | \'cart_add\' | \'search\';\\n  productId?: string;\\n  searchQuery?: string;\\n  timestamp: Date;\\n  metadata: Record<string, any>;\\n}\\n```\\n\\n## Performance Considerations\\n\\n### **Latency Optimization**\\n\\n```typescript\\nclass PerformanceOptimizer {\\n  async optimizeRetrieval(query: SearchParams): Promise<SearchResult[]> {\\n    // Parallel search strategies\\n    const [semanticResults, keywordResults, collaborativeResults] = \\n      await Promise.all([\\n        this.semanticSearch(query),\\n        this.keywordSearch(query),\\n        this.collaborativeFilter(query.userId)\\n      ]);\\n\\n    // Fast result merging\\n    return this.mergeResults(semanticResults, keywordResults, collaborativeResults);\\n  }\\n\\n  async cacheStrategy(userId: string, query: string): Promise<Recommendation[]> {\\n    const cacheKey = `recommendations:${userId}:${hash(query)}`;\\n    \\n    // Check cache first\\n    const cached = await this.cache.get(cacheKey);\\n    if (cached && !this.isStale(cached)) {\\n      return cached;\\n    }\\n\\n    // Generate fresh recommendations\\n    const recommendations = await this.generateRecommendations(userId, query);\\n    \\n    // Cache with appropriate TTL\\n    await this.cache.set(cacheKey, recommendations, this.getTTL(query));\\n    \\n    return recommendations;\\n  }\\n}\\n```\\n\\n### **Scalability Patterns**\\n\\n```typescript\\ninterface ScalabilityConfig {\\n  // Horizontal scaling parameters\\n  maxConcurrentRequests: number;\\n  vectorDBShards: number;\\n  embeddingBatchSize: number;\\n  \\n  // Performance thresholds\\n  maxLatency: number; // milliseconds\\n  minThroughput: number; // requests per second\\n  \\n  // Resource limits\\n  maxMemoryUsage: number; // MB\\n  maxCPUUsage: number; // percentage\\n}\\n\\nclass AutoScaler {\\n  async scaleBasedOnLoad(metrics: SystemMetrics): Promise<void> {\\n    if (metrics.avgLatency > this.config.maxLatency) {\\n      await this.scaleOutVectorDB();\\n      await this.increaseEmbeddingWorkers();\\n    }\\n    \\n    if (metrics.throughput < this.config.minThroughput) {\\n      await this.optimizeQueryRouting();\\n      await this.warmupCaches();\\n    }\\n  }\\n}\\n```\\n\\n## Cost Optimization Strategies\\n\\n### **Model Selection Trade-offs**\\n\\n```typescript\\ninterface CostOptimizer {\\n  selectOptimalModel(query: QueryComplexity): ModelConfig;\\n  calculateCostBenefit(model: ModelConfig, expectedQuality: number): number;\\n  optimizeEmbeddingBatching(products: Product[]): BatchConfig;\\n}\\n\\nenum QueryComplexity {\\n  SIMPLE = \'simple\',     // Basic keyword search - use smaller models\\n  MEDIUM = \'medium\',     // Semantic search - balanced models\\n  COMPLEX = \'complex\'    // Complex reasoning - premium models\\n}\\n\\nconst MODEL_COSTS = {\\n  \'gpt-4\': { input: 0.03, output: 0.06 }, // per 1K tokens\\n  \'gpt-3.5-turbo\': { input: 0.001, output: 0.002 },\\n  \'local-llama\': { input: 0, output: 0, infrastructure: 500 } // monthly\\n};\\n```\\n\\n### **Caching Strategy**\\n\\n```typescript\\nclass CacheManager {\\n  private readonly cacheLayers = {\\n    // L1: In-memory cache for hot data\\n    memory: new Map<string, CacheEntry>(),\\n    \\n    // L2: Redis for session data\\n    redis: new Redis(process.env.REDIS_URL),\\n    \\n    // L3: Database for persistent data\\n    database: new Database()\\n  };\\n\\n  async get(key: string): Promise<any> {\\n    // Check L1 cache first\\n    if (this.cacheLayers.memory.has(key)) {\\n      return this.cacheLayers.memory.get(key).value;\\n    }\\n\\n    // Check L2 cache\\n    const redisValue = await this.cacheLayers.redis.get(key);\\n    if (redisValue) {\\n      // Promote to L1\\n      this.cacheLayers.memory.set(key, {\\n        value: JSON.parse(redisValue),\\n        timestamp: Date.now()\\n      });\\n      return JSON.parse(redisValue);\\n    }\\n\\n    // Fallback to database\\n    return await this.cacheLayers.database.get(key);\\n  }\\n}\\n```\\n\\n## Success Metrics and KPIs\\n\\n### **Business Metrics**\\n\\n```typescript\\ninterface BusinessMetrics {\\n  // Revenue impact\\n  recommendationRevenue: number;\\n  averageOrderValue: number;\\n  conversionRate: number;\\n  \\n  // User engagement\\n  clickThroughRate: number;\\n  timeOnSite: number;\\n  returnCustomerRate: number;\\n  \\n  // System performance\\n  recommendationAccuracy: number;\\n  systemLatency: number;\\n  userSatisfactionScore: number;\\n}\\n\\nclass MetricsCollector {\\n  async trackRecommendationPerformance(\\n    recommendationId: string,\\n    userAction: UserAction\\n  ): Promise<void> {\\n    const metrics = {\\n      recommendationId,\\n      userId: userAction.userId,\\n      action: userAction.type,\\n      timestamp: new Date(),\\n      productId: userAction.productId,\\n      revenue: userAction.revenue || 0\\n    };\\n\\n    await this.metricsDatabase.insert(\'recommendation_events\', metrics);\\n    await this.updateRealTimeMetrics(metrics);\\n  }\\n\\n  async calculateROI(timeframe: TimeFrame): Promise<ROIMetrics> {\\n    const costs = await this.calculateSystemCosts(timeframe);\\n    const revenue = await this.calculateRecommendationRevenue(timeframe);\\n    \\n    return {\\n      roi: (revenue - costs) / costs,\\n      totalRevenue: revenue,\\n      totalCosts: costs,\\n      timeframe\\n    };\\n  }\\n}\\n```\\n\\n## Next Steps\\n\\nIn **Part 2** of this series, we\'ll dive deep into building the data pipeline and generating vector embeddings for products and users. We\'ll cover:\\n\\n- **Product Catalog Processing**: Extracting meaningful features from product data\\n- **User Behavior Tracking**: Capturing and analyzing user interactions\\n- **Vector Embedding Generation**: Creating semantic representations\\n- **Database Design**: Optimizing storage for fast retrieval\\n\\n### **Prerequisites for Part 2**\\n\\nBefore the next post, ensure you have:\\n\\n1. **Development Environment**: Node.js, Python, Docker\\n2. **Database Access**: PostgreSQL for relational data\\n3. **Vector Database**: Qdrant or Pinecone account\\n4. **LLM API Access**: OpenAI or Anthropic API keys\\n5. **Sample Data**: E-commerce product catalog and user data\\n\\n### **What You\'ll Build**\\n\\nBy the end of this series, you\'ll have a production-ready recommendation system that:\\n\\n- \u2705 Processes millions of products and user interactions\\n- \u2705 Provides sub-100ms recommendation responses\\n- \u2705 Scales horizontally with demand\\n- \u2705 Continuously learns and improves\\n- \u2705 Integrates seamlessly with existing e-commerce platforms\\n\\n---\\n\\n*Ready to revolutionize your e-commerce recommendations? The next post in this series will get hands-on with data processing and embedding generation. Subscribe to stay updated!*"},{"id":"rag-ecommerce-recommendations-part2-data-pipeline-embeddings","metadata":{"permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part2-data-pipeline-embeddings","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-08-rag-ecommerce-recommendations-part2-data-pipeline-embeddings.md","source":"@site/blog/2025-10-08-rag-ecommerce-recommendations-part2-data-pipeline-embeddings.md","title":"Building Intelligent E-commerce Recommendations with RAG: Part 2 - Data Pipeline and Vector Embeddings","description":"Welcome back to our comprehensive series on building RAG-powered e-commerce recommendation systems! In Part 1, we explored the architecture and core concepts. Now, we\'ll get hands-on with the foundation of any RAG system: building robust data pipelines and generating high-quality vector embeddings that capture the semantic essence of products and user behavior.","date":"2025-10-08T00:00:00.000Z","tags":[{"inline":false,"label":"RAG","permalink":"/fullstack-dev/blog/tags/rag","description":"Retrieval-Augmented Generation"},{"inline":false,"label":"E-commerce","permalink":"/fullstack-dev/blog/tags/ecommerce","description":"E-commerce development and strategies"},{"inline":false,"label":"Recommendations","permalink":"/fullstack-dev/blog/tags/recommendations","description":"Recommendation systems and algorithms"},{"inline":false,"label":"Vector Embeddings","permalink":"/fullstack-dev/blog/tags/vector-embeddings","description":"Vector embeddings and semantic search"},{"inline":false,"label":"Data Pipeline","permalink":"/fullstack-dev/blog/tags/data-pipeline","description":"Data processing and pipeline architectures"},{"inline":false,"label":"Machine Learning","permalink":"/fullstack-dev/blog/tags/machine-learning","description":"Machine learning and AI applications"},{"inline":false,"label":"Natural Language Processing","permalink":"/fullstack-dev/blog/tags/nlp","description":"Natural language processing techniques"},{"inline":false,"label":"Python","permalink":"/fullstack-dev/blog/tags/python","description":"Python programming language"}],"readingTime":20.6,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"rag-ecommerce-recommendations-part2-data-pipeline-embeddings","title":"Building Intelligent E-commerce Recommendations with RAG: Part 2 - Data Pipeline and Vector Embeddings","authors":["tam"],"tags":["rag","ecommerce","recommendations","vector-embeddings","data-pipeline","machine-learning","nlp","python"],"date":"2025-10-08T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 1 - Introduction and Architecture Overview","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part1-introduction"},"nextItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part3-retrieval-system"}},"content":"Welcome back to our comprehensive series on building RAG-powered e-commerce recommendation systems! In Part 1, we explored the architecture and core concepts. Now, we\'ll get hands-on with the foundation of any RAG system: building robust data pipelines and generating high-quality vector embeddings that capture the semantic essence of products and user behavior.\\n\\nVector embeddings are the secret sauce that enables our recommendation system to understand the relationships between products, users, and their preferences at a semantic level. Let\'s dive into building a production-ready data processing pipeline that transforms raw e-commerce data into meaningful vector representations.\\n\\n\x3c!--truncate--\x3e\\n\\n## Data Pipeline Architecture Overview\\n\\nOur data pipeline follows the Extract, Transform, Load (ETL) pattern, specifically designed for vector embedding generation:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502   Raw Data      \u2502    \u2502  Processing     \u2502    \u2502   Vector        \u2502\\n\u2502   Sources       \u2502\u2500\u2500\u2500\u25b6\u2502  Pipeline       \u2502\u2500\u2500\u2500\u25b6\u2502   Storage       \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\u2502                      \u2502                      \u2502                 \u2502\\n\u251c\u2500 Product Catalog     \u251c\u2500 Data Cleaning       \u251c\u2500 Product Vectors\u2502\\n\u251c\u2500 User Profiles       \u251c\u2500 Feature Extraction  \u251c\u2500 User Vectors   \u2502\\n\u251c\u2500 Interaction Logs    \u251c\u2500 Embedding Generation\u251c\u2500 Query Vectors  \u2502\\n\u251c\u2500 Reviews/Ratings     \u251c\u2500 Quality Validation  \u251c\u2500 Metadata Index \u2502\\n\u2514\u2500 Search Queries      \u2514\u2500 Batch Processing    \u2514\u2500 Search Index   \u2502\\n```\\n\\n## Setting Up the Development Environment\\n\\nFirst, let\'s set up our development environment with the necessary dependencies:\\n\\n```bash\\n# Create virtual environment\\npython -m venv rag-ecommerce\\nsource rag-ecommerce/bin/activate  # On Windows: rag-ecommerce\\\\Scripts\\\\activate\\n\\n# Install core dependencies\\npip install -r requirements.txt\\n```\\n\\n```python\\n# requirements.txt\\n# Data processing\\npandas==2.1.0\\nnumpy==1.24.3\\nsqlalchemy==2.0.20\\npsycopg2-binary==2.9.7\\n\\n# Machine learning and embeddings\\nsentence-transformers==2.2.2\\ntransformers==4.33.2\\ntorch==2.0.1\\nscikit-learn==1.3.0\\n\\n# Vector databases\\nqdrant-client==1.4.0\\npinecone-client==2.2.4\\nweaviate-client==3.23.1\\n\\n# API and LLM integration\\nopenai==0.28.0\\nanthropic==0.3.11\\nlangchain==0.0.292\\n\\n# Data validation and monitoring\\npydantic==2.3.0\\ngreat-expectations==0.17.15\\nmlflow==2.6.0\\n\\n# Utilities\\npython-dotenv==1.0.0\\ntqdm==4.66.1\\nredis==4.6.0\\ncelery==5.3.1\\n```\\n\\n## Product Data Schema and Processing\\n\\n### Product Schema Definition\\n\\n```python\\n# models/product.py\\nfrom pydantic import BaseModel, Field\\nfrom typing import List, Optional, Dict, Any\\nfrom datetime import datetime\\nfrom enum import Enum\\n\\nclass ProductCategory(str, Enum):\\n    ELECTRONICS = \\"electronics\\"\\n    CLOTHING = \\"clothing\\"\\n    HOME_GARDEN = \\"home_garden\\"\\n    BOOKS = \\"books\\"\\n    SPORTS = \\"sports\\"\\n    BEAUTY = \\"beauty\\"\\n    AUTOMOTIVE = \\"automotive\\"\\n\\nclass Product(BaseModel):\\n    id: str = Field(..., description=\\"Unique product identifier\\")\\n    title: str = Field(..., description=\\"Product title\\")\\n    description: str = Field(..., description=\\"Detailed product description\\")\\n    category: ProductCategory = Field(..., description=\\"Primary product category\\")\\n    subcategory: Optional[str] = Field(None, description=\\"Product subcategory\\")\\n    brand: Optional[str] = Field(None, description=\\"Product brand\\")\\n    price: float = Field(..., gt=0, description=\\"Product price\\")\\n    currency: str = Field(default=\\"USD\\", description=\\"Price currency\\")\\n    \\n    # Product attributes\\n    attributes: Dict[str, Any] = Field(default_factory=dict, description=\\"Product attributes\\")\\n    tags: List[str] = Field(default_factory=list, description=\\"Product tags\\")\\n    images: List[str] = Field(default_factory=list, description=\\"Product image URLs\\")\\n    \\n    # Metrics\\n    rating: Optional[float] = Field(None, ge=0, le=5, description=\\"Average rating\\")\\n    review_count: int = Field(default=0, ge=0, description=\\"Number of reviews\\")\\n    popularity_score: float = Field(default=0.0, description=\\"Popularity metric\\")\\n    \\n    # Inventory and availability\\n    stock_quantity: int = Field(default=0, ge=0, description=\\"Available stock\\")\\n    is_available: bool = Field(default=True, description=\\"Product availability\\")\\n    \\n    # Temporal data\\n    created_at: datetime = Field(default_factory=datetime.utcnow)\\n    updated_at: datetime = Field(default_factory=datetime.utcnow)\\n    \\n    # SEO and discoverability\\n    keywords: List[str] = Field(default_factory=list, description=\\"SEO keywords\\")\\n    search_terms: List[str] = Field(default_factory=list, description=\\"Common search terms\\")\\n\\n    class Config:\\n        json_encoders = {\\n            datetime: lambda v: v.isoformat()\\n        }\\n\\nclass ProductReview(BaseModel):\\n    id: str\\n    product_id: str\\n    user_id: str\\n    rating: float = Field(..., ge=1, le=5)\\n    title: Optional[str] = None\\n    content: str\\n    helpful_votes: int = Field(default=0, ge=0)\\n    verified_purchase: bool = Field(default=False)\\n    created_at: datetime = Field(default_factory=datetime.utcnow)\\n```\\n\\n### Product Data Processor\\n\\n```python\\n# processors/product_processor.py\\nimport pandas as pd\\nimport numpy as np\\nfrom typing import List, Dict, Tuple\\nimport re\\nfrom collections import Counter\\nimport logging\\nfrom models.product import Product, ProductReview\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass ProductDataProcessor:\\n    def __init__(self):\\n        self.stop_words = self._load_stop_words()\\n        self.category_keywords = self._load_category_keywords()\\n    \\n    def clean_product_data(self, products_df: pd.DataFrame) -> pd.DataFrame:\\n        \\"\\"\\"Clean and standardize product data\\"\\"\\"\\n        logger.info(f\\"Cleaning {len(products_df)} products\\")\\n        \\n        # Remove duplicates\\n        products_df = products_df.drop_duplicates(subset=[\'id\'])\\n        \\n        # Standardize text fields\\n        products_df[\'title\'] = products_df[\'title\'].apply(self._clean_text)\\n        products_df[\'description\'] = products_df[\'description\'].apply(self._clean_text)\\n        \\n        # Normalize prices\\n        products_df[\'price\'] = pd.to_numeric(products_df[\'price\'], errors=\'coerce\')\\n        products_df = products_df.dropna(subset=[\'price\'])\\n        \\n        # Fill missing values\\n        products_df[\'description\'] = products_df[\'description\'].fillna(\'\')\\n        products_df[\'brand\'] = products_df[\'brand\'].fillna(\'Unknown\')\\n        products_df[\'rating\'] = products_df[\'rating\'].fillna(0.0)\\n        products_df[\'review_count\'] = products_df[\'review_count\'].fillna(0)\\n        \\n        # Calculate derived features\\n        products_df[\'title_length\'] = products_df[\'title\'].str.len()\\n        products_df[\'description_length\'] = products_df[\'description\'].str.len()\\n        products_df[\'price_category\'] = pd.cut(\\n            products_df[\'price\'], \\n            bins=[0, 25, 100, 500, np.inf], \\n            labels=[\'budget\', \'mid-range\', \'premium\', \'luxury\']\\n        )\\n        \\n        logger.info(f\\"Cleaned data: {len(products_df)} products remaining\\")\\n        return products_df\\n    \\n    def extract_product_features(self, product: Product) -> Dict[str, Any]:\\n        \\"\\"\\"Extract meaningful features from product data\\"\\"\\"\\n        features = {\\n            # Basic features\\n            \'title\': product.title,\\n            \'description\': product.description,\\n            \'category\': product.category.value,\\n            \'subcategory\': product.subcategory or \'\',\\n            \'brand\': product.brand or \'\',\\n            \\n            # Numeric features\\n            \'price\': product.price,\\n            \'rating\': product.rating or 0.0,\\n            \'review_count\': product.review_count,\\n            \'popularity_score\': product.popularity_score,\\n            \\n            # Text processing\\n            \'combined_text\': self._create_combined_text(product),\\n            \'keywords\': product.keywords,\\n            \'search_terms\': product.search_terms,\\n            \\n            # Categorical features\\n            \'price_range\': self._categorize_price(product.price),\\n            \'rating_tier\': self._categorize_rating(product.rating or 0.0),\\n            \'popularity_tier\': self._categorize_popularity(product.popularity_score),\\n            \\n            # Availability features\\n            \'is_available\': product.is_available,\\n            \'stock_level\': self._categorize_stock(product.stock_quantity),\\n        }\\n        \\n        # Add attribute-based features\\n        features.update(self._process_attributes(product.attributes))\\n        \\n        return features\\n    \\n    def _clean_text(self, text: str) -> str:\\n        \\"\\"\\"Clean and normalize text data\\"\\"\\"\\n        if pd.isna(text) or not isinstance(text, str):\\n            return \\"\\"\\n        \\n        # Convert to lowercase\\n        text = text.lower()\\n        \\n        # Remove special characters but keep alphanumeric and spaces\\n        text = re.sub(r\'[^a-z0-9\\\\s]\', \' \', text)\\n        \\n        # Remove extra whitespaces\\n        text = re.sub(r\'\\\\s+\', \' \', text).strip()\\n        \\n        return text\\n    \\n    def _create_combined_text(self, product: Product) -> str:\\n        \\"\\"\\"Create combined text for embedding generation\\"\\"\\"\\n        components = [\\n            product.title,\\n            product.description,\\n            product.brand or \'\',\\n            product.category.value,\\n            product.subcategory or \'\',\\n            \' \'.join(product.keywords),\\n            \' \'.join(product.search_terms)\\n        ]\\n        \\n        # Filter out empty components\\n        components = [comp for comp in components if comp and comp.strip()]\\n        \\n        return \' \'.join(components)\\n    \\n    def _categorize_price(self, price: float) -> str:\\n        \\"\\"\\"Categorize price into ranges\\"\\"\\"\\n        if price < 25:\\n            return \'budget\'\\n        elif price < 100:\\n            return \'mid-range\'\\n        elif price < 500:\\n            return \'premium\'\\n        else:\\n            return \'luxury\'\\n    \\n    def _categorize_rating(self, rating: float) -> str:\\n        \\"\\"\\"Categorize rating into tiers\\"\\"\\"\\n        if rating >= 4.5:\\n            return \'excellent\'\\n        elif rating >= 4.0:\\n            return \'very_good\'\\n        elif rating >= 3.5:\\n            return \'good\'\\n        elif rating >= 3.0:\\n            return \'average\'\\n        else:\\n            return \'poor\'\\n    \\n    def _categorize_popularity(self, score: float) -> str:\\n        \\"\\"\\"Categorize popularity score\\"\\"\\"\\n        if score >= 0.8:\\n            return \'viral\'\\n        elif score >= 0.6:\\n            return \'popular\'\\n        elif score >= 0.4:\\n            return \'moderate\'\\n        elif score >= 0.2:\\n            return \'low\'\\n        else:\\n            return \'niche\'\\n    \\n    def _categorize_stock(self, quantity: int) -> str:\\n        \\"\\"\\"Categorize stock levels\\"\\"\\"\\n        if quantity == 0:\\n            return \'out_of_stock\'\\n        elif quantity < 10:\\n            return \'low_stock\'\\n        elif quantity < 100:\\n            return \'medium_stock\'\\n        else:\\n            return \'high_stock\'\\n    \\n    def _process_attributes(self, attributes: Dict[str, Any]) -> Dict[str, str]:\\n        \\"\\"\\"Process product attributes into features\\"\\"\\"\\n        processed = {}\\n        \\n        for key, value in attributes.items():\\n            # Normalize key\\n            clean_key = f\\"attr_{re.sub(r\'[^a-z0-9]\', \'_\', key.lower())}\\"\\n            \\n            # Convert value to string representation\\n            if isinstance(value, (list, tuple)):\\n                clean_value = \', \'.join(str(v) for v in value)\\n            else:\\n                clean_value = str(value)\\n            \\n            processed[clean_key] = self._clean_text(clean_value)\\n        \\n        return processed\\n    \\n    def _load_stop_words(self) -> set:\\n        \\"\\"\\"Load stop words for text processing\\"\\"\\"\\n        # Basic stop words - in production, use NLTK or spaCy\\n        return {\\n            \'the\', \'a\', \'an\', \'and\', \'or\', \'but\', \'in\', \'on\', \'at\', \'to\', \'for\',\\n            \'of\', \'with\', \'by\', \'from\', \'up\', \'about\', \'into\', \'through\', \'during\'\\n        }\\n    \\n    def _load_category_keywords(self) -> Dict[str, List[str]]:\\n        \\"\\"\\"Load category-specific keywords\\"\\"\\"\\n        return {\\n            \'electronics\': [\'smartphone\', \'laptop\', \'tablet\', \'tv\', \'camera\', \'headphones\'],\\n            \'clothing\': [\'shirt\', \'pants\', \'dress\', \'shoes\', \'jacket\', \'accessories\'],\\n            \'home_garden\': [\'furniture\', \'decor\', \'kitchen\', \'garden\', \'tools\', \'appliances\'],\\n            \'books\': [\'novel\', \'textbook\', \'magazine\', \'ebook\', \'audiobook\', \'reference\'],\\n            \'sports\': [\'equipment\', \'apparel\', \'fitness\', \'outdoor\', \'team\', \'individual\'],\\n            \'beauty\': [\'skincare\', \'makeup\', \'hair\', \'fragrance\', \'tools\', \'accessories\']\\n        }\\n```\\n\\n## User Behavior Data Processing\\n\\n### User Models and Schemas\\n\\n```python\\n# models/user.py\\nfrom pydantic import BaseModel, Field\\nfrom typing import List, Optional, Dict, Any\\nfrom datetime import datetime\\nfrom enum import Enum\\n\\nclass UserDemographic(BaseModel):\\n    age_range: Optional[str] = Field(None, description=\\"Age range (e.g., \'25-34\')\\")\\n    gender: Optional[str] = Field(None, description=\\"User gender\\")\\n    location: Optional[str] = Field(None, description=\\"User location\\")\\n    income_range: Optional[str] = Field(None, description=\\"Income bracket\\")\\n\\nclass UserPreferences(BaseModel):\\n    preferred_categories: List[str] = Field(default_factory=list)\\n    preferred_brands: List[str] = Field(default_factory=list)\\n    price_sensitivity: float = Field(default=0.5, ge=0, le=1)\\n    quality_preference: float = Field(default=0.5, ge=0, le=1)\\n    style_preferences: List[str] = Field(default_factory=list)\\n\\nclass InteractionType(str, Enum):\\n    VIEW = \\"view\\"\\n    CLICK = \\"click\\"\\n    ADD_TO_CART = \\"add_to_cart\\"\\n    PURCHASE = \\"purchase\\"\\n    REVIEW = \\"review\\"\\n    SEARCH = \\"search\\"\\n    WISHLIST = \\"wishlist\\"\\n\\nclass UserInteraction(BaseModel):\\n    id: str\\n    user_id: str\\n    product_id: Optional[str] = None\\n    interaction_type: InteractionType\\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\\n    session_id: str\\n    \\n    # Context data\\n    page_url: Optional[str] = None\\n    referrer: Optional[str] = None\\n    device_type: Optional[str] = None\\n    search_query: Optional[str] = None\\n    \\n    # Interaction specifics\\n    duration: Optional[float] = None  # Time spent (seconds)\\n    scroll_depth: Optional[float] = None  # Page scroll percentage\\n    click_position: Optional[Dict[str, float]] = None  # x, y coordinates\\n    \\n    # Purchase specific\\n    quantity: Optional[int] = None\\n    price_paid: Optional[float] = None\\n    discount_applied: Optional[float] = None\\n\\nclass User(BaseModel):\\n    id: str\\n    email: Optional[str] = None\\n    demographic: Optional[UserDemographic] = None\\n    preferences: UserPreferences = Field(default_factory=UserPreferences)\\n    \\n    # Behavioral metrics\\n    total_purchases: int = Field(default=0, ge=0)\\n    total_spent: float = Field(default=0.0, ge=0)\\n    avg_order_value: float = Field(default=0.0, ge=0)\\n    lifetime_value: float = Field(default=0.0, ge=0)\\n    \\n    # Engagement metrics\\n    session_count: int = Field(default=0, ge=0)\\n    page_views: int = Field(default=0, ge=0)\\n    avg_session_duration: float = Field(default=0.0, ge=0)\\n    \\n    # Temporal data\\n    first_seen: datetime = Field(default_factory=datetime.utcnow)\\n    last_seen: datetime = Field(default_factory=datetime.utcnow)\\n    created_at: datetime = Field(default_factory=datetime.utcnow)\\n    updated_at: datetime = Field(default_factory=datetime.utcnow)\\n```\\n\\n### User Behavior Processor\\n\\n```python\\n# processors/user_processor.py\\nimport pandas as pd\\nimport numpy as np\\nfrom typing import List, Dict, Tuple\\nfrom datetime import datetime, timedelta\\nfrom collections import defaultdict, Counter\\nimport logging\\nfrom models.user import User, UserInteraction, InteractionType\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass UserBehaviorProcessor:\\n    def __init__(self):\\n        self.interaction_weights = {\\n            InteractionType.VIEW: 1.0,\\n            InteractionType.CLICK: 2.0,\\n            InteractionType.ADD_TO_CART: 5.0,\\n            InteractionType.PURCHASE: 10.0,\\n            InteractionType.REVIEW: 8.0,\\n            InteractionType.SEARCH: 3.0,\\n            InteractionType.WISHLIST: 4.0,\\n        }\\n    \\n    def process_user_interactions(self, interactions_df: pd.DataFrame) -> pd.DataFrame:\\n        \\"\\"\\"Process and enrich user interaction data\\"\\"\\"\\n        logger.info(f\\"Processing {len(interactions_df)} user interactions\\")\\n        \\n        # Convert timestamp to datetime\\n        interactions_df[\'timestamp\'] = pd.to_datetime(interactions_df[\'timestamp\'])\\n        \\n        # Add temporal features\\n        interactions_df[\'hour\'] = interactions_df[\'timestamp\'].dt.hour\\n        interactions_df[\'day_of_week\'] = interactions_df[\'timestamp\'].dt.dayofweek\\n        interactions_df[\'is_weekend\'] = interactions_df[\'day_of_week\'].isin([5, 6])\\n        \\n        # Calculate interaction weights\\n        interactions_df[\'interaction_weight\'] = interactions_df[\'interaction_type\'].map(\\n            lambda x: self.interaction_weights.get(InteractionType(x), 1.0)\\n        )\\n        \\n        # Add session-based features\\n        interactions_df = self._add_session_features(interactions_df)\\n        \\n        return interactions_df\\n    \\n    def create_user_profiles(self, users_df: pd.DataFrame, interactions_df: pd.DataFrame) -> Dict[str, Dict]:\\n        \\"\\"\\"Create comprehensive user profiles from interaction data\\"\\"\\"\\n        user_profiles = {}\\n        \\n        for user_id in users_df[\'id\'].unique():\\n            user_interactions = interactions_df[interactions_df[\'user_id\'] == user_id]\\n            \\n            profile = {\\n                \'user_id\': user_id,\\n                \'behavioral_features\': self._extract_behavioral_features(user_interactions),\\n                \'preference_features\': self._extract_preference_features(user_interactions),\\n                \'temporal_features\': self._extract_temporal_features(user_interactions),\\n                \'engagement_features\': self._extract_engagement_features(user_interactions),\\n            }\\n            \\n            user_profiles[user_id] = profile\\n        \\n        logger.info(f\\"Created profiles for {len(user_profiles)} users\\")\\n        return user_profiles\\n    \\n    def _add_session_features(self, interactions_df: pd.DataFrame) -> pd.DataFrame:\\n        \\"\\"\\"Add session-based features to interactions\\"\\"\\"\\n        # Sort by user and timestamp\\n        interactions_df = interactions_df.sort_values([\'user_id\', \'timestamp\'])\\n        \\n        # Calculate time since previous interaction\\n        interactions_df[\'time_since_prev\'] = interactions_df.groupby(\'user_id\')[\'timestamp\'].diff()\\n        interactions_df[\'time_since_prev_seconds\'] = interactions_df[\'time_since_prev\'].dt.total_seconds()\\n        \\n        # Identify session boundaries (gap > 30 minutes)\\n        session_boundary = interactions_df[\'time_since_prev_seconds\'] > 1800  # 30 minutes\\n        interactions_df[\'session_number\'] = session_boundary.groupby(interactions_df[\'user_id\']).cumsum()\\n        \\n        return interactions_df\\n    \\n    def _extract_behavioral_features(self, user_interactions: pd.DataFrame) -> Dict[str, float]:\\n        \\"\\"\\"Extract behavioral patterns from user interactions\\"\\"\\"\\n        if len(user_interactions) == 0:\\n            return self._get_default_behavioral_features()\\n        \\n        features = {}\\n        \\n        # Interaction type distribution\\n        interaction_counts = user_interactions[\'interaction_type\'].value_counts()\\n        total_interactions = len(user_interactions)\\n        \\n        for interaction_type in InteractionType:\\n            ratio = interaction_counts.get(interaction_type.value, 0) / total_interactions\\n            features[f\'{interaction_type.value}_ratio\'] = ratio\\n        \\n        # Purchase behavior\\n        purchases = user_interactions[user_interactions[\'interaction_type\'] == InteractionType.PURCHASE.value]\\n        features[\'purchase_frequency\'] = len(purchases)\\n        features[\'avg_time_to_purchase\'] = self._calculate_avg_time_to_purchase(user_interactions)\\n        \\n        # Browsing behavior\\n        views = user_interactions[user_interactions[\'interaction_type\'] == InteractionType.VIEW.value]\\n        features[\'avg_session_length\'] = user_interactions.groupby(\'session_id\').size().mean()\\n        features[\'avg_products_per_session\'] = user_interactions.groupby(\'session_id\')[\'product_id\'].nunique().mean()\\n        \\n        # Engagement depth\\n        features[\'bounce_rate\'] = self._calculate_bounce_rate(user_interactions)\\n        features[\'repeat_visit_rate\'] = self._calculate_repeat_visit_rate(user_interactions)\\n        \\n        return features\\n    \\n    def _extract_preference_features(self, user_interactions: pd.DataFrame) -> Dict[str, Any]:\\n        \\"\\"\\"Extract user preferences from interaction patterns\\"\\"\\"\\n        if len(user_interactions) == 0:\\n            return {}\\n        \\n        # This would typically join with product data to get categories, brands, etc.\\n        # For now, we\'ll create placeholder logic\\n        features = {\\n            \'preferred_categories\': [],\\n            \'preferred_brands\': [],\\n            \'price_sensitivity\': 0.5,\\n            \'quality_preference\': 0.5,\\n        }\\n        \\n        # Calculate preferences based on weighted interactions\\n        weighted_interactions = user_interactions.copy()\\n        weighted_interactions[\'weight\'] = weighted_interactions[\'interaction_type\'].map(\\n            lambda x: self.interaction_weights.get(InteractionType(x), 1.0)\\n        )\\n        \\n        # In a real implementation, you\'d join with product data here\\n        # features[\'preferred_categories\'] = self._get_top_categories(weighted_interactions)\\n        # features[\'preferred_brands\'] = self._get_top_brands(weighted_interactions)\\n        \\n        return features\\n    \\n    def _extract_temporal_features(self, user_interactions: pd.DataFrame) -> Dict[str, float]:\\n        \\"\\"\\"Extract temporal behavior patterns\\"\\"\\"\\n        if len(user_interactions) == 0:\\n            return {}\\n        \\n        features = {}\\n        \\n        # Time-based patterns\\n        hour_distribution = user_interactions[\'hour\'].value_counts(normalize=True)\\n        features[\'peak_hour\'] = hour_distribution.idxmax()\\n        features[\'activity_variance\'] = hour_distribution.var()\\n        \\n        # Day-of-week patterns\\n        dow_distribution = user_interactions[\'day_of_week\'].value_counts(normalize=True)\\n        features[\'weekend_activity_ratio\'] = user_interactions[\'is_weekend\'].mean()\\n        \\n        # Recency and frequency\\n        features[\'days_since_last_interaction\'] = (\\n            datetime.utcnow() - user_interactions[\'timestamp\'].max()\\n        ).days\\n        \\n        features[\'interaction_frequency\'] = len(user_interactions) / max(\\n            (user_interactions[\'timestamp\'].max() - user_interactions[\'timestamp\'].min()).days, 1\\n        )\\n        \\n        return features\\n    \\n    def _extract_engagement_features(self, user_interactions: pd.DataFrame) -> Dict[str, float]:\\n        \\"\\"\\"Extract user engagement metrics\\"\\"\\"\\n        if len(user_interactions) == 0:\\n            return {}\\n        \\n        features = {}\\n        \\n        # Session-based metrics\\n        session_stats = user_interactions.groupby(\'session_id\').agg({\\n            \'timestamp\': [\'min\', \'max\'],\\n            \'product_id\': \'nunique\',\\n            \'interaction_type\': \'count\'\\n        }).reset_index()\\n        \\n        # Calculate session durations\\n        session_stats[\'duration\'] = (\\n            session_stats[(\'timestamp\', \'max\')] - session_stats[(\'timestamp\', \'min\')]\\n        ).dt.total_seconds()\\n        \\n        features[\'avg_session_duration\'] = session_stats[\'duration\'].mean()\\n        features[\'total_sessions\'] = len(session_stats)\\n        features[\'avg_actions_per_session\'] = session_stats[(\'interaction_type\', \'count\')].mean()\\n        \\n        # Conversion metrics\\n        sessions_with_purchase = user_interactions[\\n            user_interactions[\'interaction_type\'] == InteractionType.PURCHASE.value\\n        ][\'session_id\'].nunique()\\n        \\n        features[\'session_conversion_rate\'] = sessions_with_purchase / len(session_stats) if len(session_stats) > 0 else 0\\n        \\n        return features\\n    \\n    def _calculate_avg_time_to_purchase(self, user_interactions: pd.DataFrame) -> float:\\n        \\"\\"\\"Calculate average time from first interaction to purchase\\"\\"\\"\\n        purchases = user_interactions[user_interactions[\'interaction_type\'] == InteractionType.PURCHASE.value]\\n        \\n        if len(purchases) == 0:\\n            return 0.0\\n        \\n        times_to_purchase = []\\n        \\n        for _, purchase in purchases.iterrows():\\n            session_interactions = user_interactions[\\n                user_interactions[\'session_id\'] == purchase[\'session_id\']\\n            ].sort_values(\'timestamp\')\\n            \\n            first_interaction = session_interactions.iloc[0][\'timestamp\']\\n            time_to_purchase = (purchase[\'timestamp\'] - first_interaction).total_seconds()\\n            times_to_purchase.append(time_to_purchase)\\n        \\n        return np.mean(times_to_purchase) if times_to_purchase else 0.0\\n    \\n    def _calculate_bounce_rate(self, user_interactions: pd.DataFrame) -> float:\\n        \\"\\"\\"Calculate bounce rate (single-interaction sessions)\\"\\"\\"\\n        session_sizes = user_interactions.groupby(\'session_id\').size()\\n        single_interaction_sessions = (session_sizes == 1).sum()\\n        return single_interaction_sessions / len(session_sizes) if len(session_sizes) > 0 else 0\\n    \\n    def _calculate_repeat_visit_rate(self, user_interactions: pd.DataFrame) -> float:\\n        \\"\\"\\"Calculate repeat visit rate\\"\\"\\"\\n        unique_days = user_interactions[\'timestamp\'].dt.date.nunique()\\n        total_days = (\\n            user_interactions[\'timestamp\'].max() - user_interactions[\'timestamp\'].min()\\n        ).days + 1\\n        return unique_days / total_days if total_days > 0 else 0\\n    \\n    def _get_default_behavioral_features(self) -> Dict[str, float]:\\n        \\"\\"\\"Return default behavioral features for users with no interactions\\"\\"\\"\\n        features = {}\\n        for interaction_type in InteractionType:\\n            features[f\'{interaction_type.value}_ratio\'] = 0.0\\n        \\n        features.update({\\n            \'purchase_frequency\': 0.0,\\n            \'avg_time_to_purchase\': 0.0,\\n            \'avg_session_length\': 0.0,\\n            \'avg_products_per_session\': 0.0,\\n            \'bounce_rate\': 1.0,\\n            \'repeat_visit_rate\': 0.0,\\n        })\\n        \\n        return features\\n```\\n\\n## Vector Embedding Generation\\n\\nNow let\'s implement the core embedding generation system:\\n\\n```python\\n# embeddings/embedding_generator.py\\nimport numpy as np\\nimport torch\\nfrom sentence_transformers import SentenceTransformer\\nfrom transformers import AutoTokenizer, AutoModel\\nfrom typing import List, Dict, Any, Optional, Union\\nimport logging\\nfrom abc import ABC, abstractmethod\\nimport asyncio\\nimport aiohttp\\nimport openai\\nfrom tqdm import tqdm\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass BaseEmbeddingGenerator(ABC):\\n    \\"\\"\\"Abstract base class for embedding generators\\"\\"\\"\\n    \\n    @abstractmethod\\n    async def generate_embeddings(self, texts: List[str]) -> np.ndarray:\\n        pass\\n    \\n    @abstractmethod\\n    def get_embedding_dimension(self) -> int:\\n        pass\\n\\nclass SentenceTransformerEmbedding(BaseEmbeddingGenerator):\\n    \\"\\"\\"Local sentence transformer embedding generator\\"\\"\\"\\n    \\n    def __init__(self, model_name: str = \\"all-MiniLM-L6-v2\\"):\\n        self.model_name = model_name\\n        self.model = SentenceTransformer(model_name)\\n        self.device = torch.device(\\"cuda\\" if torch.cuda.is_available() else \\"cpu\\")\\n        self.model.to(self.device)\\n        \\n        logger.info(f\\"Loaded SentenceTransformer model: {model_name}\\")\\n    \\n    async def generate_embeddings(self, texts: List[str]) -> np.ndarray:\\n        \\"\\"\\"Generate embeddings for a list of texts\\"\\"\\"\\n        if not texts:\\n            return np.array([])\\n        \\n        # Process in batches to manage memory\\n        batch_size = 32\\n        all_embeddings = []\\n        \\n        for i in tqdm(range(0, len(texts), batch_size), desc=\\"Generating embeddings\\"):\\n            batch = texts[i:i + batch_size]\\n            embeddings = self.model.encode(\\n                batch,\\n                convert_to_numpy=True,\\n                show_progress_bar=False,\\n                batch_size=batch_size\\n            )\\n            all_embeddings.append(embeddings)\\n        \\n        return np.vstack(all_embeddings)\\n    \\n    def get_embedding_dimension(self) -> int:\\n        return self.model.get_sentence_embedding_dimension()\\n\\nclass OpenAIEmbedding(BaseEmbeddingGenerator):\\n    \\"\\"\\"OpenAI API embedding generator\\"\\"\\"\\n    \\n    def __init__(self, model_name: str = \\"text-embedding-ada-002\\", api_key: Optional[str] = None):\\n        self.model_name = model_name\\n        openai.api_key = api_key or os.getenv(\\"OPENAI_API_KEY\\")\\n        self.dimensions = {\\n            \\"text-embedding-ada-002\\": 1536,\\n            \\"text-embedding-3-small\\": 1536,\\n            \\"text-embedding-3-large\\": 3072,\\n        }\\n        \\n        logger.info(f\\"Initialized OpenAI embedding model: {model_name}\\")\\n    \\n    async def generate_embeddings(self, texts: List[str]) -> np.ndarray:\\n        \\"\\"\\"Generate embeddings using OpenAI API\\"\\"\\"\\n        if not texts:\\n            return np.array([])\\n        \\n        # OpenAI API has rate limits, so we batch requests\\n        batch_size = 100  # OpenAI recommends up to 2048 texts per request\\n        all_embeddings = []\\n        \\n        for i in tqdm(range(0, len(texts), batch_size), desc=\\"Generating OpenAI embeddings\\"):\\n            batch = texts[i:i + batch_size]\\n            \\n            try:\\n                response = await openai.Embedding.acreate(\\n                    model=self.model_name,\\n                    input=batch\\n                )\\n                \\n                batch_embeddings = [data.embedding for data in response.data]\\n                all_embeddings.extend(batch_embeddings)\\n                \\n                # Rate limiting\\n                await asyncio.sleep(0.1)\\n                \\n            except Exception as e:\\n                logger.error(f\\"Error generating embeddings for batch {i}: {e}\\")\\n                # Fill with zeros for failed batches\\n                zero_embedding = [0.0] * self.get_embedding_dimension()\\n                all_embeddings.extend([zero_embedding] * len(batch))\\n        \\n        return np.array(all_embeddings)\\n    \\n    def get_embedding_dimension(self) -> int:\\n        return self.dimensions.get(self.model_name, 1536)\\n\\nclass ProductEmbeddingGenerator:\\n    \\"\\"\\"Specialized embedding generator for products\\"\\"\\"\\n    \\n    def __init__(self, embedding_generator: BaseEmbeddingGenerator):\\n        self.embedding_generator = embedding_generator\\n        self.dimension = embedding_generator.get_embedding_dimension()\\n    \\n    async def generate_product_embeddings(self, products: List[Dict[str, Any]]) -> Dict[str, np.ndarray]:\\n        \\"\\"\\"Generate embeddings for products\\"\\"\\"\\n        logger.info(f\\"Generating embeddings for {len(products)} products\\")\\n        \\n        # Prepare texts for embedding\\n        product_texts = []\\n        product_ids = []\\n        \\n        for product in products:\\n            text = self._create_product_text(product)\\n            product_texts.append(text)\\n            product_ids.append(product[\'id\'])\\n        \\n        # Generate embeddings\\n        embeddings = await self.embedding_generator.generate_embeddings(product_texts)\\n        \\n        # Create mapping\\n        product_embeddings = {}\\n        for product_id, embedding in zip(product_ids, embeddings):\\n            product_embeddings[product_id] = embedding\\n        \\n        logger.info(f\\"Generated embeddings for {len(product_embeddings)} products\\")\\n        return product_embeddings\\n    \\n    def _create_product_text(self, product: Dict[str, Any]) -> str:\\n        \\"\\"\\"Create text representation of product for embedding\\"\\"\\"\\n        components = []\\n        \\n        # Title (highest weight)\\n        if product.get(\'title\'):\\n            components.append(f\\"Title: {product[\'title\']}\\")\\n        \\n        # Category and subcategory\\n        if product.get(\'category\'):\\n            components.append(f\\"Category: {product[\'category\']}\\")\\n        if product.get(\'subcategory\'):\\n            components.append(f\\"Subcategory: {product[\'subcategory\']}\\")\\n        \\n        # Brand\\n        if product.get(\'brand\'):\\n            components.append(f\\"Brand: {product[\'brand\']}\\")\\n        \\n        # Description\\n        if product.get(\'description\'):\\n            # Truncate very long descriptions\\n            description = product[\'description\'][:500]\\n            components.append(f\\"Description: {description}\\")\\n        \\n        # Price range\\n        if product.get(\'price_range\'):\\n            components.append(f\\"Price range: {product[\'price_range\']}\\")\\n        \\n        # Keywords and tags\\n        if product.get(\'keywords\'):\\n            components.append(f\\"Keywords: {\', \'.join(product[\'keywords\'])}\\")\\n        \\n        # Attributes\\n        for key, value in product.get(\'attributes\', {}).items():\\n            if isinstance(value, (str, int, float)):\\n                components.append(f\\"{key}: {value}\\")\\n        \\n        return \' \'.join(components)\\n\\nclass UserEmbeddingGenerator:\\n    \\"\\"\\"Specialized embedding generator for users\\"\\"\\"\\n    \\n    def __init__(self, embedding_generator: BaseEmbeddingGenerator):\\n        self.embedding_generator = embedding_generator\\n        self.dimension = embedding_generator.get_embedding_dimension()\\n    \\n    async def generate_user_embeddings(self, user_profiles: Dict[str, Dict[str, Any]]) -> Dict[str, np.ndarray]:\\n        \\"\\"\\"Generate embeddings for user profiles\\"\\"\\"\\n        logger.info(f\\"Generating embeddings for {len(user_profiles)} users\\")\\n        \\n        # Prepare texts for embedding\\n        user_texts = []\\n        user_ids = []\\n        \\n        for user_id, profile in user_profiles.items():\\n            text = self._create_user_text(profile)\\n            user_texts.append(text)\\n            user_ids.append(user_id)\\n        \\n        # Generate embeddings\\n        embeddings = await self.embedding_generator.generate_embeddings(user_texts)\\n        \\n        # Create mapping\\n        user_embeddings = {}\\n        for user_id, embedding in zip(user_ids, embeddings):\\n            user_embeddings[user_id] = embedding\\n        \\n        logger.info(f\\"Generated embeddings for {len(user_embeddings)} users\\")\\n        return user_embeddings\\n    \\n    def _create_user_text(self, profile: Dict[str, Any]) -> str:\\n        \\"\\"\\"Create text representation of user profile for embedding\\"\\"\\"\\n        components = []\\n        \\n        # Behavioral features\\n        behavioral = profile.get(\'behavioral_features\', {})\\n        if behavioral:\\n            high_interactions = [k.replace(\'_ratio\', \'\') for k, v in behavioral.items() \\n                               if k.endswith(\'_ratio\') and v > 0.1]\\n            if high_interactions:\\n                components.append(f\\"Frequently: {\', \'.join(high_interactions)}\\")\\n        \\n        # Preferences\\n        preferences = profile.get(\'preference_features\', {})\\n        if preferences.get(\'preferred_categories\'):\\n            components.append(f\\"Prefers categories: {\', \'.join(preferences[\'preferred_categories\'])}\\")\\n        if preferences.get(\'preferred_brands\'):\\n            components.append(f\\"Prefers brands: {\', \'.join(preferences[\'preferred_brands\'])}\\")\\n        \\n        # Engagement level\\n        engagement = profile.get(\'engagement_features\', {})\\n        if engagement.get(\'session_conversion_rate\', 0) > 0.1:\\n            components.append(\\"High converter\\")\\n        elif engagement.get(\'avg_session_duration\', 0) > 300:  # 5 minutes\\n            components.append(\\"Engaged browser\\")\\n        \\n        # Temporal patterns\\n        temporal = profile.get(\'temporal_features\', {})\\n        if temporal.get(\'weekend_activity_ratio\', 0) > 0.6:\\n            components.append(\\"Weekend shopper\\")\\n        \\n        if not components:\\n            components.append(\\"New user\\")\\n        \\n        return \' \'.join(components)\\n\\nclass QueryEmbeddingGenerator:\\n    \\"\\"\\"Generate embeddings for search queries\\"\\"\\"\\n    \\n    def __init__(self, embedding_generator: BaseEmbeddingGenerator):\\n        self.embedding_generator = embedding_generator\\n    \\n    async def generate_query_embedding(self, query: str, context: Optional[Dict[str, Any]] = None) -> np.ndarray:\\n        \\"\\"\\"Generate embedding for a search query with optional context\\"\\"\\"\\n        # Enhance query with context\\n        enhanced_query = self._enhance_query_with_context(query, context)\\n        \\n        # Generate embedding\\n        embeddings = await self.embedding_generator.generate_embeddings([enhanced_query])\\n        return embeddings[0]\\n    \\n    def _enhance_query_with_context(self, query: str, context: Optional[Dict[str, Any]] = None) -> str:\\n        \\"\\"\\"Enhance query with contextual information\\"\\"\\"\\n        if not context:\\n            return query\\n        \\n        enhancements = [query]\\n        \\n        # Add user preferences\\n        if context.get(\'preferred_categories\'):\\n            enhancements.append(f\\"Categories: {\', \'.join(context[\'preferred_categories\'])}\\")\\n        \\n        # Add price context\\n        if context.get(\'price_range\'):\\n            enhancements.append(f\\"Price range: {context[\'price_range\']}\\")\\n        \\n        # Add temporal context\\n        if context.get(\'season\'):\\n            enhancements.append(f\\"Season: {context[\'season\']}\\")\\n        \\n        return \' \'.join(enhancements)\\n```\\n\\n## Embedding Quality Validation\\n\\n```python\\n# validation/embedding_validator.py\\nimport numpy as np\\nfrom typing import List, Dict, Tuple, Any\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.cluster import KMeans\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom collections import defaultdict\\nimport logging\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass EmbeddingQualityValidator:\\n    \\"\\"\\"Validate the quality of generated embeddings\\"\\"\\"\\n    \\n    def __init__(self):\\n        self.similarity_threshold = 0.7\\n        self.diversity_threshold = 0.3\\n    \\n    def validate_product_embeddings(\\n        self, \\n        product_embeddings: Dict[str, np.ndarray],\\n        products: List[Dict[str, Any]]\\n    ) -> Dict[str, Any]:\\n        \\"\\"\\"Comprehensive validation of product embeddings\\"\\"\\"\\n        logger.info(\\"Validating product embeddings...\\")\\n        \\n        results = {\\n            \'total_products\': len(product_embeddings),\\n            \'embedding_dimension\': len(next(iter(product_embeddings.values()))),\\n            \'quality_metrics\': {},\\n            \'recommendations\': []\\n        }\\n        \\n        # Create product lookup\\n        product_lookup = {p[\'id\']: p for p in products}\\n        \\n        # Test semantic similarity\\n        similarity_results = self._test_semantic_similarity(product_embeddings, product_lookup)\\n        results[\'quality_metrics\'][\'semantic_similarity\'] = similarity_results\\n        \\n        # Test category clustering\\n        clustering_results = self._test_category_clustering(product_embeddings, product_lookup)\\n        results[\'quality_metrics\'][\'category_clustering\'] = clustering_results\\n        \\n        # Test embedding diversity\\n        diversity_results = self._test_embedding_diversity(product_embeddings)\\n        results[\'quality_metrics\'][\'diversity\'] = diversity_results\\n        \\n        # Generate recommendations\\n        results[\'recommendations\'] = self._generate_quality_recommendations(results[\'quality_metrics\'])\\n        \\n        logger.info(f\\"Validation complete. Overall quality score: {self._calculate_overall_score(results[\'quality_metrics\']):.3f}\\")\\n        \\n        return results\\n    \\n    def _test_semantic_similarity(\\n        self, \\n        embeddings: Dict[str, np.ndarray], \\n        products: Dict[str, Dict[str, Any]]\\n    ) -> Dict[str, float]:\\n        \\"\\"\\"Test if semantically similar products have similar embeddings\\"\\"\\"\\n        # Sample products for testing (to avoid O(n\xb2) computation)\\n        sample_size = min(100, len(embeddings))\\n        sampled_ids = list(embeddings.keys())[:sample_size]\\n        \\n        similarity_scores = []\\n        \\n        for i, product_id_1 in enumerate(sampled_ids):\\n            for product_id_2 in sampled_ids[i+1:]:\\n                # Calculate embedding similarity\\n                emb_sim = cosine_similarity(\\n                    embeddings[product_id_1].reshape(1, -1),\\n                    embeddings[product_id_2].reshape(1, -1)\\n                )[0, 0]\\n                \\n                # Calculate semantic similarity (based on category, brand, etc.)\\n                semantic_sim = self._calculate_semantic_similarity(\\n                    products[product_id_1], \\n                    products[product_id_2]\\n                )\\n                \\n                similarity_scores.append({\\n                    \'embedding_similarity\': emb_sim,\\n                    \'semantic_similarity\': semantic_sim\\n                })\\n        \\n        # Calculate correlation\\n        emb_sims = [s[\'embedding_similarity\'] for s in similarity_scores]\\n        sem_sims = [s[\'semantic_similarity\'] for s in similarity_scores]\\n        \\n        correlation = np.corrcoef(emb_sims, sem_sims)[0, 1]\\n        \\n        return {\\n            \'correlation\': correlation,\\n            \'avg_embedding_similarity\': np.mean(emb_sims),\\n            \'avg_semantic_similarity\': np.mean(sem_sims),\\n            \'sample_size\': len(similarity_scores)\\n        }\\n    \\n    def _test_category_clustering(\\n        self, \\n        embeddings: Dict[str, np.ndarray], \\n        products: Dict[str, Dict[str, Any]]\\n    ) -> Dict[str, Any]:\\n        \\"\\"\\"Test if products from same category cluster together\\"\\"\\"\\n        # Group by category\\n        category_embeddings = defaultdict(list)\\n        category_products = defaultdict(list)\\n        \\n        for product_id, embedding in embeddings.items():\\n            if product_id in products:\\n                category = products[product_id].get(\'category\', \'unknown\')\\n                category_embeddings[category].append(embedding)\\n                category_products[category].append(product_id)\\n        \\n        # Calculate intra-category similarity\\n        intra_similarities = {}\\n        for category, embs in category_embeddings.items():\\n            if len(embs) > 1:\\n                emb_matrix = np.array(embs)\\n                sim_matrix = cosine_similarity(emb_matrix)\\n                # Average similarity excluding diagonal\\n                mask = ~np.eye(sim_matrix.shape[0], dtype=bool)\\n                avg_similarity = sim_matrix[mask].mean()\\n                intra_similarities[category] = avg_similarity\\n        \\n        # Calculate inter-category similarity\\n        categories = list(category_embeddings.keys())\\n        inter_similarities = []\\n        \\n        for i, cat1 in enumerate(categories):\\n            for cat2 in categories[i+1:]:\\n                if len(category_embeddings[cat1]) > 0 and len(category_embeddings[cat2]) > 0:\\n                    # Calculate average similarity between categories\\n                    emb1 = np.mean(category_embeddings[cat1], axis=0)\\n                    emb2 = np.mean(category_embeddings[cat2], axis=0)\\n                    sim = cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0, 0]\\n                    inter_similarities.append(sim)\\n        \\n        return {\\n            \'intra_category_similarity\': np.mean(list(intra_similarities.values())),\\n            \'inter_category_similarity\': np.mean(inter_similarities),\\n            \'separation_score\': np.mean(list(intra_similarities.values())) - np.mean(inter_similarities),\\n            \'categories_analyzed\': len(category_embeddings)\\n        }\\n    \\n    def _test_embedding_diversity(self, embeddings: Dict[str, np.ndarray]) -> Dict[str, float]:\\n        \\"\\"\\"Test diversity of embeddings to avoid mode collapse\\"\\"\\"\\n        embedding_matrix = np.array(list(embeddings.values()))\\n        \\n        # Calculate pairwise similarities\\n        similarity_matrix = cosine_similarity(embedding_matrix)\\n        \\n        # Remove diagonal (self-similarity)\\n        mask = ~np.eye(similarity_matrix.shape[0], dtype=bool)\\n        similarities = similarity_matrix[mask]\\n        \\n        # Calculate diversity metrics\\n        avg_similarity = similarities.mean()\\n        similarity_std = similarities.std()\\n        \\n        # PCA to check dimensionality usage\\n        pca = PCA()\\n        pca.fit(embedding_matrix)\\n        explained_variance_ratio = pca.explained_variance_ratio_\\n        \\n        # Calculate effective dimensionality (95% variance)\\n        cumsum_variance = np.cumsum(explained_variance_ratio)\\n        effective_dims = np.argmax(cumsum_variance >= 0.95) + 1\\n        \\n        return {\\n            \'average_similarity\': avg_similarity,\\n            \'similarity_std\': similarity_std,\\n            \'effective_dimensions\': effective_dims,\\n            \'total_dimensions\': embedding_matrix.shape[1],\\n            \'dimension_usage_ratio\': effective_dims / embedding_matrix.shape[1]\\n        }\\n    \\n    def _calculate_semantic_similarity(self, product1: Dict[str, Any], product2: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate semantic similarity between two products\\"\\"\\"\\n        similarity = 0.0\\n        \\n        # Category similarity (highest weight)\\n        if product1.get(\'category\') == product2.get(\'category\'):\\n            similarity += 0.4\\n            \\n            # Subcategory similarity\\n            if product1.get(\'subcategory\') == product2.get(\'subcategory\'):\\n                similarity += 0.2\\n        \\n        # Brand similarity\\n        if product1.get(\'brand\') == product2.get(\'brand\'):\\n            similarity += 0.2\\n        \\n        # Price range similarity\\n        if product1.get(\'price_range\') == product2.get(\'price_range\'):\\n            similarity += 0.1\\n        \\n        # Title similarity (simple word overlap)\\n        title1_words = set(product1.get(\'title\', \'\').lower().split())\\n        title2_words = set(product2.get(\'title\', \'\').lower().split())\\n        if title1_words and title2_words:\\n            word_overlap = len(title1_words & title2_words) / len(title1_words | title2_words)\\n            similarity += 0.1 * word_overlap\\n        \\n        return similarity\\n    \\n    def _calculate_overall_score(self, metrics: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate overall quality score\\"\\"\\"\\n        scores = []\\n        \\n        # Semantic similarity correlation (should be positive)\\n        if \'semantic_similarity\' in metrics:\\n            correlation = metrics[\'semantic_similarity\'].get(\'correlation\', 0)\\n            scores.append(max(0, correlation))\\n        \\n        # Category clustering separation\\n        if \'category_clustering\' in metrics:\\n            separation = metrics[\'category_clustering\'].get(\'separation_score\', 0)\\n            scores.append(max(0, min(1, separation)))\\n        \\n        # Diversity (should not be too high or too low)\\n        if \'diversity\' in metrics:\\n            avg_sim = metrics[\'diversity\'].get(\'average_similarity\', 0.5)\\n            # Optimal similarity around 0.3-0.5\\n            diversity_score = 1 - abs(avg_sim - 0.4) / 0.4\\n            scores.append(max(0, diversity_score))\\n        \\n        return np.mean(scores) if scores else 0.0\\n    \\n    def _generate_quality_recommendations(self, metrics: Dict[str, Any]) -> List[str]:\\n        \\"\\"\\"Generate recommendations based on quality metrics\\"\\"\\"\\n        recommendations = []\\n        \\n        # Check semantic similarity\\n        if \'semantic_similarity\' in metrics:\\n            correlation = metrics[\'semantic_similarity\'].get(\'correlation\', 0)\\n            if correlation < 0.3:\\n                recommendations.append(\\n                    \\"Low semantic similarity correlation. Consider improving text preprocessing \\"\\n                    \\"or using a more powerful embedding model.\\"\\n                )\\n        \\n        # Check category clustering\\n        if \'category_clustering\' in metrics:\\n            separation = metrics[\'category_clustering\'].get(\'separation_score\', 0)\\n            if separation < 0.1:\\n                recommendations.append(\\n                    \\"Poor category separation. Consider adding category information to \\"\\n                    \\"product text or using category-specific embeddings.\\"\\n                )\\n        \\n        # Check diversity\\n        if \'diversity\' in metrics:\\n            avg_sim = metrics[\'diversity\'].get(\'average_similarity\', 0.5)\\n            if avg_sim > 0.8:\\n                recommendations.append(\\n                    \\"Embeddings are too similar (mode collapse). Consider using a different \\"\\n                    \\"embedding model or improving text diversity.\\"\\n                )\\n            elif avg_sim < 0.1:\\n                recommendations.append(\\n                    \\"Embeddings are too diverse. Consider improving text preprocessing \\"\\n                    \\"or using a more consistent embedding approach.\\"\\n                )\\n        \\n        if not recommendations:\\n            recommendations.append(\\"Embedding quality looks good!\\")\\n        \\n        return recommendations\\n```\\n\\n## Next Steps\\n\\nIn **Part 3** of this series, we\'ll implement the retrieval system using vector databases and build sophisticated search capabilities. We\'ll cover:\\n\\n- **Vector Database Setup**: Detailed implementation with Qdrant, Pinecone, and Weaviate\\n- **Hybrid Search Strategies**: Combining semantic and keyword search\\n- **Performance Optimization**: Indexing, sharding, and caching strategies\\n- **Real-time Updates**: Handling dynamic product catalogs\\n\\n### **What We\'ve Accomplished**\\n\\nIn this post, we\'ve built the foundation for our RAG recommendation system:\\n\\n\u2705 **Robust Data Processing Pipeline**: Handles product catalogs and user behavior data\\n\u2705 **Quality Vector Embeddings**: Generates semantic representations for products and users  \\n\u2705 **Comprehensive Validation**: Ensures embedding quality and semantic coherence\\n\u2705 **Scalable Architecture**: Designed for production workloads\\n\\n### **Before Part 3**\\n\\nMake sure you have:\\n1. Generated embeddings for your product catalog\\n2. Set up user behavior tracking\\n3. Validated embedding quality\\n4. Chosen your vector database provider\\n\\n---\\n\\n*The data pipeline and embeddings are the foundation of intelligent recommendations. Next, we\'ll build the retrieval engine that makes it all come together!*"},{"id":"rag-ecommerce-recommendations-part3-retrieval-system","metadata":{"permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part3-retrieval-system","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-08-rag-ecommerce-recommendations-part3-retrieval-system.md","source":"@site/blog/2025-10-08-rag-ecommerce-recommendations-part3-retrieval-system.md","title":"Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation","description":"Welcome to Part 3 of our RAG-powered e-commerce recommendation series! We\'ve built our data pipeline and generated high-quality embeddings. Now comes the exciting part: implementing a sophisticated retrieval system that can find the most relevant products using multiple search strategies.","date":"2025-10-08T00:00:00.000Z","tags":[{"inline":false,"label":"RAG","permalink":"/fullstack-dev/blog/tags/rag","description":"Retrieval-Augmented Generation"},{"inline":false,"label":"E-commerce","permalink":"/fullstack-dev/blog/tags/ecommerce","description":"E-commerce development and strategies"},{"inline":false,"label":"Recommendations","permalink":"/fullstack-dev/blog/tags/recommendations","description":"Recommendation systems and algorithms"},{"inline":false,"label":"Vector Search","permalink":"/fullstack-dev/blog/tags/vector-search","description":"Vector similarity search"},{"inline":false,"label":"Qdrant","permalink":"/fullstack-dev/blog/tags/qdrant","description":"Qdrant vector database"},{"inline":false,"label":"Pinecone","permalink":"/fullstack-dev/blog/tags/pinecone","description":"Pinecone vector database"},{"inline":false,"label":"Hybrid Search","permalink":"/fullstack-dev/blog/tags/hybrid-search","description":"Hybrid search combining multiple techniques"},{"inline":false,"label":"Retrieval","permalink":"/fullstack-dev/blog/tags/retrieval","description":"Information retrieval systems"}],"readingTime":21.69,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"rag-ecommerce-recommendations-part3-retrieval-system","title":"Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation","authors":["tam"],"tags":["rag","ecommerce","recommendations","vector-search","qdrant","pinecone","hybrid-search","retrieval"],"date":"2025-10-08T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 2 - Data Pipeline and Vector Embeddings","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part2-data-pipeline-embeddings"},"nextItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 4 - Generation and Personalization Engine","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part4-generation-personalization"}},"content":"Welcome to Part 3 of our RAG-powered e-commerce recommendation series! We\'ve built our data pipeline and generated high-quality embeddings. Now comes the exciting part: implementing a sophisticated retrieval system that can find the most relevant products using multiple search strategies.\\n\\nThe retrieval system is the heart of our RAG architecture, responsible for efficiently finding relevant products from millions of items using semantic search, keyword matching, and hybrid approaches. We\'ll implement production-ready solutions using popular vector databases and explore advanced optimization techniques.\\n\\n\x3c!--truncate--\x3e\\n\\n## Retrieval System Architecture\\n\\nOur retrieval system combines multiple search strategies to maximize relevance and coverage:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        Query Processing Layer                       \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   Query     \u2502  \u2502  Context    \u2502  \u2502   Intent    \u2502  \u2502  Filter     \u2502 \u2502\\n\u2502  \u2502 Embedding   \u2502  \u2502 Enhancement \u2502  \u2502 Detection   \u2502  \u2502 Extraction  \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                      Retrieval Strategies                           \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502  Semantic   \u2502  \u2502  Keyword    \u2502  \u2502Collaborative\u2502  \u2502   Hybrid    \u2502 \u2502\\n\u2502  \u2502   Search    \u2502  \u2502   Search    \u2502  \u2502  Filtering  \u2502  \u2502   Fusion    \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        Storage Layer                                \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   Vector    \u2502  \u2502  Full-Text  \u2502  \u2502   Graph     \u2502  \u2502   Cache     \u2502 \u2502\\n\u2502  \u2502  Database   \u2502  \u2502   Search    \u2502  \u2502  Database   \u2502  \u2502   Layer     \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## Vector Database Implementation\\n\\nLet\'s implement retrieval systems for the three most popular vector databases:\\n\\n### 1. Qdrant Implementation\\n\\n```python\\n# retrieval/qdrant_retriever.py\\nimport asyncio\\nfrom typing import List, Dict, Any, Optional, Tuple\\nimport numpy as np\\nfrom qdrant_client import QdrantClient\\nfrom qdrant_client.http import models\\nfrom qdrant_client.http.models import (\\n    Distance, VectorParams, CreateCollection, PointStruct,\\n    Filter, FieldCondition, PayloadSchemaType\\n)\\nimport logging\\nfrom abc import ABC, abstractmethod\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass BaseVectorRetriever(ABC):\\n    \\"\\"\\"Abstract base class for vector retrievers\\"\\"\\"\\n    \\n    @abstractmethod\\n    async def create_collection(self, collection_name: str, vector_dimension: int) -> bool:\\n        pass\\n    \\n    @abstractmethod\\n    async def upsert_vectors(self, collection_name: str, vectors: List[Dict[str, Any]]) -> bool:\\n        pass\\n    \\n    @abstractmethod\\n    async def search(self, collection_name: str, query_vector: np.ndarray, \\n                    limit: int = 10, filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\\n        pass\\n\\nclass QdrantRetriever(BaseVectorRetriever):\\n    \\"\\"\\"Qdrant vector database retriever implementation\\"\\"\\"\\n    \\n    def __init__(self, host: str = \\"localhost\\", port: int = 6333, api_key: Optional[str] = None):\\n        self.client = QdrantClient(\\n            host=host,\\n            port=port,\\n            api_key=api_key,\\n            timeout=30\\n        )\\n        self.collection_configs = {}\\n        logger.info(f\\"Connected to Qdrant at {host}:{port}\\")\\n    \\n    async def create_collection(self, collection_name: str, vector_dimension: int, \\n                               distance_metric: Distance = Distance.COSINE) -> bool:\\n        \\"\\"\\"Create a new collection in Qdrant\\"\\"\\"\\n        try:\\n            # Check if collection already exists\\n            collections = self.client.get_collections()\\n            existing_names = [col.name for col in collections.collections]\\n            \\n            if collection_name in existing_names:\\n                logger.info(f\\"Collection {collection_name} already exists\\")\\n                return True\\n            \\n            # Create collection\\n            self.client.create_collection(\\n                collection_name=collection_name,\\n                vectors_config=VectorParams(\\n                    size=vector_dimension,\\n                    distance=distance_metric\\n                ),\\n                optimizers_config=models.OptimizersConfig(\\n                    default_segment_number=2,\\n                    max_segment_size=20000,\\n                    memmap_threshold=20000,\\n                    indexing_threshold=20000,\\n                ),\\n                replication_factor=1,\\n                write_consistency_factor=1,\\n            )\\n            \\n            # Create payload schema for better performance\\n            self.client.create_payload_index(\\n                collection_name=collection_name,\\n                field_name=\\"category\\",\\n                field_schema=PayloadSchemaType.KEYWORD\\n            )\\n            \\n            self.client.create_payload_index(\\n                collection_name=collection_name,\\n                field_name=\\"brand\\",\\n                field_schema=PayloadSchemaType.KEYWORD\\n            )\\n            \\n            self.client.create_payload_index(\\n                collection_name=collection_name,\\n                field_name=\\"price\\",\\n                field_schema=PayloadSchemaType.FLOAT\\n            )\\n            \\n            self.client.create_payload_index(\\n                collection_name=collection_name,\\n                field_name=\\"rating\\",\\n                field_schema=PayloadSchemaType.FLOAT\\n            )\\n            \\n            logger.info(f\\"Created collection {collection_name} with dimension {vector_dimension}\\")\\n            return True\\n            \\n        except Exception as e:\\n            logger.error(f\\"Failed to create collection {collection_name}: {e}\\")\\n            return False\\n    \\n    async def upsert_vectors(self, collection_name: str, vectors: List[Dict[str, Any]]) -> bool:\\n        \\"\\"\\"Insert or update vectors in the collection\\"\\"\\"\\n        try:\\n            points = []\\n            for i, vector_data in enumerate(vectors):\\n                point = PointStruct(\\n                    id=vector_data.get(\'id\', i),\\n                    vector=vector_data[\'vector\'].tolist() if isinstance(vector_data[\'vector\'], np.ndarray) \\n                           else vector_data[\'vector\'],\\n                    payload=vector_data.get(\'payload\', {})\\n                )\\n                points.append(point)\\n            \\n            # Batch upsert\\n            batch_size = 100\\n            for i in range(0, len(points), batch_size):\\n                batch = points[i:i + batch_size]\\n                operation_info = self.client.upsert(\\n                    collection_name=collection_name,\\n                    wait=True,\\n                    points=batch\\n                )\\n                logger.debug(f\\"Upserted batch {i//batch_size + 1}: {operation_info}\\")\\n            \\n            logger.info(f\\"Successfully upserted {len(vectors)} vectors to {collection_name}\\")\\n            return True\\n            \\n        except Exception as e:\\n            logger.error(f\\"Failed to upsert vectors to {collection_name}: {e}\\")\\n            return False\\n    \\n    async def search(self, collection_name: str, query_vector: np.ndarray, \\n                    limit: int = 10, filters: Optional[Dict] = None,\\n                    score_threshold: Optional[float] = None) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Search for similar vectors\\"\\"\\"\\n        try:\\n            # Convert numpy array to list\\n            query_vector_list = query_vector.tolist() if isinstance(query_vector, np.ndarray) else query_vector\\n            \\n            # Build filters\\n            qdrant_filter = self._build_qdrant_filter(filters) if filters else None\\n            \\n            # Perform search\\n            search_result = self.client.search(\\n                collection_name=collection_name,\\n                query_vector=query_vector_list,\\n                limit=limit,\\n                query_filter=qdrant_filter,\\n                score_threshold=score_threshold,\\n                with_payload=True,\\n                with_vectors=False\\n            )\\n            \\n            # Format results\\n            results = []\\n            for scored_point in search_result:\\n                result = {\\n                    \'id\': scored_point.id,\\n                    \'score\': scored_point.score,\\n                    \'payload\': scored_point.payload\\n                }\\n                results.append(result)\\n            \\n            logger.debug(f\\"Found {len(results)} results for query in {collection_name}\\")\\n            return results\\n            \\n        except Exception as e:\\n            logger.error(f\\"Search failed in {collection_name}: {e}\\")\\n            return []\\n    \\n    async def hybrid_search(self, collection_name: str, query_vector: np.ndarray,\\n                           text_query: str, limit: int = 10, \\n                           alpha: float = 0.7) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Hybrid search combining vector and text search\\"\\"\\"\\n        try:\\n            # Vector search\\n            vector_results = await self.search(\\n                collection_name=collection_name,\\n                query_vector=query_vector,\\n                limit=limit * 2  # Get more candidates\\n            )\\n            \\n            # Text-based filtering/scoring\\n            text_scored_results = self._score_text_relevance(vector_results, text_query)\\n            \\n            # Combine scores\\n            final_results = []\\n            for result in text_scored_results:\\n                vector_score = result[\'score\']\\n                text_score = result.get(\'text_score\', 0.0)\\n                \\n                # Weighted combination\\n                combined_score = alpha * vector_score + (1 - alpha) * text_score\\n                \\n                result[\'combined_score\'] = combined_score\\n                result[\'vector_score\'] = vector_score\\n                result[\'text_score\'] = text_score\\n                \\n                final_results.append(result)\\n            \\n            # Sort by combined score and limit results\\n            final_results.sort(key=lambda x: x[\'combined_score\'], reverse=True)\\n            return final_results[:limit]\\n            \\n        except Exception as e:\\n            logger.error(f\\"Hybrid search failed: {e}\\")\\n            return []\\n    \\n    def _build_qdrant_filter(self, filters: Dict[str, Any]) -> Filter:\\n        \\"\\"\\"Build Qdrant filter from dictionary\\"\\"\\"\\n        conditions = []\\n        \\n        for field, value in filters.items():\\n            if isinstance(value, dict):\\n                # Range filter\\n                if \'gte\' in value or \'lte\' in value or \'gt\' in value or \'lt\' in value:\\n                    condition = FieldCondition(\\n                        key=field,\\n                        range=models.Range(**value)\\n                    )\\n                # Match any filter\\n                elif \'any\' in value:\\n                    condition = FieldCondition(\\n                        key=field,\\n                        match=models.MatchAny(any=value[\'any\'])\\n                    )\\n                else:\\n                    continue\\n            else:\\n                # Exact match\\n                condition = FieldCondition(\\n                    key=field,\\n                    match=models.MatchValue(value=value)\\n                )\\n            \\n            conditions.append(condition)\\n        \\n        return Filter(must=conditions) if conditions else None\\n    \\n    def _score_text_relevance(self, results: List[Dict[str, Any]], \\n                             text_query: str) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Score results based on text relevance\\"\\"\\"\\n        query_terms = set(text_query.lower().split())\\n        \\n        for result in results:\\n            text_score = 0.0\\n            payload = result.get(\'payload\', {})\\n            \\n            # Score based on title match\\n            title = payload.get(\'title\', \'\').lower()\\n            title_words = set(title.split())\\n            title_overlap = len(query_terms & title_words) / max(len(query_terms), 1)\\n            text_score += title_overlap * 0.6\\n            \\n            # Score based on description match\\n            description = payload.get(\'description\', \'\').lower()\\n            desc_words = set(description.split())\\n            desc_overlap = len(query_terms & desc_words) / max(len(query_terms), 1)\\n            text_score += desc_overlap * 0.3\\n            \\n            # Score based on category/brand match\\n            category = payload.get(\'category\', \'\').lower()\\n            brand = payload.get(\'brand\', \'\').lower()\\n            \\n            if any(term in category for term in query_terms):\\n                text_score += 0.1\\n            if any(term in brand for term in query_terms):\\n                text_score += 0.1\\n            \\n            result[\'text_score\'] = text_score\\n        \\n        return results\\n    \\n    async def get_collection_info(self, collection_name: str) -> Dict[str, Any]:\\n        \\"\\"\\"Get information about a collection\\"\\"\\"\\n        try:\\n            info = self.client.get_collection(collection_name)\\n            return {\\n                \'status\': info.status,\\n                \'vectors_count\': info.vectors_count,\\n                \'points_count\': info.points_count,\\n                \'config\': info.config\\n            }\\n        except Exception as e:\\n            logger.error(f\\"Failed to get collection info: {e}\\")\\n            return {}\\n    \\n    async def delete_collection(self, collection_name: str) -> bool:\\n        \\"\\"\\"Delete a collection\\"\\"\\"\\n        try:\\n            self.client.delete_collection(collection_name)\\n            logger.info(f\\"Deleted collection {collection_name}\\")\\n            return True\\n        except Exception as e:\\n            logger.error(f\\"Failed to delete collection {collection_name}: {e}\\")\\n            return False\\n```\\n\\n### 2. Pinecone Implementation\\n\\n```python\\n# retrieval/pinecone_retriever.py\\nimport pinecone\\nimport numpy as np\\nfrom typing import List, Dict, Any, Optional\\nimport logging\\nimport asyncio\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass PineconeRetriever(BaseVectorRetriever):\\n    \\"\\"\\"Pinecone vector database retriever implementation\\"\\"\\"\\n    \\n    def __init__(self, api_key: str, environment: str):\\n        pinecone.init(api_key=api_key, environment=environment)\\n        self.api_key = api_key\\n        self.environment = environment\\n        self.indexes = {}\\n        self.executor = ThreadPoolExecutor(max_workers=10)\\n        logger.info(f\\"Initialized Pinecone in environment: {environment}\\")\\n    \\n    async def create_collection(self, collection_name: str, vector_dimension: int,\\n                               metric: str = \\"cosine\\", pods: int = 1,\\n                               pod_type: str = \\"p1.x1\\") -> bool:\\n        \\"\\"\\"Create a new index in Pinecone\\"\\"\\"\\n        try:\\n            # Check if index exists\\n            if collection_name in pinecone.list_indexes():\\n                logger.info(f\\"Index {collection_name} already exists\\")\\n                self.indexes[collection_name] = pinecone.Index(collection_name)\\n                return True\\n            \\n            # Create index\\n            pinecone.create_index(\\n                name=collection_name,\\n                dimension=vector_dimension,\\n                metric=metric,\\n                pods=pods,\\n                pod_type=pod_type\\n            )\\n            \\n            # Wait for index to be ready\\n            await asyncio.sleep(10)  # Pinecone needs time to initialize\\n            \\n            self.indexes[collection_name] = pinecone.Index(collection_name)\\n            logger.info(f\\"Created Pinecone index {collection_name}\\")\\n            return True\\n            \\n        except Exception as e:\\n            logger.error(f\\"Failed to create Pinecone index {collection_name}: {e}\\")\\n            return False\\n    \\n    async def upsert_vectors(self, collection_name: str, vectors: List[Dict[str, Any]]) -> bool:\\n        \\"\\"\\"Insert or update vectors in Pinecone\\"\\"\\"\\n        try:\\n            if collection_name not in self.indexes:\\n                self.indexes[collection_name] = pinecone.Index(collection_name)\\n            \\n            index = self.indexes[collection_name]\\n            \\n            # Prepare vectors for Pinecone format\\n            pinecone_vectors = []\\n            for vector_data in vectors:\\n                vector_id = str(vector_data.get(\'id\'))\\n                vector_values = vector_data[\'vector\'].tolist() if isinstance(vector_data[\'vector\'], np.ndarray) else vector_data[\'vector\']\\n                metadata = vector_data.get(\'payload\', {})\\n                \\n                pinecone_vectors.append((vector_id, vector_values, metadata))\\n            \\n            # Batch upsert\\n            batch_size = 100\\n            for i in range(0, len(pinecone_vectors), batch_size):\\n                batch = pinecone_vectors[i:i + batch_size]\\n                \\n                # Run in executor to avoid blocking\\n                await asyncio.get_event_loop().run_in_executor(\\n                    self.executor, \\n                    lambda: index.upsert(vectors=batch)\\n                )\\n            \\n            logger.info(f\\"Upserted {len(vectors)} vectors to Pinecone index {collection_name}\\")\\n            return True\\n            \\n        except Exception as e:\\n            logger.error(f\\"Failed to upsert vectors to Pinecone: {e}\\")\\n            return False\\n    \\n    async def search(self, collection_name: str, query_vector: np.ndarray,\\n                    limit: int = 10, filters: Optional[Dict] = None,\\n                    include_metadata: bool = True) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Search for similar vectors in Pinecone\\"\\"\\"\\n        try:\\n            if collection_name not in self.indexes:\\n                self.indexes[collection_name] = pinecone.Index(collection_name)\\n            \\n            index = self.indexes[collection_name]\\n            \\n            # Convert numpy array to list\\n            query_vector_list = query_vector.tolist() if isinstance(query_vector, np.ndarray) else query_vector\\n            \\n            # Perform search\\n            search_response = await asyncio.get_event_loop().run_in_executor(\\n                self.executor,\\n                lambda: index.query(\\n                    vector=query_vector_list,\\n                    top_k=limit,\\n                    filter=filters,\\n                    include_metadata=include_metadata\\n                )\\n            )\\n            \\n            # Format results\\n            results = []\\n            for match in search_response.matches:\\n                result = {\\n                    \'id\': match.id,\\n                    \'score\': match.score,\\n                    \'payload\': match.metadata if include_metadata else {}\\n                }\\n                results.append(result)\\n            \\n            logger.debug(f\\"Found {len(results)} results in Pinecone index {collection_name}\\")\\n            return results\\n            \\n        except Exception as e:\\n            logger.error(f\\"Pinecone search failed: {e}\\")\\n            return []\\n    \\n    async def delete_collection(self, collection_name: str) -> bool:\\n        \\"\\"\\"Delete a Pinecone index\\"\\"\\"\\n        try:\\n            pinecone.delete_index(collection_name)\\n            if collection_name in self.indexes:\\n                del self.indexes[collection_name]\\n            logger.info(f\\"Deleted Pinecone index {collection_name}\\")\\n            return True\\n        except Exception as e:\\n            logger.error(f\\"Failed to delete Pinecone index {collection_name}: {e}\\")\\n            return False\\n    \\n    async def get_collection_info(self, collection_name: str) -> Dict[str, Any]:\\n        \\"\\"\\"Get information about a Pinecone index\\"\\"\\"\\n        try:\\n            index_stats = await asyncio.get_event_loop().run_in_executor(\\n                self.executor,\\n                lambda: pinecone.Index(collection_name).describe_index_stats()\\n            )\\n            return {\\n                \'total_vector_count\': index_stats.total_vector_count,\\n                \'dimension\': index_stats.dimension,\\n                \'index_fullness\': index_stats.index_fullness\\n            }\\n        except Exception as e:\\n            logger.error(f\\"Failed to get Pinecone index info: {e}\\")\\n            return {}\\n```\\n\\n### 3. Hybrid Search Implementation\\n\\n```python\\n# retrieval/hybrid_retriever.py\\nimport asyncio\\nfrom typing import List, Dict, Any, Optional, Tuple\\nimport numpy as np\\nfrom elasticsearch import AsyncElasticsearch\\nimport logging\\nfrom collections import defaultdict\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass HybridRetriever:\\n    \\"\\"\\"Combines vector search with traditional text search\\"\\"\\"\\n    \\n    def __init__(self, vector_retriever: BaseVectorRetriever, \\n                 elasticsearch_client: Optional[AsyncElasticsearch] = None):\\n        self.vector_retriever = vector_retriever\\n        self.elasticsearch_client = elasticsearch_client\\n        self.fusion_methods = {\\n            \'rrf\': self._reciprocal_rank_fusion,\\n            \'weighted\': self._weighted_fusion,\\n            \'linear\': self._linear_combination\\n        }\\n    \\n    async def hybrid_search(self, collection_name: str, query_vector: np.ndarray,\\n                           text_query: str, limit: int = 10,\\n                           vector_weight: float = 0.7,\\n                           fusion_method: str = \'rrf\',\\n                           filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Perform hybrid search combining vector and text search\\"\\"\\"\\n        \\n        # Run searches in parallel\\n        vector_task = self._vector_search(collection_name, query_vector, limit * 2, filters)\\n        text_task = self._text_search(collection_name, text_query, limit * 2, filters)\\n        \\n        vector_results, text_results = await asyncio.gather(vector_task, text_task)\\n        \\n        # Fuse results\\n        fusion_func = self.fusion_methods.get(fusion_method, self._reciprocal_rank_fusion)\\n        fused_results = fusion_func(vector_results, text_results, vector_weight)\\n        \\n        # Limit and return results\\n        return fused_results[:limit]\\n    \\n    async def _vector_search(self, collection_name: str, query_vector: np.ndarray,\\n                            limit: int, filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Perform vector similarity search\\"\\"\\"\\n        try:\\n            results = await self.vector_retriever.search(\\n                collection_name=collection_name,\\n                query_vector=query_vector,\\n                limit=limit,\\n                filters=filters\\n            )\\n            \\n            # Add search type and normalize scores\\n            for i, result in enumerate(results):\\n                result[\'search_type\'] = \'vector\'\\n                result[\'rank\'] = i + 1\\n                result[\'normalized_score\'] = result[\'score\']  # Assumes cosine similarity [0,1]\\n            \\n            return results\\n            \\n        except Exception as e:\\n            logger.error(f\\"Vector search failed: {e}\\")\\n            return []\\n    \\n    async def _text_search(self, collection_name: str, text_query: str,\\n                          limit: int, filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Perform full-text search using Elasticsearch\\"\\"\\"\\n        if not self.elasticsearch_client:\\n            logger.warning(\\"Elasticsearch client not configured, skipping text search\\")\\n            return []\\n        \\n        try:\\n            # Build Elasticsearch query\\n            es_query = {\\n                \\"query\\": {\\n                    \\"bool\\": {\\n                        \\"must\\": [\\n                            {\\n                                \\"multi_match\\": {\\n                                    \\"query\\": text_query,\\n                                    \\"fields\\": [\\"title^3\\", \\"description^2\\", \\"category\\", \\"brand\\"],\\n                                    \\"type\\": \\"best_fields\\",\\n                                    \\"fuzziness\\": \\"AUTO\\"\\n                                }\\n                            }\\n                        ]\\n                    }\\n                },\\n                \\"size\\": limit\\n            }\\n            \\n            # Add filters if provided\\n            if filters:\\n                es_filters = self._build_elasticsearch_filters(filters)\\n                es_query[\\"query\\"][\\"bool\\"][\\"filter\\"] = es_filters\\n            \\n            # Execute search\\n            response = await self.elasticsearch_client.search(\\n                index=collection_name,\\n                body=es_query\\n            )\\n            \\n            # Format results\\n            results = []\\n            for i, hit in enumerate(response[\'hits\'][\'hits\']):\\n                result = {\\n                    \'id\': hit[\'_id\'],\\n                    \'score\': hit[\'_score\'],\\n                    \'payload\': hit[\'_source\'],\\n                    \'search_type\': \'text\',\\n                    \'rank\': i + 1,\\n                    \'normalized_score\': hit[\'_score\'] / response[\'hits\'][\'max_score\'] if response[\'hits\'][\'max_score\'] > 0 else 0\\n                }\\n                results.append(result)\\n            \\n            return results\\n            \\n        except Exception as e:\\n            logger.error(f\\"Text search failed: {e}\\")\\n            return []\\n    \\n    def _reciprocal_rank_fusion(self, vector_results: List[Dict[str, Any]],\\n                               text_results: List[Dict[str, Any]],\\n                               vector_weight: float = 0.7,\\n                               k: int = 60) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Combine results using Reciprocal Rank Fusion\\"\\"\\"\\n        # Create score maps\\n        vector_scores = {result[\'id\']: 1 / (k + result[\'rank\']) for result in vector_results}\\n        text_scores = {result[\'id\']: 1 / (k + result[\'rank\']) for result in text_results}\\n        \\n        # Get all unique IDs\\n        all_ids = set(vector_scores.keys()) | set(text_scores.keys())\\n        \\n        # Calculate combined scores\\n        combined_results = []\\n        item_map = {}\\n        \\n        # Create item lookup\\n        for result in vector_results + text_results:\\n            if result[\'id\'] not in item_map:\\n                item_map[result[\'id\']] = result\\n        \\n        for item_id in all_ids:\\n            vector_score = vector_scores.get(item_id, 0)\\n            text_score = text_scores.get(item_id, 0)\\n            \\n            # Weighted RRF score\\n            combined_score = (vector_weight * vector_score + \\n                            (1 - vector_weight) * text_score)\\n            \\n            if item_id in item_map:\\n                result = item_map[item_id].copy()\\n                result[\'rrf_score\'] = combined_score\\n                result[\'vector_rrf\'] = vector_score\\n                result[\'text_rrf\'] = text_score\\n                combined_results.append(result)\\n        \\n        # Sort by combined score\\n        combined_results.sort(key=lambda x: x[\'rrf_score\'], reverse=True)\\n        return combined_results\\n    \\n    def _weighted_fusion(self, vector_results: List[Dict[str, Any]],\\n                        text_results: List[Dict[str, Any]],\\n                        vector_weight: float = 0.7) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Combine results using weighted score fusion\\"\\"\\"\\n        # Create score maps\\n        vector_scores = {result[\'id\']: result[\'normalized_score\'] for result in vector_results}\\n        text_scores = {result[\'id\']: result[\'normalized_score\'] for result in text_results}\\n        \\n        # Get all unique IDs\\n        all_ids = set(vector_scores.keys()) | set(text_scores.keys())\\n        \\n        # Calculate combined scores\\n        combined_results = []\\n        item_map = {}\\n        \\n        # Create item lookup\\n        for result in vector_results + text_results:\\n            if result[\'id\'] not in item_map:\\n                item_map[result[\'id\']] = result\\n        \\n        for item_id in all_ids:\\n            vector_score = vector_scores.get(item_id, 0)\\n            text_score = text_scores.get(item_id, 0)\\n            \\n            # Weighted combination\\n            combined_score = (vector_weight * vector_score + \\n                            (1 - vector_weight) * text_score)\\n            \\n            if item_id in item_map:\\n                result = item_map[item_id].copy()\\n                result[\'combined_score\'] = combined_score\\n                result[\'vector_score\'] = vector_score\\n                result[\'text_score\'] = text_score\\n                combined_results.append(result)\\n        \\n        # Sort by combined score\\n        combined_results.sort(key=lambda x: x[\'combined_score\'], reverse=True)\\n        return combined_results\\n    \\n    def _linear_combination(self, vector_results: List[Dict[str, Any]],\\n                           text_results: List[Dict[str, Any]],\\n                           vector_weight: float = 0.7) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Simple linear combination of normalized scores\\"\\"\\"\\n        return self._weighted_fusion(vector_results, text_results, vector_weight)\\n    \\n    def _build_elasticsearch_filters(self, filters: Dict[str, Any]) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Convert filters to Elasticsearch format\\"\\"\\"\\n        es_filters = []\\n        \\n        for field, value in filters.items():\\n            if isinstance(value, dict):\\n                if \'gte\' in value or \'lte\' in value:\\n                    es_filters.append({\\n                        \\"range\\": {\\n                            field: value\\n                        }\\n                    })\\n                elif \'any\' in value:\\n                    es_filters.append({\\n                        \\"terms\\": {\\n                            field: value[\'any\']\\n                        }\\n                    })\\n            else:\\n                es_filters.append({\\n                    \\"term\\": {\\n                        field: value\\n                    }\\n                })\\n        \\n        return es_filters\\n```\\n\\n## Advanced Search Strategies\\n\\n### 1. Contextual Search Implementation\\n\\n```python\\n# retrieval/contextual_search.py\\nfrom typing import List, Dict, Any, Optional\\nimport numpy as np\\nfrom datetime import datetime, timedelta\\nimport logging\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass ContextualSearchEngine:\\n    \\"\\"\\"Advanced search engine with context awareness\\"\\"\\"\\n    \\n    def __init__(self, retriever: BaseVectorRetriever):\\n        self.retriever = retriever\\n        self.context_weights = {\\n            \'seasonal\': 0.1,\\n            \'trending\': 0.15,\\n            \'personal\': 0.3,\\n            \'behavioral\': 0.25,\\n            \'collaborative\': 0.2\\n        }\\n    \\n    async def contextual_search(self, collection_name: str, query_vector: np.ndarray,\\n                               user_context: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Perform context-aware search\\"\\"\\"\\n        \\n        # Get base search results\\n        base_results = await self.retriever.search(\\n            collection_name=collection_name,\\n            query_vector=query_vector,\\n            limit=limit * 3  # Get more candidates for reranking\\n        )\\n        \\n        # Apply contextual reranking\\n        reranked_results = await self._apply_contextual_reranking(\\n            base_results, user_context\\n        )\\n        \\n        # Apply diversity filtering\\n        diverse_results = self._apply_diversity_filtering(reranked_results, limit)\\n        \\n        return diverse_results\\n    \\n    async def _apply_contextual_reranking(self, results: List[Dict[str, Any]], \\n                                         context: Dict[str, Any]) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Rerank results based on context\\"\\"\\"\\n        \\n        for result in results:\\n            payload = result.get(\'payload\', {})\\n            base_score = result[\'score\']\\n            \\n            # Calculate context-based adjustments\\n            seasonal_boost = self._calculate_seasonal_boost(payload, context)\\n            trending_boost = self._calculate_trending_boost(payload, context)\\n            personal_boost = self._calculate_personal_boost(payload, context)\\n            behavioral_boost = self._calculate_behavioral_boost(payload, context)\\n            collaborative_boost = self._calculate_collaborative_boost(payload, context)\\n            \\n            # Apply weighted boosts\\n            context_score = (\\n                self.context_weights[\'seasonal\'] * seasonal_boost +\\n                self.context_weights[\'trending\'] * trending_boost +\\n                self.context_weights[\'personal\'] * personal_boost +\\n                self.context_weights[\'behavioral\'] * behavioral_boost +\\n                self.context_weights[\'collaborative\'] * collaborative_boost\\n            )\\n            \\n            # Combine base score with context score\\n            result[\'contextual_score\'] = base_score * (1 + context_score)\\n            result[\'context_breakdown\'] = {\\n                \'seasonal\': seasonal_boost,\\n                \'trending\': trending_boost,\\n                \'personal\': personal_boost,\\n                \'behavioral\': behavioral_boost,\\n                \'collaborative\': collaborative_boost\\n            }\\n        \\n        # Sort by contextual score\\n        results.sort(key=lambda x: x[\'contextual_score\'], reverse=True)\\n        return results\\n    \\n    def _calculate_seasonal_boost(self, product: Dict[str, Any], \\n                                 context: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate seasonal relevance boost\\"\\"\\"\\n        current_month = datetime.now().month\\n        product_category = product.get(\'category\', \'\').lower()\\n        \\n        # Define seasonal categories\\n        seasonal_categories = {\\n            \'winter\': [\'coats\', \'sweaters\', \'boots\', \'heating\'],\\n            \'spring\': [\'flowers\', \'gardening\', \'light_clothing\'],\\n            \'summer\': [\'swimwear\', \'shorts\', \'cooling\', \'outdoor\'],\\n            \'fall\': [\'jackets\', \'school_supplies\', \'warm_drinks\']\\n        }\\n        \\n        # Determine current season\\n        season_map = {\\n            12: \'winter\', 1: \'winter\', 2: \'winter\',\\n            3: \'spring\', 4: \'spring\', 5: \'spring\',\\n            6: \'summer\', 7: \'summer\', 8: \'summer\',\\n            9: \'fall\', 10: \'fall\', 11: \'fall\'\\n        }\\n        \\n        current_season = season_map.get(current_month, \'spring\')\\n        seasonal_items = seasonal_categories.get(current_season, [])\\n        \\n        # Check if product matches current season\\n        for item in seasonal_items:\\n            if item in product_category or item in product.get(\'title\', \'\').lower():\\n                return 0.2  # 20% boost for seasonal items\\n        \\n        return 0.0\\n    \\n    def _calculate_trending_boost(self, product: Dict[str, Any], \\n                                 context: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate trending boost based on recent popularity\\"\\"\\"\\n        popularity_score = product.get(\'popularity_score\', 0)\\n        recent_views = product.get(\'recent_views\', 0)\\n        \\n        # Boost based on popularity and recent activity\\n        trending_score = 0.0\\n        \\n        if popularity_score > 0.8:\\n            trending_score += 0.15\\n        elif popularity_score > 0.6:\\n            trending_score += 0.1\\n        \\n        if recent_views > 1000:  # High recent activity\\n            trending_score += 0.1\\n        \\n        return trending_score\\n    \\n    def _calculate_personal_boost(self, product: Dict[str, Any], \\n                                 context: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate personal preference boost\\"\\"\\"\\n        user_preferences = context.get(\'preferences\', {})\\n        personal_score = 0.0\\n        \\n        # Category preference\\n        preferred_categories = user_preferences.get(\'preferred_categories\', [])\\n        if product.get(\'category\') in preferred_categories:\\n            personal_score += 0.3\\n        \\n        # Brand preference\\n        preferred_brands = user_preferences.get(\'preferred_brands\', [])\\n        if product.get(\'brand\') in preferred_brands:\\n            personal_score += 0.2\\n        \\n        # Price preference\\n        price_sensitivity = user_preferences.get(\'price_sensitivity\', 0.5)\\n        product_price = product.get(\'price\', 0)\\n        user_avg_price = context.get(\'avg_order_value\', 100)\\n        \\n        if price_sensitivity < 0.3:  # Price-conscious user\\n            if product_price <= user_avg_price * 0.8:\\n                personal_score += 0.1\\n        elif price_sensitivity > 0.7:  # Premium-oriented user\\n            if product_price >= user_avg_price * 1.2:\\n                personal_score += 0.1\\n        \\n        return personal_score\\n    \\n    def _calculate_behavioral_boost(self, product: Dict[str, Any], \\n                                   context: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate behavioral pattern boost\\"\\"\\"\\n        user_behavior = context.get(\'behavioral_features\', {})\\n        behavioral_score = 0.0\\n        \\n        # Time-based patterns\\n        current_hour = datetime.now().hour\\n        user_peak_hour = context.get(\'peak_hour\', 12)\\n        \\n        # Boost items typically purchased at current time\\n        if abs(current_hour - user_peak_hour) <= 2:\\n            behavioral_score += 0.1\\n        \\n        # Purchase frequency patterns\\n        purchase_frequency = user_behavior.get(\'purchase_frequency\', 0)\\n        if purchase_frequency > 10:  # Frequent buyer\\n            # Boost consumable/replenishable items\\n            if any(keyword in product.get(\'title\', \'\').lower() \\n                   for keyword in [\'refill\', \'pack\', \'bulk\']):\\n                behavioral_score += 0.15\\n        \\n        return behavioral_score\\n    \\n    def _calculate_collaborative_boost(self, product: Dict[str, Any], \\n                                      context: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate collaborative filtering boost\\"\\"\\"\\n        # This would typically use precomputed user similarity scores\\n        # For now, we\'ll use simplified logic\\n        \\n        similar_users_preferences = context.get(\'similar_users_bought\', [])\\n        if product.get(\'id\') in similar_users_preferences:\\n            return 0.2\\n        \\n        return 0.0\\n    \\n    def _apply_diversity_filtering(self, results: List[Dict[str, Any]], \\n                                  limit: int, diversity_threshold: float = 0.3) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Apply diversity filtering to avoid too similar items\\"\\"\\"\\n        if not results:\\n            return results\\n        \\n        diverse_results = [results[0]]  # Always include top result\\n        \\n        for result in results[1:]:\\n            if len(diverse_results) >= limit:\\n                break\\n            \\n            # Check diversity against already selected items\\n            is_diverse = True\\n            result_category = result.get(\'payload\', {}).get(\'category\', \'\')\\n            result_brand = result.get(\'payload\', {}).get(\'brand\', \'\')\\n            \\n            category_count = sum(1 for r in diverse_results \\n                               if r.get(\'payload\', {}).get(\'category\', \'\') == result_category)\\n            brand_count = sum(1 for r in diverse_results \\n                            if r.get(\'payload\', {}).get(\'brand\', \'\') == result_brand)\\n            \\n            # Avoid too many items from same category/brand\\n            if (category_count >= limit * diversity_threshold or \\n                brand_count >= limit * diversity_threshold):\\n                is_diverse = False\\n            \\n            if is_diverse:\\n                diverse_results.append(result)\\n        \\n        return diverse_results\\n```\\n\\n### 2. Performance Optimization\\n\\n```python\\n# retrieval/performance_optimizer.py\\nimport asyncio\\nfrom typing import List, Dict, Any, Optional\\nimport numpy as np\\nimport redis\\nimport json\\nimport hashlib\\nfrom datetime import datetime, timedelta\\nimport logging\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass SearchPerformanceOptimizer:\\n    \\"\\"\\"Optimize search performance through caching and query optimization\\"\\"\\"\\n    \\n    def __init__(self, redis_client: Optional[redis.Redis] = None):\\n        self.redis_client = redis_client\\n        self.cache_ttl = {\\n            \'search_results\': 3600,    # 1 hour\\n            \'user_embeddings\': 86400,  # 24 hours\\n            \'popular_queries\': 7200,   # 2 hours\\n        }\\n        self.query_stats = {}\\n    \\n    async def optimized_search(self, search_func, cache_key: str, \\n                              ttl: int = 3600, *args, **kwargs) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Wrapper for optimized search with caching\\"\\"\\"\\n        \\n        # Try cache first\\n        cached_result = await self._get_cached_result(cache_key)\\n        if cached_result is not None:\\n            logger.debug(f\\"Cache hit for key: {cache_key}\\")\\n            return cached_result\\n        \\n        # Execute search\\n        start_time = datetime.now()\\n        results = await search_func(*args, **kwargs)\\n        execution_time = (datetime.now() - start_time).total_seconds()\\n        \\n        # Cache results\\n        await self._cache_result(cache_key, results, ttl)\\n        \\n        # Update query statistics\\n        self._update_query_stats(cache_key, execution_time, len(results))\\n        \\n        logger.debug(f\\"Search executed in {execution_time:.3f}s, {len(results)} results\\")\\n        return results\\n    \\n    async def _get_cached_result(self, cache_key: str) -> Optional[List[Dict[str, Any]]]:\\n        \\"\\"\\"Retrieve cached search results\\"\\"\\"\\n        if not self.redis_client:\\n            return None\\n        \\n        try:\\n            cached_data = self.redis_client.get(cache_key)\\n            if cached_data:\\n                return json.loads(cached_data)\\n        except Exception as e:\\n            logger.warning(f\\"Cache retrieval failed: {e}\\")\\n        \\n        return None\\n    \\n    async def _cache_result(self, cache_key: str, results: List[Dict[str, Any]], \\n                           ttl: int) -> None:\\n        \\"\\"\\"Cache search results\\"\\"\\"\\n        if not self.redis_client:\\n            return\\n        \\n        try:\\n            # Serialize results (handle numpy arrays)\\n            serializable_results = self._make_serializable(results)\\n            cached_data = json.dumps(serializable_results)\\n            \\n            self.redis_client.setex(cache_key, ttl, cached_data)\\n            logger.debug(f\\"Cached results for key: {cache_key}\\")\\n        except Exception as e:\\n            logger.warning(f\\"Caching failed: {e}\\")\\n    \\n    def _make_serializable(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Convert results to JSON-serializable format\\"\\"\\"\\n        serializable_results = []\\n        \\n        for result in results:\\n            serializable_result = {}\\n            for key, value in result.items():\\n                if isinstance(value, np.ndarray):\\n                    serializable_result[key] = value.tolist()\\n                elif isinstance(value, (np.int64, np.int32)):\\n                    serializable_result[key] = int(value)\\n                elif isinstance(value, (np.float64, np.float32)):\\n                    serializable_result[key] = float(value)\\n                else:\\n                    serializable_result[key] = value\\n            \\n            serializable_results.append(serializable_result)\\n        \\n        return serializable_results\\n    \\n    def _update_query_stats(self, cache_key: str, execution_time: float, \\n                           result_count: int) -> None:\\n        \\"\\"\\"Update query performance statistics\\"\\"\\"\\n        if cache_key not in self.query_stats:\\n            self.query_stats[cache_key] = {\\n                \'count\': 0,\\n                \'total_time\': 0.0,\\n                \'total_results\': 0,\\n                \'avg_time\': 0.0,\\n                \'avg_results\': 0.0\\n            }\\n        \\n        stats = self.query_stats[cache_key]\\n        stats[\'count\'] += 1\\n        stats[\'total_time\'] += execution_time\\n        stats[\'total_results\'] += result_count\\n        stats[\'avg_time\'] = stats[\'total_time\'] / stats[\'count\']\\n        stats[\'avg_results\'] = stats[\'total_results\'] / stats[\'count\']\\n    \\n    def generate_cache_key(self, *args, **kwargs) -> str:\\n        \\"\\"\\"Generate cache key from search parameters\\"\\"\\"\\n        # Create deterministic key from parameters\\n        key_data = {\\n            \'args\': args,\\n            \'kwargs\': kwargs\\n        }\\n        \\n        key_string = json.dumps(key_data, sort_keys=True, default=str)\\n        return hashlib.md5(key_string.encode()).hexdigest()\\n    \\n    async def warm_cache(self, collection_name: str, popular_queries: List[str],\\n                        retriever: BaseVectorRetriever, \\n                        embedding_generator) -> None:\\n        \\"\\"\\"Pre-warm cache with popular queries\\"\\"\\"\\n        logger.info(f\\"Warming cache with {len(popular_queries)} popular queries\\")\\n        \\n        for query in popular_queries:\\n            try:\\n                # Generate query embedding\\n                query_embedding = await embedding_generator.generate_query_embedding(query)\\n                \\n                # Generate cache key\\n                cache_key = self.generate_cache_key(\\n                    \'search\', collection_name, query, limit=20\\n                )\\n                \\n                # Execute search if not cached\\n                cached_result = await self._get_cached_result(cache_key)\\n                if cached_result is None:\\n                    results = await retriever.search(\\n                        collection_name=collection_name,\\n                        query_vector=query_embedding,\\n                        limit=20\\n                    )\\n                    await self._cache_result(cache_key, results, \\n                                           self.cache_ttl[\'search_results\'])\\n                \\n                # Rate limiting to avoid overwhelming the system\\n                await asyncio.sleep(0.1)\\n                \\n            except Exception as e:\\n                logger.warning(f\\"Failed to warm cache for query \'{query}\': {e}\\")\\n        \\n        logger.info(\\"Cache warming completed\\")\\n    \\n    def get_performance_stats(self) -> Dict[str, Any]:\\n        \\"\\"\\"Get performance statistics\\"\\"\\"\\n        total_queries = sum(stats[\'count\'] for stats in self.query_stats.values())\\n        avg_execution_time = np.mean([stats[\'avg_time\'] for stats in self.query_stats.values()]) if self.query_stats else 0\\n        \\n        return {\\n            \'total_queries\': total_queries,\\n            \'unique_query_patterns\': len(self.query_stats),\\n            \'avg_execution_time\': avg_execution_time,\\n            \'query_breakdown\': self.query_stats\\n        }\\n```\\n\\n## Testing and Evaluation\\n\\n```python\\n# tests/test_retrieval_system.py\\nimport pytest\\nimport numpy as np\\nfrom typing import List, Dict, Any\\nimport asyncio\\nimport time\\nfrom retrieval.qdrant_retriever import QdrantRetriever\\nfrom retrieval.hybrid_retriever import HybridRetriever\\n\\nclass RetrievalSystemTester:\\n    \\"\\"\\"Comprehensive testing for retrieval system\\"\\"\\"\\n    \\n    def __init__(self, retriever: BaseVectorRetriever):\\n        self.retriever = retriever\\n        self.test_collection = \\"test_products\\"\\n        self.test_data = self._generate_test_data()\\n    \\n    async def run_all_tests(self) -> Dict[str, Any]:\\n        \\"\\"\\"Run comprehensive test suite\\"\\"\\"\\n        results = {\\n            \'accuracy_tests\': await self._test_search_accuracy(),\\n            \'performance_tests\': await self._test_search_performance(),\\n            \'scalability_tests\': await self._test_scalability(),\\n            \'relevance_tests\': await self._test_relevance_ranking()\\n        }\\n        \\n        return results\\n    \\n    async def _test_search_accuracy(self) -> Dict[str, float]:\\n        \\"\\"\\"Test search accuracy using ground truth data\\"\\"\\"\\n        # Set up test collection\\n        await self.retriever.create_collection(self.test_collection, 384)\\n        await self.retriever.upsert_vectors(self.test_collection, self.test_data)\\n        \\n        accuracy_scores = []\\n        \\n        # Test with known similar items\\n        for test_case in self._get_accuracy_test_cases():\\n            query_vector = test_case[\'query_vector\']\\n            expected_ids = set(test_case[\'expected_ids\'])\\n            \\n            results = await self.retriever.search(\\n                collection_name=self.test_collection,\\n                query_vector=query_vector,\\n                limit=len(expected_ids) * 2\\n            )\\n            \\n            # Calculate accuracy metrics\\n            retrieved_ids = set([r[\'id\'] for r in results[:len(expected_ids)]])\\n            precision = len(retrieved_ids & expected_ids) / len(retrieved_ids) if retrieved_ids else 0\\n            recall = len(retrieved_ids & expected_ids) / len(expected_ids) if expected_ids else 0\\n            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\\n            \\n            accuracy_scores.append({\\n                \'precision\': precision,\\n                \'recall\': recall,\\n                \'f1_score\': f1_score\\n            })\\n        \\n        # Calculate average metrics\\n        avg_precision = np.mean([s[\'precision\'] for s in accuracy_scores])\\n        avg_recall = np.mean([s[\'recall\'] for s in accuracy_scores])\\n        avg_f1 = np.mean([s[\'f1_score\'] for s in accuracy_scores])\\n        \\n        return {\\n            \'precision\': avg_precision,\\n            \'recall\': avg_recall,\\n            \'f1_score\': avg_f1\\n        }\\n    \\n    async def _test_search_performance(self) -> Dict[str, float]:\\n        \\"\\"\\"Test search performance and latency\\"\\"\\"\\n        query_vector = np.random.rand(384)\\n        \\n        # Warm up\\n        await self.retriever.search(self.test_collection, query_vector, limit=10)\\n        \\n        # Performance test\\n        latencies = []\\n        for _ in range(50):\\n            start_time = time.time()\\n            await self.retriever.search(self.test_collection, query_vector, limit=10)\\n            latency = time.time() - start_time\\n            latencies.append(latency)\\n        \\n        return {\\n            \'avg_latency\': np.mean(latencies),\\n            \'p95_latency\': np.percentile(latencies, 95),\\n            \'p99_latency\': np.percentile(latencies, 99),\\n            \'min_latency\': np.min(latencies),\\n            \'max_latency\': np.max(latencies)\\n        }\\n    \\n    async def _test_scalability(self) -> Dict[str, Any]:\\n        \\"\\"\\"Test system scalability with increasing load\\"\\"\\"\\n        results = {}\\n        \\n        # Test concurrent queries\\n        for concurrency in [1, 5, 10, 20]:\\n            query_vector = np.random.rand(384)\\n            \\n            start_time = time.time()\\n            tasks = []\\n            for _ in range(concurrency):\\n                task = self.retriever.search(self.test_collection, query_vector, limit=10)\\n                tasks.append(task)\\n            \\n            await asyncio.gather(*tasks)\\n            total_time = time.time() - start_time\\n            \\n            results[f\'concurrency_{concurrency}\'] = {\\n                \'total_time\': total_time,\\n                \'avg_time_per_query\': total_time / concurrency,\\n                \'queries_per_second\': concurrency / total_time\\n            }\\n        \\n        return results\\n    \\n    async def _test_relevance_ranking(self) -> Dict[str, float]:\\n        \\"\\"\\"Test relevance ranking quality\\"\\"\\"\\n        # This would test if more relevant items appear higher in results\\n        # For now, we\'ll implement a simplified version\\n        \\n        relevance_scores = []\\n        \\n        for test_case in self._get_relevance_test_cases():\\n            query_vector = test_case[\'query_vector\']\\n            relevance_map = test_case[\'relevance_map\']  # id -> relevance_score\\n            \\n            results = await self.retriever.search(\\n                collection_name=self.test_collection,\\n                query_vector=query_vector,\\n                limit=10\\n            )\\n            \\n            # Calculate NDCG (Normalized Discounted Cumulative Gain)\\n            dcg = 0.0\\n            ideal_dcg = 0.0\\n            \\n            # Calculate DCG for retrieved results\\n            for i, result in enumerate(results):\\n                relevance = relevance_map.get(result[\'id\'], 0)\\n                dcg += relevance / np.log2(i + 2)\\n            \\n            # Calculate ideal DCG\\n            ideal_relevances = sorted(relevance_map.values(), reverse=True)\\n            for i, relevance in enumerate(ideal_relevances[:len(results)]):\\n                ideal_dcg += relevance / np.log2(i + 2)\\n            \\n            ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\\n            relevance_scores.append(ndcg)\\n        \\n        return {\\n            \'avg_ndcg\': np.mean(relevance_scores),\\n            \'min_ndcg\': np.min(relevance_scores),\\n            \'max_ndcg\': np.max(relevance_scores)\\n        }\\n    \\n    def _generate_test_data(self) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Generate test data for evaluation\\"\\"\\"\\n        test_data = []\\n        \\n        # Generate synthetic product vectors and metadata\\n        for i in range(1000):\\n            vector = np.random.rand(384)\\n            payload = {\\n                \'id\': f\'product_{i}\',\\n                \'title\': f\'Test Product {i}\',\\n                \'category\': [\'electronics\', \'clothing\', \'books\'][i % 3],\\n                \'brand\': [\'BrandA\', \'BrandB\', \'BrandC\'][i % 3],\\n                \'price\': 10 + (i % 200),\\n                \'rating\': 3.0 + (i % 3)\\n            }\\n            \\n            test_data.append({\\n                \'id\': f\'product_{i}\',\\n                \'vector\': vector,\\n                \'payload\': payload\\n            })\\n        \\n        return test_data\\n    \\n    def _get_accuracy_test_cases(self) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Get test cases for accuracy evaluation\\"\\"\\"\\n        # Create test cases where we know which items should be similar\\n        test_cases = []\\n        \\n        # Electronics category test\\n        electronics_vector = np.random.rand(384)\\n        electronics_ids = [f\'product_{i}\' for i in range(0, 334, 3)]  # Every 3rd electronics item\\n        \\n        test_cases.append({\\n            \'query_vector\': electronics_vector,\\n            \'expected_ids\': electronics_ids[:10]  # Top 10 expected\\n        })\\n        \\n        return test_cases\\n    \\n    def _get_relevance_test_cases(self) -> List[Dict[str, Any]]:\\n        \\"\\"\\"Get test cases for relevance evaluation\\"\\"\\"\\n        test_cases = []\\n        \\n        # Create relevance maps for test queries\\n        query_vector = np.random.rand(384)\\n        relevance_map = {}\\n        \\n        # Assign higher relevance to certain products\\n        for i in range(100):\\n            if i % 10 == 0:  # High relevance\\n                relevance_map[f\'product_{i}\'] = 3\\n            elif i % 5 == 0:  # Medium relevance\\n                relevance_map[f\'product_{i}\'] = 2\\n            else:  # Low relevance\\n                relevance_map[f\'product_{i}\'] = 1\\n        \\n        test_cases.append({\\n            \'query_vector\': query_vector,\\n            \'relevance_map\': relevance_map\\n        })\\n        \\n        return test_cases\\n```\\n\\n## Next Steps\\n\\nIn **Part 4** of this series, we\'ll implement the generation and personalization engine that transforms retrieved products into intelligent, personalized recommendations. We\'ll cover:\\n\\n- **LLM Integration**: Connecting with OpenAI, Anthropic, and local models\\n- **Prompt Engineering**: Crafting effective prompts for recommendation generation\\n- **Personalization Algorithms**: Advanced techniques for user-specific recommendations\\n- **A/B Testing Framework**: Measuring and optimizing recommendation quality\\n\\n### **What We\'ve Accomplished**\\n\\nIn this post, we\'ve built a sophisticated retrieval system:\\n\\n\u2705 **Multi-Database Support**: Implementations for Qdrant, Pinecone, and hybrid approaches\\n\u2705 **Advanced Search Strategies**: Semantic, keyword, and hybrid search with fusion algorithms\\n\u2705 **Contextual Intelligence**: Context-aware search with seasonal, behavioral, and collaborative signals\\n\u2705 **Performance Optimization**: Caching, query optimization, and scalability testing\\n\u2705 **Comprehensive Testing**: Accuracy, performance, and relevance evaluation frameworks\\n\\n### **Before Part 4**\\n\\nEnsure you have:\\n1. Set up your chosen vector database\\n2. Indexed your product catalog with embeddings\\n3. Implemented and tested basic search functionality\\n4. Prepared for LLM integration (API keys, model selection)\\n\\n---\\n\\n*The retrieval system is the engine that finds relevant products. Next, we\'ll build the intelligence layer that transforms these results into personalized recommendations!*"},{"id":"rag-ecommerce-recommendations-part4-generation-personalization","metadata":{"permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part4-generation-personalization","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-08-rag-ecommerce-recommendations-part4-generation-personalization.md","source":"@site/blog/2025-10-08-rag-ecommerce-recommendations-part4-generation-personalization.md","title":"Building Intelligent E-commerce Recommendations with RAG: Part 4 - Generation and Personalization Engine","description":"Welcome to Part 4 of our RAG-powered e-commerce recommendation series! We\'ve built our data pipeline, generated embeddings, and implemented sophisticated retrieval systems. Now we\'ll create the crown jewel: an intelligent generation and personalization engine that transforms raw product matches into compelling, personalized recommendations that drive engagement and conversions.","date":"2025-10-08T00:00:00.000Z","tags":[{"inline":false,"label":"RAG","permalink":"/fullstack-dev/blog/tags/rag","description":"Retrieval-Augmented Generation"},{"inline":false,"label":"E-commerce","permalink":"/fullstack-dev/blog/tags/ecommerce","description":"E-commerce development and strategies"},{"inline":false,"label":"Recommendations","permalink":"/fullstack-dev/blog/tags/recommendations","description":"Recommendation systems and algorithms"},{"inline":false,"label":"Large Language Models","permalink":"/fullstack-dev/blog/tags/llm","description":"Large language models and applications"},{"inline":false,"label":"Personalization","permalink":"/fullstack-dev/blog/tags/personalization","description":"User personalization and customization"},{"inline":false,"label":"OpenAI","permalink":"/fullstack-dev/blog/tags/openai","description":"OpenAI APIs and models"},{"inline":false,"label":"Anthropic","permalink":"/fullstack-dev/blog/tags/anthropic","description":"Anthropic AI models and Claude"},{"inline":false,"label":"Prompt Engineering","permalink":"/fullstack-dev/blog/tags/prompt-engineering","description":"Prompt design and optimization"},{"inline":false,"label":"Generation","permalink":"/fullstack-dev/blog/tags/generation","description":"Content and text generation"}],"readingTime":20.19,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"rag-ecommerce-recommendations-part4-generation-personalization","title":"Building Intelligent E-commerce Recommendations with RAG: Part 4 - Generation and Personalization Engine","authors":["tam"],"tags":["rag","ecommerce","recommendations","llm","personalization","openai","anthropic","prompt-engineering","generation"],"date":"2025-10-08T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part3-retrieval-system"},"nextItem":{"title":"Building Smart Location-Aware Applications: Complete Geo-targeting Implementation with Node.js and React","permalink":"/fullstack-dev/blog/geo-targeting-implementation-nodejs-react"}},"content":"Welcome to Part 4 of our RAG-powered e-commerce recommendation series! We\'ve built our data pipeline, generated embeddings, and implemented sophisticated retrieval systems. Now we\'ll create the crown jewel: an intelligent generation and personalization engine that transforms raw product matches into compelling, personalized recommendations that drive engagement and conversions.\\n\\nThis generation engine leverages large language models to understand context, craft personalized explanations, and create recommendations that feel natural and relevant to each individual user. We\'ll explore advanced prompt engineering, personalization algorithms, and A/B testing frameworks.\\n\\n\x3c!--truncate--\x3e\\n\\n## Generation Engine Architecture\\n\\nOur generation engine combines retrieval results with user context to create personalized, explainable recommendations:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                          Input Processing                            \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502 Retrieved   \u2502  \u2502    User     \u2502  \u2502   Context   \u2502  \u2502   Intent    \u2502 \u2502\\n\u2502  \u2502  Products   \u2502  \u2502   Profile   \u2502  \u2502    Data     \u2502  \u2502 Detection   \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                       Prompt Engineering                            \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   Template  \u2502  \u2502 Personality \u2502  \u2502   Context   \u2502  \u2502   Output    \u2502 \u2502\\n\u2502  \u2502  Selection  \u2502  \u2502   Matching  \u2502  \u2502 Injection   \u2502  \u2502 Formatting  \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        LLM Generation                               \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502   OpenAI    \u2502  \u2502  Anthropic  \u2502  \u2502    Local    \u2502  \u2502   Custom    \u2502 \u2502\\n\u2502  \u2502   Models    \u2502  \u2502   Claude    \u2502  \u2502   Models    \u2502  \u2502   Models    \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                      \u2502\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                    Post-Processing                                  \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\\n\u2502  \u2502 Response    \u2502  \u2502 Validation  \u2502  \u2502 Formatting  \u2502  \u2502  Quality    \u2502 \u2502\\n\u2502  \u2502 Parsing     \u2502  \u2502   Logic     \u2502  \u2502   Polish    \u2502  \u2502 Assurance   \u2502 \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## LLM Integration Layer\\n\\nLet\'s start by implementing a flexible LLM integration layer that supports multiple providers:\\n\\n```python\\n# generation/llm_client.py\\nimport asyncio\\nimport openai\\nimport anthropic\\nfrom typing import List, Dict, Any, Optional, Union\\nimport json\\nimport logging\\nfrom abc import ABC, abstractmethod\\nfrom dataclasses import dataclass\\nfrom enum import Enum\\nimport time\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass ModelProvider(Enum):\\n    OPENAI = \\"openai\\"\\n    ANTHROPIC = \\"anthropic\\"\\n    LOCAL = \\"local\\"\\n    AZURE_OPENAI = \\"azure_openai\\"\\n\\n@dataclass\\nclass GenerationConfig:\\n    temperature: float = 0.7\\n    max_tokens: int = 1000\\n    top_p: float = 0.9\\n    frequency_penalty: float = 0.0\\n    presence_penalty: float = 0.0\\n    stop_sequences: Optional[List[str]] = None\\n\\n@dataclass\\nclass GenerationRequest:\\n    prompt: str\\n    config: GenerationConfig\\n    model: str\\n    system_prompt: Optional[str] = None\\n    context: Optional[Dict[str, Any]] = None\\n\\n@dataclass\\nclass GenerationResponse:\\n    content: str\\n    model: str\\n    provider: ModelProvider\\n    token_usage: Dict[str, int]\\n    latency: float\\n    cost: float\\n\\nclass BaseLLMClient(ABC):\\n    \\"\\"\\"Abstract base class for LLM clients\\"\\"\\"\\n    \\n    @abstractmethod\\n    async def generate(self, request: GenerationRequest) -> GenerationResponse:\\n        pass\\n    \\n    @abstractmethod\\n    def calculate_cost(self, token_usage: Dict[str, int], model: str) -> float:\\n        pass\\n\\nclass OpenAIClient(BaseLLMClient):\\n    \\"\\"\\"OpenAI API client implementation\\"\\"\\"\\n    \\n    def __init__(self, api_key: str, organization: Optional[str] = None):\\n        self.client = openai.AsyncOpenAI(\\n            api_key=api_key,\\n            organization=organization\\n        )\\n        self.pricing = {\\n            \\"gpt-4\\": {\\"input\\": 0.03, \\"output\\": 0.06},\\n            \\"gpt-4-turbo\\": {\\"input\\": 0.01, \\"output\\": 0.03},\\n            \\"gpt-3.5-turbo\\": {\\"input\\": 0.001, \\"output\\": 0.002},\\n            \\"gpt-3.5-turbo-16k\\": {\\"input\\": 0.003, \\"output\\": 0.004}\\n        }\\n    \\n    async def generate(self, request: GenerationRequest) -> GenerationResponse:\\n        \\"\\"\\"Generate response using OpenAI API\\"\\"\\"\\n        start_time = time.time()\\n        \\n        try:\\n            messages = []\\n            \\n            # Add system prompt if provided\\n            if request.system_prompt:\\n                messages.append({\\n                    \\"role\\": \\"system\\",\\n                    \\"content\\": request.system_prompt\\n                })\\n            \\n            # Add main prompt\\n            messages.append({\\n                \\"role\\": \\"user\\",\\n                \\"content\\": request.prompt\\n            })\\n            \\n            # Make API call\\n            response = await self.client.chat.completions.create(\\n                model=request.model,\\n                messages=messages,\\n                temperature=request.config.temperature,\\n                max_tokens=request.config.max_tokens,\\n                top_p=request.config.top_p,\\n                frequency_penalty=request.config.frequency_penalty,\\n                presence_penalty=request.config.presence_penalty,\\n                stop=request.config.stop_sequences\\n            )\\n            \\n            latency = time.time() - start_time\\n            token_usage = {\\n                \\"prompt_tokens\\": response.usage.prompt_tokens,\\n                \\"completion_tokens\\": response.usage.completion_tokens,\\n                \\"total_tokens\\": response.usage.total_tokens\\n            }\\n            \\n            cost = self.calculate_cost(token_usage, request.model)\\n            \\n            return GenerationResponse(\\n                content=response.choices[0].message.content,\\n                model=request.model,\\n                provider=ModelProvider.OPENAI,\\n                token_usage=token_usage,\\n                latency=latency,\\n                cost=cost\\n            )\\n            \\n        except Exception as e:\\n            logger.error(f\\"OpenAI generation failed: {e}\\")\\n            raise\\n    \\n    def calculate_cost(self, token_usage: Dict[str, int], model: str) -> float:\\n        \\"\\"\\"Calculate cost based on token usage\\"\\"\\"\\n        pricing = self.pricing.get(model, self.pricing[\\"gpt-3.5-turbo\\"])\\n        \\n        input_cost = token_usage[\\"prompt_tokens\\"] * pricing[\\"input\\"] / 1000\\n        output_cost = token_usage[\\"completion_tokens\\"] * pricing[\\"output\\"] / 1000\\n        \\n        return input_cost + output_cost\\n\\nclass AnthropicClient(BaseLLMClient):\\n    \\"\\"\\"Anthropic Claude API client implementation\\"\\"\\"\\n    \\n    def __init__(self, api_key: str):\\n        self.client = anthropic.AsyncAnthropic(api_key=api_key)\\n        self.pricing = {\\n            \\"claude-3-opus-20240229\\": {\\"input\\": 0.015, \\"output\\": 0.075},\\n            \\"claude-3-sonnet-20240229\\": {\\"input\\": 0.003, \\"output\\": 0.015},\\n            \\"claude-3-haiku-20240307\\": {\\"input\\": 0.00025, \\"output\\": 0.00125}\\n        }\\n    \\n    async def generate(self, request: GenerationRequest) -> GenerationResponse:\\n        \\"\\"\\"Generate response using Anthropic API\\"\\"\\"\\n        start_time = time.time()\\n        \\n        try:\\n            # Prepare prompt for Claude\\n            full_prompt = request.prompt\\n            if request.system_prompt:\\n                full_prompt = f\\"{request.system_prompt}\\\\n\\\\n{request.prompt}\\"\\n            \\n            # Make API call\\n            response = await self.client.messages.create(\\n                model=request.model,\\n                max_tokens=request.config.max_tokens,\\n                temperature=request.config.temperature,\\n                top_p=request.config.top_p,\\n                stop_sequences=request.config.stop_sequences or [],\\n                messages=[\\n                    {\\"role\\": \\"user\\", \\"content\\": full_prompt}\\n                ]\\n            )\\n            \\n            latency = time.time() - start_time\\n            token_usage = {\\n                \\"prompt_tokens\\": response.usage.input_tokens,\\n                \\"completion_tokens\\": response.usage.output_tokens,\\n                \\"total_tokens\\": response.usage.input_tokens + response.usage.output_tokens\\n            }\\n            \\n            cost = self.calculate_cost(token_usage, request.model)\\n            \\n            return GenerationResponse(\\n                content=response.content[0].text,\\n                model=request.model,\\n                provider=ModelProvider.ANTHROPIC,\\n                token_usage=token_usage,\\n                latency=latency,\\n                cost=cost\\n            )\\n            \\n        except Exception as e:\\n            logger.error(f\\"Anthropic generation failed: {e}\\")\\n            raise\\n    \\n    def calculate_cost(self, token_usage: Dict[str, int], model: str) -> float:\\n        \\"\\"\\"Calculate cost based on token usage\\"\\"\\"\\n        pricing = self.pricing.get(model, self.pricing[\\"claude-3-haiku-20240307\\"])\\n        \\n        input_cost = token_usage[\\"prompt_tokens\\"] * pricing[\\"input\\"] / 1000\\n        output_cost = token_usage[\\"completion_tokens\\"] * pricing[\\"output\\"] / 1000\\n        \\n        return input_cost + output_cost\\n\\nclass LLMClientManager:\\n    \\"\\"\\"Manages multiple LLM clients with fallback and load balancing\\"\\"\\"\\n    \\n    def __init__(self):\\n        self.clients: Dict[ModelProvider, BaseLLMClient] = {}\\n        self.model_mapping: Dict[str, ModelProvider] = {}\\n        self.fallback_order = [ModelProvider.OPENAI, ModelProvider.ANTHROPIC]\\n    \\n    def register_client(self, provider: ModelProvider, client: BaseLLMClient):\\n        \\"\\"\\"Register an LLM client\\"\\"\\"\\n        self.clients[provider] = client\\n        logger.info(f\\"Registered {provider.value} client\\")\\n    \\n    def register_model(self, model_name: str, provider: ModelProvider):\\n        \\"\\"\\"Register a model with its provider\\"\\"\\"\\n        self.model_mapping[model_name] = provider\\n    \\n    async def generate(self, request: GenerationRequest) -> GenerationResponse:\\n        \\"\\"\\"Generate response with fallback support\\"\\"\\"\\n        provider = self.model_mapping.get(request.model)\\n        \\n        if not provider:\\n            raise ValueError(f\\"Unknown model: {request.model}\\")\\n        \\n        # Try primary provider\\n        if provider in self.clients:\\n            try:\\n                return await self.clients[provider].generate(request)\\n            except Exception as e:\\n                logger.warning(f\\"Primary provider {provider.value} failed: {e}\\")\\n        \\n        # Try fallback providers\\n        for fallback_provider in self.fallback_order:\\n            if fallback_provider != provider and fallback_provider in self.clients:\\n                try:\\n                    logger.info(f\\"Trying fallback provider: {fallback_provider.value}\\")\\n                    fallback_request = self._adapt_request_for_provider(request, fallback_provider)\\n                    return await self.clients[fallback_provider].generate(fallback_request)\\n                except Exception as e:\\n                    logger.warning(f\\"Fallback provider {fallback_provider.value} failed: {e}\\")\\n                    continue\\n        \\n        raise Exception(\\"All LLM providers failed\\")\\n    \\n    def _adapt_request_for_provider(self, request: GenerationRequest, \\n                                   provider: ModelProvider) -> GenerationRequest:\\n        \\"\\"\\"Adapt request for different provider\\"\\"\\"\\n        # Map models between providers\\n        model_mappings = {\\n            ModelProvider.OPENAI: {\\n                \\"claude-3-opus-20240229\\": \\"gpt-4\\",\\n                \\"claude-3-sonnet-20240229\\": \\"gpt-3.5-turbo-16k\\",\\n                \\"claude-3-haiku-20240307\\": \\"gpt-3.5-turbo\\"\\n            },\\n            ModelProvider.ANTHROPIC: {\\n                \\"gpt-4\\": \\"claude-3-opus-20240229\\",\\n                \\"gpt-3.5-turbo\\": \\"claude-3-haiku-20240307\\",\\n                \\"gpt-3.5-turbo-16k\\": \\"claude-3-sonnet-20240229\\"\\n            }\\n        }\\n        \\n        adapted_model = model_mappings.get(provider, {}).get(request.model, request.model)\\n        \\n        return GenerationRequest(\\n            prompt=request.prompt,\\n            config=request.config,\\n            model=adapted_model,\\n            system_prompt=request.system_prompt,\\n            context=request.context\\n        )\\n```\\n\\n## Prompt Engineering Framework\\n\\n```python\\n# generation/prompt_engineer.py\\nfrom typing import Dict, Any, List, Optional\\nfrom dataclasses import dataclass\\nfrom enum import Enum\\nimport json\\nimport logging\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass RecommendationType(Enum):\\n    PRODUCT_DISCOVERY = \\"product_discovery\\"\\n    SIMILAR_PRODUCTS = \\"similar_products\\"\\n    PERSONALIZED_SUGGESTIONS = \\"personalized_suggestions\\"\\n    TRENDING_ITEMS = \\"trending_items\\"\\n    BUNDLE_RECOMMENDATIONS = \\"bundle_recommendations\\"\\n    REORDER_SUGGESTIONS = \\"reorder_suggestions\\"\\n\\nclass PersonalityType(Enum):\\n    PROFESSIONAL = \\"professional\\"\\n    FRIENDLY = \\"friendly\\"\\n    ENTHUSIASTIC = \\"enthusiastic\\"\\n    MINIMALIST = \\"minimalist\\"\\n    EXPERT = \\"expert\\"\\n\\n@dataclass\\nclass PromptTemplate:\\n    template: str\\n    required_variables: List[str]\\n    optional_variables: List[str]\\n    output_format: str\\n    personality: PersonalityType\\n\\nclass PromptEngineer:\\n    \\"\\"\\"Advanced prompt engineering for e-commerce recommendations\\"\\"\\"\\n    \\n    def __init__(self):\\n        self.templates = self._initialize_templates()\\n        self.personality_traits = self._initialize_personalities()\\n    \\n    def create_recommendation_prompt(self, \\n                                   recommendation_type: RecommendationType,\\n                                   user_context: Dict[str, Any],\\n                                   products: List[Dict[str, Any]],\\n                                   personality: PersonalityType = PersonalityType.FRIENDLY,\\n                                   additional_context: Optional[Dict[str, Any]] = None) -> str:\\n        \\"\\"\\"Create a comprehensive recommendation prompt\\"\\"\\"\\n        \\n        template = self.templates[recommendation_type][personality]\\n        personality_traits = self.personality_traits[personality]\\n        \\n        # Prepare product information\\n        product_info = self._format_products(products)\\n        \\n        # Prepare user context\\n        user_info = self._format_user_context(user_context)\\n        \\n        # Prepare additional context\\n        context_info = self._format_additional_context(additional_context or {})\\n        \\n        # Build the prompt\\n        prompt = template.template.format(\\n            personality_traits=personality_traits,\\n            user_context=user_info,\\n            products=product_info,\\n            additional_context=context_info,\\n            output_format=template.output_format\\n        )\\n        \\n        return prompt\\n    \\n    def create_explanation_prompt(self,\\n                                 recommended_product: Dict[str, Any],\\n                                 user_context: Dict[str, Any],\\n                                 reasoning_factors: List[str],\\n                                 personality: PersonalityType = PersonalityType.FRIENDLY) -> str:\\n        \\"\\"\\"Create a prompt for generating explanations\\"\\"\\"\\n        \\n        personality_traits = self.personality_traits[personality]\\n        \\n        prompt = f\\"\\"\\"\\n{personality_traits}\\n\\nI need you to explain why this product is recommended for this specific user.\\n\\nUSER PROFILE:\\n{self._format_user_context(user_context)}\\n\\nRECOMMENDED PRODUCT:\\n{self._format_single_product(recommended_product)}\\n\\nREASONING FACTORS:\\n{self._format_reasoning_factors(reasoning_factors)}\\n\\nPlease provide a personalized explanation that:\\n1. Highlights why this product matches their needs\\n2. Mentions specific benefits relevant to their profile\\n3. Addresses any potential concerns\\n4. Keeps the tone {personality.value}\\n\\nFormat your response as a natural, conversational explanation (2-3 sentences).\\n\\"\\"\\"\\n        \\n        return prompt\\n    \\n    def create_comparison_prompt(self,\\n                               products: List[Dict[str, Any]],\\n                               comparison_criteria: List[str],\\n                               user_context: Dict[str, Any],\\n                               personality: PersonalityType = PersonalityType.EXPERT) -> str:\\n        \\"\\"\\"Create a prompt for product comparisons\\"\\"\\"\\n        \\n        personality_traits = self.personality_traits[personality]\\n        \\n        prompt = f\\"\\"\\"\\n{personality_traits}\\n\\nI need you to compare these products for a specific user.\\n\\nUSER PROFILE:\\n{self._format_user_context(user_context)}\\n\\nPRODUCTS TO COMPARE:\\n{self._format_products_for_comparison(products)}\\n\\nCOMPARISON CRITERIA:\\n{\', \'.join(comparison_criteria)}\\n\\nPlease provide a detailed comparison that:\\n1. Compares each product across the specified criteria\\n2. Highlights strengths and weaknesses of each\\n3. Provides a recommendation based on the user\'s profile\\n4. Uses a {personality.value} tone\\n\\nFormat your response as structured comparison with clear recommendations.\\n\\"\\"\\"\\n        \\n        return prompt\\n    \\n    def _initialize_templates(self) -> Dict[RecommendationType, Dict[PersonalityType, PromptTemplate]]:\\n        \\"\\"\\"Initialize prompt templates for different recommendation types and personalities\\"\\"\\"\\n        templates = {}\\n        \\n        # Product Discovery Templates\\n        templates[RecommendationType.PRODUCT_DISCOVERY] = {\\n            PersonalityType.FRIENDLY: PromptTemplate(\\n                template=\\"\\"\\"\\n{personality_traits}\\n\\nI\'m helping a customer discover new products they might love. Here\'s what I know about them:\\n\\nUSER PROFILE:\\n{user_context}\\n\\nAVAILABLE PRODUCTS:\\n{products}\\n\\nADDITIONAL CONTEXT:\\n{additional_context}\\n\\nPlease recommend 3-5 products from the list that would be perfect for this user. For each recommendation:\\n\\n1. **Product Name & Brief Description**\\n2. **Why it\'s perfect for them** (personalized reasoning)\\n3. **Key benefits** they\'ll appreciate\\n4. **Price & value consideration**\\n\\n{output_format}\\n\\"\\"\\",\\n                required_variables=[\\"user_context\\", \\"products\\"],\\n                optional_variables=[\\"additional_context\\"],\\n                output_format=\\"JSON format with product recommendations\\",\\n                personality=PersonalityType.FRIENDLY\\n            ),\\n            \\n            PersonalityType.PROFESSIONAL: PromptTemplate(\\n                template=\\"\\"\\"\\n{personality_traits}\\n\\nBased on the user profile and available product catalog, I need to provide data-driven product recommendations.\\n\\nUSER ANALYSIS:\\n{user_context}\\n\\nPRODUCT CATALOG:\\n{products}\\n\\nCONTEXTUAL FACTORS:\\n{additional_context}\\n\\nPlease provide analytical product recommendations with:\\n\\n1. **Product Selection Rationale**\\n2. **Compatibility Assessment**\\n3. **Value Proposition Analysis**\\n4. **Risk/Benefit Evaluation**\\n\\n{output_format}\\n\\"\\"\\",\\n                required_variables=[\\"user_context\\", \\"products\\"],\\n                optional_variables=[\\"additional_context\\"],\\n                output_format=\\"Structured analytical format\\",\\n                personality=PersonalityType.PROFESSIONAL\\n            )\\n        }\\n        \\n        # Similar Products Templates\\n        templates[RecommendationType.SIMILAR_PRODUCTS] = {\\n            PersonalityType.FRIENDLY: PromptTemplate(\\n                template=\\"\\"\\"\\n{personality_traits}\\n\\nA customer is interested in similar products to what they\'re currently viewing. Help me suggest alternatives!\\n\\nUSER PROFILE:\\n{user_context}\\n\\nSIMILAR PRODUCTS:\\n{products}\\n\\nContext: {additional_context}\\n\\nPlease recommend the best alternatives, explaining:\\n1. **How each product is similar** to their interest\\n2. **What makes each unique** or better\\n3. **Price comparison** and value\\n4. **Why they might prefer** each option\\n\\n{output_format}\\n\\"\\"\\",\\n                required_variables=[\\"user_context\\", \\"products\\"],\\n                optional_variables=[\\"additional_context\\"],\\n                output_format=\\"Friendly recommendation list\\",\\n                personality=PersonalityType.FRIENDLY\\n            )\\n        }\\n        \\n        # Add more templates for other recommendation types...\\n        \\n        return templates\\n    \\n    def _initialize_personalities(self) -> Dict[PersonalityType, str]:\\n        \\"\\"\\"Initialize personality traits for different tones\\"\\"\\"\\n        return {\\n            PersonalityType.FRIENDLY: \\"\\"\\"\\nYou are a helpful, warm, and enthusiastic shopping assistant. You love helping people find products they\'ll genuinely enjoy. You speak conversationally, use occasional emojis, and always consider the human element in your recommendations. You\'re knowledgeable but not overwhelming, and you always keep the customer\'s best interests at heart.\\n\\"\\"\\",\\n            \\n            PersonalityType.PROFESSIONAL: \\"\\"\\"\\nYou are a professional product consultant with deep expertise in e-commerce and consumer behavior. You provide data-driven, analytical recommendations backed by clear reasoning. Your tone is authoritative but approachable, and you focus on providing maximum value through informed decision-making.\\n\\"\\"\\",\\n            \\n            PersonalityType.ENTHUSIASTIC: \\"\\"\\"\\nYou are an excited product expert who absolutely loves discovering amazing finds for customers! You\'re genuinely thrilled about every recommendation and can\'t wait to share why each product is fantastic. Your enthusiasm is contagious, and you help customers get excited about their potential purchases.\\n\\"\\"\\",\\n            \\n            PersonalityType.MINIMALIST: \\"\\"\\"\\nYou are a concise, no-nonsense product advisor. You provide clear, direct recommendations without unnecessary fluff. Every word serves a purpose, and you focus on the most important information customers need to make decisions quickly and confidently.\\n\\"\\"\\",\\n            \\n            PersonalityType.EXPERT: \\"\\"\\"\\nYou are a seasoned industry expert with deep knowledge across multiple product categories. You provide detailed, technical insights while remaining accessible. Your recommendations are backed by expertise, and you help customers understand the nuances that matter most.\\n\\"\\"\\"\\n        }\\n    \\n    def _format_products(self, products: List[Dict[str, Any]]) -> str:\\n        \\"\\"\\"Format products for prompt inclusion\\"\\"\\"\\n        formatted_products = []\\n        \\n        for i, product in enumerate(products, 1):\\n            payload = product.get(\'payload\', product)\\n            \\n            product_text = f\\"\\"\\"\\nProduct {i}:\\n- ID: {payload.get(\'id\', \'N/A\')}\\n- Title: {payload.get(\'title\', \'N/A\')}\\n- Category: {payload.get(\'category\', \'N/A\')}\\n- Brand: {payload.get(\'brand\', \'N/A\')}\\n- Price: ${payload.get(\'price\', \'N/A\')}\\n- Rating: {payload.get(\'rating\', \'N/A\')}/5 ({payload.get(\'review_count\', 0)} reviews)\\n- Description: {payload.get(\'description\', \'N/A\')[:200]}...\\n\\"\\"\\"\\n            if product.get(\'score\'):\\n                product_text += f\\"- Relevance Score: {product[\'score\']:.3f}\\\\n\\"\\n            \\n            formatted_products.append(product_text)\\n        \\n        return \\"\\\\n\\".join(formatted_products)\\n    \\n    def _format_user_context(self, user_context: Dict[str, Any]) -> str:\\n        \\"\\"\\"Format user context for prompt inclusion\\"\\"\\"\\n        context_parts = []\\n        \\n        # Demographics\\n        demographics = user_context.get(\'demographics\', {})\\n        if demographics:\\n            context_parts.append(f\\"Demographics: {demographics}\\")\\n        \\n        # Preferences\\n        preferences = user_context.get(\'preferences\', {})\\n        if preferences:\\n            pref_text = []\\n            if preferences.get(\'preferred_categories\'):\\n                pref_text.append(f\\"Preferred categories: {\', \'.join(preferences[\'preferred_categories\'])}\\")\\n            if preferences.get(\'preferred_brands\'):\\n                pref_text.append(f\\"Preferred brands: {\', \'.join(preferences[\'preferred_brands\'])}\\")\\n            if preferences.get(\'price_sensitivity\'):\\n                price_level = \\"budget-conscious\\" if preferences[\'price_sensitivity\'] < 0.3 else \\\\\\n                             \\"premium-oriented\\" if preferences[\'price_sensitivity\'] > 0.7 else \\"balanced\\"\\n                pref_text.append(f\\"Price preference: {price_level}\\")\\n            \\n            if pref_text:\\n                context_parts.append(\\"Preferences: \\" + \\"; \\".join(pref_text))\\n        \\n        # Behavioral patterns\\n        behavioral = user_context.get(\'behavioral_features\', {})\\n        if behavioral:\\n            behavior_text = []\\n            purchase_freq = behavioral.get(\'purchase_frequency\', 0)\\n            if purchase_freq > 10:\\n                behavior_text.append(\\"frequent buyer\\")\\n            elif purchase_freq > 5:\\n                behavior_text.append(\\"regular customer\\")\\n            else:\\n                behavior_text.append(\\"occasional shopper\\")\\n            \\n            if behavioral.get(\'avg_session_duration\', 0) > 300:\\n                behavior_text.append(\\"detailed researcher\\")\\n            \\n            if behavior_text:\\n                context_parts.append(\\"Shopping behavior: \\" + \\", \\".join(behavior_text))\\n        \\n        # Purchase history summary\\n        if user_context.get(\'recent_purchases\'):\\n            recent = user_context[\'recent_purchases\'][:3]  # Last 3 purchases\\n            context_parts.append(f\\"Recent purchases: {\', \'.join([p.get(\'title\', \'Unknown\') for p in recent])}\\")\\n        \\n        return \\"\\\\n\\".join(context_parts) if context_parts else \\"New customer with limited profile data\\"\\n    \\n    def _format_additional_context(self, context: Dict[str, Any]) -> str:\\n        \\"\\"\\"Format additional context information\\"\\"\\"\\n        context_parts = []\\n        \\n        if context.get(\'season\'):\\n            context_parts.append(f\\"Season: {context[\'season\']}\\")\\n        \\n        if context.get(\'current_trends\'):\\n            context_parts.append(f\\"Current trends: {\', \'.join(context[\'current_trends\'])}\\")\\n        \\n        if context.get(\'inventory_status\'):\\n            context_parts.append(f\\"Inventory considerations: {context[\'inventory_status\']}\\")\\n        \\n        if context.get(\'promotion_info\'):\\n            context_parts.append(f\\"Active promotions: {context[\'promotion_info\']}\\")\\n        \\n        return \\"\\\\n\\".join(context_parts) if context_parts else \\"No additional context\\"\\n    \\n    def _format_single_product(self, product: Dict[str, Any]) -> str:\\n        \\"\\"\\"Format a single product for detailed analysis\\"\\"\\"\\n        payload = product.get(\'payload\', product)\\n        \\n        return f\\"\\"\\"\\nTitle: {payload.get(\'title\', \'N/A\')}\\nCategory: {payload.get(\'category\', \'N/A\')}\\nBrand: {payload.get(\'brand\', \'N/A\')}\\nPrice: ${payload.get(\'price\', \'N/A\')}\\nRating: {payload.get(\'rating\', \'N/A\')}/5 ({payload.get(\'review_count\', 0)} reviews)\\nDescription: {payload.get(\'description\', \'N/A\')}\\nKey Features: {\', \'.join(payload.get(\'features\', []))}\\n\\"\\"\\"\\n    \\n    def _format_reasoning_factors(self, factors: List[str]) -> str:\\n        \\"\\"\\"Format reasoning factors for explanation\\"\\"\\"\\n        return \\"\\\\n\\".join([f\\"- {factor}\\" for factor in factors])\\n    \\n    def _format_products_for_comparison(self, products: List[Dict[str, Any]]) -> str:\\n        \\"\\"\\"Format products specifically for comparison\\"\\"\\"\\n        formatted = []\\n        \\n        for i, product in enumerate(products, 1):\\n            payload = product.get(\'payload\', product)\\n            formatted.append(f\\"\\"\\"\\nOption {i}: {payload.get(\'title\', \'N/A\')}\\n- Brand: {payload.get(\'brand\', \'N/A\')}\\n- Price: ${payload.get(\'price\', \'N/A\')}\\n- Rating: {payload.get(\'rating\', \'N/A\')}/5\\n- Key Features: {\', \'.join(payload.get(\'features\', [])[:3])}\\n\\"\\"\\")\\n        \\n        return \\"\\\\n\\".join(formatted)\\n```\\n\\n## Personalization Engine\\n\\n```python\\n# generation/personalization_engine.py\\nimport numpy as np\\nfrom typing import Dict, Any, List, Optional, Tuple\\nfrom dataclasses import dataclass\\nfrom enum import Enum\\nimport logging\\nfrom datetime import datetime, timedelta\\nimport json\\n\\nlogger = logging.getLogger(__name__)\\n\\nclass PersonalizationStrategy(Enum):\\n    COLLABORATIVE_FILTERING = \\"collaborative_filtering\\"\\n    CONTENT_BASED = \\"content_based\\"\\n    HYBRID = \\"hybrid\\"\\n    CONTEXTUAL = \\"contextual\\"\\n    DEEP_LEARNING = \\"deep_learning\\"\\n\\n@dataclass\\nclass PersonalizationConfig:\\n    strategy: PersonalizationStrategy\\n    weights: Dict[str, float]\\n    min_confidence: float = 0.5\\n    diversity_factor: float = 0.3\\n    novelty_factor: float = 0.2\\n    serendipity_factor: float = 0.1\\n\\n@dataclass\\nclass PersonalizedRecommendation:\\n    product_id: str\\n    score: float\\n    reasoning: List[str]\\n    confidence: float\\n    personalization_factors: Dict[str, float]\\n    explanation: str\\n    metadata: Dict[str, Any]\\n\\nclass PersonalizationEngine:\\n    \\"\\"\\"Advanced personalization engine for recommendation generation\\"\\"\\"\\n    \\n    def __init__(self, config: PersonalizationConfig):\\n        self.config = config\\n        self.user_profiles = {}\\n        self.item_profiles = {}\\n        self.interaction_matrix = {}\\n        \\n    async def personalize_recommendations(self,\\n                                        user_id: str,\\n                                        candidate_products: List[Dict[str, Any]],\\n                                        user_context: Dict[str, Any],\\n                                        additional_context: Optional[Dict[str, Any]] = None) -> List[PersonalizedRecommendation]:\\n        \\"\\"\\"Generate personalized recommendations for a specific user\\"\\"\\"\\n        \\n        # Get user profile\\n        user_profile = await self._get_user_profile(user_id, user_context)\\n        \\n        # Calculate personalization scores for each candidate\\n        personalized_products = []\\n        \\n        for product in candidate_products:\\n            personalization_score = await self._calculate_personalization_score(\\n                user_profile, product, additional_context or {}\\n            )\\n            \\n            if personalization_score.confidence >= self.config.min_confidence:\\n                personalized_products.append(personalization_score)\\n        \\n        # Apply diversity and novelty filters\\n        final_recommendations = self._apply_diversification(\\n            personalized_products, user_profile\\n        )\\n        \\n        # Sort by personalized score\\n        final_recommendations.sort(key=lambda x: x.score, reverse=True)\\n        \\n        return final_recommendations\\n    \\n    async def _get_user_profile(self, user_id: str, context: Dict[str, Any]) -> Dict[str, Any]:\\n        \\"\\"\\"Get or create comprehensive user profile\\"\\"\\"\\n        \\n        if user_id in self.user_profiles:\\n            profile = self.user_profiles[user_id]\\n            # Update with latest context\\n            profile.update(context)\\n        else:\\n            # Create new profile\\n            profile = {\\n                \'user_id\': user_id,\\n                \'preferences\': context.get(\'preferences\', {}),\\n                \'behavioral_features\': context.get(\'behavioral_features\', {}),\\n                \'demographic_features\': context.get(\'demographics\', {}),\\n                \'interaction_history\': context.get(\'interaction_history\', []),\\n                \'purchase_history\': context.get(\'purchase_history\', []),\\n                \'created_at\': datetime.utcnow(),\\n                \'last_updated\': datetime.utcnow()\\n            }\\n            self.user_profiles[user_id] = profile\\n        \\n        # Enrich profile with derived features\\n        profile = await self._enrich_user_profile(profile)\\n        \\n        return profile\\n    \\n    async def _enrich_user_profile(self, profile: Dict[str, Any]) -> Dict[str, Any]:\\n        \\"\\"\\"Enrich user profile with derived features\\"\\"\\"\\n        \\n        # Calculate user preferences vector\\n        profile[\'preference_vector\'] = self._calculate_preference_vector(profile)\\n        \\n        # Calculate user clusters/segments\\n        profile[\'user_segment\'] = self._determine_user_segment(profile)\\n        \\n        # Calculate temporal patterns\\n        profile[\'temporal_patterns\'] = self._analyze_temporal_patterns(profile)\\n        \\n        # Calculate price sensitivity\\n        profile[\'price_sensitivity\'] = self._calculate_price_sensitivity(profile)\\n        \\n        # Calculate brand affinity\\n        profile[\'brand_affinity\'] = self._calculate_brand_affinity(profile)\\n        \\n        return profile\\n    \\n    async def _calculate_personalization_score(self,\\n                                             user_profile: Dict[str, Any],\\n                                             product: Dict[str, Any],\\n                                             context: Dict[str, Any]) -> PersonalizedRecommendation:\\n        \\"\\"\\"Calculate comprehensive personalization score\\"\\"\\"\\n        \\n        product_payload = product.get(\'payload\', product)\\n        base_score = product.get(\'score\', 0.5)\\n        \\n        # Calculate different personalization factors\\n        factors = {}\\n        reasoning = []\\n        \\n        # 1. Content-based similarity\\n        content_score = self._calculate_content_similarity(user_profile, product_payload)\\n        factors[\'content_similarity\'] = content_score\\n        if content_score > 0.7:\\n            reasoning.append(f\\"Matches your interest in {product_payload.get(\'category\', \'this category\')}\\")\\n        \\n        # 2. Collaborative filtering score\\n        collaborative_score = self._calculate_collaborative_score(user_profile, product_payload)\\n        factors[\'collaborative_filtering\'] = collaborative_score\\n        if collaborative_score > 0.6:\\n            reasoning.append(\\"Popular among users with similar preferences\\")\\n        \\n        # 3. Behavioral alignment\\n        behavioral_score = self._calculate_behavioral_alignment(user_profile, product_payload)\\n        factors[\'behavioral_alignment\'] = behavioral_score\\n        if behavioral_score > 0.6:\\n            reasoning.append(\\"Matches your shopping behavior patterns\\")\\n        \\n        # 4. Contextual relevance\\n        contextual_score = self._calculate_contextual_relevance(user_profile, product_payload, context)\\n        factors[\'contextual_relevance\'] = contextual_score\\n        if contextual_score > 0.6:\\n            reasoning.append(\\"Relevant to your current context\\")\\n        \\n        # 5. Price alignment\\n        price_score = self._calculate_price_alignment(user_profile, product_payload)\\n        factors[\'price_alignment\'] = price_score\\n        if price_score > 0.7:\\n            reasoning.append(\\"Within your preferred price range\\")\\n        \\n        # 6. Brand preference\\n        brand_score = self._calculate_brand_preference(user_profile, product_payload)\\n        factors[\'brand_preference\'] = brand_score\\n        if brand_score > 0.7:\\n            reasoning.append(f\\"From {product_payload.get(\'brand\', \'a brand\')} you\'ve shown interest in\\")\\n        \\n        # 7. Temporal relevance\\n        temporal_score = self._calculate_temporal_relevance(user_profile, product_payload, context)\\n        factors[\'temporal_relevance\'] = temporal_score\\n        if temporal_score > 0.6:\\n            reasoning.append(\\"Timely for your current needs\\")\\n        \\n        # 8. Social proof\\n        social_score = self._calculate_social_proof(product_payload)\\n        factors[\'social_proof\'] = social_score\\n        if social_score > 0.8:\\n            reasoning.append(\\"Highly rated by other customers\\")\\n        \\n        # Calculate weighted personalization score\\n        personalization_weights = {\\n            \'content_similarity\': 0.20,\\n            \'collaborative_filtering\': 0.15,\\n            \'behavioral_alignment\': 0.15,\\n            \'contextual_relevance\': 0.10,\\n            \'price_alignment\': 0.15,\\n            \'brand_preference\': 0.10,\\n            \'temporal_relevance\': 0.10,\\n            \'social_proof\': 0.05\\n        }\\n        \\n        personalization_score = sum(\\n            factors[factor] * weight \\n            for factor, weight in personalization_weights.items()\\n        )\\n        \\n        # Combine with base relevance score\\n        final_score = 0.6 * base_score + 0.4 * personalization_score\\n        \\n        # Calculate confidence based on data availability\\n        confidence = self._calculate_confidence(user_profile, factors)\\n        \\n        # Generate explanation\\n        explanation = self._generate_explanation(reasoning, product_payload, user_profile)\\n        \\n        return PersonalizedRecommendation(\\n            product_id=product_payload.get(\'id\'),\\n            score=final_score,\\n            reasoning=reasoning,\\n            confidence=confidence,\\n            personalization_factors=factors,\\n            explanation=explanation,\\n            metadata={\\n                \'base_score\': base_score,\\n                \'personalization_score\': personalization_score,\\n                \'weights_used\': personalization_weights\\n            }\\n        )\\n    \\n    def _calculate_preference_vector(self, profile: Dict[str, Any]) -> np.ndarray:\\n        \\"\\"\\"Calculate user preference vector from interaction history\\"\\"\\"\\n        # Simplified implementation - in production, use more sophisticated methods\\n        categories = [\'electronics\', \'clothing\', \'books\', \'home\', \'sports\', \'beauty\']\\n        vector = np.zeros(len(categories))\\n        \\n        purchase_history = profile.get(\'purchase_history\', [])\\n        for purchase in purchase_history:\\n            category = purchase.get(\'category\', \'\').lower()\\n            if category in categories:\\n                idx = categories.index(category)\\n                vector[idx] += 1\\n        \\n        # Normalize\\n        if np.sum(vector) > 0:\\n            vector = vector / np.sum(vector)\\n        \\n        return vector\\n    \\n    def _determine_user_segment(self, profile: Dict[str, Any]) -> str:\\n        \\"\\"\\"Determine user segment based on behavior and preferences\\"\\"\\"\\n        behavioral = profile.get(\'behavioral_features\', {})\\n        \\n        purchase_freq = behavioral.get(\'purchase_frequency\', 0)\\n        avg_order_value = behavioral.get(\'avg_order_value\', 0)\\n        session_duration = behavioral.get(\'avg_session_duration\', 0)\\n        \\n        if purchase_freq > 10 and avg_order_value > 100:\\n            return \\"premium_frequent\\"\\n        elif purchase_freq > 10:\\n            return \\"frequent_budget\\"\\n        elif avg_order_value > 100:\\n            return \\"premium_occasional\\"\\n        elif session_duration > 300:\\n            return \\"researcher\\"\\n        else:\\n            return \\"casual\\"\\n    \\n    def _analyze_temporal_patterns(self, profile: Dict[str, Any]) -> Dict[str, Any]:\\n        \\"\\"\\"Analyze user\'s temporal shopping patterns\\"\\"\\"\\n        # Simplified implementation\\n        return {\\n            \'preferred_shopping_time\': \'evening\',\\n            \'seasonal_preferences\': [\'winter_clothing\', \'summer_outdoor\'],\\n            \'frequency_pattern\': \'monthly\'\\n        }\\n    \\n    def _calculate_price_sensitivity(self, profile: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate user\'s price sensitivity\\"\\"\\"\\n        purchase_history = profile.get(\'purchase_history\', [])\\n        if not purchase_history:\\n            return 0.5  # Default neutral sensitivity\\n        \\n        prices = [p.get(\'price\', 0) for p in purchase_history]\\n        avg_price = np.mean(prices) if prices else 0\\n        \\n        # Normalize to 0-1 scale (simplified)\\n        return min(avg_price / 200, 1.0)  # Assuming 200 is high price threshold\\n    \\n    def _calculate_brand_affinity(self, profile: Dict[str, Any]) -> Dict[str, float]:\\n        \\"\\"\\"Calculate user\'s brand preferences\\"\\"\\"\\n        purchase_history = profile.get(\'purchase_history\', [])\\n        brand_counts = {}\\n        \\n        for purchase in purchase_history:\\n            brand = purchase.get(\'brand\', \'unknown\')\\n            brand_counts[brand] = brand_counts.get(brand, 0) + 1\\n        \\n        total_purchases = len(purchase_history)\\n        brand_affinity = {}\\n        \\n        for brand, count in brand_counts.items():\\n            brand_affinity[brand] = count / total_purchases if total_purchases > 0 else 0\\n        \\n        return brand_affinity\\n    \\n    def _calculate_content_similarity(self, user_profile: Dict[str, Any], \\n                                    product: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate content-based similarity\\"\\"\\"\\n        user_preferences = user_profile.get(\'preferences\', {})\\n        \\n        score = 0.0\\n        \\n        # Category preference\\n        preferred_categories = user_preferences.get(\'preferred_categories\', [])\\n        product_category = product.get(\'category\', \'\')\\n        if product_category in preferred_categories:\\n            score += 0.4\\n        \\n        # Brand preference\\n        brand_affinity = user_profile.get(\'brand_affinity\', {})\\n        product_brand = product.get(\'brand\', \'\')\\n        brand_score = brand_affinity.get(product_brand, 0)\\n        score += 0.3 * brand_score\\n        \\n        # Price alignment\\n        price_sensitivity = user_profile.get(\'price_sensitivity\', 0.5)\\n        product_price = product.get(\'price\', 0)\\n        # Simplified price scoring\\n        if product_price < 50 and price_sensitivity < 0.5:\\n            score += 0.3\\n        elif product_price > 100 and price_sensitivity > 0.7:\\n            score += 0.3\\n        elif 50 <= product_price <= 100:\\n            score += 0.2\\n        \\n        return min(score, 1.0)\\n    \\n    def _calculate_collaborative_score(self, user_profile: Dict[str, Any],\\n                                     product: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate collaborative filtering score\\"\\"\\"\\n        # Simplified implementation - in production, use matrix factorization\\n        user_segment = user_profile.get(\'user_segment\', \'casual\')\\n        \\n        # Mock collaborative scores based on user segment\\n        collaborative_scores = {\\n            \'premium_frequent\': 0.8,\\n            \'frequent_budget\': 0.6,\\n            \'premium_occasional\': 0.7,\\n            \'researcher\': 0.65,\\n            \'casual\': 0.5\\n        }\\n        \\n        return collaborative_scores.get(user_segment, 0.5)\\n    \\n    def _calculate_behavioral_alignment(self, user_profile: Dict[str, Any],\\n                                      product: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate behavioral pattern alignment\\"\\"\\"\\n        behavioral = user_profile.get(\'behavioral_features\', {})\\n        \\n        # Shopping frequency alignment\\n        purchase_freq = behavioral.get(\'purchase_frequency\', 0)\\n        product_type = product.get(\'category\', \'\').lower()\\n        \\n        if purchase_freq > 10 and product_type in [\'consumables\', \'electronics\']:\\n            return 0.8\\n        elif purchase_freq < 5 and product_type in [\'luxury\', \'furniture\']:\\n            return 0.7\\n        else:\\n            return 0.5\\n    \\n    def _calculate_contextual_relevance(self, user_profile: Dict[str, Any],\\n                                      product: Dict[str, Any],\\n                                      context: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate contextual relevance score\\"\\"\\"\\n        score = 0.5  # Base score\\n        \\n        # Seasonal relevance\\n        current_season = context.get(\'season\', \'unknown\')\\n        product_category = product.get(\'category\', \'\').lower()\\n        \\n        seasonal_relevance = {\\n            \'winter\': [\'coats\', \'heating\', \'warm_clothing\'],\\n            \'summer\': [\'swimwear\', \'outdoor\', \'cooling\'],\\n            \'spring\': [\'gardening\', \'light_clothing\'],\\n            \'fall\': [\'jackets\', \'school_supplies\']\\n        }\\n        \\n        if current_season in seasonal_relevance:\\n            relevant_categories = seasonal_relevance[current_season]\\n            if any(cat in product_category for cat in relevant_categories):\\n                score += 0.3\\n        \\n        # Time-based relevance\\n        current_hour = datetime.now().hour\\n        if 9 <= current_hour <= 17 and \'office\' in product_category:\\n            score += 0.2\\n        elif 18 <= current_hour <= 22 and \'entertainment\' in product_category:\\n            score += 0.2\\n        \\n        return min(score, 1.0)\\n    \\n    def _calculate_price_alignment(self, user_profile: Dict[str, Any],\\n                                 product: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate price alignment with user preferences\\"\\"\\"\\n        user_price_sensitivity = user_profile.get(\'price_sensitivity\', 0.5)\\n        product_price = product.get(\'price\', 0)\\n        \\n        # Calculate price score based on user\'s typical spending\\n        purchase_history = user_profile.get(\'purchase_history\', [])\\n        if purchase_history:\\n            avg_user_price = np.mean([p.get(\'price\', 0) for p in purchase_history])\\n        else:\\n            avg_user_price = 50  # Default assumption\\n        \\n        price_ratio = product_price / avg_user_price if avg_user_price > 0 else 1\\n        \\n        if user_price_sensitivity < 0.3:  # Budget-conscious\\n            return max(0, 1 - (price_ratio - 0.8) / 0.5) if price_ratio > 0.8 else 1.0\\n        elif user_price_sensitivity > 0.7:  # Premium-oriented\\n            return min(1, price_ratio / 1.5) if price_ratio < 1.5 else 1.0\\n        else:  # Balanced\\n            return max(0, 1 - abs(price_ratio - 1) / 0.5)\\n    \\n    def _calculate_brand_preference(self, user_profile: Dict[str, Any],\\n                                  product: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate brand preference alignment\\"\\"\\"\\n        brand_affinity = user_profile.get(\'brand_affinity\', {})\\n        product_brand = product.get(\'brand\', \'\')\\n        \\n        return brand_affinity.get(product_brand, 0.3)  # Default slight preference\\n    \\n    def _calculate_temporal_relevance(self, user_profile: Dict[str, Any],\\n                                    product: Dict[str, Any],\\n                                    context: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate temporal relevance\\"\\"\\"\\n        temporal_patterns = user_profile.get(\'temporal_patterns\', {})\\n        \\n        # Check if product aligns with user\'s shopping patterns\\n        current_time = datetime.now().hour\\n        preferred_time = temporal_patterns.get(\'preferred_shopping_time\', \'evening\')\\n        \\n        if preferred_time == \'morning\' and 6 <= current_time <= 12:\\n            return 0.8\\n        elif preferred_time == \'evening\' and 18 <= current_time <= 23:\\n            return 0.8\\n        else:\\n            return 0.5\\n    \\n    def _calculate_social_proof(self, product: Dict[str, Any]) -> float:\\n        \\"\\"\\"Calculate social proof score\\"\\"\\"\\n        rating = product.get(\'rating\', 0)\\n        review_count = product.get(\'review_count\', 0)\\n        \\n        # Normalize rating (0-5 to 0-1)\\n        rating_score = rating / 5 if rating > 0 else 0\\n        \\n        # Review count bonus (logarithmic scale)\\n        review_bonus = min(np.log(review_count + 1) / np.log(1000), 0.3) if review_count > 0 else 0\\n        \\n        return min(rating_score + review_bonus, 1.0)\\n    \\n    def _calculate_confidence(self, user_profile: Dict[str, Any], \\n                            factors: Dict[str, float]) -> float:\\n        \\"\\"\\"Calculate confidence in personalization\\"\\"\\"\\n        # Base confidence on amount of user data available\\n        data_points = 0\\n        \\n        if user_profile.get(\'purchase_history\'):\\n            data_points += len(user_profile[\'purchase_history\'])\\n        \\n        if user_profile.get(\'interaction_history\'):\\n            data_points += min(len(user_profile[\'interaction_history\']), 50)\\n        \\n        if user_profile.get(\'preferences\'):\\n            data_points += 10  # Explicit preferences are valuable\\n        \\n        # Normalize to 0-1 scale\\n        data_confidence = min(data_points / 100, 1.0)\\n        \\n        # Factor in score variance (more consistent scores = higher confidence)\\n        score_variance = np.var(list(factors.values()))\\n        variance_penalty = min(score_variance, 0.3)\\n        \\n        return max(data_confidence - variance_penalty, 0.1)\\n    \\n    def _generate_explanation(self, reasoning: List[str], \\n                            product: Dict[str, Any],\\n                            user_profile: Dict[str, Any]) -> str:\\n        \\"\\"\\"Generate human-readable explanation\\"\\"\\"\\n        if not reasoning:\\n            return f\\"This {product.get(\'category\', \'product\')} might interest you\\"\\n        \\n        primary_reason = reasoning[0]\\n        \\n        if len(reasoning) == 1:\\n            return primary_reason\\n        elif len(reasoning) == 2:\\n            return f\\"{primary_reason} and {reasoning[1].lower()}\\"\\n        else:\\n            return f\\"{primary_reason}, {reasoning[1].lower()}, and {len(reasoning)-2} other factors\\"\\n    \\n    def _apply_diversification(self, recommendations: List[PersonalizedRecommendation],\\n                             user_profile: Dict[str, Any]) -> List[PersonalizedRecommendation]:\\n        \\"\\"\\"Apply diversification to avoid echo chamber effect\\"\\"\\"\\n        if len(recommendations) <= 3:\\n            return recommendations\\n        \\n        diversified = []\\n        category_counts = {}\\n        brand_counts = {}\\n        \\n        # Sort by score first\\n        recommendations.sort(key=lambda x: x.score, reverse=True)\\n        \\n        for rec in recommendations:\\n            # Get product info (simplified access)\\n            category = rec.metadata.get(\'category\', \'unknown\')\\n            brand = rec.metadata.get(\'brand\', \'unknown\')\\n            \\n            # Apply diversity constraints\\n            max_per_category = max(len(recommendations) // 4, 2)\\n            max_per_brand = max(len(recommendations) // 6, 1)\\n            \\n            if (category_counts.get(category, 0) < max_per_category and\\n                brand_counts.get(brand, 0) < max_per_brand):\\n                \\n                diversified.append(rec)\\n                category_counts[category] = category_counts.get(category, 0) + 1\\n                brand_counts[brand] = brand_counts.get(brand, 0) + 1\\n        \\n        return diversified\\n```\\n\\n## Next Steps\\n\\nIn **Part 5** (final part) of this series, we\'ll focus on production deployment, monitoring, and optimization. We\'ll cover:\\n\\n- **Production Architecture**: Scaling strategies and infrastructure design\\n- **Performance Monitoring**: Tracking recommendation quality and system performance\\n- **A/B Testing Framework**: Measuring and optimizing recommendation effectiveness\\n- **Cost Optimization**: Strategies for managing LLM and infrastructure costs\\n- **Continuous Improvement**: Feedback loops and model updates\\n\\n### **What We\'ve Accomplished**\\n\\nIn this post, we\'ve built an intelligent generation and personalization engine:\\n\\n\u2705 **Flexible LLM Integration**: Support for OpenAI, Anthropic, and local models with fallback\\n\u2705 **Advanced Prompt Engineering**: Sophisticated prompts for different personalities and use cases\\n\u2705 **Comprehensive Personalization**: Multi-factor personalization with confidence scoring\\n\u2705 **Explainable Recommendations**: Clear reasoning and human-readable explanations\\n\u2705 **Diversification Logic**: Preventing echo chambers and ensuring variety\\n\\n### **Before Part 5**\\n\\nMake sure you have:\\n1. Integrated your chosen LLM provider\\n2. Tested prompt templates with your product data\\n3. Implemented basic personalization logic\\n4. Prepared production infrastructure planning\\n\\n---\\n\\n*The generation engine transforms raw search results into intelligent, personalized experiences. In our final post, we\'ll make it production-ready and continuously improving!*"},{"id":"geo-targeting-implementation-nodejs-react","metadata":{"permalink":"/fullstack-dev/blog/geo-targeting-implementation-nodejs-react","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-07-geo-targeting-implementation-nodejs-react.md","source":"@site/blog/2025-10-07-geo-targeting-implementation-nodejs-react.md","title":"Building Smart Location-Aware Applications: Complete Geo-targeting Implementation with Node.js and React","description":"Modern applications need to deliver personalized experiences based on user location. Whether you\'re implementing regional pricing, content localization, compliance restrictions, or location-based features, geo-targeting is essential for creating relevant user experiences.","date":"2025-10-07T00:00:00.000Z","tags":[{"inline":false,"label":"Geo Targeting","permalink":"/fullstack-dev/blog/tags/geo-targeting","description":"Geographic targeting and location-based services"},{"inline":false,"label":"Geolocation","permalink":"/fullstack-dev/blog/tags/geolocation","description":"Geolocation services and APIs"},{"inline":false,"label":"Node.js","permalink":"/fullstack-dev/blog/tags/nodejs","description":"Node.js runtime and development"},{"inline":false,"label":"NestJS","permalink":"/fullstack-dev/blog/tags/nestjs","description":"NestJS framework for Node.js applications"},{"inline":false,"label":"React","permalink":"/fullstack-dev/blog/tags/react","description":"React framework and component development"},{"inline":false,"label":"Next.js","permalink":"/fullstack-dev/blog/tags/nextjs","description":"Next.js framework and related topics"},{"inline":false,"label":"IP Geolocation","permalink":"/fullstack-dev/blog/tags/ip-geolocation","description":"IP-based geolocation services"},{"inline":false,"label":"Location Based Services","permalink":"/fullstack-dev/blog/tags/location-based-services","description":"Location-aware application features"},{"inline":false,"label":"Personalization","permalink":"/fullstack-dev/blog/tags/personalization","description":"User personalization and customization"}],"readingTime":14.48,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"geo-targeting-implementation-nodejs-react","title":"Building Smart Location-Aware Applications: Complete Geo-targeting Implementation with Node.js and React","authors":["tam"],"tags":["geo-targeting","geolocation","nodejs","nestjs","react","nextjs","ip-geolocation","location-based-services","personalization"]},"unlisted":false,"prevItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 4 - Generation and Personalization Engine","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part4-generation-personalization"},"nextItem":{"title":"GitOps in Practice: Deploying Node.js Microservices to GCP GKE with ArgoCD and Kustomize","permalink":"/fullstack-dev/blog/gitops-microservices-nodejs-gcp-practical-guide"}},"content":"Modern applications need to deliver personalized experiences based on user location. Whether you\'re implementing regional pricing, content localization, compliance restrictions, or location-based features, geo-targeting is essential for creating relevant user experiences.\\n\\nThis comprehensive guide demonstrates how to implement robust geo-targeting functionality in a Node.js/NestJS backend with React/Next.js frontend, covering everything from basic location detection to advanced geo-fencing and privacy compliance.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Why Geo-targeting Matters\\n\\nGeo-targeting enables applications to:\\n\\n- **Personalize Content**: Show relevant information based on location\\n- **Implement Regional Pricing**: Different pricing for different markets\\n- **Ensure Compliance**: GDPR, data residency, and regional regulations\\n- **Optimize Performance**: Route users to nearest servers/CDN\\n- **Enhance Security**: Detect suspicious location changes\\n- **Improve Conversions**: Location-specific offers and content\\n\\n## Architecture Overview\\n\\nOur geo-targeting system consists of multiple layers:\\n\\n```mermaid\\ngraph TD\\n    A[User Request] --\x3e B[CDN/Load Balancer]\\n    B --\x3e C[Geo Detection Middleware]\\n    C --\x3e D[Location Cache]\\n    C --\x3e E[IP Geolocation APIs]\\n    C --\x3e F[Browser Geolocation]\\n    \\n    G[Geo Context Service] --\x3e H[Database Rules]\\n    G --\x3e I[Content Personalization]\\n    G --\x3e J[Restriction Checking]\\n    \\n    C --\x3e G\\n    I --\x3e K[Cached Response]\\n    K --\x3e L[User Experience]\\n```\\n\\n## Step 1: Backend Implementation with NestJS\\n\\n### Geo-targeting Service\\n\\nLet\'s start with a comprehensive geolocation service that handles multiple detection methods:\\n\\n```typescript\\n// src/geotargeting/geotargeting.service.ts\\nimport { Injectable, Logger } from \'@nestjs/common\';\\nimport { ConfigService } from \'@nestjs/config\';\\nimport { Request } from \'express\';\\nimport geoip from \'geoip-lite\';\\n\\nexport interface LocationInfo {\\n  ip: string;\\n  country: string;\\n  countryCode: string;\\n  region: string;\\n  city: string;\\n  latitude: number;\\n  longitude: number;\\n  timezone: string;\\n  accuracy: \'high\' | \'medium\' | \'low\';\\n  source: \'browser\' | \'ip\' | \'header\' | \'default\';\\n}\\n\\n@Injectable()\\nexport class GeotargetingService {\\n  private readonly logger = new Logger(GeotargetingService.name);\\n\\n  constructor(private configService: ConfigService) {}\\n\\n  async detectLocationFromRequest(request: Request): Promise<LocationInfo> {\\n    const ip = this.extractIP(request);\\n    \\n    // Try CDN headers first (most accurate)\\n    const headerLocation = this.getLocationFromHeaders(request);\\n    if (headerLocation) {\\n      return {\\n        ...headerLocation,\\n        ip,\\n        accuracy: \'high\',\\n        source: \'header\',\\n      };\\n    }\\n\\n    // Fallback to IP geolocation\\n    const geoData = geoip.lookup(ip);\\n    if (geoData) {\\n      return {\\n        ip,\\n        country: geoData.country,\\n        countryCode: geoData.country,\\n        region: geoData.region,\\n        city: geoData.city,\\n        latitude: geoData.ll[0],\\n        longitude: geoData.ll[1],\\n        timezone: geoData.timezone,\\n        accuracy: \'medium\',\\n        source: \'ip\',\\n      };\\n    }\\n\\n    return this.getDefaultLocation(ip);\\n  }\\n\\n  private extractIP(request: Request): string {\\n    const forwarded = request.headers[\'x-forwarded-for\'] as string;\\n    const realIP = request.headers[\'x-real-ip\'] as string;\\n    \\n    if (forwarded) {\\n      return forwarded.split(\',\')[0].trim();\\n    }\\n    \\n    return realIP || request.connection?.remoteAddress || \'127.0.0.1\';\\n  }\\n\\n  private getLocationFromHeaders(request: Request): Partial<LocationInfo> | null {\\n    // Cloudflare headers\\n    const cfCountry = request.headers[\'cf-ipcountry\'] as string;\\n    const cfRegion = request.headers[\'cf-region\'] as string;\\n    const cfCity = request.headers[\'cf-city\'] as string;\\n\\n    if (cfCountry && cfCountry !== \'XX\') {\\n      return {\\n        country: cfCountry,\\n        countryCode: cfCountry,\\n        region: cfRegion || \'\',\\n        city: cfCity || \'\',\\n        latitude: 0,\\n        longitude: 0,\\n        timezone: \'\',\\n      };\\n    }\\n\\n    return null;\\n  }\\n\\n  getGeoContent(location: LocationInfo): any {\\n    return {\\n      currency: this.getCurrencyForCountry(location.countryCode),\\n      language: this.getLanguageForCountry(location.countryCode),\\n      timezone: location.timezone,\\n      pricing: this.getPricingTier(location.countryCode),\\n    };\\n  }\\n\\n  private getCurrencyForCountry(countryCode: string): string {\\n    const currencyMap: Record<string, string> = {\\n      \'US\': \'USD\', \'GB\': \'GBP\', \'DE\': \'EUR\', \'FR\': \'EUR\',\\n      \'JP\': \'JPY\', \'CA\': \'CAD\', \'AU\': \'AUD\', \'IN\': \'INR\',\\n    };\\n    return currencyMap[countryCode] || \'USD\';\\n  }\\n\\n  private getLanguageForCountry(countryCode: string): string {\\n    const languageMap: Record<string, string> = {\\n      \'US\': \'en\', \'GB\': \'en\', \'DE\': \'de\', \'FR\': \'fr\',\\n      \'ES\': \'es\', \'JP\': \'ja\', \'CN\': \'zh\', \'IN\': \'en\',\\n    };\\n    return languageMap[countryCode] || \'en\';\\n  }\\n\\n  private getPricingTier(countryCode: string): string {\\n    const developedCountries = [\'US\', \'GB\', \'DE\', \'FR\', \'CA\', \'AU\', \'JP\'];\\n    const emergingMarkets = [\'IN\', \'BR\', \'MX\', \'TH\', \'PL\'];\\n    \\n    if (developedCountries.includes(countryCode)) {\\n      return \'premium\';\\n    } else if (emergingMarkets.includes(countryCode)) {\\n      return \'standard\';\\n    }\\n    return \'basic\';\\n  }\\n}\\n```\\n\\n### Geo-targeting Middleware\\n\\nCreate middleware to automatically detect and attach location data to requests:\\n\\n```typescript\\n// src/geotargeting/middleware/geo-targeting.middleware.ts\\nimport { Injectable, NestMiddleware } from \'@nestjs/common\';\\nimport { Request, Response, NextFunction } from \'express\';\\nimport { GeotargetingService } from \'../geotargeting.service\';\\n\\n@Injectable()\\nexport class GeoTargetingMiddleware implements NestMiddleware {\\n  constructor(private readonly geotargetingService: GeotargetingService) {}\\n\\n  async use(req: Request, res: Response, next: NextFunction) {\\n    try {\\n      const location = await this.geotargetingService.detectLocationFromRequest(req);\\n      const geoContent = this.geotargetingService.getGeoContent(location);\\n      \\n      req[\'geoLocation\'] = location;\\n      req[\'geoContent\'] = geoContent;\\n      \\n      // Set response headers for client-side access\\n      res.setHeader(\'X-User-Country\', location.countryCode);\\n      res.setHeader(\'X-User-Currency\', geoContent.currency);\\n      res.setHeader(\'X-User-Language\', geoContent.language);\\n      \\n      next();\\n    } catch (error) {\\n      console.error(\'Geo-targeting middleware error:\', error);\\n      next(); // Continue without geo-targeting\\n    }\\n  }\\n}\\n```\\n\\n### Geo-targeting Controller\\n\\n```typescript\\n// src/geotargeting/geotargeting.controller.ts\\nimport { Controller, Get, Post, Body, Param, UseGuards } from \'@nestjs/common\';\\nimport { ApiTags, ApiOperation } from \'@nestjs/swagger\';\\nimport { GeotargetingService, LocationInfo } from \'./geotargeting.service\';\\nimport { GeoLocation } from \'./decorators/geo-targeting.decorator\';\\n\\n@ApiTags(\'Geo-targeting\')\\n@Controller(\'api/geo\')\\nexport class GeotargetingController {\\n  constructor(private readonly geotargetingService: GeotargetingService) {}\\n\\n  @Get(\'location\')\\n  @ApiOperation({ summary: \'Get current user location\' })\\n  async getCurrentLocation(@GeoLocation() location: LocationInfo) {\\n    return {\\n      success: true,\\n      data: location,\\n    };\\n  }\\n\\n  @Get(\'content\')\\n  @ApiOperation({ summary: \'Get geo-specific content\' })\\n  async getGeoContent(@GeoLocation() location: LocationInfo) {\\n    const content = this.geotargetingService.getGeoContent(location);\\n    return {\\n      success: true,\\n      data: content,\\n    };\\n  }\\n\\n  @Get(\'pricing/:product\')\\n  @ApiOperation({ summary: \'Get geo-specific pricing\' })\\n  async getGeoPricing(\\n    @Param(\'product\') product: string,\\n    @GeoLocation() location: LocationInfo\\n  ) {\\n    const pricing = await this.geotargetingService.getGeoPricing(\\n      product,\\n      location.countryCode\\n    );\\n    return {\\n      success: true,\\n      data: pricing,\\n    };\\n  }\\n}\\n```\\n\\n### Parameter Decorator\\n\\n```typescript\\n// src/geotargeting/decorators/geo-targeting.decorator.ts\\nimport { createParamDecorator, ExecutionContext } from \'@nestjs/common\';\\n\\nexport const GeoLocation = createParamDecorator(\\n  (data: unknown, ctx: ExecutionContext) => {\\n    const request = ctx.switchToHttp().getRequest();\\n    return request[\'geoLocation\'];\\n  },\\n);\\n\\nexport const GeoContent = createParamDecorator(\\n  (data: unknown, ctx: ExecutionContext) => {\\n    const request = ctx.switchToHttp().getRequest();\\n    return request[\'geoContent\'];\\n  },\\n);\\n```\\n\\n## Step 2: Frontend Implementation with React\\n\\n### Geolocation Hook\\n\\nCreate a comprehensive React hook for handling geolocation:\\n\\n```typescript\\n// hooks/useGeoTargeting.ts\\nimport { useState, useEffect, useCallback } from \'react\';\\n\\nexport interface GeoTargetingData {\\n  location: {\\n    latitude?: number;\\n    longitude?: number;\\n    country?: string;\\n    countryCode?: string;\\n    region?: string;\\n    city?: string;\\n  } | null;\\n  content: {\\n    currency: string;\\n    language: string;\\n    pricing: string;\\n  };\\n  loading: boolean;\\n  error: string | null;\\n}\\n\\nexport const useGeoTargeting = () => {\\n  const [geoData, setGeoData] = useState<GeoTargetingData>({\\n    location: null,\\n    content: {\\n      currency: \'USD\',\\n      language: \'en\',\\n      pricing: \'standard\',\\n    },\\n    loading: true,\\n    error: null,\\n  });\\n\\n  const fetchGeoData = useCallback(async () => {\\n    try {\\n      setGeoData(prev => ({ ...prev, loading: true, error: null }));\\n\\n      // Try browser geolocation first\\n      let browserLocation = null;\\n      try {\\n        browserLocation = await getCurrentPosition();\\n      } catch (error) {\\n        console.warn(\'Browser geolocation failed:\', error);\\n      }\\n\\n      // Get server-side geo data\\n      const response = await fetch(\'/api/geo/content\');\\n      const result = await response.json();\\n\\n      if (!response.ok) {\\n        throw new Error(result.message || \'Failed to fetch geo data\');\\n      }\\n\\n      setGeoData({\\n        location: {\\n          ...result.data.location,\\n          ...(browserLocation && {\\n            latitude: browserLocation.latitude,\\n            longitude: browserLocation.longitude,\\n          }),\\n        },\\n        content: result.data.content,\\n        loading: false,\\n        error: null,\\n      });\\n    } catch (error) {\\n      const errorMessage = error instanceof Error ? error.message : \'Unknown error\';\\n      setGeoData(prev => ({\\n        ...prev,\\n        loading: false,\\n        error: errorMessage,\\n      }));\\n    }\\n  }, []);\\n\\n  const getCurrentPosition = (): Promise<{ latitude: number; longitude: number }> => {\\n    return new Promise((resolve, reject) => {\\n      if (!navigator.geolocation) {\\n        reject(new Error(\'Geolocation is not supported\'));\\n        return;\\n      }\\n\\n      navigator.geolocation.getCurrentPosition(\\n        (position) => {\\n          resolve({\\n            latitude: position.coords.latitude,\\n            longitude: position.coords.longitude,\\n          });\\n        },\\n        (error) => {\\n          reject(error);\\n        },\\n        {\\n          enableHighAccuracy: true,\\n          timeout: 10000,\\n          maximumAge: 300000, // 5 minutes\\n        }\\n      );\\n    });\\n  };\\n\\n  useEffect(() => {\\n    fetchGeoData();\\n  }, [fetchGeoData]);\\n\\n  return {\\n    ...geoData,\\n    refresh: fetchGeoData,\\n  };\\n};\\n```\\n\\n### Geo-targeted Components\\n\\n#### Currency Display Component\\n\\n```tsx\\n// components/CurrencyDisplay.tsx\\nimport React from \'react\';\\nimport { useGeoTargeting } from \'../hooks/useGeoTargeting\';\\n\\ninterface CurrencyDisplayProps {\\n  amount: number;\\n  className?: string;\\n}\\n\\nconst CURRENCY_RATES: Record<string, number> = {\\n  USD: 1,     EUR: 0.85,   GBP: 0.73,   JPY: 110,\\n  CAD: 1.25,  AUD: 1.35,   INR: 74,     CNY: 6.45,\\n};\\n\\nconst formatCurrency = (amount: number, currency: string): string => {\\n  const convertedAmount = amount * (CURRENCY_RATES[currency] || 1);\\n  \\n  return new Intl.NumberFormat(\'en-US\', {\\n    style: \'currency\',\\n    currency: currency,\\n    minimumFractionDigits: currency === \'JPY\' ? 0 : 2,\\n  }).format(convertedAmount);\\n};\\n\\nexport const CurrencyDisplay: React.FC<CurrencyDisplayProps> = ({\\n  amount,\\n  className = \'\',\\n}) => {\\n  const { content, loading } = useGeoTargeting();\\n\\n  if (loading) {\\n    return <span className={`animate-pulse ${className}`}>$--</span>;\\n  }\\n\\n  return (\\n    <span className={className}>\\n      {formatCurrency(amount, content.currency)}\\n    </span>\\n  );\\n};\\n```\\n\\n#### Location Restriction Component\\n\\n```tsx\\n// components/LocationRestriction.tsx\\nimport React from \'react\';\\nimport { useGeoTargeting } from \'../hooks/useGeoTargeting\';\\n\\ninterface LocationRestrictionProps {\\n  children: React.ReactNode;\\n  allowedCountries?: string[];\\n  blockedCountries?: string[];\\n  fallback?: React.ReactNode;\\n  showMessage?: boolean;\\n}\\n\\nexport const LocationRestriction: React.FC<LocationRestrictionProps> = ({\\n  children,\\n  allowedCountries,\\n  blockedCountries,\\n  fallback,\\n  showMessage = true,\\n}) => {\\n  const { location, loading, error } = useGeoTargeting();\\n\\n  if (loading) {\\n    return (\\n      <div className=\\"flex items-center justify-center p-4\\">\\n        <div className=\\"animate-spin rounded-full h-6 w-6 border-b-2 border-blue-600\\"></div>\\n        <span className=\\"ml-2\\">Checking location...</span>\\n      </div>\\n    );\\n  }\\n\\n  if (error || !location?.countryCode) {\\n    return fallback || <>{children}</>;\\n  }\\n\\n  const isAllowed = !allowedCountries || allowedCountries.includes(location.countryCode);\\n  const isBlocked = blockedCountries && blockedCountries.includes(location.countryCode);\\n\\n  if (!isAllowed || isBlocked) {\\n    if (!showMessage) return null;\\n    \\n    return (\\n      <div className=\\"p-4 bg-yellow-50 border border-yellow-200 rounded-md\\">\\n        <p className=\\"text-yellow-800\\">\\n          This content is not available in your region ({location.country || location.countryCode}).\\n        </p>\\n      </div>\\n    );\\n  }\\n\\n  return <>{children}</>;\\n};\\n```\\n\\n#### Geo-targeted Pricing Component\\n\\n```tsx\\n// components/GeoPricing.tsx\\nimport React, { useState, useEffect } from \'react\';\\nimport { useGeoTargeting } from \'../hooks/useGeoTargeting\';\\nimport { CurrencyDisplay } from \'./CurrencyDisplay\';\\n\\ninterface GeoPricingProps {\\n  productId: string;\\n  basePrice: number;\\n  className?: string;\\n}\\n\\ninterface PricingData {\\n  price: number;\\n  discount?: number;\\n  promotional?: boolean;\\n  message?: string;\\n}\\n\\nexport const GeoPricing: React.FC<GeoPricingProps> = ({\\n  productId,\\n  basePrice,\\n  className = \'\',\\n}) => {\\n  const { location, content, loading } = useGeoTargeting();\\n  const [pricing, setPricing] = useState<PricingData>({ price: basePrice });\\n\\n  useEffect(() => {\\n    if (!loading && location?.countryCode) {\\n      fetchGeoPricing();\\n    }\\n  }, [location, loading]);\\n\\n  const fetchGeoPricing = async () => {\\n    try {\\n      const response = await fetch(`/api/geo/pricing/${productId}`);\\n      const result = await response.json();\\n      \\n      if (result.success) {\\n        setPricing(result.data);\\n      }\\n    } catch (error) {\\n      console.error(\'Error fetching geo pricing:\', error);\\n    }\\n  };\\n\\n  if (loading) {\\n    return (\\n      <div className={`animate-pulse ${className}`}>\\n        <div className=\\"h-6 bg-gray-200 rounded w-20\\"></div>\\n      </div>\\n    );\\n  }\\n\\n  return (\\n    <div className={className}>\\n      <div className=\\"flex items-center gap-2\\">\\n        {pricing.discount && (\\n          <span className=\\"text-sm text-gray-500 line-through\\">\\n            <CurrencyDisplay amount={basePrice} />\\n          </span>\\n        )}\\n        <span className=\\"text-lg font-bold\\">\\n          <CurrencyDisplay amount={pricing.price} />\\n        </span>\\n        {pricing.discount && (\\n          <span className=\\"text-sm text-green-600 bg-green-100 px-2 py-1 rounded\\">\\n            {pricing.discount}% off\\n          </span>\\n        )}\\n      </div>\\n      \\n      {pricing.promotional && (\\n        <p className=\\"text-sm text-blue-600 mt-1\\">\\n          {pricing.message || `Special pricing for ${location?.country}!`}\\n        </p>\\n      )}\\n      \\n      {content.pricing !== \'premium\' && (\\n        <p className=\\"text-xs text-gray-500 mt-1\\">\\n          Price adjusted for your region\\n        </p>\\n      )}\\n    </div>\\n  );\\n};\\n```\\n\\n## Step 3: Advanced Features Implementation\\n\\n### Location-based A/B Testing\\n\\n```typescript\\n// services/geo-ab-testing.ts\\nexport interface ABTestVariant {\\n  id: string;\\n  name: string;\\n  config: any;\\n  countries?: string[];\\n  regions?: string[];\\n}\\n\\nexport class GeoABTestingService {\\n  private experiments: Map<string, ABTestVariant[]> = new Map();\\n\\n  addExperiment(experimentId: string, variants: ABTestVariant[]): void {\\n    this.experiments.set(experimentId, variants);\\n  }\\n\\n  getVariantForLocation(\\n    experimentId: string,\\n    countryCode: string,\\n    region?: string,\\n    userId?: string\\n  ): ABTestVariant | null {\\n    const variants = this.experiments.get(experimentId);\\n    if (!variants) return null;\\n\\n    // Filter variants by geo restrictions\\n    const eligibleVariants = variants.filter(variant => {\\n      if (variant.countries && !variant.countries.includes(countryCode)) {\\n        return false;\\n      }\\n      if (variant.regions && region && !variant.regions.includes(region)) {\\n        return false;\\n      }\\n      return true;\\n    });\\n\\n    if (eligibleVariants.length === 0) return null;\\n\\n    // Use consistent hashing for user assignment\\n    const hash = this.hashString(`${userId || \'anonymous\'}-${countryCode}`);\\n    const index = hash % eligibleVariants.length;\\n    \\n    return eligibleVariants[index];\\n  }\\n\\n  private hashString(str: string): number {\\n    let hash = 0;\\n    for (let i = 0; i < str.length; i++) {\\n      const char = str.charCodeAt(i);\\n      hash = ((hash << 5) - hash) + char;\\n      hash = hash & hash;\\n    }\\n    return Math.abs(hash);\\n  }\\n}\\n```\\n\\n### Geo-fencing Implementation\\n\\n```typescript\\n// services/geofencing.service.ts\\nexport interface GeofenceArea {\\n  id: string;\\n  name: string;\\n  center: { lat: number; lng: number };\\n  radius: number; // in meters\\n  triggers: GeofenceTrigger[];\\n}\\n\\nexport interface GeofenceTrigger {\\n  type: \'enter\' | \'exit\' | \'dwell\';\\n  action: string;\\n  data?: any;\\n}\\n\\nexport class GeofencingService {\\n  private geofences: Map<string, GeofenceArea> = new Map();\\n  private userStates: Map<string, { inside: Set<string>; lastUpdate: number }> = new Map();\\n\\n  addGeofence(geofence: GeofenceArea): void {\\n    this.geofences.set(geofence.id, geofence);\\n  }\\n\\n  checkGeofences(\\n    userId: string,\\n    latitude: number,\\n    longitude: number\\n  ): GeofenceTrigger[] {\\n    const triggers: GeofenceTrigger[] = [];\\n    const currentState = this.userStates.get(userId) || { \\n      inside: new Set(), \\n      lastUpdate: 0 \\n    };\\n    \\n    const currentlyInside = new Set<string>();\\n\\n    for (const [id, geofence] of this.geofences) {\\n      const distance = this.calculateDistance(\\n        latitude,\\n        longitude,\\n        geofence.center.lat,\\n        geofence.center.lng\\n      );\\n\\n      const isInside = distance <= geofence.radius;\\n      const wasInside = currentState.inside.has(id);\\n\\n      if (isInside) {\\n        currentlyInside.add(id);\\n      }\\n\\n      // Check for enter/exit events\\n      if (isInside && !wasInside) {\\n        triggers.push(...geofence.triggers.filter(t => t.type === \'enter\'));\\n      } else if (!isInside && wasInside) {\\n        triggers.push(...geofence.triggers.filter(t => t.type === \'exit\'));\\n      } else if (isInside && wasInside) {\\n        // Check for dwell events\\n        const dwellTime = Date.now() - currentState.lastUpdate;\\n        const dwellTriggers = geofence.triggers.filter(\\n          t => t.type === \'dwell\' && dwellTime >= (t.data?.minDwellTime || 0)\\n        );\\n        triggers.push(...dwellTriggers);\\n      }\\n    }\\n\\n    // Update user state\\n    this.userStates.set(userId, {\\n      inside: currentlyInside,\\n      lastUpdate: Date.now(),\\n    });\\n\\n    return triggers;\\n  }\\n\\n  private calculateDistance(\\n    lat1: number,\\n    lng1: number,\\n    lat2: number,\\n    lng2: number\\n  ): number {\\n    const R = 6371e3; // Earth\'s radius in meters\\n    const \u03c61 = (lat1 * Math.PI) / 180;\\n    const \u03c62 = (lat2 * Math.PI) / 180;\\n    const \u0394\u03c6 = ((lat2 - lat1) * Math.PI) / 180;\\n    const \u0394\u03bb = ((lng2 - lng1) * Math.PI) / 180;\\n\\n    const a =\\n      Math.sin(\u0394\u03c6 / 2) * Math.sin(\u0394\u03c6 / 2) +\\n      Math.cos(\u03c61) * Math.cos(\u03c62) * Math.sin(\u0394\u03bb / 2) * Math.sin(\u0394\u03bb / 2);\\n    const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));\\n\\n    return R * c;\\n  }\\n}\\n```\\n\\n## Step 4: Privacy and Compliance\\n\\n### GDPR Compliance Implementation\\n\\n```typescript\\n// services/geo-privacy.service.ts\\n@Injectable()\\nexport class GeoPrivacyService {\\n  async checkComplianceRequirements(countryCode: string): Promise<{\\n    requiresConsent: boolean;\\n    dataRetentionDays: number;\\n    anonymizationRequired: boolean;\\n  }> {\\n    const gdprCountries = [\\n      \'AT\', \'BE\', \'BG\', \'HR\', \'CY\', \'CZ\', \'DK\', \'EE\', \'FI\', \'FR\',\\n      \'DE\', \'GR\', \'HU\', \'IE\', \'IT\', \'LV\', \'LT\', \'LU\', \'MT\', \'NL\',\\n      \'PL\', \'PT\', \'RO\', \'SK\', \'SI\', \'ES\', \'SE\'\\n    ];\\n\\n    const ccpaStates = [\'CA\']; // California\\n    const isGDPR = gdprCountries.includes(countryCode);\\n    const isCCPA = ccpaStates.includes(countryCode);\\n\\n    return {\\n      requiresConsent: isGDPR || isCCPA,\\n      dataRetentionDays: isGDPR ? 90 : 365,\\n      anonymizationRequired: isGDPR,\\n    };\\n  }\\n\\n  anonymizeLocationData(data: any): any {\\n    return {\\n      ...data,\\n      ip: this.anonymizeIP(data.ip),\\n      latitude: this.roundCoordinate(data.latitude, 1), // Reduce precision\\n      longitude: this.roundCoordinate(data.longitude, 1),\\n    };\\n  }\\n\\n  private anonymizeIP(ip: string): string {\\n    const parts = ip.split(\'.\');\\n    return parts.length === 4 ? `${parts[0]}.${parts[1]}.${parts[2]}.0` : ip;\\n  }\\n\\n  private roundCoordinate(coord: number, precision: number): number {\\n    const factor = Math.pow(10, precision);\\n    return Math.round(coord * factor) / factor;\\n  }\\n}\\n```\\n\\n### Privacy-aware Frontend Component\\n\\n```tsx\\n// components/LocationConsent.tsx\\nimport React, { useState, useEffect } from \'react\';\\n\\ninterface LocationConsentProps {\\n  onConsent: (granted: boolean) => void;\\n  requiredForFeature?: string;\\n}\\n\\nexport const LocationConsent: React.FC<LocationConsentProps> = ({\\n  onConsent,\\n  requiredForFeature,\\n}) => {\\n  const [showConsent, setShowConsent] = useState(false);\\n\\n  useEffect(() => {\\n    const consent = localStorage.getItem(\'geo-consent\');\\n    if (!consent) {\\n      setShowConsent(true);\\n    } else {\\n      onConsent(consent === \'granted\');\\n    }\\n  }, [onConsent]);\\n\\n  const handleConsent = (granted: boolean) => {\\n    localStorage.setItem(\'geo-consent\', granted ? \'granted\' : \'denied\');\\n    setShowConsent(false);\\n    onConsent(granted);\\n  };\\n\\n  if (!showConsent) return null;\\n\\n  return (\\n    <div className=\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\">\\n      <div className=\\"bg-white p-6 rounded-lg max-w-md mx-4\\">\\n        <h3 className=\\"text-lg font-semibold mb-4\\">Location Access</h3>\\n        <p className=\\"text-gray-600 mb-4\\">\\n          {requiredForFeature \\n            ? `${requiredForFeature} requires access to your location to provide personalized content and pricing.`\\n            : \'We use your location to provide personalized content, pricing, and comply with regional regulations.\'\\n          }\\n        </p>\\n        <p className=\\"text-sm text-gray-500 mb-6\\">\\n          Your location data is processed securely and in compliance with privacy regulations.\\n          You can withdraw consent at any time in your privacy settings.\\n        </p>\\n        <div className=\\"flex gap-3\\">\\n          <button\\n            onClick={() => handleConsent(true)}\\n            className=\\"flex-1 bg-blue-600 text-white py-2 px-4 rounded hover:bg-blue-700\\"\\n          >\\n            Allow Location Access\\n          </button>\\n          <button\\n            onClick={() => handleConsent(false)}\\n            className=\\"flex-1 bg-gray-300 text-gray-700 py-2 px-4 rounded hover:bg-gray-400\\"\\n          >\\n            Use Default Location\\n          </button>\\n        </div>\\n      </div>\\n    </div>\\n  );\\n};\\n```\\n\\n## Step 5: Performance Optimization\\n\\n### Caching Strategy with Redis\\n\\n```typescript\\n// services/geo-cache.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { InjectRedis } from \'@nestjs-modules/ioredis\';\\nimport { Redis } from \'ioredis\';\\n\\n@Injectable()\\nexport class GeoCacheService {\\n  constructor(@InjectRedis() private readonly redis: Redis) {}\\n\\n  async cacheLocationData(\\n    ip: string,\\n    data: any,\\n    ttlSeconds: number = 3600\\n  ): Promise<void> {\\n    const key = `geo:location:${ip}`;\\n    await this.redis.setex(key, ttlSeconds, JSON.stringify(data));\\n  }\\n\\n  async getCachedLocation(ip: string): Promise<any | null> {\\n    const key = `geo:location:${ip}`;\\n    const cached = await this.redis.get(key);\\n    return cached ? JSON.parse(cached) : null;\\n  }\\n\\n  async cacheGeoContent(\\n    countryCode: string,\\n    content: any,\\n    ttlSeconds: number = 1800\\n  ): Promise<void> {\\n    const key = `geo:content:${countryCode}`;\\n    await this.redis.setex(key, ttlSeconds, JSON.stringify(content));\\n  }\\n\\n  async getCachedContent(countryCode: string): Promise<any | null> {\\n    const key = `geo:content:${countryCode}`;\\n    const cached = await this.redis.get(key);\\n    return cached ? JSON.parse(cached) : null;\\n  }\\n}\\n```\\n\\n## Step 6: Testing Your Implementation\\n\\n### Unit Tests for Geo-targeting Service\\n\\n```typescript\\n// geotargeting.service.spec.ts\\nimport { Test, TestingModule } from \'@nestjs/testing\';\\nimport { GeotargetingService } from \'./geotargeting.service\';\\nimport { ConfigService } from \'@nestjs/config\';\\n\\ndescribe(\'GeotargetingService\', () => {\\n  let service: GeotargetingService;\\n\\n  beforeEach(async () => {\\n    const module: TestingModule = await Test.createTestingModule({\\n      providers: [\\n        GeotargetingService,\\n        {\\n          provide: ConfigService,\\n          useValue: {\\n            get: jest.fn(),\\n          },\\n        },\\n      ],\\n    }).compile();\\n\\n    service = module.get<GeotargetingService>(GeotargetingService);\\n  });\\n\\n  describe(\'detectLocationFromRequest\', () => {\\n    it(\'should detect location from Cloudflare headers\', async () => {\\n      const mockRequest = {\\n        headers: {\\n          \'cf-ipcountry\': \'US\',\\n          \'cf-region\': \'CA\',\\n          \'cf-city\': \'San Francisco\',\\n          \'x-forwarded-for\': \'192.168.1.1\',\\n        },\\n        connection: {},\\n      } as any;\\n\\n      const location = await service.detectLocationFromRequest(mockRequest);\\n\\n      expect(location.countryCode).toBe(\'US\');\\n      expect(location.region).toBe(\'CA\');\\n      expect(location.city).toBe(\'San Francisco\');\\n      expect(location.source).toBe(\'header\');\\n      expect(location.accuracy).toBe(\'high\');\\n    });\\n\\n    it(\'should fallback to IP geolocation when headers are missing\', async () => {\\n      const mockRequest = {\\n        headers: {},\\n        connection: { remoteAddress: \'8.8.8.8\' },\\n      } as any;\\n\\n      const location = await service.detectLocationFromRequest(mockRequest);\\n\\n      expect(location.ip).toBe(\'8.8.8.8\');\\n      expect(location.source).toBe(\'ip\');\\n    });\\n  });\\n\\n  describe(\'getGeoContent\', () => {\\n    it(\'should return correct currency for US\', () => {\\n      const location = {\\n        countryCode: \'US\',\\n        timezone: \'America/Los_Angeles\',\\n      } as any;\\n\\n      const content = service.getGeoContent(location);\\n\\n      expect(content.currency).toBe(\'USD\');\\n      expect(content.language).toBe(\'en\');\\n      expect(content.pricing).toBe(\'premium\');\\n    });\\n\\n    it(\'should return correct content for emerging markets\', () => {\\n      const location = {\\n        countryCode: \'IN\',\\n        timezone: \'Asia/Kolkata\',\\n      } as any;\\n\\n      const content = service.getGeoContent(location);\\n\\n      expect(content.currency).toBe(\'INR\');\\n      expect(content.pricing).toBe(\'standard\');\\n    });\\n  });\\n});\\n```\\n\\n### React Testing Library Tests\\n\\n```typescript\\n// useGeoTargeting.test.ts\\nimport { renderHook, waitFor } from \'@testing-library/react\';\\nimport { useGeoTargeting } from \'./useGeoTargeting\';\\n\\n// Mock fetch\\nglobal.fetch = jest.fn();\\n\\ndescribe(\'useGeoTargeting\', () => {\\n  beforeEach(() => {\\n    jest.clearAllMocks();\\n    // Mock geolocation\\n    const mockGeolocation = {\\n      getCurrentPosition: jest.fn(),\\n    };\\n    Object.defineProperty(global.navigator, \'geolocation\', {\\n      value: mockGeolocation,\\n      writable: true,\\n    });\\n  });\\n\\n  it(\'should fetch geo data successfully\', async () => {\\n    const mockGeoData = {\\n      success: true,\\n      data: {\\n        location: { countryCode: \'US\', country: \'United States\' },\\n        content: { currency: \'USD\', language: \'en\', pricing: \'premium\' },\\n      },\\n    };\\n\\n    (fetch as jest.Mock).mockResolvedValueOnce({\\n      ok: true,\\n      json: () => Promise.resolve(mockGeoData),\\n    });\\n\\n    const { result } = renderHook(() => useGeoTargeting());\\n\\n    expect(result.current.loading).toBe(true);\\n\\n    await waitFor(() => {\\n      expect(result.current.loading).toBe(false);\\n    });\\n\\n    expect(result.current.location?.countryCode).toBe(\'US\');\\n    expect(result.current.content.currency).toBe(\'USD\');\\n    expect(result.current.error).toBeNull();\\n  });\\n\\n  it(\'should handle fetch errors gracefully\', async () => {\\n    (fetch as jest.Mock).mockRejectedValueOnce(new Error(\'Network error\'));\\n\\n    const { result } = renderHook(() => useGeoTargeting());\\n\\n    await waitFor(() => {\\n      expect(result.current.loading).toBe(false);\\n    });\\n\\n    expect(result.current.error).toBe(\'Network error\');\\n  });\\n});\\n```\\n\\n## Production Deployment Considerations\\n\\n### Environment Configuration\\n\\n```typescript\\n// config/geo.config.ts\\nexport default () => ({\\n  geo: {\\n    enableBrowserGeolocation: process.env.ENABLE_BROWSER_GEOLOCATION === \'true\',\\n    ipApiKey: process.env.IP_GEOLOCATION_API_KEY,\\n    cacheTimeout: parseInt(process.env.GEO_CACHE_TIMEOUT || \'3600\'),\\n    enableGeoFencing: process.env.ENABLE_GEOFENCING === \'true\',\\n    privacyMode: process.env.GEO_PRIVACY_MODE || \'standard\', // strict, standard, minimal\\n    maxLocationHistory: parseInt(process.env.MAX_LOCATION_HISTORY || \'100\'),\\n  },\\n});\\n```\\n\\n### CDN Integration\\n\\n```nginx\\n# nginx.conf for CDN geo headers\\nlocation / {\\n    # Add geo headers for application use\\n    proxy_set_header X-Real-IP $remote_addr;\\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n    proxy_set_header X-Country-Code $geoip_country_code;\\n    proxy_set_header X-Region $geoip_region;\\n    proxy_set_header X-City $geoip_city;\\n    \\n    proxy_pass http://backend;\\n}\\n```\\n\\n## Best Practices and Security\\n\\n1. **Privacy First**: Always request consent before accessing precise location data\\n2. **Fallback Strategy**: Implement graceful degradation when location detection fails\\n3. **Cache Wisely**: Cache geo data appropriately to balance performance and accuracy\\n4. **Security**: Validate and sanitize all location data inputs\\n5. **Compliance**: Stay updated with regional privacy regulations\\n6. **Performance**: Use CDN geo headers when available for better performance\\n7. **Testing**: Test with VPNs and different IP ranges to ensure accuracy\\n\\n## Conclusion\\n\\nThis comprehensive geo-targeting implementation provides a solid foundation for building location-aware applications. The modular approach allows you to implement only the features you need while maintaining flexibility for future enhancements.\\n\\nKey benefits of this implementation:\\n- **Multiple detection methods** for maximum accuracy\\n- **Privacy-compliant** data handling\\n- **Performance optimized** with caching strategies\\n- **Flexible** and extensible architecture\\n- **Production-ready** with comprehensive error handling\\n\\nStart with the basic location detection and gradually add advanced features like geo-fencing and A/B testing as your application requirements grow."},{"id":"gitops-microservices-nodejs-gcp-practical-guide","metadata":{"permalink":"/fullstack-dev/blog/gitops-microservices-nodejs-gcp-practical-guide","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-07-gitops-microservices-nodejs-gcp-practical-guide.md","source":"@site/blog/2025-10-07-gitops-microservices-nodejs-gcp-practical-guide.md","title":"GitOps in Practice: Deploying Node.js Microservices to GCP GKE with ArgoCD and Kustomize","description":"Implementing GitOps for microservices deployment brings consistency, reliability, and traceability to your deployment pipeline. This practical guide walks through setting up a complete GitOps workflow for Node.js microservices on Google Cloud Platform (GCP) using Google Kubernetes Engine (GKE), ArgoCD, and Kustomize.","date":"2025-10-07T00:00:00.000Z","tags":[{"inline":false,"label":"GitOps","permalink":"/fullstack-dev/blog/tags/gitops","description":"GitOps deployment practices"},{"inline":false,"label":"Microservices","permalink":"/fullstack-dev/blog/tags/microservices","description":"Microservices architecture and patterns"},{"inline":false,"label":"Node.js","permalink":"/fullstack-dev/blog/tags/nodejs","description":"Node.js runtime and development"},{"inline":false,"label":"NestJS","permalink":"/fullstack-dev/blog/tags/nestjs","description":"NestJS framework for Node.js applications"},{"inline":false,"label":"Google Cloud Platform","permalink":"/fullstack-dev/blog/tags/gcp","description":"Google Cloud Platform services"},{"inline":false,"label":"Google Kubernetes Engine","permalink":"/fullstack-dev/blog/tags/gke","description":"Google Kubernetes Engine"},{"inline":false,"label":"ArgoCD","permalink":"/fullstack-dev/blog/tags/argocd","description":"ArgoCD GitOps deployment"},{"inline":false,"label":"Kustomize","permalink":"/fullstack-dev/blog/tags/kustomize","description":"Kubernetes configuration management"},{"inline":false,"label":"Kubernetes","permalink":"/fullstack-dev/blog/tags/kubernetes","description":"Kubernetes container orchestration"},{"inline":false,"label":"Infrastructure as Code","permalink":"/fullstack-dev/blog/tags/infrastructure-as-code","description":"Infrastructure automation and versioning"},{"inline":false,"label":"DevOps","permalink":"/fullstack-dev/blog/tags/devops","description":"DevOps practices and tools"}],"readingTime":10.65,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"gitops-microservices-nodejs-gcp-practical-guide","title":"GitOps in Practice: Deploying Node.js Microservices to GCP GKE with ArgoCD and Kustomize","authors":["tam"],"tags":["gitops","microservices","nodejs","nestjs","gcp","gke","argocd","kustomize","kubernetes","infrastructure-as-code","devops"]},"unlisted":false,"prevItem":{"title":"Building Smart Location-Aware Applications: Complete Geo-targeting Implementation with Node.js and React","permalink":"/fullstack-dev/blog/geo-targeting-implementation-nodejs-react"},"nextItem":{"title":"Global Cookie Privacy Compliance: A Complete Guide to Country-Specific Regulations in 2025","permalink":"/fullstack-dev/blog/global-cookie-privacy-compliance-guide-2025"}},"content":"Implementing GitOps for microservices deployment brings consistency, reliability, and traceability to your deployment pipeline. This practical guide walks through setting up a complete GitOps workflow for Node.js microservices on Google Cloud Platform (GCP) using Google Kubernetes Engine (GKE), ArgoCD, and Kustomize.\\n\\nWe\'ll build a production-ready deployment pipeline that follows infrastructure as code principles and implements security best practices for enterprise-grade applications.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The GitOps Promise\\n\\nGitOps transforms how we think about deployments by making Git the single source of truth for both application code and infrastructure configuration. Instead of pushing deployments to environments, GitOps pulls the desired state from Git repositories and continuously reconciles the actual state with the declared state.\\n\\n### Key Benefits We\'ll Achieve\\n\\n- **Declarative Infrastructure**: Everything defined as code\\n- **Version Control**: Full audit trail of all changes\\n- **Automated Deployments**: Reduced human error and faster delivery\\n- **Security**: No direct cluster access required for deployments\\n- **Rollback Capability**: Easy recovery from failed deployments\\n- **Multi-Environment Management**: Consistent configuration across environments\\n\\n## Architecture Overview\\n\\nOur GitOps implementation uses a three-repository strategy:\\n\\n```mermaid\\ngraph TD\\n    A[Application Repos] --\x3e B[CI Pipeline]\\n    B --\x3e C[Container Registry]\\n    B --\x3e D[GitOps Repo Update]\\n    D --\x3e E[ArgoCD Sync]\\n    E --\x3e F[GKE Deployment]\\n    \\n    G[Infrastructure Repo] --\x3e H[Terraform]\\n    H --\x3e I[GCP Resources]\\n    \\n    J[GitOps Repo] --\x3e K[Kustomize Overlays]\\n    K --\x3e E\\n```\\n\\n## Step 1: Infrastructure Setup with Terraform\\n\\nFirst, let\'s set up our GKE cluster using Terraform for infrastructure as code.\\n\\n### Project Structure\\n\\n```\\ninfrastructure/\\n\u251c\u2500\u2500 terraform/\\n\u2502   \u251c\u2500\u2500 environments/\\n\u2502   \u2502   \u251c\u2500\u2500 dev/\\n\u2502   \u2502   \u251c\u2500\u2500 staging/\\n\u2502   \u2502   \u2514\u2500\u2500 production/\\n\u2502   \u251c\u2500\u2500 modules/\\n\u2502   \u2502   \u251c\u2500\u2500 gke/\\n\u2502   \u2502   \u251c\u2500\u2500 networking/\\n\u2502   \u2502   \u2514\u2500\u2500 security/\\n\u2502   \u2514\u2500\u2500 shared/\\n\u2514\u2500\u2500 scripts/\\n    \u251c\u2500\u2500 setup.sh\\n    \u2514\u2500\u2500 teardown.sh\\n```\\n\\n### GKE Cluster Configuration\\n\\n```hcl\\n# terraform/modules/gke/main.tf\\nresource \\"google_container_cluster\\" \\"microservices\\" {\\n  name     = var.cluster_name\\n  location = var.region\\n  \\n  # Remove default node pool\\n  remove_default_node_pool = true\\n  initial_node_count       = 1\\n  \\n  # Network configuration\\n  network    = google_compute_network.vpc.name\\n  subnetwork = google_compute_subnetwork.subnet.name\\n  \\n  # Enable workload identity for secure pod-to-GCP service communication\\n  workload_identity_config {\\n    workload_pool = \\"${var.project_id}.svc.id.goog\\"\\n  }\\n  \\n  # Private cluster for enhanced security\\n  private_cluster_config {\\n    enable_private_nodes    = true\\n    enable_private_endpoint = false\\n    master_ipv4_cidr_block  = \\"172.16.0.0/28\\"\\n  }\\n  \\n  # Networking features\\n  network_policy {\\n    enabled = true\\n  }\\n  \\n  # Enable necessary APIs\\n  addons_config {\\n    horizontal_pod_autoscaling {\\n      disabled = false\\n    }\\n    network_policy_config {\\n      disabled = false\\n    }\\n    http_load_balancing {\\n      disabled = false\\n    }\\n  }\\n  \\n  # Logging and monitoring\\n  logging_service    = \\"logging.googleapis.com/kubernetes\\"\\n  monitoring_service = \\"monitoring.googleapis.com/kubernetes\\"\\n}\\n\\nresource \\"google_container_node_pool\\" \\"primary_nodes\\" {\\n  name       = \\"${var.cluster_name}-nodes\\"\\n  location   = var.region\\n  cluster    = google_container_cluster.microservices.name\\n  \\n  # Auto-scaling configuration\\n  autoscaling {\\n    min_node_count = var.min_node_count\\n    max_node_count = var.max_node_count\\n  }\\n  \\n  node_config {\\n    preemptible  = var.preemptible\\n    machine_type = var.machine_type\\n    disk_size_gb = var.disk_size_gb\\n    disk_type    = \\"pd-ssd\\"\\n    \\n    # Service account for nodes\\n    service_account = google_service_account.gke_nodes.email\\n    oauth_scopes = [\\n      \\"https://www.googleapis.com/auth/logging.write\\",\\n      \\"https://www.googleapis.com/auth/monitoring\\",\\n      \\"https://www.googleapis.com/auth/devstorage.read_only\\"\\n    ]\\n    \\n    # Security settings\\n    workload_metadata_config {\\n      mode = \\"GKE_METADATA\\"\\n    }\\n    \\n    labels = {\\n      environment = var.environment\\n      managed-by  = \\"terraform\\"\\n    }\\n  }\\n  \\n  management {\\n    auto_repair  = true\\n    auto_upgrade = true\\n  }\\n}\\n```\\n\\n### Environment-Specific Variables\\n\\n```hcl\\n# terraform/environments/production/terraform.tfvars\\nproject_id     = \\"your-microservices-project\\"\\ncluster_name   = \\"microservices-prod\\"\\nregion         = \\"us-central1\\"\\nenvironment    = \\"production\\"\\n\\n# Node configuration\\nmachine_type   = \\"e2-standard-4\\"\\nmin_node_count = 3\\nmax_node_count = 10\\ndisk_size_gb   = 100\\npreemptible    = false\\n```\\n\\n## Step 2: GitOps Repository Structure\\n\\nCreate a dedicated GitOps repository with a clear structure:\\n\\n```\\ngitops-microservices/\\n\u251c\u2500\u2500 applications/\\n\u2502   \u251c\u2500\u2500 api-gateway/\\n\u2502   \u2502   \u251c\u2500\u2500 base/\\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 deployment.yaml\\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 service.yaml\\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 configmap.yaml\\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 kustomization.yaml\\n\u2502   \u2502   \u2514\u2500\u2500 overlays/\\n\u2502   \u2502       \u251c\u2500\u2500 development/\\n\u2502   \u2502       \u251c\u2500\u2500 staging/\\n\u2502   \u2502       \u2514\u2500\u2500 production/\\n\u2502   \u251c\u2500\u2500 user-service/\\n\u2502   \u251c\u2500\u2500 order-service/\\n\u2502   \u2514\u2500\u2500 payment-service/\\n\u251c\u2500\u2500 infrastructure/\\n\u2502   \u251c\u2500\u2500 argocd/\\n\u2502   \u251c\u2500\u2500 ingress-nginx/\\n\u2502   \u251c\u2500\u2500 cert-manager/\\n\u2502   \u2514\u2500\u2500 monitoring/\\n\u2514\u2500\u2500 scripts/\\n    \u251c\u2500\u2500 bootstrap.sh\\n    \u2514\u2500\u2500 validate.sh\\n```\\n\\n## Step 3: Kustomize Configuration\\n\\nKustomize enables environment-specific configurations without duplicating YAML files.\\n\\n### Base Configuration\\n\\n```yaml\\n# applications/user-service/base/deployment.yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: user-service\\n  labels:\\n    app: user-service\\n    version: v1\\nspec:\\n  replicas: 2\\n  selector:\\n    matchLabels:\\n      app: user-service\\n  template:\\n    metadata:\\n      labels:\\n        app: user-service\\n        version: v1\\n    spec:\\n      serviceAccountName: user-service\\n      securityContext:\\n        runAsNonRoot: true\\n        runAsUser: 1000\\n        fsGroup: 1000\\n      containers:\\n      - name: user-service\\n        image: gcr.io/PROJECT_ID/user-service:latest\\n        ports:\\n        - containerPort: 3000\\n          name: http\\n        env:\\n        - name: NODE_ENV\\n          value: production\\n        - name: PORT\\n          value: \\"3000\\"\\n        - name: DATABASE_URL\\n          valueFrom:\\n            secretKeyRef:\\n              name: user-service-secrets\\n              key: database-url\\n        resources:\\n          requests:\\n            memory: \\"256Mi\\"\\n            cpu: \\"250m\\"\\n          limits:\\n            memory: \\"512Mi\\"\\n            cpu: \\"500m\\"\\n        livenessProbe:\\n          httpGet:\\n            path: /health\\n            port: 3000\\n          initialDelaySeconds: 30\\n          periodSeconds: 10\\n          timeoutSeconds: 5\\n          failureThreshold: 3\\n        readinessProbe:\\n          httpGet:\\n            path: /ready\\n            port: 3000\\n          initialDelaySeconds: 5\\n          periodSeconds: 5\\n          timeoutSeconds: 3\\n          failureThreshold: 3\\n        securityContext:\\n          allowPrivilegeEscalation: false\\n          readOnlyRootFilesystem: true\\n          capabilities:\\n            drop:\\n            - ALL\\n```\\n\\n### Base Kustomization\\n\\n```yaml\\n# applications/user-service/base/kustomization.yaml\\napiVersion: kustomize.config.k8s.io/v1beta1\\nkind: Kustomization\\n\\nmetadata:\\n  name: user-service-base\\n\\nresources:\\n  - deployment.yaml\\n  - service.yaml\\n  - serviceaccount.yaml\\n  - networkpolicy.yaml\\n\\ncommonLabels:\\n  app: user-service\\n  component: backend\\n  part-of: microservices\\n\\nimages:\\n  - name: gcr.io/PROJECT_ID/user-service\\n    newTag: latest\\n\\nconfigMapGenerator:\\n  - name: user-service-config\\n    literals:\\n      - PORT=3000\\n      - LOG_LEVEL=info\\n      - METRICS_ENABLED=true\\n      - HEALTH_CHECK_TIMEOUT=5000\\n\\nsecretGenerator:\\n  - name: user-service-secrets\\n    literals:\\n      - database-url=placeholder\\n      - jwt-secret=placeholder\\n    type: Opaque\\n```\\n\\n### Production Overlay\\n\\n```yaml\\n# applications/user-service/overlays/production/kustomization.yaml\\napiVersion: kustomize.config.k8s.io/v1beta1\\nkind: Kustomization\\n\\nnamespace: microservices-prod\\n\\nresources:\\n  - ../../base\\n  - hpa.yaml\\n  - pdb.yaml\\n  - networkpolicy-prod.yaml\\n\\npatchesStrategicMerge:\\n  - deployment-patch.yaml\\n\\nreplicas:\\n  - name: user-service\\n    count: 3\\n\\nimages:\\n  - name: gcr.io/PROJECT_ID/user-service\\n    newTag: v1.2.3\\n\\nconfigMapGenerator:\\n  - name: user-service-config\\n    behavior: merge\\n    literals:\\n      - LOG_LEVEL=warn\\n      - CACHE_TTL=3600\\n      - DB_POOL_SIZE=20\\n\\nsecretGenerator:\\n  - name: user-service-secrets\\n    behavior: replace\\n    files:\\n      - database-url=secrets/database-url\\n      - jwt-secret=secrets/jwt-secret\\n```\\n\\n### Production Resource Patches\\n\\n```yaml\\n# applications/user-service/overlays/production/deployment-patch.yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: user-service\\nspec:\\n  template:\\n    spec:\\n      containers:\\n      - name: user-service\\n        resources:\\n          requests:\\n            memory: \\"512Mi\\"\\n            cpu: \\"500m\\"\\n          limits:\\n            memory: \\"1Gi\\"\\n            cpu: \\"1000m\\"\\n        env:\\n        - name: NODE_ENV\\n          value: production\\n        - name: LOG_LEVEL\\n          value: warn\\n        - name: DB_CONNECTION_POOL\\n          value: \\"20\\"\\n```\\n\\n### Horizontal Pod Autoscaler\\n\\n```yaml\\n# applications/user-service/overlays/production/hpa.yaml\\napiVersion: autoscaling/v2\\nkind: HorizontalPodAutoscaler\\nmetadata:\\n  name: user-service-hpa\\nspec:\\n  scaleTargetRef:\\n    apiVersion: apps/v1\\n    kind: Deployment\\n    name: user-service\\n  minReplicas: 3\\n  maxReplicas: 10\\n  metrics:\\n  - type: Resource\\n    resource:\\n      name: cpu\\n      target:\\n        type: Utilization\\n        averageUtilization: 70\\n  - type: Resource\\n    resource:\\n      name: memory\\n      target:\\n        type: Utilization\\n        averageUtilization: 80\\n  behavior:\\n    scaleDown:\\n      stabilizationWindowSeconds: 300\\n      policies:\\n      - type: Percent\\n        value: 10\\n        periodSeconds: 60\\n    scaleUp:\\n      stabilizationWindowSeconds: 0\\n      policies:\\n      - type: Percent\\n        value: 100\\n        periodSeconds: 15\\n      - type: Pods\\n        value: 4\\n        periodSeconds: 15\\n      selectPolicy: Max\\n```\\n\\n## Step 4: ArgoCD Installation and Configuration\\n\\n### ArgoCD Installation\\n\\n```bash\\n# Create ArgoCD namespace\\nkubectl create namespace argocd\\n\\n# Install ArgoCD\\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\\n\\n# Wait for deployment\\nkubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd\\n\\n# Get initial admin password\\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\\"{.data.password}\\" | base64 -d\\n\\n# Port forward to access UI\\nkubectl port-forward svc/argocd-server -n argocd 8080:443\\n```\\n\\n### ArgoCD Configuration\\n\\n```yaml\\n# infrastructure/argocd/argocd-config.yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: argocd-cm\\n  namespace: argocd\\ndata:\\n  repositories: |\\n    - type: git\\n      url: https://github.com/your-org/gitops-microservices\\n      passwordSecret:\\n        name: gitops-repo-secret\\n        key: password\\n      usernameSecret:\\n        name: gitops-repo-secret\\n        key: username\\n  \\n  application.instanceLabelKey: argocd.argoproj.io/instance\\n  \\n  server.rbac.log.enforce.enable: \\"true\\"\\n  \\n  policy.default: role:readonly\\n  policy.csv: |\\n    p, role:admin, applications, *, */*, allow\\n    p, role:admin, clusters, *, *, allow\\n    p, role:admin, repositories, *, *, allow\\n    p, role:developer, applications, get, */*, allow\\n    p, role:developer, applications, sync, microservices/*, allow\\n    g, argocd-admins, role:admin\\n    g, developers, role:developer\\n```\\n\\n### Application Project\\n\\n```yaml\\n# infrastructure/argocd/projects/microservices.yaml\\napiVersion: argoproj.io/v1alpha1\\nkind: AppProject\\nmetadata:\\n  name: microservices\\n  namespace: argocd\\nspec:\\n  description: Microservices applications\\n  \\n  sourceRepos:\\n  - \'https://github.com/your-org/gitops-microservices\'\\n  \\n  destinations:\\n  - namespace: \'microservices-*\'\\n    server: https://kubernetes.default.svc\\n  \\n  clusterResourceWhitelist:\\n  - group: \'\'\\n    kind: Namespace\\n  \\n  namespaceResourceWhitelist:\\n  - group: \'\'\\n    kind: ConfigMap\\n  - group: \'\'\\n    kind: Secret\\n  - group: \'\'\\n    kind: Service\\n  - group: \'\'\\n    kind: ServiceAccount\\n  - group: apps\\n    kind: Deployment\\n  - group: networking.k8s.io\\n    kind: Ingress\\n  - group: autoscaling\\n    kind: HorizontalPodAutoscaler\\n  - group: policy\\n    kind: PodDisruptionBudget\\n  \\n  roles:\\n  - name: developer\\n    policies:\\n    - p, proj:microservices:developer, applications, get, microservices/*, allow\\n    - p, proj:microservices:developer, applications, sync, microservices/*, allow\\n    groups:\\n    - developers\\n```\\n\\n### Application Definition\\n\\n```yaml\\n# infrastructure/argocd/applications/user-service.yaml\\napiVersion: argoproj.io/v1alpha1\\nkind: Application\\nmetadata:\\n  name: user-service-prod\\n  namespace: argocd\\n  finalizers:\\n    - resources-finalizer.argocd.argoproj.io\\nspec:\\n  project: microservices\\n  \\n  source:\\n    repoURL: https://github.com/your-org/gitops-microservices\\n    targetRevision: HEAD\\n    path: applications/user-service/overlays/production\\n  \\n  destination:\\n    server: https://kubernetes.default.svc\\n    namespace: microservices-prod\\n  \\n  syncPolicy:\\n    automated:\\n      prune: true\\n      selfHeal: true\\n      allowEmpty: false\\n    syncOptions:\\n    - CreateNamespace=true\\n    - PrunePropagationPolicy=foreground\\n    - PruneLast=true\\n    retry:\\n      limit: 5\\n      backoff:\\n        duration: 5s\\n        factor: 2\\n        maxDuration: 3m\\n  \\n  revisionHistoryLimit: 10\\n```\\n\\n## Step 5: CI/CD Pipeline Implementation\\n\\n### GitHub Actions Workflow\\n\\n```yaml\\n# .github/workflows/user-service.yml\\nname: User Service CI/CD\\n\\non:\\n  push:\\n    branches: [main, develop]\\n    paths:\\n    - \'services/user-service/**\'\\n  pull_request:\\n    branches: [main]\\n    paths:\\n    - \'services/user-service/**\'\\n\\nenv:\\n  SERVICE_NAME: user-service\\n  GCP_PROJECT: your-project-id\\n  REGISTRY: gcr.io\\n\\njobs:\\n  test:\\n    runs-on: ubuntu-latest\\n    steps:\\n    - uses: actions/checkout@v4\\n    \\n    - name: Setup Node.js\\n      uses: actions/setup-node@v4\\n      with:\\n        node-version: \'18\'\\n        cache: \'npm\'\\n        cache-dependency-path: services/${{ env.SERVICE_NAME }}/package-lock.json\\n    \\n    - name: Install dependencies\\n      run: |\\n        cd services/${{ env.SERVICE_NAME }}\\n        npm ci\\n    \\n    - name: Run tests\\n      run: |\\n        cd services/${{ env.SERVICE_NAME }}\\n        npm run test:coverage\\n    \\n    - name: Security audit\\n      run: |\\n        cd services/${{ env.SERVICE_NAME }}\\n        npm audit --audit-level high\\n\\n  build-and-deploy:\\n    needs: test\\n    if: github.ref == \'refs/heads/main\'\\n    runs-on: ubuntu-latest\\n    outputs:\\n      image-tag: ${{ steps.build.outputs.image-tag }}\\n    steps:\\n    - uses: actions/checkout@v4\\n    \\n    - name: Setup Google Cloud CLI\\n      uses: google-github-actions/setup-gcloud@v1\\n      with:\\n        service_account_key: ${{ secrets.GCP_SA_KEY }}\\n        project_id: ${{ env.GCP_PROJECT }}\\n    \\n    - name: Configure Docker\\n      run: gcloud auth configure-docker\\n    \\n    - name: Build and push image\\n      id: build\\n      run: |\\n        cd services/${{ env.SERVICE_NAME }}\\n        \\n        IMAGE_TAG=\\"v$(date +\'%Y%m%d\')-${GITHUB_SHA::8}\\"\\n        IMAGE_NAME=\\"${REGISTRY}/${GCP_PROJECT}/${SERVICE_NAME}:${IMAGE_TAG}\\"\\n        \\n        docker build -t $IMAGE_NAME .\\n        docker push $IMAGE_NAME\\n        \\n        echo \\"image-tag=${IMAGE_TAG}\\" >> $GITHUB_OUTPUT\\n    \\n    - name: Security scan\\n      uses: aquasecurity/trivy-action@master\\n      with:\\n        image-ref: ${{ env.REGISTRY }}/${{ env.GCP_PROJECT }}/${{ env.SERVICE_NAME }}:${{ steps.build.outputs.image-tag }}\\n        format: \'sarif\'\\n        output: \'trivy-results.sarif\'\\n\\n  update-gitops:\\n    needs: build-and-deploy\\n    runs-on: ubuntu-latest\\n    steps:\\n    - name: Checkout GitOps repo\\n      uses: actions/checkout@v4\\n      with:\\n        repository: your-org/gitops-microservices\\n        token: ${{ secrets.GITOPS_TOKEN }}\\n        path: gitops\\n    \\n    - name: Update image tag\\n      run: |\\n        cd gitops/applications/${SERVICE_NAME}/overlays/production\\n        \\n        kustomize edit set image \\\\\\n          ${REGISTRY}/${GCP_PROJECT}/${SERVICE_NAME}:${{ needs.build-and-deploy.outputs.image-tag }}\\n    \\n    - name: Commit and push\\n      run: |\\n        cd gitops\\n        git config user.name \\"github-actions[bot]\\"\\n        git config user.email \\"41898282+github-actions[bot]@users.noreply.github.com\\"\\n        \\n        git add .\\n        git commit -m \\"Update ${SERVICE_NAME} to ${{ needs.build-and-deploy.outputs.image-tag }}\\"\\n        git push\\n```\\n\\n### Application Dockerfile\\n\\n```dockerfile\\n# services/user-service/Dockerfile\\nFROM node:18-alpine AS base\\n\\n# Install security updates\\nRUN apk update && apk upgrade && apk add --no-cache dumb-init\\n\\n# Create app user\\nRUN addgroup -g 1001 -S nodejs && adduser -S nodejs -u 1001\\n\\nFROM base AS deps\\nWORKDIR /app\\nCOPY package*.json ./\\nRUN npm ci --only=production && npm cache clean --force\\n\\nFROM base AS build\\nWORKDIR /app\\nCOPY package*.json ./\\nRUN npm ci\\nCOPY . .\\nRUN npm run build\\n\\nFROM base AS runtime\\nWORKDIR /app\\nUSER nodejs\\n\\nCOPY --from=deps --chown=nodejs:nodejs /app/node_modules ./node_modules\\nCOPY --from=build --chown=nodejs:nodejs /app/dist ./dist\\nCOPY --from=build --chown=nodejs:nodejs /app/package*.json ./\\n\\nEXPOSE 3000\\n\\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\\\\n  CMD node ./dist/health-check.js || exit 1\\n\\nENTRYPOINT [\\"dumb-init\\", \\"--\\"]\\nCMD [\\"node\\", \\"dist/main.js\\"]\\n```\\n\\n## Step 6: Security Implementation\\n\\n### Network Policies\\n\\n```yaml\\n# applications/user-service/base/networkpolicy.yaml\\napiVersion: networking.k8s.io/v1\\nkind: NetworkPolicy\\nmetadata:\\n  name: user-service-netpol\\nspec:\\n  podSelector:\\n    matchLabels:\\n      app: user-service\\n  policyTypes:\\n  - Ingress\\n  - Egress\\n  ingress:\\n  - from:\\n    - podSelector:\\n        matchLabels:\\n          app: api-gateway\\n    ports:\\n    - protocol: TCP\\n      port: 3000\\n  egress:\\n  - to: []\\n    ports:\\n    - protocol: TCP\\n      port: 5432 # PostgreSQL\\n    - protocol: TCP\\n      port: 443  # HTTPS\\n    - protocol: TCP\\n      port: 53   # DNS\\n    - protocol: UDP\\n      port: 53   # DNS\\n```\\n\\n### Secret Management with External Secrets\\n\\n```yaml\\n# infrastructure/external-secrets/user-service-secrets.yaml\\napiVersion: external-secrets.io/v1beta1\\nkind: ExternalSecret\\nmetadata:\\n  name: user-service-secrets\\n  namespace: microservices-prod\\nspec:\\n  refreshInterval: 15s\\n  secretStoreRef:\\n    name: gcpsm-secret-store\\n    kind: SecretStore\\n  target:\\n    name: user-service-secrets\\n    creationPolicy: Owner\\n  data:\\n  - secretKey: database-url\\n    remoteRef:\\n      key: user-service-database-url\\n  - secretKey: jwt-secret\\n    remoteRef:\\n      key: user-service-jwt-secret\\n```\\n\\n## Step 7: Monitoring and Observability\\n\\n### Prometheus ServiceMonitor\\n\\n```yaml\\n# applications/user-service/base/servicemonitor.yaml\\napiVersion: monitoring.coreos.com/v1\\nkind: ServiceMonitor\\nmetadata:\\n  name: user-service\\nspec:\\n  selector:\\n    matchLabels:\\n      app: user-service\\n  endpoints:\\n  - port: http\\n    path: /metrics\\n    interval: 30s\\n```\\n\\n### Application Health Checks\\n\\n```typescript\\n// services/user-service/src/health/health.controller.ts\\nimport { Controller, Get } from \'@nestjs/common\';\\nimport { HealthCheckService, HttpHealthIndicator, HealthCheck } from \'@nestjs/terminus\';\\n\\n@Controller(\'health\')\\nexport class HealthController {\\n  constructor(\\n    private health: HealthCheckService,\\n    private http: HttpHealthIndicator,\\n  ) {}\\n\\n  @Get()\\n  @HealthCheck()\\n  check() {\\n    return this.health.check([\\n      () => this.http.pingCheck(\'database\', \'http://localhost:3000/api/database/ping\'),\\n    ]);\\n  }\\n\\n  @Get(\'ready\')\\n  ready() {\\n    return { status: \'ready\' };\\n  }\\n}\\n```\\n\\n## Step 8: Deployment and Validation\\n\\n### Bootstrap Script\\n\\n```bash\\n#!/bin/bash\\n# scripts/bootstrap.sh\\n\\nset -e\\n\\necho \\"\ud83d\ude80 Bootstrapping GitOps environment...\\"\\n\\n# Apply ArgoCD installation\\nkubectl apply -k infrastructure/argocd/\\n\\n# Wait for ArgoCD to be ready\\nkubectl wait --for=condition=available --timeout=300s deployment/argocd-server -n argocd\\n\\n# Apply projects and applications\\nkubectl apply -f infrastructure/argocd/projects/\\nkubectl apply -f infrastructure/argocd/applications/\\n\\necho \\"\u2705 GitOps environment ready!\\"\\necho \\"ArgoCD UI: kubectl port-forward svc/argocd-server -n argocd 8080:443\\"\\n```\\n\\n### Validation Commands\\n\\n```bash\\n# Check ArgoCD applications\\nargocd app list\\n\\n# Sync specific application\\nargocd app sync user-service-prod\\n\\n# Check deployment status\\nkubectl get deployments -n microservices-prod\\n\\n# View application logs\\nkubectl logs -f deployment/user-service -n microservices-prod\\n\\n# Check HPA status\\nkubectl get hpa -n microservices-prod\\n```\\n\\n## Benefits Achieved\\n\\nAfter implementing this GitOps workflow, you\'ll have:\\n\\n1. **Consistent Deployments**: Every environment uses the same deployment process\\n2. **Full Audit Trail**: Every change is tracked in Git\\n3. **Automated Security**: Security scanning and policies enforced\\n4. **Easy Rollbacks**: Git-based rollback capability\\n5. **Environment Parity**: Configuration drift eliminated\\n6. **Developer Productivity**: Self-service deployments via Git\\n\\n## Next Steps\\n\\n1. **Multi-Cluster Management**: Extend to multiple GKE clusters\\n2. **Advanced Deployment Strategies**: Implement canary and blue-green deployments\\n3. **Policy as Code**: Add Open Policy Agent (OPA) for governance\\n4. **Observability**: Enhanced monitoring with distributed tracing\\n5. **Disaster Recovery**: Automated backup and recovery procedures\\n\\nThis GitOps implementation provides a solid foundation for scaling your microservices deployment pipeline while maintaining security, reliability, and developer productivity."},{"id":"global-cookie-privacy-compliance-guide-2025","metadata":{"permalink":"/fullstack-dev/blog/global-cookie-privacy-compliance-guide-2025","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-07-global-cookie-privacy-compliance-guide.md","source":"@site/blog/2025-10-07-global-cookie-privacy-compliance-guide.md","title":"Global Cookie Privacy Compliance: A Complete Guide to Country-Specific Regulations in 2025","description":"Navigating the complex landscape of global privacy regulations has become increasingly challenging as countries worldwide implement comprehensive data protection laws. With over 100 countries now having privacy legislation, understanding the specific requirements for cookie consent and data collection in each jurisdiction is crucial for any business operating internationally.","date":"2025-10-07T00:00:00.000Z","tags":[{"inline":false,"label":"Privacy","permalink":"/fullstack-dev/blog/tags/privacy","description":"Data privacy and protection"},{"inline":false,"label":"Cookies","permalink":"/fullstack-dev/blog/tags/cookies","description":"Web cookies and session management"},{"inline":false,"label":"GDPR","permalink":"/fullstack-dev/blog/tags/gdpr","description":"General Data Protection Regulation"},{"inline":false,"label":"CCPA","permalink":"/fullstack-dev/blog/tags/ccpa","description":"California Consumer Privacy Act"},{"inline":false,"label":"Compliance","permalink":"/fullstack-dev/blog/tags/compliance","description":"Regulatory compliance and standards"},{"inline":false,"label":"Privacy Laws","permalink":"/fullstack-dev/blog/tags/privacy-laws","description":"Data protection regulations"},{"inline":false,"label":"Data Protection","permalink":"/fullstack-dev/blog/tags/data-protection","description":"Data protection strategies"},{"inline":false,"label":"Consent Management","permalink":"/fullstack-dev/blog/tags/consent-management","description":"User consent and preference management"},{"inline":false,"label":"Global Regulations","permalink":"/fullstack-dev/blog/tags/global-regulations","description":"International regulatory requirements"}],"readingTime":10.37,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"global-cookie-privacy-compliance-guide-2025","title":"Global Cookie Privacy Compliance: A Complete Guide to Country-Specific Regulations in 2025","authors":["tam"],"tags":["privacy","cookies","gdpr","ccpa","compliance","privacy-laws","data-protection","consent-management","global-regulations"]},"unlisted":false,"prevItem":{"title":"GitOps in Practice: Deploying Node.js Microservices to GCP GKE with ArgoCD and Kustomize","permalink":"/fullstack-dev/blog/gitops-microservices-nodejs-gcp-practical-guide"},"nextItem":{"title":"Building Scalable Microservices with NestJS: Message Queues Implementation and Comparison Guide","permalink":"/fullstack-dev/blog/nestjs-microservices-message-queues-comparison"}},"content":"Navigating the complex landscape of global privacy regulations has become increasingly challenging as countries worldwide implement comprehensive data protection laws. With over 100 countries now having privacy legislation, understanding the specific requirements for cookie consent and data collection in each jurisdiction is crucial for any business operating internationally.\\n\\nThis comprehensive guide examines the cookie and privacy requirements across major jurisdictions, providing practical implementation guidance and compliance strategies for 2025.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Global Privacy Landscape in 2025\\n\\nThe privacy regulatory environment has evolved dramatically since the GDPR\'s introduction in 2018. What started as a European initiative has now spread globally, with each jurisdiction adding its unique requirements and interpretations.\\n\\n### Key Trends Shaping Privacy Regulations\\n\\n1. **Convergence on Core Rights**: Most laws now include rights to access, delete, and port data\\n2. **Consent Fatigue Solutions**: Regulators seeking balance between privacy and user experience\\n3. **Cross-Border Transfer Restrictions**: Increasing focus on data localization\\n4. **Enforcement Intensification**: Higher fines and more aggressive enforcement\\n5. **Children\'s Privacy**: Enhanced protections for minors across jurisdictions\\n\\n## European Union: The Gold Standard (GDPR + ePrivacy)\\n\\n### Scope and Applicability\\nThe GDPR applies to any organization processing personal data of EU residents, regardless of where the company is located. Combined with the ePrivacy Directive (and upcoming ePrivacy Regulation), this creates the most comprehensive privacy framework globally.\\n\\n### Cookie Consent Requirements\\n\\n```typescript\\ninterface EUCookieCompliance {\\n  beforeCookiesSet: {\\n    consentBannerDisplayed: boolean;\\n    noCookiesPlaced: boolean; // Except strictly necessary\\n    clearInformation: boolean;\\n  };\\n  consentMechanism: {\\n    explicitConsent: boolean; // Must be opt-in\\n    granularChoices: boolean; // Per category\\n    freelyGiven: boolean; // No cookie walls\\n    withdrawable: boolean; // Easy withdrawal\\n    informed: boolean; // Clear purposes\\n    specific: boolean; // Not bundled\\n  };\\n  technicalRequirements: {\\n    consentRecording: boolean;\\n    versionTracking: boolean;\\n    ipAnonymization: boolean;\\n    consentExpiry: string; // \\"12 months maximum\\"\\n  };\\n}\\n```\\n\\n### Country-Specific Interpretations\\n\\n**Germany**: Strictest interpretation globally\\n- Planet49 ruling: Pre-checked boxes invalid\\n- No implied consent for any non-essential cookies\\n- Must show reject button equally prominent to accept\\n\\n**France**: CNIL guidance evolution\\n- Cookie walls forbidden (2020 ruling)\\n- Analytics cookies require consent (Google Analytics ban)\\n- Legitimate interest narrowly interpreted\\n\\n**Netherlands**: Authority for Consumers and Markets (ACM)\\n- Focus on dark patterns in consent interfaces\\n- Strict enforcement on withdrawal mechanisms\\n- Regular audits of major websites\\n\\n**Ireland**: DPC as lead regulator\\n- Meta and Google enforcement actions\\n- Focus on data transfer mechanisms\\n- Consent validity for large-scale processing\\n\\n### Implementation Example\\n\\n```typescript\\nclass EUGDPRConsentManager {\\n  private readonly CONSENT_VERSION = \'2024.1\';\\n  private readonly MAX_CONSENT_AGE = 365 * 24 * 60 * 60 * 1000; // 1 year\\n\\n  async displayConsentBanner(): Promise<void> {\\n    // Ensure no non-essential cookies before consent\\n    this.clearNonEssentialCookies();\\n    \\n    const banner = new ConsentBanner({\\n      title: \'Your Privacy Matters\',\\n      description: this.getGDPRCompliantDescription(),\\n      categories: this.getCookieCategories(),\\n      buttons: {\\n        acceptAll: { text: \'Accept All\', style: \'primary\' },\\n        rejectAll: { text: \'Reject All\', style: \'secondary\' }, // Equally prominent\\n        customize: { text: \'Manage Preferences\', style: \'secondary\' }\\n      },\\n      layout: \'gdpr-compliant\', // No cookie wall design\\n      withdrawalLink: \'/cookie-settings\'\\n    });\\n\\n    await banner.display();\\n  }\\n\\n  private getGDPRCompliantDescription(): string {\\n    return `We use cookies to enhance your experience and analyze site usage. ` +\\n           `You can choose which categories to accept. You can change your ` +\\n           `preferences at any time through our Cookie Settings.`;\\n  }\\n\\n  private getCookieCategories(): CookieCategory[] {\\n    return [\\n      {\\n        id: \'necessary\',\\n        name: \'Strictly Necessary\',\\n        description: \'Essential for website functionality\',\\n        required: true,\\n        legalBasis: \'legitimate_interest\'\\n      },\\n      {\\n        id: \'analytics\',\\n        name: \'Analytics\',\\n        description: \'Help us understand how visitors use our site\',\\n        required: false,\\n        legalBasis: \'consent\',\\n        vendors: [\'Google Analytics\', \'Hotjar\']\\n      },\\n      {\\n        id: \'marketing\',\\n        name: \'Marketing\',\\n        description: \'Used to deliver relevant advertisements\',\\n        required: false,\\n        legalBasis: \'consent\',\\n        vendors: [\'Facebook Pixel\', \'Google Ads\']\\n      }\\n    ];\\n  }\\n\\n  recordConsent(consent: ConsentChoices): void {\\n    const record: ConsentRecord = {\\n      timestamp: new Date().toISOString(),\\n      version: this.CONSENT_VERSION,\\n      choices: consent,\\n      method: \'banner_interaction\',\\n      ipAddress: this.anonymizeIP(this.getUserIP()),\\n      userAgent: navigator.userAgent.substring(0, 200), // Truncated for privacy\\n      pageUrl: window.location.href,\\n      gdprApplies: true\\n    };\\n\\n    // Store locally and send to server\\n    this.storeConsentRecord(record);\\n    this.sendToConsentAPI(record);\\n  }\\n\\n  private anonymizeIP(ip: string): string {\\n    // GDPR requires IP anonymization for consent logs\\n    const parts = ip.split(\'.\');\\n    return parts.length === 4 ? `${parts[0]}.${parts[1]}.${parts[2]}.0` : ip;\\n  }\\n}\\n```\\n\\n## United Kingdom: Post-Brexit Privacy Framework\\n\\n### UK GDPR + PECR Combination\\nThe UK operates its own version of GDPR combined with the Privacy and Electronic Communications Regulations (PECR), creating a unique regulatory environment.\\n\\n### Key Differences from EU GDPR\\n\\n```typescript\\ninterface UKPrivacyRequirements {\\n  ukGDPR: {\\n    similarToEU: boolean; // Largely identical\\n    icoGuidance: boolean; // UK-specific interpretations\\n    adequacyStatus: \'maintained\' | \'under_review\' | \'lost\';\\n  };\\n  pecr: {\\n    electronicMarketing: boolean; // Stricter than GDPR\\n    cookieConsent: boolean; // Specific cookie rules\\n    directMarketing: boolean; // B2B exemptions\\n  };\\n  enforcement: {\\n    maxFines: string; // \\"\xa317.5 million or 4% of turnover\\"\\n    recentActions: string[]; // ICO enforcement examples\\n  };\\n}\\n```\\n\\n### ICO Guidance Implementation\\n\\n```typescript\\nclass UKConsentManager extends EUGDPRConsentManager {\\n  protected getUKSpecificRequirements(): UKRequirements {\\n    return {\\n      pecrCompliance: true,\\n      directMarketingConsent: true,\\n      emailMarketingOptIn: true,\\n      electronicMarketingRules: true\\n    };\\n  }\\n\\n  async handleDirectMarketing(consent: ConsentChoices): Promise<void> {\\n    if (consent.marketing) {\\n      // PECR requires specific consent for electronic marketing\\n      await this.recordMarketingConsent({\\n        email: consent.emailMarketing || false,\\n        sms: consent.smsMarketing || false,\\n        phone: consent.phoneMarketing || false,\\n        post: true // Postal marketing doesn\'t require consent under PECR\\n      });\\n    }\\n  }\\n}\\n```\\n\\n## United States: Patchwork of State Laws\\n\\n### Federal vs. State Approach\\nThe US lacks comprehensive federal privacy legislation, resulting in a complex patchwork of state laws with varying requirements.\\n\\n### California: CCPA/CPRA Leadership\\n\\n```typescript\\ninterface CaliforniaCompliance {\\n  ccpaRequirements: {\\n    doNotSellLink: boolean; // Must be visible\\n    privacyPolicy: boolean; // Detailed disclosures\\n    dataInventory: string[]; // Categories collected\\n    consumerRights: {\\n      rightToKnow: boolean;\\n      rightToDelete: boolean;\\n      rightToOptOut: boolean;\\n      rightToCorrect: boolean; // CPRA addition\\n      rightToLimit: boolean; // CPRA addition\\n    };\\n  };\\n  technicalRequirements: {\\n    globalPrivacyControl: boolean; // Must respect GPC signals\\n    optOutMethods: string[]; // Multiple methods required\\n    verificationProcess: boolean; // Identity verification\\n    responseTimeline: string; // \\"45 days\\"\\n  };\\n}\\n```\\n\\n### CCPA Implementation Example\\n\\n```typescript\\nclass CCPAConsentManager {\\n  private readonly CCPA_VERSION = \'2024.1\';\\n\\n  async initializeCCPACompliance(): Promise<void> {\\n    // Check for Global Privacy Control\\n    this.handleGlobalPrivacyControl();\\n    \\n    // Display \\"Do Not Sell\\" link\\n    this.displayDoNotSellLink();\\n    \\n    // Set up opt-out mechanisms\\n    this.setupOptOutMechanisms();\\n  }\\n\\n  private handleGlobalPrivacyControl(): void {\\n    if (navigator.globalPrivacyControl === true) {\\n      // Automatically honor GPC signal\\n      this.processOptOutRequest({\\n        method: \'gpc\',\\n        timestamp: new Date().toISOString(),\\n        automatic: true\\n      });\\n      \\n      // Update user preferences\\n      this.updateDataSaleOptOut(true);\\n      \\n      // Record GPC processing\\n      this.recordGPCSignal();\\n    }\\n  }\\n\\n  private displayDoNotSellLink(): void {\\n    const doNotSellLink = document.createElement(\'a\');\\n    doNotSellLink.href = \'/do-not-sell\';\\n    doNotSellLink.textContent = \'Do Not Sell My Personal Information\';\\n    doNotSellLink.className = \'ccpa-do-not-sell-link\';\\n    \\n    // Must be visible and accessible\\n    doNotSellLink.style.minHeight = \'20px\';\\n    doNotSellLink.style.minWidth = \'200px\';\\n    doNotSellLink.setAttribute(\'aria-label\', \'Opt out of personal information sale\');\\n    \\n    // Add to footer or prominent location\\n    const footer = document.querySelector(\'footer\') || document.body;\\n    footer.appendChild(doNotSellLink);\\n  }\\n\\n  async processDataRequest(request: CCPADataRequest): Promise<void> {\\n    const { type, email, verificationCode } = request;\\n    \\n    // Verify identity (required for CCPA requests)\\n    const verified = await this.verifyIdentity(email, verificationCode);\\n    if (!verified) {\\n      throw new Error(\'Identity verification failed\');\\n    }\\n\\n    switch (type) {\\n      case \'access\':\\n        return this.processAccessRequest(email);\\n      case \'delete\':\\n        return this.processDeletionRequest(email);\\n      case \'opt-out\':\\n        return this.processOptOutRequest({ email, method: \'form\' });\\n      case \'correct\':\\n        return this.processCorrectionRequest(request);\\n    }\\n  }\\n\\n  private async verifyIdentity(email: string, code?: string): Promise<boolean> {\\n    // CCPA requires reasonable verification methods\\n    if (code) {\\n      return this.verifyTwoFactorCode(email, code);\\n    }\\n    \\n    // For low-risk requests, email verification may suffice\\n    return this.sendVerificationEmail(email);\\n  }\\n}\\n```\\n\\n### Virginia, Colorado, and Connecticut\\n\\n```typescript\\ninterface StatePrivacyLaws {\\n  virginia: {\\n    effectiveDate: \'2023-01-01\';\\n    applicabilityThreshold: \'100k consumers or 25k sales\';\\n    rights: [\'access\', \'correct\', \'delete\', \'portability\', \'opt-out\'];\\n    sensitiveDataConsent: boolean;\\n  };\\n  colorado: {\\n    effectiveDate: \'2023-07-01\';\\n    universalOptOut: boolean; // Must respect GPC\\n    dataProtectionAssessments: boolean;\\n    rights: [\'access\', \'correct\', \'delete\', \'portability\', \'opt-out\'];\\n  };\\n  connecticut: {\\n    effectiveDate: \'2023-07-01\';\\n    similarToVirginia: boolean;\\n    dataMinimization: boolean;\\n    consumerRights: string[];\\n  };\\n}\\n```\\n\\n## Canada: Federal and Provincial Framework\\n\\n### PIPEDA + Provincial Laws\\n\\n```typescript\\ninterface CanadianPrivacyCompliance {\\n  federal: {\\n    pipeda: {\\n      meaningfulConsent: boolean;\\n      plainLanguage: boolean;\\n      withdrawalRights: boolean;\\n      breachNotification: boolean;\\n    };\\n  };\\n  provincial: {\\n    quebec: {\\n      law25: {\\n        gdprLike: boolean;\\n        explicitConsent: boolean;\\n        privacyByDesign: boolean;\\n        effectiveDate: \'2023-09-22\';\\n      };\\n    };\\n    britishColumbia: {\\n      pipa: boolean;\\n      sectorSpecific: boolean;\\n    };\\n    alberta: {\\n      pipa: boolean;\\n      similarToBC: boolean;\\n    };\\n  };\\n}\\n```\\n\\n### Quebec Law 25 Implementation\\n\\n```typescript\\nclass QuebecLaw25ConsentManager {\\n  private readonly LAW25_VERSION = \'2024.1\';\\n\\n  async implementLaw25Compliance(): Promise<void> {\\n    // Similar to GDPR in requirements\\n    const consent = await this.getExplicitConsent();\\n    \\n    // Privacy by design principles\\n    this.implementPrivacyByDesign();\\n    \\n    // Enhanced breach notification\\n    this.setupBreachNotification();\\n    \\n    // Data subject rights\\n    this.setupDataSubjectRights();\\n  }\\n\\n  private async getExplicitConsent(): Promise<ConsentRecord> {\\n    // Quebec requires explicit consent similar to GDPR\\n    return this.displayGDPRStyleBanner({\\n      language: this.detectLanguage(), // French/English\\n      explicitConsent: true,\\n      granularOptions: true,\\n      withdrawalMechanism: true\\n    });\\n  }\\n\\n  private implementPrivacyByDesign(): void {\\n    // Privacy by design is mandatory under Law 25\\n    this.configureDefaultPrivacySettings();\\n    this.minimizeDataCollection();\\n    this.implementDataProtectionMeasures();\\n  }\\n}\\n```\\n\\n## Asia-Pacific: Emerging Privacy Powerhouses\\n\\n### China: PIPL (Personal Information Protection Law)\\n\\n```typescript\\ninterface PIPLCompliance {\\n  applicability: {\\n    dataProcessingInChina: boolean;\\n    chineseNaturalPersons: boolean;\\n    crossBorderTransfers: boolean;\\n  };\\n  keyRequirements: {\\n    explicitConsent: {\\n      informed: boolean;\\n      specific: boolean;\\n      clear: boolean;\\n      voluntary: boolean;\\n    };\\n    dataLocalization: {\\n      criticalInformation: boolean;\\n      importantData: boolean;\\n      personalDataOver1Million: boolean;\\n    };\\n    sensitiveData: {\\n      separateConsent: boolean;\\n      biometricData: boolean;\\n      religiousBeliefs: boolean;\\n      healthData: boolean;\\n    };\\n  };\\n  enforcement: {\\n    fines: string; // \\"Up to 50 million RMB or 5% of revenue\\"\\n    criminalLiability: boolean;\\n  };\\n}\\n```\\n\\n### Implementation for PIPL\\n\\n```typescript\\nclass PIPLConsentManager {\\n  async implementPIPLCompliance(): Promise<void> {\\n    // Check if PIPL applies\\n    if (!this.isPIPLApplicable()) return;\\n\\n    // Implement explicit consent requirements\\n    await this.getExplicitConsent();\\n    \\n    // Handle data localization\\n    this.ensureDataLocalization();\\n    \\n    // Manage sensitive data separately\\n    this.handleSensitiveData();\\n  }\\n\\n  private isPIPLApplicable(): boolean {\\n    const userLocation = this.detectUserLocation();\\n    const dataProcessingLocation = this.getDataProcessingLocation();\\n    \\n    return userLocation === \'CN\' || \\n           dataProcessingLocation === \'CN\' ||\\n           this.targetingChineseUsers();\\n  }\\n\\n  private async getExplicitConsent(): Promise<void> {\\n    const consent = await this.displayConsentBanner({\\n      title: \'\u9690\u79c1\u653f\u7b56\', // Privacy Policy in Chinese\\n      explicitConsentRequired: true,\\n      separateSensitiveDataConsent: true,\\n      dataLocalizationNotice: true,\\n      minimumAge: 14, // China\'s minimum age for consent\\n      parentalConsentRequired: true\\n    });\\n\\n    this.recordPIPLConsent(consent);\\n  }\\n}\\n```\\n\\n### India: DPDP Act 2023\\n\\n```typescript\\ninterface DPDPCompliance {\\n  keyPrinciples: {\\n    lawfulBasis: string[];\\n    dataMinimization: boolean;\\n    accuracy: boolean;\\n    storageLimitation: boolean;\\n    accountability: boolean;\\n  };\\n  consentRequirements: {\\n    clear: boolean;\\n    specific: boolean;\\n    informed: boolean;\\n    freeGiven: boolean;\\n    retrievable: boolean;\\n  };\\n  childrensData: {\\n    parentalConsent: boolean;\\n    ageThreshold: number; // 18 years\\n    verificationRequired: boolean;\\n  };\\n  crossBorderTransfers: {\\n    governmentApproval: boolean;\\n    adequacyDecisions: boolean;\\n    contractualSafeguards: boolean;\\n  };\\n}\\n```\\n\\n## Multi-Jurisdictional Compliance Strategy\\n\\n### Global Compliance Architecture\\n\\n```typescript\\nclass GlobalPrivacyComplianceManager {\\n  private jurisdictionDetector: JurisdictionDetector;\\n  private complianceEngine: ComplianceEngine;\\n  private consentManager: ConsentManager;\\n\\n  constructor() {\\n    this.jurisdictionDetector = new JurisdictionDetector();\\n    this.complianceEngine = new ComplianceEngine();\\n    this.consentManager = new ConsentManager();\\n  }\\n\\n  async initializeCompliance(): Promise<void> {\\n    // Detect user jurisdiction\\n    const jurisdiction = await this.jurisdictionDetector.detect();\\n    \\n    // Get applicable laws\\n    const applicableLaws = this.getApplicableLaws(jurisdiction);\\n    \\n    // Generate compliance configuration\\n    const config = this.complianceEngine.generateConfig(applicableLaws);\\n    \\n    // Initialize consent management\\n    await this.consentManager.initialize(config);\\n  }\\n\\n  private getApplicableLaws(jurisdiction: string): PrivacyLaw[] {\\n    const lawMap: Record<string, PrivacyLaw[]> = {\\n      \'EU\': [PrivacyLaw.GDPR, PrivacyLaw.EPRIVACY],\\n      \'UK\': [PrivacyLaw.UK_GDPR, PrivacyLaw.PECR],\\n      \'US-CA\': [PrivacyLaw.CCPA, PrivacyLaw.CPRA],\\n      \'US-VA\': [PrivacyLaw.VCDPA],\\n      \'US-CO\': [PrivacyLaw.CPA],\\n      \'CA\': [PrivacyLaw.PIPEDA],\\n      \'CA-QC\': [PrivacyLaw.PIPEDA, PrivacyLaw.QUEBEC_LAW25],\\n      \'BR\': [PrivacyLaw.LGPD],\\n      \'CN\': [PrivacyLaw.PIPL],\\n      \'IN\': [PrivacyLaw.DPDP],\\n      \'AU\': [PrivacyLaw.PRIVACY_ACT],\\n      \'JP\': [PrivacyLaw.JAPAN_PIPA],\\n      \'KR\': [PrivacyLaw.KOREA_PIPA],\\n      \'SG\': [PrivacyLaw.SINGAPORE_PDPA]\\n    };\\n\\n    return lawMap[jurisdiction] || [PrivacyLaw.DEFAULT];\\n  }\\n}\\n\\nclass JurisdictionDetector {\\n  async detect(): Promise<string> {\\n    // Primary: User preference/explicit selection\\n    const userPreference = localStorage.getItem(\'jurisdiction_preference\');\\n    if (userPreference) return userPreference;\\n\\n    // Secondary: Geo-IP location\\n    const geoLocation = await this.getGeoIPLocation();\\n    if (geoLocation) return this.mapGeoToJurisdiction(geoLocation);\\n\\n    // Tertiary: Browser language/locale\\n    const browserLocale = navigator.language;\\n    return this.mapLocaleToJurisdiction(browserLocale);\\n  }\\n\\n  private async getGeoIPLocation(): Promise<string | null> {\\n    try {\\n      const response = await fetch(\'/api/geo-location\');\\n      const data = await response.json();\\n      return data.country;\\n    } catch {\\n      return null;\\n    }\\n  }\\n\\n  private mapGeoToJurisdiction(country: string): string {\\n    const euCountries = [\'DE\', \'FR\', \'IT\', \'ES\', \'NL\', \'PL\', \'BE\', \'AT\', \'PT\', \'CZ\', \'HU\', \'SE\', \'GR\', \'DK\', \'FI\', \'SK\', \'IE\', \'HR\', \'LT\', \'SI\', \'LV\', \'EE\', \'CY\', \'LU\', \'MT\'];\\n    \\n    if (euCountries.includes(country)) return \'EU\';\\n    if (country === \'GB\') return \'UK\';\\n    if (country === \'US\') return \'US\'; // Will need state detection\\n    if (country === \'CA\') return \'CA\';\\n    if (country === \'BR\') return \'BR\';\\n    if (country === \'CN\') return \'CN\';\\n    if (country === \'IN\') return \'IN\';\\n    \\n    return \'DEFAULT\';\\n  }\\n}\\n```\\n\\n### Testing Multi-Jurisdictional Compliance\\n\\n```typescript\\n// Automated testing for global compliance\\ndescribe(\'Global Privacy Compliance\', () => {\\n  const jurisdictions = [\\n    { name: \'EU\', geoIP: \'DE\', expectedLaws: [\'GDPR\', \'ePrivacy\'] },\\n    { name: \'UK\', geoIP: \'GB\', expectedLaws: [\'UK_GDPR\', \'PECR\'] },\\n    { name: \'California\', geoIP: \'US\', state: \'CA\', expectedLaws: [\'CCPA\'] },\\n    { name: \'Canada\', geoIP: \'CA\', expectedLaws: [\'PIPEDA\'] },\\n    { name: \'Brazil\', geoIP: \'BR\', expectedLaws: [\'LGPD\'] },\\n    { name: \'China\', geoIP: \'CN\', expectedLaws: [\'PIPL\'] }\\n  ];\\n\\n  jurisdictions.forEach(jurisdiction => {\\n    describe(`${jurisdiction.name} Compliance`, () => {\\n      beforeEach(async () => {\\n        // Mock geo-location\\n        await mockGeoLocation(jurisdiction.geoIP);\\n        if (jurisdiction.state) {\\n          await mockState(jurisdiction.state);\\n        }\\n      });\\n\\n      test(\'should detect correct jurisdiction\', async () => {\\n        const detector = new JurisdictionDetector();\\n        const detected = await detector.detect();\\n        expect(detected).toBe(jurisdiction.name.replace(\' \', \'-\'));\\n      });\\n\\n      test(\'should apply correct privacy laws\', async () => {\\n        const manager = new GlobalPrivacyComplianceManager();\\n        await manager.initializeCompliance();\\n        \\n        const config = manager.getCurrentConfig();\\n        expect(config.applicableLaws).toEqual(\\n          expect.arrayContaining(jurisdiction.expectedLaws)\\n        );\\n      });\\n\\n      test(\'should display appropriate consent banner\', async () => {\\n        const page = await browser.newPage();\\n        await page.goto(\'/\');\\n        \\n        if (jurisdiction.expectedLaws.includes(\'GDPR\')) {\\n          await expect(page.locator(\'[data-testid=\\"gdpr-banner\\"]\')).toBeVisible();\\n          await expect(page.locator(\'[data-testid=\\"reject-all\\"]\')).toBeVisible();\\n        }\\n        \\n        if (jurisdiction.expectedLaws.includes(\'CCPA\')) {\\n          await expect(page.locator(\'text=\\"Do Not Sell\\"\')).toBeVisible();\\n        }\\n      });\\n    });\\n  });\\n});\\n```\\n\\n## 2025 Compliance Trends and Predictions\\n\\n### Emerging Regulatory Trends\\n\\n1. **Harmonization Efforts**: International frameworks for cross-border data transfers\\n2. **AI-Specific Regulations**: Cookie consent for AI training data\\n3. **Children\'s Privacy**: Enhanced protections becoming global standard\\n4. **Consent Fatigue Solutions**: Regulatory push for better UX patterns\\n5. **Real-Time Enforcement**: Automated compliance monitoring tools\\n\\n### Technical Innovation Areas\\n\\n```typescript\\ninterface Future PrivacyTech {\\n  consentBrokers: {\\n    centralizedConsent: boolean;\\n    crossSiteConsent: boolean;\\n    blockchainConsent: boolean;\\n  };\\n  privacyEnhancingTechnologies: {\\n    differentialPrivacy: boolean;\\n    homomorphicEncryption: boolean;\\n    secureMultipartyComputation: boolean;\\n  };\\n  automatedCompliance: {\\n    aiPoweredAuditing: boolean;\\n    realTimeMonitoring: boolean;\\n    predictiveCompliance: boolean;\\n  };\\n}\\n```\\n\\n## Best Practices for Global Compliance\\n\\n### 1. Design for the Strictest Standard\\nImplement GDPR-level controls globally to simplify compliance management.\\n\\n### 2. Layered Privacy Notices\\nProvide summary information upfront with detailed explanations available on demand.\\n\\n### 3. Privacy by Design\\nBuild privacy controls into your architecture from the beginning.\\n\\n### 4. Regular Compliance Audits\\nConduct quarterly reviews of your privacy program and consent mechanisms.\\n\\n### 5. Legal Partnership\\nWork closely with privacy attorneys familiar with each jurisdiction\'s nuances.\\n\\n### 6. User Education\\nHelp users understand their privacy choices through clear, jargon-free explanations.\\n\\n## Conclusion\\n\\nGlobal privacy compliance requires a nuanced understanding of each jurisdiction\'s specific requirements, combined with robust technical implementation and ongoing monitoring. As the regulatory landscape continues to evolve, organizations must balance compliance obligations with user experience considerations.\\n\\nThe key to success lies in building flexible, scalable privacy systems that can adapt to new requirements while maintaining user trust and business functionality. By understanding the specific requirements outlined in this guide and implementing comprehensive compliance strategies, organizations can navigate the complex global privacy landscape effectively.\\n\\nRemember that privacy regulations are continuously evolving, and this guide should be supplemented with current legal advice and regular monitoring of regulatory updates in each jurisdiction where you operate."},{"id":"nestjs-microservices-message-queues-comparison","metadata":{"permalink":"/fullstack-dev/blog/nestjs-microservices-message-queues-comparison","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-07-nestjs-microservices-message-queues-comparison.md","source":"@site/blog/2025-10-07-nestjs-microservices-message-queues-comparison.md","title":"Building Scalable Microservices with NestJS: Message Queues Implementation and Comparison Guide","description":"Message queues are the backbone of modern microservice architectures, enabling asynchronous communication, decoupling services, and providing fault tolerance. In this comprehensive guide, we\'ll explore how to implement message queues in NestJS microservices and compare the most popular message queue solutions: RabbitMQ, Redis, Apache Kafka, and AWS SQS.","date":"2025-10-07T00:00:00.000Z","tags":[{"inline":false,"label":"NestJS","permalink":"/fullstack-dev/blog/tags/nestjs","description":"NestJS framework for Node.js applications"},{"inline":false,"label":"Microservices","permalink":"/fullstack-dev/blog/tags/microservices","description":"Microservices architecture and patterns"},{"inline":false,"label":"Message Queues","permalink":"/fullstack-dev/blog/tags/message-queues","description":"Asynchronous messaging systems"},{"inline":false,"label":"RabbitMQ","permalink":"/fullstack-dev/blog/tags/rabbitmq","description":"RabbitMQ message broker"},{"inline":false,"label":"Redis","permalink":"/fullstack-dev/blog/tags/redis","description":"Redis caching and data storage"},{"inline":false,"label":"Apache Kafka","permalink":"/fullstack-dev/blog/tags/kafka","description":"Apache Kafka streaming platform"},{"inline":false,"label":"AWS SQS","permalink":"/fullstack-dev/blog/tags/aws-sqs","description":"Amazon Simple Queue Service"},{"inline":false,"label":"Architecture","permalink":"/fullstack-dev/blog/tags/architecture","description":"Software architecture and design patterns"},{"inline":false,"label":"Asynchronous","permalink":"/fullstack-dev/blog/tags/asynchronous","description":"Asynchronous programming patterns"},{"inline":false,"label":"Event Driven","permalink":"/fullstack-dev/blog/tags/event-driven","description":"Event-driven architecture"}],"readingTime":12.54,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"nestjs-microservices-message-queues-comparison","title":"Building Scalable Microservices with NestJS: Message Queues Implementation and Comparison Guide","authors":["tam"],"tags":["nestjs","microservices","message-queues","rabbitmq","redis","kafka","aws-sqs","architecture","asynchronous","event-driven"],"date":"2025-10-07T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Global Cookie Privacy Compliance: A Complete Guide to Country-Specific Regulations in 2025","permalink":"/fullstack-dev/blog/global-cookie-privacy-compliance-guide-2025"},"nextItem":{"title":"Comprehensive Guide to Bot Prevention: Protecting Your Website from Automated Threats","permalink":"/fullstack-dev/blog/bot-prevention-mechanisms-website-security"}},"content":"Message queues are the backbone of modern microservice architectures, enabling asynchronous communication, decoupling services, and providing fault tolerance. In this comprehensive guide, we\'ll explore how to implement message queues in NestJS microservices and compare the most popular message queue solutions: RabbitMQ, Redis, Apache Kafka, and AWS SQS.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why Message Queues in Microservices?\\n\\n### \ud83d\udd04 **Asynchronous Communication**\\n- **Decoupled Services**: Services don\'t need to wait for synchronous responses\\n- **Better Performance**: Non-blocking operations improve overall system throughput\\n- **Fault Tolerance**: Messages persist even if consumers are temporarily unavailable\\n- **Scalability**: Independent scaling of producers and consumers\\n\\n### \ud83d\udee1\ufe0f **Reliability Benefits**\\n- **Message Persistence**: Critical data survives service restarts and failures\\n- **Retry Mechanisms**: Automatic retry logic for failed message processing\\n- **Dead Letter Queues**: Failed messages are preserved for analysis\\n- **At-Least-Once Delivery**: Guarantees message delivery under normal conditions\\n\\n### \ud83c\udfd7\ufe0f **Microservice Architecture Patterns**\\n- **Event-Driven Architecture**: Services communicate through domain events\\n- **CQRS (Command Query Responsibility Segregation)**: Separate read/write operations\\n- **Saga Pattern**: Distributed transaction management across services\\n- **Pub/Sub Pattern**: One-to-many message distribution\\n\\n## Architecture Overview\\n\\nLet\'s establish our target microservice architecture with message queues:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502   User Service  \u2502    \u2502  Order Service  \u2502    \u2502Payment Service  \u2502\\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502 Publisher \u2502\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2502 Consumer  \u2502  \u2502    \u2502  \u2502 Consumer  \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2502                 \u2502    \u2502                 \u2502    \u2502                 \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502 Consumer  \u2502  \u2502    \u2502  \u2502 Publisher \u2502\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2502 Consumer  \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n          \u2502                       \u2502                       \u2502\\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                                  \u2502\\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n              \u2502        Message Queue Broker        \u2502\\n              \u2502    (RabbitMQ/Redis/Kafka/SQS)      \u2502\\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## Message Queue Technologies Comparison\\n\\n### 1. **RabbitMQ** \ud83d\udc30\\n\\n**Best For**: Complex routing, guaranteed delivery, enterprise applications\\n\\n**Pros:**\\n- Advanced routing capabilities (exchanges, bindings)\\n- Strong consistency guarantees\\n- Built-in management UI\\n- Excellent NestJS integration\\n- Support for multiple messaging patterns\\n\\n**Cons:**\\n- Higher resource consumption\\n- More complex setup and configuration\\n- Not ideal for extremely high throughput scenarios\\n\\n**Use Cases:**\\n- E-commerce order processing\\n- Financial transaction systems\\n- Task queues with complex routing\\n\\n### 2. **Redis** \u26a1\\n\\n**Best For**: High performance, simple pub/sub, caching + messaging\\n\\n**Pros:**\\n- Extremely fast (in-memory)\\n- Simple setup and configuration\\n- Multiple data structures support\\n- Built-in persistence options\\n- Great for real-time applications\\n\\n**Cons:**\\n- Limited message persistence guarantees\\n- Memory constraints for large message volumes\\n- Basic routing capabilities\\n\\n**Use Cases:**\\n- Real-time notifications\\n- Chat applications\\n- Simple event broadcasting\\n- Cache invalidation events\\n\\n### 3. **Apache Kafka** \ud83d\ude80\\n\\n**Best For**: High throughput, event streaming, big data pipelines\\n\\n**Pros:**\\n- Exceptional throughput and scalability\\n- Event sourcing capabilities\\n- Distributed and fault-tolerant\\n- Long-term message retention\\n- Stream processing support\\n\\n**Cons:**\\n- Complex setup and operations\\n- Higher latency for small messages\\n- Steep learning curve\\n- Resource intensive\\n\\n**Use Cases:**\\n- Event sourcing systems\\n- Real-time analytics\\n- Log aggregation\\n- High-volume transaction processing\\n\\n### 4. **AWS SQS** \u2601\ufe0f\\n\\n**Best For**: Cloud-native applications, serverless architectures\\n\\n**Pros:**\\n- Fully managed service\\n- Automatic scaling\\n- Pay-per-use pricing model\\n- Integrated with AWS ecosystem\\n- Built-in security features\\n\\n**Cons:**\\n- Vendor lock-in\\n- Limited message size (256KB)\\n- Potential latency in cross-region scenarios\\n- Less flexible than self-hosted solutions\\n\\n**Use Cases:**\\n- Serverless applications\\n- AWS-native microservices\\n- Background job processing\\n- Decoupling AWS services\\n\\n## Implementation Examples\\n\\n### 1. NestJS with RabbitMQ\\n\\n#### Installation and Setup\\n\\n```bash\\nnpm install @nestjs/microservices amqplib amqp-connection-manager\\n```\\n\\n#### Message Queue Configuration\\n\\n```typescript\\n// rabbitmq.config.ts\\nimport { Transport } from \'@nestjs/microservices\';\\n\\nexport const rabbitmqConfig = {\\n  transport: Transport.RMQ,\\n  options: {\\n    urls: [process.env.RABBITMQ_URL || \'amqp://localhost:5672\'],\\n    queue: \'main_queue\',\\n    queueOptions: {\\n      durable: true,\\n    },\\n    prefetchCount: 10,\\n    socketOptions: {\\n      heartbeatIntervalInSeconds: 60,\\n      reconnectTimeInSeconds: 5,\\n    },\\n  },\\n};\\n```\\n\\n#### Producer Service\\n\\n```typescript\\n// producer.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { ClientProxy, ClientProxyFactory } from \'@nestjs/microservices\';\\nimport { rabbitmqConfig } from \'./rabbitmq.config\';\\n\\n@Injectable()\\nexport class ProducerService {\\n  private client: ClientProxy;\\n\\n  constructor() {\\n    this.client = ClientProxyFactory.create(rabbitmqConfig);\\n  }\\n\\n  async sendOrderCreated(orderData: any) {\\n    const pattern = \'order.created\';\\n    return this.client.emit(pattern, orderData).toPromise();\\n  }\\n\\n  async sendPaymentRequest(paymentData: any) {\\n    const pattern = \'payment.process\';\\n    return this.client.send(pattern, paymentData).toPromise();\\n  }\\n\\n  async onModuleDestroy() {\\n    await this.client.close();\\n  }\\n}\\n```\\n\\n#### Consumer Controller\\n\\n```typescript\\n// order.controller.ts\\nimport { Controller } from \'@nestjs/common\';\\nimport { MessagePattern, Payload } from \'@nestjs/microservices\';\\nimport { OrderService } from \'./order.service\';\\n\\n@Controller()\\nexport class OrderController {\\n  constructor(private readonly orderService: OrderService) {}\\n\\n  @MessagePattern(\'order.created\')\\n  async handleOrderCreated(@Payload() data: any) {\\n    console.log(\'Processing order:\', data);\\n    \\n    try {\\n      await this.orderService.processOrder(data);\\n      return { success: true, message: \'Order processed successfully\' };\\n    } catch (error) {\\n      console.error(\'Failed to process order:\', error);\\n      throw error;\\n    }\\n  }\\n\\n  @MessagePattern(\'order.cancelled\')\\n  async handleOrderCancelled(@Payload() data: any) {\\n    console.log(\'Cancelling order:\', data);\\n    await this.orderService.cancelOrder(data.orderId);\\n    return { success: true };\\n  }\\n}\\n```\\n\\n#### Microservice Bootstrap\\n\\n```typescript\\n// main.ts\\nimport { NestFactory } from \'@nestjs/core\';\\nimport { AppModule } from \'./app.module\';\\nimport { rabbitmqConfig } from \'./rabbitmq.config\';\\n\\nasync function bootstrap() {\\n  const app = await NestFactory.createMicroservice(AppModule, rabbitmqConfig);\\n  \\n  await app.listen();\\n  console.log(\'Order microservice is listening on RabbitMQ\');\\n}\\nbootstrap();\\n```\\n\\n### 2. NestJS with Redis\\n\\n#### Installation and Setup\\n\\n```bash\\nnpm install @nestjs/microservices redis\\n```\\n\\n#### Redis Configuration\\n\\n```typescript\\n// redis.config.ts\\nimport { Transport } from \'@nestjs/microservices\';\\n\\nexport const redisConfig = {\\n  transport: Transport.REDIS,\\n  options: {\\n    host: process.env.REDIS_HOST || \'localhost\',\\n    port: parseInt(process.env.REDIS_PORT) || 6379,\\n    password: process.env.REDIS_PASSWORD,\\n    retryAttempts: 5,\\n    retryDelay: 3000,\\n  },\\n};\\n```\\n\\n#### Redis Producer\\n\\n```typescript\\n// redis-producer.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { ClientProxy, ClientProxyFactory } from \'@nestjs/microservices\';\\nimport { redisConfig } from \'./redis.config\';\\n\\n@Injectable()\\nexport class RedisProducerService {\\n  private client: ClientProxy;\\n\\n  constructor() {\\n    this.client = ClientProxyFactory.create(redisConfig);\\n  }\\n\\n  async publishNotification(notification: any) {\\n    return this.client.emit(\'notification.send\', notification);\\n  }\\n\\n  async publishCacheInvalidation(cacheKey: string) {\\n    return this.client.emit(\'cache.invalidate\', { key: cacheKey });\\n  }\\n}\\n```\\n\\n#### Redis Consumer\\n\\n```typescript\\n// redis-consumer.controller.ts\\nimport { Controller } from \'@nestjs/common\';\\nimport { EventPattern, Payload } from \'@nestjs/microservices\';\\n\\n@Controller()\\nexport class RedisConsumerController {\\n  @EventPattern(\'notification.send\')\\n  async handleNotification(@Payload() data: any) {\\n    console.log(\'Sending notification:\', data);\\n    // Implement notification logic (email, SMS, push, etc.)\\n  }\\n\\n  @EventPattern(\'cache.invalidate\')\\n  async handleCacheInvalidation(@Payload() data: { key: string }) {\\n    console.log(\'Invalidating cache:\', data.key);\\n    // Implement cache invalidation logic\\n  }\\n}\\n```\\n\\n### 3. NestJS with Apache Kafka\\n\\n#### Installation and Setup\\n\\n```bash\\nnpm install @nestjs/microservices kafkajs\\n```\\n\\n#### Kafka Configuration\\n\\n```typescript\\n// kafka.config.ts\\nimport { Transport } from \'@nestjs/microservices\';\\n\\nexport const kafkaConfig = {\\n  transport: Transport.KAFKA,\\n  options: {\\n    client: {\\n      clientId: \'order-service\',\\n      brokers: [process.env.KAFKA_BROKER || \'localhost:9092\'],\\n    },\\n    consumer: {\\n      groupId: \'order-consumer-group\',\\n      allowAutoTopicCreation: true,\\n    },\\n    producer: {\\n      allowAutoTopicCreation: true,\\n    },\\n  },\\n};\\n```\\n\\n#### Kafka Producer\\n\\n```typescript\\n// kafka-producer.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { ClientKafka, ClientProxyFactory } from \'@nestjs/microservices\';\\nimport { kafkaConfig } from \'./kafka.config\';\\n\\n@Injectable()\\nexport class KafkaProducerService {\\n  private kafka: ClientKafka;\\n\\n  constructor() {\\n    this.kafka = ClientProxyFactory.create(kafkaConfig) as ClientKafka;\\n  }\\n\\n  async onModuleInit() {\\n    await this.kafka.connect();\\n  }\\n\\n  async publishEvent(topic: string, event: any) {\\n    return this.kafka.emit(topic, {\\n      key: event.id,\\n      value: JSON.stringify(event),\\n      timestamp: Date.now().toString(),\\n    });\\n  }\\n\\n  async publishOrderEvent(orderEvent: any) {\\n    return this.publishEvent(\'order-events\', orderEvent);\\n  }\\n\\n  async onModuleDestroy() {\\n    await this.kafka.close();\\n  }\\n}\\n```\\n\\n#### Kafka Consumer\\n\\n```typescript\\n// kafka-consumer.controller.ts\\nimport { Controller } from \'@nestjs/common\';\\nimport { EventPattern, Payload, Ctx, KafkaContext } from \'@nestjs/microservices\';\\n\\n@Controller()\\nexport class KafkaConsumerController {\\n  @EventPattern(\'order-events\')\\n  async handleOrderEvent(@Payload() message: any, @Ctx() context: KafkaContext) {\\n    const { partition, offset, timestamp } = context.getMessage();\\n    \\n    console.log(\'Received order event:\', {\\n      value: message,\\n      partition,\\n      offset,\\n      timestamp,\\n    });\\n\\n    try {\\n      // Process the order event\\n      await this.processOrderEvent(JSON.parse(message.value));\\n      \\n      // Manually commit offset (if needed)\\n      const heartbeat = context.getHeartbeat();\\n      await heartbeat();\\n    } catch (error) {\\n      console.error(\'Failed to process order event:\', error);\\n      throw error;\\n    }\\n  }\\n\\n  private async processOrderEvent(event: any) {\\n    switch (event.type) {\\n      case \'ORDER_CREATED\':\\n        await this.handleOrderCreated(event.data);\\n        break;\\n      case \'ORDER_UPDATED\':\\n        await this.handleOrderUpdated(event.data);\\n        break;\\n      case \'ORDER_CANCELLED\':\\n        await this.handleOrderCancelled(event.data);\\n        break;\\n      default:\\n        console.warn(\'Unknown event type:\', event.type);\\n    }\\n  }\\n}\\n```\\n\\n### 4. NestJS with AWS SQS\\n\\n#### Installation and Setup\\n\\n```bash\\nnpm install @aws-sdk/client-sqs\\n```\\n\\n#### SQS Service Implementation\\n\\n```typescript\\n// sqs.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { SQSClient, SendMessageCommand, ReceiveMessageCommand, DeleteMessageCommand } from \'@aws-sdk/client-sqs\';\\n\\n@Injectable()\\nexport class SQSService {\\n  private readonly sqsClient: SQSClient;\\n  private readonly queueUrl: string;\\n\\n  constructor() {\\n    this.sqsClient = new SQSClient({\\n      region: process.env.AWS_REGION || \'us-east-1\',\\n      credentials: {\\n        accessKeyId: process.env.AWS_ACCESS_KEY_ID,\\n        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,\\n      },\\n    });\\n    this.queueUrl = process.env.SQS_QUEUE_URL;\\n  }\\n\\n  async sendMessage(messageBody: any, delaySeconds?: number) {\\n    const command = new SendMessageCommand({\\n      QueueUrl: this.queueUrl,\\n      MessageBody: JSON.stringify(messageBody),\\n      DelaySeconds: delaySeconds || 0,\\n      MessageAttributes: {\\n        \'timestamp\': {\\n          DataType: \'String\',\\n          StringValue: new Date().toISOString(),\\n        },\\n        \'service\': {\\n          DataType: \'String\',\\n          StringValue: \'order-service\',\\n        },\\n      },\\n    });\\n\\n    return await this.sqsClient.send(command);\\n  }\\n\\n  async receiveMessages(maxMessages: number = 10) {\\n    const command = new ReceiveMessageCommand({\\n      QueueUrl: this.queueUrl,\\n      MaxNumberOfMessages: maxMessages,\\n      WaitTimeSeconds: 20, // Long polling\\n      MessageAttributeNames: [\'All\'],\\n    });\\n\\n    return await this.sqsClient.send(command);\\n  }\\n\\n  async deleteMessage(receiptHandle: string) {\\n    const command = new DeleteMessageCommand({\\n      QueueUrl: this.queueUrl,\\n      ReceiptHandle: receiptHandle,\\n    });\\n\\n    return await this.sqsClient.send(command);\\n  }\\n}\\n```\\n\\n#### SQS Consumer Service\\n\\n```typescript\\n// sqs-consumer.service.ts\\nimport { Injectable, OnModuleInit } from \'@nestjs/common\';\\nimport { SQSService } from \'./sqs.service\';\\n\\n@Injectable()\\nexport class SQSConsumerService implements OnModuleInit {\\n  private isPolling = false;\\n\\n  constructor(private readonly sqsService: SQSService) {}\\n\\n  onModuleInit() {\\n    this.startPolling();\\n  }\\n\\n  private async startPolling() {\\n    if (this.isPolling) return;\\n    \\n    this.isPolling = true;\\n    \\n    while (this.isPolling) {\\n      try {\\n        const result = await this.sqsService.receiveMessages(10);\\n        \\n        if (result.Messages && result.Messages.length > 0) {\\n          await Promise.all(\\n            result.Messages.map(message => this.processMessage(message))\\n          );\\n        }\\n      } catch (error) {\\n        console.error(\'Error polling SQS:\', error);\\n        await this.sleep(5000); // Wait 5 seconds before retrying\\n      }\\n    }\\n  }\\n\\n  private async processMessage(message: any) {\\n    try {\\n      const messageBody = JSON.parse(message.Body);\\n      console.log(\'Processing SQS message:\', messageBody);\\n      \\n      // Process your message here\\n      await this.handleMessage(messageBody);\\n      \\n      // Delete message after successful processing\\n      await this.sqsService.deleteMessage(message.ReceiptHandle);\\n    } catch (error) {\\n      console.error(\'Failed to process message:\', error);\\n      // Message will be returned to queue after visibility timeout\\n    }\\n  }\\n\\n  private async handleMessage(messageBody: any) {\\n    // Implement your business logic here\\n    switch (messageBody.type) {\\n      case \'ORDER_CREATED\':\\n        await this.handleOrderCreated(messageBody.data);\\n        break;\\n      case \'PAYMENT_PROCESSED\':\\n        await this.handlePaymentProcessed(messageBody.data);\\n        break;\\n      default:\\n        console.warn(\'Unknown message type:\', messageBody.type);\\n    }\\n  }\\n\\n  private async sleep(ms: number) {\\n    return new Promise(resolve => setTimeout(resolve, ms));\\n  }\\n}\\n```\\n\\n## Advanced Patterns and Best Practices\\n\\n### 1. Dead Letter Queue Implementation\\n\\n```typescript\\n// dead-letter.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class DeadLetterService {\\n  async handleFailedMessage(message: any, error: Error, retryCount: number) {\\n    if (retryCount >= 3) {\\n      // Send to dead letter queue\\n      await this.sendToDeadLetterQueue({\\n        originalMessage: message,\\n        error: error.message,\\n        failedAt: new Date(),\\n        retryCount,\\n      });\\n    } else {\\n      // Retry with exponential backoff\\n      const delay = Math.pow(2, retryCount) * 1000;\\n      setTimeout(() => {\\n        this.retryMessage(message, retryCount + 1);\\n      }, delay);\\n    }\\n  }\\n\\n  private async sendToDeadLetterQueue(failedMessage: any) {\\n    // Implementation depends on your message queue choice\\n    console.log(\'Sending to dead letter queue:\', failedMessage);\\n  }\\n\\n  private async retryMessage(message: any, retryCount: number) {\\n    // Retry logic here\\n  }\\n}\\n```\\n\\n### 2. Message Deduplication\\n\\n```typescript\\n// deduplication.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class DeduplicationService {\\n  private readonly processedMessages = new Set<string>();\\n\\n  async isMessageProcessed(messageId: string): Promise<boolean> {\\n    return this.processedMessages.has(messageId);\\n  }\\n\\n  async markMessageAsProcessed(messageId: string): Promise<void> {\\n    this.processedMessages.add(messageId);\\n    \\n    // In production, use Redis or database for persistence\\n    // await this.redis.setex(`processed:${messageId}`, 3600, \'true\');\\n  }\\n\\n  async processMessageIdempotently<T>(\\n    messageId: string,\\n    processor: () => Promise<T>\\n  ): Promise<T | null> {\\n    if (await this.isMessageProcessed(messageId)) {\\n      console.log(`Message ${messageId} already processed, skipping`);\\n      return null;\\n    }\\n\\n    try {\\n      const result = await processor();\\n      await this.markMessageAsProcessed(messageId);\\n      return result;\\n    } catch (error) {\\n      console.error(`Failed to process message ${messageId}:`, error);\\n      throw error;\\n    }\\n  }\\n}\\n```\\n\\n### 3. Circuit Breaker Pattern\\n\\n```typescript\\n// circuit-breaker.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\n\\nenum CircuitState {\\n  CLOSED = \'CLOSED\',\\n  OPEN = \'OPEN\',\\n  HALF_OPEN = \'HALF_OPEN\',\\n}\\n\\n@Injectable()\\nexport class CircuitBreakerService {\\n  private state = CircuitState.CLOSED;\\n  private failures = 0;\\n  private lastFailureTime: number = 0;\\n  private readonly failureThreshold = 5;\\n  private readonly timeout = 60000; // 1 minute\\n\\n  async executeWithCircuitBreaker<T>(operation: () => Promise<T>): Promise<T> {\\n    if (this.state === CircuitState.OPEN) {\\n      if (Date.now() - this.lastFailureTime > this.timeout) {\\n        this.state = CircuitState.HALF_OPEN;\\n      } else {\\n        throw new Error(\'Circuit breaker is OPEN\');\\n      }\\n    }\\n\\n    try {\\n      const result = await operation();\\n      this.onSuccess();\\n      return result;\\n    } catch (error) {\\n      this.onFailure();\\n      throw error;\\n    }\\n  }\\n\\n  private onSuccess() {\\n    this.failures = 0;\\n    this.state = CircuitState.CLOSED;\\n  }\\n\\n  private onFailure() {\\n    this.failures++;\\n    this.lastFailureTime = Date.now();\\n\\n    if (this.failures >= this.failureThreshold) {\\n      this.state = CircuitState.OPEN;\\n    }\\n  }\\n}\\n```\\n\\n## Performance Optimization Strategies\\n\\n### 1. Message Batching\\n\\n```typescript\\n// batch-processor.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class BatchProcessorService {\\n  private batch: any[] = [];\\n  private readonly batchSize = 100;\\n  private readonly batchTimeout = 5000; // 5 seconds\\n  private batchTimer: NodeJS.Timeout;\\n\\n  async addToBatch(message: any) {\\n    this.batch.push(message);\\n\\n    if (this.batch.length >= this.batchSize) {\\n      await this.processBatch();\\n    } else if (!this.batchTimer) {\\n      this.batchTimer = setTimeout(() => {\\n        this.processBatch();\\n      }, this.batchTimeout);\\n    }\\n  }\\n\\n  private async processBatch() {\\n    if (this.batch.length === 0) return;\\n\\n    const currentBatch = [...this.batch];\\n    this.batch = [];\\n\\n    if (this.batchTimer) {\\n      clearTimeout(this.batchTimer);\\n      this.batchTimer = null;\\n    }\\n\\n    try {\\n      await this.processMessages(currentBatch);\\n    } catch (error) {\\n      console.error(\'Batch processing failed:\', error);\\n      // Handle failed batch (retry, DLQ, etc.)\\n    }\\n  }\\n\\n  private async processMessages(messages: any[]) {\\n    console.log(`Processing batch of ${messages.length} messages`);\\n    // Implement batch processing logic\\n  }\\n}\\n```\\n\\n### 2. Connection Pooling\\n\\n```typescript\\n// connection-pool.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class ConnectionPoolService {\\n  private readonly pool: any[] = [];\\n  private readonly maxConnections = 10;\\n  private readonly minConnections = 2;\\n\\n  async getConnection() {\\n    if (this.pool.length > 0) {\\n      return this.pool.pop();\\n    }\\n\\n    if (this.getTotalConnections() < this.maxConnections) {\\n      return await this.createConnection();\\n    }\\n\\n    // Wait for available connection\\n    return await this.waitForConnection();\\n  }\\n\\n  async releaseConnection(connection: any) {\\n    if (this.pool.length < this.minConnections) {\\n      this.pool.push(connection);\\n    } else {\\n      await this.closeConnection(connection);\\n    }\\n  }\\n\\n  private async createConnection() {\\n    // Create and return new connection\\n  }\\n\\n  private async waitForConnection() {\\n    // Implement connection waiting logic\\n  }\\n\\n  private getTotalConnections(): number {\\n    // Return total number of connections\\n    return this.pool.length;\\n  }\\n}\\n```\\n\\n## Monitoring and Observability\\n\\n### 1. Metrics Collection\\n\\n```typescript\\n// metrics.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class MetricsService {\\n  private metrics = {\\n    messagesProduced: 0,\\n    messagesConsumed: 0,\\n    messagesFailed: 0,\\n    averageProcessingTime: 0,\\n  };\\n\\n  incrementProduced() {\\n    this.metrics.messagesProduced++;\\n  }\\n\\n  incrementConsumed() {\\n    this.metrics.messagesConsumed++;\\n  }\\n\\n  incrementFailed() {\\n    this.metrics.messagesFailed++;\\n  }\\n\\n  recordProcessingTime(duration: number) {\\n    // Calculate rolling average\\n    this.metrics.averageProcessingTime = \\n      (this.metrics.averageProcessingTime + duration) / 2;\\n  }\\n\\n  getMetrics() {\\n    return {\\n      ...this.metrics,\\n      successRate: this.calculateSuccessRate(),\\n      timestamp: new Date(),\\n    };\\n  }\\n\\n  private calculateSuccessRate(): number {\\n    const total = this.metrics.messagesConsumed + this.metrics.messagesFailed;\\n    return total > 0 ? (this.metrics.messagesConsumed / total) * 100 : 100;\\n  }\\n}\\n```\\n\\n### 2. Health Checks\\n\\n```typescript\\n// health-check.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class HealthCheckService {\\n  async checkMessageQueueHealth(): Promise<boolean> {\\n    try {\\n      // Implement health check for your message queue\\n      await this.pingMessageQueue();\\n      return true;\\n    } catch (error) {\\n      console.error(\'Message queue health check failed:\', error);\\n      return false;\\n    }\\n  }\\n\\n  async checkDatabaseHealth(): Promise<boolean> {\\n    try {\\n      // Implement database health check\\n      return true;\\n    } catch (error) {\\n      console.error(\'Database health check failed:\', error);\\n      return false;\\n    }\\n  }\\n\\n  async getHealthStatus() {\\n    const [mqHealth, dbHealth] = await Promise.all([\\n      this.checkMessageQueueHealth(),\\n      this.checkDatabaseHealth(),\\n    ]);\\n\\n    return {\\n      status: mqHealth && dbHealth ? \'healthy\' : \'unhealthy\',\\n      services: {\\n        messageQueue: mqHealth ? \'up\' : \'down\',\\n        database: dbHealth ? \'up\' : \'down\',\\n      },\\n      timestamp: new Date(),\\n    };\\n  }\\n\\n  private async pingMessageQueue() {\\n    // Implement specific ping logic for your message queue\\n  }\\n}\\n```\\n\\n## Testing Strategies\\n\\n### 1. Unit Testing Message Handlers\\n\\n```typescript\\n// order.controller.spec.ts\\nimport { Test, TestingModule } from \'@nestjs/testing\';\\nimport { OrderController } from \'./order.controller\';\\nimport { OrderService } from \'./order.service\';\\n\\ndescribe(\'OrderController\', () => {\\n  let controller: OrderController;\\n  let orderService: OrderService;\\n\\n  beforeEach(async () => {\\n    const module: TestingModule = await Test.createTestingModule({\\n      controllers: [OrderController],\\n      providers: [\\n        {\\n          provide: OrderService,\\n          useValue: {\\n            processOrder: jest.fn(),\\n            cancelOrder: jest.fn(),\\n          },\\n        },\\n      ],\\n    }).compile();\\n\\n    controller = module.get<OrderController>(OrderController);\\n    orderService = module.get<OrderService>(OrderService);\\n  });\\n\\n  describe(\'handleOrderCreated\', () => {\\n    it(\'should process order successfully\', async () => {\\n      const orderData = { id: \'123\', amount: 100 };\\n      jest.spyOn(orderService, \'processOrder\').mockResolvedValue(undefined);\\n\\n      const result = await controller.handleOrderCreated(orderData);\\n\\n      expect(orderService.processOrder).toHaveBeenCalledWith(orderData);\\n      expect(result).toEqual({ success: true, message: \'Order processed successfully\' });\\n    });\\n\\n    it(\'should handle processing errors\', async () => {\\n      const orderData = { id: \'123\', amount: 100 };\\n      const error = new Error(\'Processing failed\');\\n      jest.spyOn(orderService, \'processOrder\').mockRejectedValue(error);\\n\\n      await expect(controller.handleOrderCreated(orderData)).rejects.toThrow(error);\\n    });\\n  });\\n});\\n```\\n\\n### 2. Integration Testing\\n\\n```typescript\\n// message-queue.integration.spec.ts\\nimport { Test, TestingModule } from \'@nestjs/testing\';\\nimport { ClientProxy } from \'@nestjs/microservices\';\\nimport { ProducerService } from \'./producer.service\';\\n\\ndescribe(\'Message Queue Integration\', () => {\\n  let producerService: ProducerService;\\n  let client: ClientProxy;\\n\\n  beforeEach(async () => {\\n    const module: TestingModule = await Test.createTestingModule({\\n      providers: [\\n        ProducerService,\\n        {\\n          provide: \'MESSAGE_QUEUE_CLIENT\',\\n          useValue: {\\n            emit: jest.fn(),\\n            send: jest.fn(),\\n          },\\n        },\\n      ],\\n    }).compile();\\n\\n    producerService = module.get<ProducerService>(ProducerService);\\n    client = module.get<ClientProxy>(\'MESSAGE_QUEUE_CLIENT\');\\n  });\\n\\n  it(\'should send order created event\', async () => {\\n    const orderData = { id: \'123\', amount: 100 };\\n    jest.spyOn(client, \'emit\').mockReturnValue(Promise.resolve());\\n\\n    await producerService.sendOrderCreated(orderData);\\n\\n    expect(client.emit).toHaveBeenCalledWith(\'order.created\', orderData);\\n  });\\n});\\n```\\n\\n## Decision Matrix: Choosing the Right Message Queue\\n\\n| Factor | RabbitMQ | Redis | Kafka | AWS SQS |\\n|--------|----------|-------|-------|---------|\\n| **Setup Complexity** | Medium | Low | High | Very Low |\\n| **Throughput** | High | Very High | Extreme | Medium |\\n| **Persistence** | Excellent | Good | Excellent | Good |\\n| **Routing Flexibility** | Excellent | Basic | Medium | Basic |\\n| **Operational Overhead** | Medium | Low | High | None |\\n| **Cost** | Medium | Low | Medium | Variable |\\n| **Learning Curve** | Medium | Low | High | Low |\\n| **Cloud Native** | Good | Good | Good | Excellent |\\n\\n### Recommendation Guidelines\\n\\n**Choose RabbitMQ when:**\\n- You need complex routing and message patterns\\n- Reliability and message guarantees are critical\\n- You have moderate to high throughput requirements\\n- You prefer open-source solutions\\n\\n**Choose Redis when:**\\n- You need extremely fast message processing\\n- You\'re already using Redis for caching\\n- You have simple pub/sub requirements\\n- Real-time performance is critical\\n\\n**Choose Kafka when:**\\n- You need to handle massive message volumes\\n- Event sourcing is part of your architecture\\n- You need long-term message retention\\n- You\'re building data streaming pipelines\\n\\n**Choose AWS SQS when:**\\n- You\'re building on AWS infrastructure\\n- You prefer managed services\\n- You need automatic scaling\\n- You want to minimize operational overhead\\n\\n## Conclusion\\n\\nImplementing message queues in NestJS microservices provides the foundation for building scalable, resilient, and maintainable applications. Each message queue technology has its strengths and ideal use cases:\\n\\n- **RabbitMQ** excels in enterprise applications requiring complex routing and strong guarantees\\n- **Redis** provides unmatched performance for real-time applications\\n- **Kafka** handles massive scale and supports event-driven architectures\\n- **AWS SQS** offers simplicity and seamless cloud integration\\n\\nThe key to success lies in understanding your specific requirements, considering factors like throughput, persistence, complexity, and operational overhead. Start with simpler solutions like Redis or AWS SQS for basic use cases, and consider RabbitMQ or Kafka as your requirements grow in complexity and scale.\\n\\nRemember to implement proper error handling, monitoring, and testing strategies regardless of your chosen message queue technology. These patterns ensure your microservices remain robust and maintainable as they evolve.\\n\\n---\\n\\n*Ready to implement message queues in your NestJS microservices? Start with the technology that best fits your current needs, and don\'t hesitate to evolve your solution as your requirements change.*"},{"id":"bot-prevention-mechanisms-website-security","metadata":{"permalink":"/fullstack-dev/blog/bot-prevention-mechanisms-website-security","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-06-bot-prevention-mechanisms-website-security.md","source":"@site/blog/2025-10-06-bot-prevention-mechanisms-website-security.md","title":"Comprehensive Guide to Bot Prevention: Protecting Your Website from Automated Threats","description":"In today\'s digital landscape, bots account for nearly 40% of all web traffic, and not all of them are benign. While some bots serve legitimate purposes like search engine crawlers and monitoring services, malicious bots can scrape content, launch DDoS attacks, attempt credential stuffing, and consume resources. Implementing effective bot prevention mechanisms is crucial for maintaining website performance, security, and user experience.","date":"2025-10-06T00:00:00.000Z","tags":[{"inline":false,"label":"Bot Prevention","permalink":"/fullstack-dev/blog/tags/bot-prevention","description":"Bot prevention and anti-spam techniques"},{"inline":false,"label":"Web Security","permalink":"/fullstack-dev/blog/tags/web-security","description":"Web application security practices"},{"inline":false,"label":"Rate Limiting","permalink":"/fullstack-dev/blog/tags/rate-limiting","description":"Rate limiting and throttling techniques"},{"inline":false,"label":"CAPTCHA","permalink":"/fullstack-dev/blog/tags/captcha","description":"CAPTCHA and bot detection systems"},{"inline":false,"label":"Cybersecurity","permalink":"/fullstack-dev/blog/tags/cybersecurity","description":"Cybersecurity practices and principles"},{"inline":false,"label":"DDoS Protection","permalink":"/fullstack-dev/blog/tags/ddos-protection","description":"DDoS attack prevention and mitigation"},{"inline":false,"label":"Nginx","permalink":"/fullstack-dev/blog/tags/nginx","description":"Nginx web server and configuration"},{"inline":false,"label":"Cloudflare","permalink":"/fullstack-dev/blog/tags/cloudflare","description":"Cloudflare CDN and security services"}],"readingTime":17.11,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"bot-prevention-mechanisms-website-security","title":"Comprehensive Guide to Bot Prevention: Protecting Your Website from Automated Threats","authors":["tam"],"tags":["bot-prevention","web-security","rate-limiting","captcha","cybersecurity","ddos-protection","nginx","cloudflare"]},"unlisted":false,"prevItem":{"title":"Building Scalable Microservices with NestJS: Message Queues Implementation and Comparison Guide","permalink":"/fullstack-dev/blog/nestjs-microservices-message-queues-comparison"},"nextItem":{"title":"Securing Your Website with Let\'s Encrypt and Nginx: A Complete Guide","permalink":"/fullstack-dev/blog/lets-encrypt-nginx-ssl-setup"}},"content":"In today\'s digital landscape, bots account for nearly 40% of all web traffic, and not all of them are benign. While some bots serve legitimate purposes like search engine crawlers and monitoring services, malicious bots can scrape content, launch DDoS attacks, attempt credential stuffing, and consume resources. Implementing effective bot prevention mechanisms is crucial for maintaining website performance, security, and user experience.\\n\\nThis comprehensive guide explores various bot prevention strategies, from basic techniques to advanced AI-powered solutions, helping you build a robust defense against automated threats.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Understanding the Bot Landscape\\n\\n### Types of Bots\\n\\n**Good Bots**:\\n- Search engine crawlers (Googlebot, Bingbot)\\n- Social media crawlers (Facebook, Twitter)\\n- Monitoring and uptime services\\n- SEO tools and analytics bots\\n- API clients and legitimate automation\\n\\n**Bad Bots**:\\n- Web scrapers stealing content\\n- DDoS attack bots\\n- Credential stuffing bots\\n- Click fraud bots\\n- Spam bots\\n- Vulnerability scanners\\n\\n### Common Bot Attack Patterns\\n\\n1. **High-frequency requests** from single IP addresses\\n2. **Unusual user agents** or missing browser headers\\n3. **Sequential access patterns** (systematic crawling)\\n4. **Abnormal session behavior** (no cookies, JavaScript disabled)\\n5. **Geolocation anomalies** (requests from unexpected locations)\\n\\n## Basic Bot Prevention Techniques\\n\\n### 1. Rate Limiting\\n\\nRate limiting is the first line of defense against bot attacks by controlling request frequency.\\n\\n#### Nginx Rate Limiting Configuration\\n\\n```nginx\\n# Basic rate limiting by IP\\nhttp {\\n    limit_req_zone $binary_remote_addr zone=general:10m rate=10r/s;\\n    limit_req_zone $binary_remote_addr zone=login:10m rate=1r/s;\\n    limit_req_zone $binary_remote_addr zone=api:10m rate=20r/s;\\n    \\n    # Rate limiting with burst and delay\\n    server {\\n        location / {\\n            limit_req zone=general burst=20 nodelay;\\n            limit_req_status 429;\\n        }\\n        \\n        location /login {\\n            limit_req zone=login burst=3;\\n            limit_req_status 429;\\n        }\\n        \\n        location /api/ {\\n            limit_req zone=api burst=50 nodelay;\\n        }\\n    }\\n}\\n```\\n\\n#### Advanced Rate Limiting with Whitelisting\\n\\n```nginx\\n# Whitelist trusted IPs and services\\ngeo $limit {\\n    default 1;\\n    10.0.0.0/8 0;        # Internal network\\n    66.249.64.0/19 0;    # Googlebot\\n    157.55.39.0/24 0;    # Bingbot\\n    69.63.176.0/20 0;    # Yahoo bot\\n}\\n\\nmap $limit $limit_key {\\n    0 \\"\\";\\n    1 $binary_remote_addr;\\n}\\n\\nlimit_req_zone $limit_key zone=protected:10m rate=5r/s;\\n\\nserver {\\n    location / {\\n        limit_req zone=protected burst=10 nodelay;\\n    }\\n}\\n```\\n\\n### 2. User Agent Analysis\\n\\nBlocking requests based on suspicious or missing user agents.\\n\\n```nginx\\n# Block empty or suspicious user agents\\nmap $http_user_agent $bad_bot {\\n    default 0;\\n    \\"\\" 1;                           # Empty user agent\\n    \\"~*bot\\" 1;                      # Generic bot patterns\\n    \\"~*spider\\" 1;                   # Spider patterns\\n    \\"~*crawler\\" 1;                  # Crawler patterns\\n    \\"~*(curl|wget|python)\\" 1;       # Command line tools\\n    \\"~*scrapy\\" 1;                   # Scrapy framework\\n    \\"~*http_request\\" 1;             # Generic HTTP libraries\\n}\\n\\nserver {\\n    if ($bad_bot) {\\n        return 403;\\n    }\\n    \\n    # Allow legitimate bots\\n    if ($http_user_agent ~* \\"(googlebot|bingbot|slurp|duckduckbot)\\") {\\n        set $bad_bot 0;\\n    }\\n}\\n```\\n\\n### 3. IP-Based Blocking\\n\\n```nginx\\n# Block known malicious IP ranges\\ngeo $blocked_ip {\\n    default 0;\\n    # Example malicious IP ranges\\n    192.168.1.0/24 1;\\n    10.0.0.0/8 1;\\n}\\n\\n# GeoIP blocking (requires GeoIP module)\\nmap $geoip_country_code $blocked_country {\\n    default 0;\\n    CN 1;  # Example: block China\\n    RU 1;  # Example: block Russia\\n}\\n\\nserver {\\n    if ($blocked_ip) {\\n        return 403;\\n    }\\n    \\n    if ($blocked_country) {\\n        return 403;\\n    }\\n}\\n```\\n\\n## Intermediate Bot Prevention Methods\\n\\n### 1. JavaScript Challenges\\n\\nImplement client-side challenges that require JavaScript execution.\\n\\n```html\\n\x3c!-- Simple JavaScript challenge --\x3e\\n<script>\\ndocument.addEventListener(\'DOMContentLoaded\', function() {\\n    // Generate random challenge\\n    const challenge = Math.floor(Math.random() * 1000);\\n    const answer = challenge * 2;\\n    \\n    // Set cookie with answer\\n    document.cookie = `bot_check=${answer}; path=/; max-age=3600`;\\n    \\n    // Submit challenge\\n    fetch(\'/bot-check\', {\\n        method: \'POST\',\\n        headers: {\\n            \'Content-Type\': \'application/json\',\\n        },\\n        body: JSON.stringify({\\n            challenge: challenge,\\n            answer: answer\\n        })\\n    });\\n});\\n<\/script>\\n```\\n\\nServer-side validation (Node.js example):\\n```javascript\\napp.post(\'/bot-check\', (req, res) => {\\n    const { challenge, answer } = req.body;\\n    const expectedAnswer = challenge * 2;\\n    \\n    if (answer === expectedAnswer) {\\n        // Set session as human-verified\\n        req.session.humanVerified = true;\\n        res.json({ success: true });\\n    } else {\\n        res.status(403).json({ error: \'Bot detected\' });\\n    }\\n});\\n```\\n\\n### 2. Honeypot Fields\\n\\nAdd hidden form fields that humans won\'t fill but bots might.\\n\\n```html\\n\x3c!-- HTML form with honeypot --\x3e\\n<form action=\\"/submit\\" method=\\"post\\">\\n    <input type=\\"text\\" name=\\"username\\" placeholder=\\"Username\\" required>\\n    <input type=\\"password\\" name=\\"password\\" placeholder=\\"Password\\" required>\\n    \\n    \x3c!-- Honeypot field (hidden from humans) --\x3e\\n    <input type=\\"text\\" name=\\"website\\" style=\\"display:none;\\" tabindex=\\"-1\\" autocomplete=\\"off\\">\\n    \\n    <button type=\\"submit\\">Login</button>\\n</form>\\n\\n<style>\\n/* Additional CSS hiding */\\ninput[name=\\"website\\"] {\\n    opacity: 0;\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n    height: 0;\\n    width: 0;\\n    z-index: -1;\\n}\\n</style>\\n```\\n\\nServer-side validation:\\n```javascript\\napp.post(\'/submit\', (req, res) => {\\n    // If honeypot field is filled, it\'s likely a bot\\n    if (req.body.website && req.body.website.trim() !== \'\') {\\n        return res.status(403).json({ error: \'Bot detected\' });\\n    }\\n    \\n    // Process legitimate request\\n    // ... normal form processing\\n});\\n```\\n\\n### 3. CAPTCHA Implementation\\n\\n#### reCAPTCHA v3 Integration\\n\\n```html\\n\x3c!-- Google reCAPTCHA v3 --\x3e\\n<script src=\\"https://www.google.com/recaptcha/api.js?render=YOUR_SITE_KEY\\"><\/script>\\n\\n<form id=\\"contact-form\\">\\n    <input type=\\"text\\" name=\\"name\\" required>\\n    <input type=\\"email\\" name=\\"email\\" required>\\n    <textarea name=\\"message\\" required></textarea>\\n    <button type=\\"submit\\">Submit</button>\\n</form>\\n\\n<script>\\ndocument.getElementById(\'contact-form\').addEventListener(\'submit\', function(e) {\\n    e.preventDefault();\\n    \\n    grecaptcha.ready(function() {\\n        grecaptcha.execute(\'YOUR_SITE_KEY\', {action: \'submit\'}).then(function(token) {\\n            // Add token to form\\n            const input = document.createElement(\'input\');\\n            input.type = \'hidden\';\\n            input.name = \'recaptcha_token\';\\n            input.value = token;\\n            e.target.appendChild(input);\\n            \\n            // Submit form\\n            e.target.submit();\\n        });\\n    });\\n});\\n<\/script>\\n```\\n\\nServer-side verification:\\n```javascript\\nconst axios = require(\'axios\');\\n\\napp.post(\'/submit\', async (req, res) => {\\n    const { recaptcha_token } = req.body;\\n    \\n    try {\\n        const response = await axios.post(\'https://www.google.com/recaptcha/api/siteverify\', {\\n            secret: process.env.RECAPTCHA_SECRET_KEY,\\n            response: recaptcha_token\\n        });\\n        \\n        const { success, score } = response.data;\\n        \\n        if (success && score > 0.5) {\\n            // Process as human\\n            // ... handle form submission\\n        } else {\\n            res.status(403).json({ error: \'Suspicious activity detected\' });\\n        }\\n    } catch (error) {\\n        res.status(500).json({ error: \'Verification failed\' });\\n    }\\n});\\n```\\n\\n#### Cloudflare Turnstile - Privacy-Focused Alternative\\n\\nCloudflare Turnstile is a privacy-focused alternative to traditional CAPTCHAs that doesn\'t require users to solve puzzles.\\n\\n**Client-Side Implementation**:\\n```html\\n\x3c!-- Cloudflare Turnstile --\x3e\\n<script src=\\"https://challenges.cloudflare.com/turnstile/v0/api.js\\" async defer><\/script>\\n\\n<form id=\\"demo-form\\">\\n    <input type=\\"text\\" name=\\"name\\" placeholder=\\"Name\\" required>\\n    <input type=\\"email\\" name=\\"email\\" placeholder=\\"Email\\" required>\\n    <textarea name=\\"message\\" placeholder=\\"Message\\" required></textarea>\\n    \\n    \x3c!-- Turnstile widget --\x3e\\n    <div class=\\"cf-turnstile\\" \\n         data-sitekey=\\"YOUR_SITE_KEY\\"\\n         data-callback=\\"onTurnstileSuccess\\"\\n         data-error-callback=\\"onTurnstileError\\"\\n         data-expired-callback=\\"onTurnstileExpired\\"\\n         data-theme=\\"light\\"\\n         data-size=\\"normal\\">\\n    </div>\\n    \\n    <button type=\\"submit\\" id=\\"submit-btn\\" disabled>Submit</button>\\n</form>\\n\\n<script>\\nlet turnstileToken = null;\\n\\nfunction onTurnstileSuccess(token) {\\n    turnstileToken = token;\\n    document.getElementById(\'submit-btn\').disabled = false;\\n    console.log(\'Turnstile verification successful\');\\n}\\n\\nfunction onTurnstileError(error) {\\n    console.error(\'Turnstile error:\', error);\\n    document.getElementById(\'submit-btn\').disabled = true;\\n}\\n\\nfunction onTurnstileExpired() {\\n    console.log(\'Turnstile token expired\');\\n    turnstileToken = null;\\n    document.getElementById(\'submit-btn\').disabled = true;\\n}\\n\\ndocument.getElementById(\'demo-form\').addEventListener(\'submit\', function(e) {\\n    e.preventDefault();\\n    \\n    if (!turnstileToken) {\\n        alert(\'Please complete the verification\');\\n        return;\\n    }\\n    \\n    // Add token to form data\\n    const formData = new FormData(this);\\n    formData.append(\'cf-turnstile-response\', turnstileToken);\\n    \\n    // Submit form\\n    fetch(\'/submit\', {\\n        method: \'POST\',\\n        body: formData\\n    })\\n    .then(response => response.json())\\n    .then(data => {\\n        if (data.success) {\\n            alert(\'Form submitted successfully!\');\\n            // Reset Turnstile widget\\n            turnstile.reset();\\n            turnstileToken = null;\\n            document.getElementById(\'submit-btn\').disabled = true;\\n        } else {\\n            alert(\'Verification failed\');\\n        }\\n    })\\n    .catch(error => {\\n        console.error(\'Error:\', error);\\n        alert(\'Submission failed\');\\n    });\\n});\\n<\/script>\\n```\\n\\n**Server-Side Verification**:\\n```javascript\\nconst axios = require(\'axios\');\\n\\napp.post(\'/submit\', async (req, res) => {\\n    const turnstileToken = req.body[\'cf-turnstile-response\'];\\n    \\n    if (!turnstileToken) {\\n        return res.status(400).json({ \\n            success: false, \\n            error: \'Turnstile token missing\' \\n        });\\n    }\\n    \\n    try {\\n        // Verify with Cloudflare\\n        const verificationResponse = await axios.post(\\n            \'https://challenges.cloudflare.com/turnstile/v0/siteverify\',\\n            new URLSearchParams({\\n                secret: process.env.TURNSTILE_SECRET_KEY,\\n                response: turnstileToken,\\n                remoteip: req.ip // Optional\\n            }),\\n            {\\n                headers: {\\n                    \'Content-Type\': \'application/x-www-form-urlencoded\'\\n                }\\n            }\\n        );\\n        \\n        const { success, \'error-codes\': errorCodes } = verificationResponse.data;\\n        \\n        if (success) {\\n            // Process form submission\\n            console.log(\'Turnstile verification successful\');\\n            \\n            // Process your form data here\\n            const { name, email, message } = req.body;\\n            \\n            // ... handle form submission logic\\n            \\n            res.json({ \\n                success: true, \\n                message: \'Form submitted successfully\' \\n            });\\n        } else {\\n            console.log(\'Turnstile verification failed:\', errorCodes);\\n            res.status(403).json({ \\n                success: false, \\n                error: \'Verification failed\',\\n                errorCodes \\n            });\\n        }\\n    } catch (error) {\\n        console.error(\'Turnstile verification error:\', error);\\n        res.status(500).json({ \\n            success: false, \\n            error: \'Verification service unavailable\' \\n        });\\n    }\\n});\\n```\\n\\n**Advanced Turnstile Configuration**:\\n```html\\n\x3c!-- Invisible Turnstile (no visible widget) --\x3e\\n<div class=\\"cf-turnstile\\" \\n     data-sitekey=\\"YOUR_SITE_KEY\\"\\n     data-callback=\\"onTurnstileSuccess\\"\\n     data-size=\\"invisible\\"\\n     data-theme=\\"auto\\">\\n</div>\\n\\n\x3c!-- Compact Turnstile --\x3e\\n<div class=\\"cf-turnstile\\" \\n     data-sitekey=\\"YOUR_SITE_KEY\\"\\n     data-callback=\\"onTurnstileSuccess\\"\\n     data-size=\\"compact\\"\\n     data-theme=\\"dark\\">\\n</div>\\n\\n\x3c!-- Turnstile with custom retry action --\x3e\\n<div class=\\"cf-turnstile\\" \\n     data-sitekey=\\"YOUR_SITE_KEY\\"\\n     data-callback=\\"onTurnstileSuccess\\"\\n     data-error-callback=\\"onTurnstileError\\"\\n     data-retry=\\"auto\\"\\n     data-retry-interval=\\"8000\\">\\n</div>\\n```\\n\\n**JavaScript API Usage**:\\n```javascript\\n// Programmatic Turnstile control\\nclass TurnstileManager {\\n    constructor(siteKey, containerId) {\\n        this.siteKey = siteKey;\\n        this.containerId = containerId;\\n        this.widgetId = null;\\n        this.token = null;\\n    }\\n    \\n    async render() {\\n        return new Promise((resolve, reject) => {\\n            if (typeof turnstile === \'undefined\') {\\n                reject(new Error(\'Turnstile not loaded\'));\\n                return;\\n            }\\n            \\n            this.widgetId = turnstile.render(this.containerId, {\\n                sitekey: this.siteKey,\\n                callback: (token) => {\\n                    this.token = token;\\n                    this.onSuccess(token);\\n                    resolve(token);\\n                },\\n                \'error-callback\': (error) => {\\n                    this.onError(error);\\n                    reject(error);\\n                },\\n                \'expired-callback\': () => {\\n                    this.token = null;\\n                    this.onExpired();\\n                }\\n            });\\n        });\\n    }\\n    \\n    reset() {\\n        if (this.widgetId !== null) {\\n            turnstile.reset(this.widgetId);\\n            this.token = null;\\n        }\\n    }\\n    \\n    remove() {\\n        if (this.widgetId !== null) {\\n            turnstile.remove(this.widgetId);\\n            this.widgetId = null;\\n            this.token = null;\\n        }\\n    }\\n    \\n    getResponse() {\\n        if (this.widgetId !== null) {\\n            return turnstile.getResponse(this.widgetId);\\n        }\\n        return null;\\n    }\\n    \\n    isExpired() {\\n        if (this.widgetId !== null) {\\n            return turnstile.isExpired(this.widgetId);\\n        }\\n        return true;\\n    }\\n    \\n    onSuccess(token) {\\n        console.log(\'Turnstile success:\', token);\\n        // Custom success handling\\n    }\\n    \\n    onError(error) {\\n        console.error(\'Turnstile error:\', error);\\n        // Custom error handling\\n    }\\n    \\n    onExpired() {\\n        console.log(\'Turnstile expired\');\\n        // Custom expiry handling\\n    }\\n}\\n\\n// Usage\\nconst turnstileManager = new TurnstileManager(\'YOUR_SITE_KEY\', \'turnstile-container\');\\n\\n// Render when needed\\ndocument.getElementById(\'show-captcha\').addEventListener(\'click\', async () => {\\n    try {\\n        const token = await turnstileManager.render();\\n        console.log(\'Turnstile rendered with token:\', token);\\n    } catch (error) {\\n        console.error(\'Failed to render Turnstile:\', error);\\n    }\\n});\\n\\n// Reset when needed\\ndocument.getElementById(\'reset-captcha\').addEventListener(\'click\', () => {\\n    turnstileManager.reset();\\n});\\n```\\n\\n**Express.js Middleware for Turnstile**:\\n```javascript\\n// Turnstile verification middleware\\nconst verifyTurnstile = async (req, res, next) => {\\n    const token = req.body[\'cf-turnstile-response\'];\\n    \\n    if (!token) {\\n        return res.status(400).json({\\n            error: \'Turnstile verification required\'\\n        });\\n    }\\n    \\n    try {\\n        const response = await axios.post(\\n            \'https://challenges.cloudflare.com/turnstile/v0/siteverify\',\\n            new URLSearchParams({\\n                secret: process.env.TURNSTILE_SECRET_KEY,\\n                response: token,\\n                remoteip: req.ip\\n            })\\n        );\\n        \\n        if (response.data.success) {\\n            req.turnstileVerified = true;\\n            next();\\n        } else {\\n            res.status(403).json({\\n                error: \'Turnstile verification failed\',\\n                errorCodes: response.data[\'error-codes\']\\n            });\\n        }\\n    } catch (error) {\\n        res.status(500).json({\\n            error: \'Verification service error\'\\n        });\\n    }\\n};\\n\\n// Use middleware on protected routes\\napp.post(\'/protected-endpoint\', verifyTurnstile, (req, res) => {\\n    // Handle verified request\\n    res.json({ success: true, message: \'Request processed\' });\\n});\\n\\napp.post(\'/contact\', verifyTurnstile, (req, res) => {\\n    // Handle contact form submission\\n    const { name, email, message } = req.body;\\n    // ... process contact form\\n    res.json({ success: true });\\n});\\n```\\n\\n**Turnstile vs reCAPTCHA Comparison**:\\n\\n| Feature | Cloudflare Turnstile | Google reCAPTCHA v3 |\\n|---------|---------------------|---------------------|\\n| **Privacy** | No personal data collection | Collects browsing data |\\n| **User Experience** | Invisible, no puzzles | Invisible scoring |\\n| **Performance** | Fast, lightweight | Heavier JavaScript |\\n| **Accessibility** | Better accessibility | Can be challenging |\\n| **Cost** | Free (Cloudflare plans) | Free tier available |\\n| **Integration** | Simple setup | Requires Google account |\\n| **Data Location** | Cloudflare global network | Google servers |\\n\\n**Best Practices for Turnstile Implementation**:\\n\\n```javascript\\n// Production-ready Turnstile implementation\\nclass ProductionTurnstile {\\n    constructor(config) {\\n        this.config = {\\n            siteKey: config.siteKey,\\n            theme: config.theme || \'auto\',\\n            size: config.size || \'normal\',\\n            retryInterval: config.retryInterval || 8000,\\n            maxRetries: config.maxRetries || 3,\\n            ...config\\n        };\\n        this.retryCount = 0;\\n        this.isLoaded = false;\\n    }\\n    \\n    async init() {\\n        // Load Turnstile script if not already loaded\\n        if (!window.turnstile) {\\n            await this.loadScript();\\n        }\\n        this.isLoaded = true;\\n    }\\n    \\n    loadScript() {\\n        return new Promise((resolve, reject) => {\\n            if (document.querySelector(\'script[src*=\\"challenges.cloudflare.com\\"]\')) {\\n                resolve();\\n                return;\\n            }\\n            \\n            const script = document.createElement(\'script\');\\n            script.src = \'https://challenges.cloudflare.com/turnstile/v0/api.js\';\\n            script.async = true;\\n            script.defer = true;\\n            script.onload = resolve;\\n            script.onerror = reject;\\n            document.head.appendChild(script);\\n        });\\n    }\\n    \\n    async render(containerId) {\\n        if (!this.isLoaded) {\\n            await this.init();\\n        }\\n        \\n        return turnstile.render(containerId, {\\n            sitekey: this.config.siteKey,\\n            theme: this.config.theme,\\n            size: this.config.size,\\n            \'retry-interval\': this.config.retryInterval,\\n            callback: this.handleSuccess.bind(this),\\n            \'error-callback\': this.handleError.bind(this),\\n            \'expired-callback\': this.handleExpired.bind(this)\\n        });\\n    }\\n    \\n    handleSuccess(token) {\\n        this.retryCount = 0;\\n        if (this.config.onSuccess) {\\n            this.config.onSuccess(token);\\n        }\\n    }\\n    \\n    handleError(error) {\\n        this.retryCount++;\\n        console.error(`Turnstile error (attempt ${this.retryCount}):`, error);\\n        \\n        if (this.retryCount >= this.config.maxRetries) {\\n            if (this.config.onMaxRetriesReached) {\\n                this.config.onMaxRetriesReached(error);\\n            }\\n        } else if (this.config.onError) {\\n            this.config.onError(error, this.retryCount);\\n        }\\n    }\\n    \\n    handleExpired() {\\n        if (this.config.onExpired) {\\n            this.config.onExpired();\\n        }\\n    }\\n}\\n\\n// Usage\\nconst turnstile = new ProductionTurnstile({\\n    siteKey: \'YOUR_SITE_KEY\',\\n    theme: \'auto\',\\n    size: \'normal\',\\n    maxRetries: 3,\\n    onSuccess: (token) => {\\n        console.log(\'Verification successful\');\\n        document.getElementById(\'submit-btn\').disabled = false;\\n    },\\n    onError: (error, retryCount) => {\\n        console.log(`Verification failed (attempt ${retryCount})`);\\n    },\\n    onMaxRetriesReached: (error) => {\\n        alert(\'Verification failed. Please refresh the page and try again.\');\\n    },\\n    onExpired: () => {\\n        document.getElementById(\'submit-btn\').disabled = true;\\n    }\\n});\\n\\n// Initialize\\nturnstile.render(\'turnstile-container\');\\n```\\n\\n### 1. Behavioral Analysis\\n\\nMonitor user behavior patterns to identify bot-like activities.\\n\\n```javascript\\n// Client-side behavior tracking\\nclass BehaviorTracker {\\n    constructor() {\\n        this.mouseMovements = 0;\\n        this.keystrokes = 0;\\n        this.clickPattern = [];\\n        this.startTime = Date.now();\\n        this.setupTracking();\\n    }\\n    \\n    setupTracking() {\\n        // Track mouse movements\\n        document.addEventListener(\'mousemove\', () => {\\n            this.mouseMovements++;\\n        });\\n        \\n        // Track keystrokes\\n        document.addEventListener(\'keydown\', () => {\\n            this.keystrokes++;\\n        });\\n        \\n        // Track click patterns\\n        document.addEventListener(\'click\', (e) => {\\n            this.clickPattern.push({\\n                x: e.clientX,\\n                y: e.clientY,\\n                timestamp: Date.now() - this.startTime\\n            });\\n        });\\n    }\\n    \\n    getBehaviorScore() {\\n        const sessionDuration = Date.now() - this.startTime;\\n        \\n        return {\\n            mouseMovements: this.mouseMovements,\\n            keystrokes: this.keystrokes,\\n            clickPattern: this.clickPattern,\\n            sessionDuration: sessionDuration,\\n            score: this.calculateHumanScore()\\n        };\\n    }\\n    \\n    calculateHumanScore() {\\n        let score = 0;\\n        \\n        // More mouse movements = more human-like\\n        if (this.mouseMovements > 10) score += 20;\\n        \\n        // Keystrokes indicate human interaction\\n        if (this.keystrokes > 5) score += 20;\\n        \\n        // Natural click patterns\\n        if (this.clickPattern.length > 1) {\\n            const avgTimeBetweenClicks = this.getAverageTimeBetweenClicks();\\n            if (avgTimeBetweenClicks > 500 && avgTimeBetweenClicks < 5000) {\\n                score += 30;\\n            }\\n        }\\n        \\n        // Session duration\\n        const sessionDuration = Date.now() - this.startTime;\\n        if (sessionDuration > 5000) score += 30;\\n        \\n        return score;\\n    }\\n    \\n    getAverageTimeBetweenClicks() {\\n        if (this.clickPattern.length < 2) return 0;\\n        \\n        let totalTime = 0;\\n        for (let i = 1; i < this.clickPattern.length; i++) {\\n            totalTime += this.clickPattern[i].timestamp - this.clickPattern[i-1].timestamp;\\n        }\\n        \\n        return totalTime / (this.clickPattern.length - 1);\\n    }\\n}\\n\\n// Initialize behavior tracking\\nconst behaviorTracker = new BehaviorTracker();\\n\\n// Send behavior data before form submission\\ndocument.addEventListener(\'submit\', function(e) {\\n    const behaviorData = behaviorTracker.getBehaviorScore();\\n    \\n    // Add behavior data to form\\n    const input = document.createElement(\'input\');\\n    input.type = \'hidden\';\\n    input.name = \'behavior_data\';\\n    input.value = JSON.stringify(behaviorData);\\n    e.target.appendChild(input);\\n});\\n```\\n\\n### 2. Device Fingerprinting\\n\\nCreate unique device fingerprints to identify and track suspicious devices.\\n\\n```javascript\\nclass DeviceFingerprinter {\\n    constructor() {\\n        this.fingerprint = {};\\n        this.generateFingerprint();\\n    }\\n    \\n    async generateFingerprint() {\\n        this.fingerprint = {\\n            userAgent: navigator.userAgent,\\n            language: navigator.language,\\n            platform: navigator.platform,\\n            screenResolution: `${screen.width}x${screen.height}`,\\n            colorDepth: screen.colorDepth,\\n            timezone: Intl.DateTimeFormat().resolvedOptions().timeZone,\\n            canvas: this.getCanvasFingerprint(),\\n            webgl: this.getWebGLFingerprint(),\\n            fonts: await this.getAvailableFonts(),\\n            plugins: this.getPlugins(),\\n            touch: \'ontouchstart\' in window,\\n            doNotTrack: navigator.doNotTrack,\\n            cookiesEnabled: navigator.cookieEnabled\\n        };\\n        \\n        return this.hashFingerprint();\\n    }\\n    \\n    getCanvasFingerprint() {\\n        const canvas = document.createElement(\'canvas\');\\n        const ctx = canvas.getContext(\'2d\');\\n        \\n        ctx.textBaseline = \'top\';\\n        ctx.font = \'14px Arial\';\\n        ctx.fillText(\'Device fingerprint\', 2, 2);\\n        \\n        return canvas.toDataURL();\\n    }\\n    \\n    getWebGLFingerprint() {\\n        const canvas = document.createElement(\'canvas\');\\n        const gl = canvas.getContext(\'webgl\');\\n        \\n        if (!gl) return null;\\n        \\n        return {\\n            vendor: gl.getParameter(gl.VENDOR),\\n            renderer: gl.getParameter(gl.RENDERER),\\n            version: gl.getParameter(gl.VERSION)\\n        };\\n    }\\n    \\n    async getAvailableFonts() {\\n        const fonts = [\\n            \'Arial\', \'Helvetica\', \'Times New Roman\', \'Courier New\',\\n            \'Verdana\', \'Georgia\', \'Palatino\', \'Garamond\',\\n            \'Comic Sans MS\', \'Trebuchet MS\', \'Arial Black\'\\n        ];\\n        \\n        const availableFonts = [];\\n        \\n        for (const font of fonts) {\\n            if (await this.isFontAvailable(font)) {\\n                availableFonts.push(font);\\n            }\\n        }\\n        \\n        return availableFonts;\\n    }\\n    \\n    isFontAvailable(fontName) {\\n        return new Promise((resolve) => {\\n            const testText = \'mmmmmmmmmmlli\';\\n            const fontSize = \'72px\';\\n            \\n            const canvas = document.createElement(\'canvas\');\\n            const context = canvas.getContext(\'2d\');\\n            \\n            context.font = `${fontSize} monospace`;\\n            const baselineWidth = context.measureText(testText).width;\\n            \\n            context.font = `${fontSize} ${fontName}, monospace`;\\n            const testWidth = context.measureText(testText).width;\\n            \\n            resolve(baselineWidth !== testWidth);\\n        });\\n    }\\n    \\n    getPlugins() {\\n        return Array.from(navigator.plugins).map(plugin => ({\\n            name: plugin.name,\\n            filename: plugin.filename\\n        }));\\n    }\\n    \\n    async hashFingerprint() {\\n        const fingerPrintString = JSON.stringify(this.fingerprint);\\n        const encoder = new TextEncoder();\\n        const data = encoder.encode(fingerPrintString);\\n        const hashBuffer = await crypto.subtle.digest(\'SHA-256\', data);\\n        const hashArray = Array.from(new Uint8Array(hashBuffer));\\n        return hashArray.map(b => b.toString(16).padStart(2, \'0\')).join(\'\');\\n    }\\n}\\n\\n// Usage\\nconst fingerprinter = new DeviceFingerprinter();\\nfingerprinter.generateFingerprint().then(hash => {\\n    // Send fingerprint to server for analysis\\n    fetch(\'/device-fingerprint\', {\\n        method: \'POST\',\\n        headers: {\\n            \'Content-Type\': \'application/json\',\\n        },\\n        body: JSON.stringify({\\n            fingerprint: hash,\\n            details: fingerprinter.fingerprint\\n        })\\n    });\\n});\\n```\\n\\n### 3. AI-Powered Bot Detection\\n\\nImplement machine learning models to detect sophisticated bots.\\n\\n```python\\n# Python/Flask example with scikit-learn\\nimport joblib\\nimport numpy as np\\nfrom flask import Flask, request, jsonify\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.preprocessing import StandardScaler\\n\\napp = Flask(__name__)\\n\\n# Load pre-trained model (you would train this on historical data)\\n# Features might include: request frequency, session duration, click patterns, etc.\\nmodel = joblib.load(\'bot_detection_model.pkl\')\\nscaler = joblib.load(\'feature_scaler.pkl\')\\n\\n@app.route(\'/analyze-request\', methods=[\'POST\'])\\ndef analyze_request():\\n    data = request.json\\n    \\n    # Extract features from request\\n    features = extract_features(data)\\n    \\n    # Scale features\\n    features_scaled = scaler.transform([features])\\n    \\n    # Predict\\n    prediction = model.predict(features_scaled)[0]\\n    probability = model.predict_proba(features_scaled)[0]\\n    \\n    bot_probability = probability[1]  # Probability of being a bot\\n    \\n    response = {\\n        \'is_bot\': prediction == 1,\\n        \'bot_probability\': float(bot_probability),\\n        \'risk_level\': get_risk_level(bot_probability)\\n    }\\n    \\n    return jsonify(response)\\n\\ndef extract_features(data):\\n    \\"\\"\\"Extract features for ML model\\"\\"\\"\\n    return [\\n        data.get(\'request_frequency\', 0),\\n        data.get(\'session_duration\', 0),\\n        data.get(\'mouse_movements\', 0),\\n        data.get(\'keystrokes\', 0),\\n        len(data.get(\'click_pattern\', [])),\\n        data.get(\'behavior_score\', 0),\\n        1 if data.get(\'javascript_enabled\') else 0,\\n        1 if data.get(\'cookies_enabled\') else 0,\\n        data.get(\'screen_resolution_entropy\', 0),\\n        data.get(\'user_agent_entropy\', 0)\\n    ]\\n\\ndef get_risk_level(probability):\\n    if probability < 0.3:\\n        return \'low\'\\n    elif probability < 0.7:\\n        return \'medium\'\\n    else:\\n        return \'high\'\\n\\nif __name__ == \'__main__\':\\n    app.run(debug=True)\\n```\\n\\n## Cloud-Based Bot Protection Services\\n\\n### 1. Cloudflare Bot Management\\n\\n```javascript\\n// Cloudflare Workers script for custom bot detection\\naddEventListener(\'fetch\', event => {\\n    event.respondWith(handleRequest(event.request))\\n})\\n\\nasync function handleRequest(request) {\\n    const botScore = request.cf.botManagement.score\\n    const isBot = botScore < 30\\n    \\n    if (isBot) {\\n        // Challenge suspicious requests\\n        return new Response(\'Bot detected\', {\\n            status: 403,\\n            headers: {\\n                \'content-type\': \'text/plain\',\\n            },\\n        })\\n    }\\n    \\n    // Continue to origin for legitimate requests\\n    return fetch(request)\\n}\\n```\\n\\n### 2. AWS WAF Bot Control\\n\\n```yaml\\n# AWS CloudFormation template for WAF Bot Control\\nAWSTemplateFormatVersion: \'2010-09-09\'\\nResources:\\n  WebACL:\\n    Type: AWS::WAFv2::WebACL\\n    Properties:\\n      Scope: CLOUDFRONT\\n      DefaultAction:\\n        Allow: {}\\n      Rules:\\n        - Name: BotControlRule\\n          Priority: 1\\n          OverrideAction:\\n            None: {}\\n          Statement:\\n            ManagedRuleGroupStatement:\\n              VendorName: AWS\\n              Name: AWSManagedRulesBotControlRuleSet\\n          VisibilityConfig:\\n            SampledRequestsEnabled: true\\n            CloudWatchMetricsEnabled: true\\n            MetricName: BotControlRule\\n```\\n\\n## Implementation Best Practices\\n\\n### 1. Layered Defense Strategy\\n\\n```nginx\\n# Nginx configuration with multiple bot prevention layers\\nserver {\\n    # Layer 1: Basic rate limiting\\n    limit_req zone=general burst=20 nodelay;\\n    \\n    # Layer 2: Geographic filtering\\n    if ($blocked_country) {\\n        return 403;\\n    }\\n    \\n    # Layer 3: User agent filtering\\n    if ($bad_bot) {\\n        return 403;\\n    }\\n    \\n    # Layer 4: Behavioral analysis endpoint\\n    location /api/ {\\n        # Custom header for bot score\\n        set $bot_score \\"\\";\\n        access_by_lua_block {\\n            local bot_score = ngx.var.http_x_bot_score\\n            if bot_score and tonumber(bot_score) > 0.7 then\\n                ngx.status = 403\\n                ngx.say(\\"High bot probability detected\\")\\n                ngx.exit(403)\\n            end\\n        }\\n        \\n        proxy_pass http://backend;\\n    }\\n}\\n```\\n\\n### 2. Monitoring and Analytics\\n\\n```javascript\\n// Bot detection analytics\\nclass BotAnalytics {\\n    constructor(apiEndpoint) {\\n        this.apiEndpoint = apiEndpoint;\\n        this.metrics = {\\n            totalRequests: 0,\\n            blockedRequests: 0,\\n            challengedRequests: 0,\\n            falsePositives: 0\\n        };\\n    }\\n    \\n    recordRequest(type, details = {}) {\\n        this.metrics.totalRequests++;\\n        \\n        switch(type) {\\n            case \'blocked\':\\n                this.metrics.blockedRequests++;\\n                break;\\n            case \'challenged\':\\n                this.metrics.challengedRequests++;\\n                break;\\n            case \'false_positive\':\\n                this.metrics.falsePositives++;\\n                break;\\n        }\\n        \\n        // Send to analytics endpoint\\n        this.sendMetric(type, details);\\n    }\\n    \\n    async sendMetric(type, details) {\\n        try {\\n            await fetch(`${this.apiEndpoint}/bot-metrics`, {\\n                method: \'POST\',\\n                headers: {\\n                    \'Content-Type\': \'application/json\',\\n                },\\n                body: JSON.stringify({\\n                    type,\\n                    details,\\n                    timestamp: new Date().toISOString(),\\n                    userAgent: navigator.userAgent,\\n                    ip: await this.getClientIP()\\n                })\\n            });\\n        } catch (error) {\\n            console.error(\'Failed to send bot metric:\', error);\\n        }\\n    }\\n    \\n    async getClientIP() {\\n        try {\\n            const response = await fetch(\'https://api.ipify.org?format=json\');\\n            const data = await response.json();\\n            return data.ip;\\n        } catch (error) {\\n            return \'unknown\';\\n        }\\n    }\\n    \\n    getMetrics() {\\n        return {\\n            ...this.metrics,\\n            blockRate: this.metrics.blockedRequests / this.metrics.totalRequests,\\n            challengeRate: this.metrics.challengedRequests / this.metrics.totalRequests,\\n            falsePositiveRate: this.metrics.falsePositives / this.metrics.totalRequests\\n        };\\n    }\\n}\\n\\n// Usage\\nconst analytics = new BotAnalytics(\'/api\');\\n\\n// Record when a bot is detected\\nanalytics.recordRequest(\'blocked\', {\\n    reason: \'high_request_frequency\',\\n    userAgent: navigator.userAgent\\n});\\n```\\n\\n### 3. Legitimate Bot Allowlisting\\n\\n```nginx\\n# Allow legitimate bots and services\\nmap $http_user_agent $allowed_bot {\\n    default 0;\\n    \\"~*googlebot\\" 1;\\n    \\"~*bingbot\\" 1;\\n    \\"~*slurp\\" 1;\\n    \\"~*duckduckbot\\" 1;\\n    \\"~*baiduspider\\" 1;\\n    \\"~*yandexbot\\" 1;\\n    \\"~*facebookexternalhit\\" 1;\\n    \\"~*twitterbot\\" 1;\\n    \\"~*linkedinbot\\" 1;\\n    \\"~*uptimerobot\\" 1;\\n    \\"~*pingdom\\" 1;\\n}\\n\\n# Verify legitimate bots by reverse DNS lookup\\nmap $remote_addr $verified_bot {\\n    default 0;\\n    # This would be populated by a script that verifies\\n    # bot IPs through reverse DNS lookups\\n}\\n\\nserver {\\n    # Bypass rate limiting for verified legitimate bots\\n    if ($allowed_bot) {\\n        set $limit_key \\"\\";\\n    }\\n    \\n    if ($verified_bot) {\\n        set $limit_key \\"\\";\\n    }\\n    \\n    limit_req zone=general burst=20 nodelay;\\n}\\n```\\n\\n## Performance Considerations\\n\\n### 1. Caching Bot Detection Results\\n\\n```javascript\\n// Redis-based bot detection caching\\nconst redis = require(\'redis\');\\nconst client = redis.createClient();\\n\\nclass BotDetectionCache {\\n    constructor(redisClient, defaultTTL = 3600) {\\n        this.redis = redisClient;\\n        this.defaultTTL = defaultTTL;\\n    }\\n    \\n    async isBotCached(identifier) {\\n        const key = `bot_check:${identifier}`;\\n        const result = await this.redis.get(key);\\n        \\n        if (result) {\\n            return JSON.parse(result);\\n        }\\n        \\n        return null;\\n    }\\n    \\n    async cacheBotResult(identifier, isBot, confidence, ttl = null) {\\n        const key = `bot_check:${identifier}`;\\n        const value = JSON.stringify({\\n            isBot,\\n            confidence,\\n            timestamp: Date.now()\\n        });\\n        \\n        await this.redis.setex(key, ttl || this.defaultTTL, value);\\n    }\\n    \\n    async getCacheStats() {\\n        const keys = await this.redis.keys(\'bot_check:*\');\\n        const stats = {\\n            totalEntries: keys.length,\\n            botEntries: 0,\\n            humanEntries: 0\\n        };\\n        \\n        for (const key of keys.slice(0, 1000)) { // Sample first 1000\\n            const data = await this.redis.get(key);\\n            if (data) {\\n                const parsed = JSON.parse(data);\\n                if (parsed.isBot) {\\n                    stats.botEntries++;\\n                } else {\\n                    stats.humanEntries++;\\n                }\\n            }\\n        }\\n        \\n        return stats;\\n    }\\n}\\n\\n// Usage in Express middleware\\nconst botCache = new BotDetectionCache(client);\\n\\napp.use(async (req, res, next) => {\\n    const identifier = req.ip + \':\' + req.get(\'User-Agent\');\\n    \\n    // Check cache first\\n    const cached = await botCache.isBotCached(identifier);\\n    if (cached) {\\n        req.botDetection = cached;\\n        return next();\\n    }\\n    \\n    // Perform bot detection\\n    const result = await performBotDetection(req);\\n    \\n    // Cache result\\n    await botCache.cacheBotResult(identifier, result.isBot, result.confidence);\\n    \\n    req.botDetection = result;\\n    next();\\n});\\n```\\n\\n## Legal and Ethical Considerations\\n\\n### 1. Privacy Compliance\\n\\nWhen implementing bot detection, consider privacy regulations:\\n\\n```javascript\\n// GDPR-compliant bot detection\\nclass PrivacyAwareBotDetection {\\n    constructor(options = {}) {\\n        this.consentRequired = options.gdprCompliant || false;\\n        this.dataRetentionDays = options.dataRetentionDays || 30;\\n        this.anonymizeData = options.anonymizeData || true;\\n    }\\n    \\n    async detectBot(request, userConsent = false) {\\n        if (this.consentRequired && !userConsent) {\\n            // Use only basic, non-personal detection methods\\n            return this.basicBotDetection(request);\\n        }\\n        \\n        // Full bot detection with user consent\\n        return this.advancedBotDetection(request);\\n    }\\n    \\n    basicBotDetection(request) {\\n        // Use only request patterns, not fingerprinting\\n        const indicators = {\\n            rapidRequests: this.checkRequestFrequency(request),\\n            suspiciousUserAgent: this.checkUserAgent(request),\\n            missingHeaders: this.checkRequiredHeaders(request)\\n        };\\n        \\n        return {\\n            isBot: Object.values(indicators).some(Boolean),\\n            method: \'basic\',\\n            confidence: this.calculateBasicConfidence(indicators)\\n        };\\n    }\\n    \\n    advancedBotDetection(request) {\\n        // Full detection including fingerprinting\\n        // ... implementation\\n    }\\n    \\n    anonymizeFingerprint(fingerprint) {\\n        // Hash sensitive data\\n        const crypto = require(\'crypto\');\\n        return crypto.createHash(\'sha256\')\\n                    .update(JSON.stringify(fingerprint))\\n                    .digest(\'hex\');\\n    }\\n}\\n```\\n\\n### 2. Accessibility Considerations\\n\\nEnsure bot prevention doesn\'t interfere with accessibility tools:\\n\\n```javascript\\n// Accessibility-aware bot detection\\nclass AccessibleBotDetection {\\n    constructor() {\\n        this.accessibilityTools = [\\n            \'JAWS\', \'NVDA\', \'Dragon\', \'VoiceOver\',\\n            \'screen reader\', \'accessibility\'\\n        ];\\n    }\\n    \\n    isAccessibilityTool(userAgent) {\\n        return this.accessibilityTools.some(tool => \\n            userAgent.toLowerCase().includes(tool.toLowerCase())\\n        );\\n    }\\n    \\n    detectBot(request) {\\n        // Exempt accessibility tools from strict checks\\n        if (this.isAccessibilityTool(request.userAgent)) {\\n            return {\\n                isBot: false,\\n                confidence: 0,\\n                reason: \'accessibility_tool_exemption\'\\n            };\\n        }\\n        \\n        // Continue with normal detection\\n        return this.normalBotDetection(request);\\n    }\\n}\\n```\\n\\n## Conclusion\\n\\nEffective bot prevention requires a multi-layered approach combining various techniques:\\n\\n1. **Basic Defenses**: Rate limiting, IP blocking, and user agent analysis\\n2. **Intermediate Methods**: JavaScript challenges, CAPTCHAs, and honeypots\\n3. **Advanced Techniques**: Behavioral analysis, device fingerprinting, and AI/ML\\n4. **Cloud Solutions**: Leverage services like Cloudflare, AWS WAF, or Google reCAPTCHA\\n\\n### Key Implementation Principles:\\n\\n- **Start Simple**: Begin with basic rate limiting and gradually add complexity\\n- **Monitor Continuously**: Track false positives and adjust thresholds\\n- **Respect Privacy**: Comply with data protection regulations\\n- **Consider Accessibility**: Don\'t block legitimate accessibility tools\\n- **Plan for Scale**: Use caching and efficient algorithms for high-traffic sites\\n- **Stay Updated**: Bot techniques evolve; keep your defenses current\\n\\n### Success Metrics:\\n\\n- **Reduced malicious bot traffic** (measured by analytics)\\n- **Improved site performance** (faster load times, lower server load)\\n- **Decreased security incidents** (fewer successful attacks)\\n- **Maintained user experience** (low false positive rate)\\n\\nRemember that perfect bot detection is impossible\u2014the goal is to make automated attacks uneconomical while maintaining a smooth experience for legitimate users. Regular testing, monitoring, and adjustment of your bot prevention mechanisms are essential for long-term effectiveness.\\n\\n## Further Resources\\n\\n- [OWASP Automated Threat Handbook](https://owasp.org/www-project-automated-threats-to-web-applications/)\\n- [Bot Management Best Practices](https://www.cloudflare.com/learning/bots/what-is-bot-management/)\\n- [Google reCAPTCHA Documentation](https://developers.google.com/recaptcha)\\n- [Nginx Rate Limiting Guide](https://www.nginx.com/blog/rate-limiting-nginx/)\\n- [AWS WAF Bot Control](https://docs.aws.amazon.com/waf/latest/developerguide/aws-managed-rule-groups-bot.html)\\n\\n---\\n\\n*Have you implemented bot prevention on your website? Share your experiences and which techniques worked best for your use case!*"},{"id":"lets-encrypt-nginx-ssl-setup","metadata":{"permalink":"/fullstack-dev/blog/lets-encrypt-nginx-ssl-setup","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-06-lets-encrypt-nginx-ssl-setup.md","source":"@site/blog/2025-10-06-lets-encrypt-nginx-ssl-setup.md","title":"Securing Your Website with Let\'s Encrypt and Nginx: A Complete Guide","description":"In today\'s web landscape, HTTPS is no longer optional\u2014it\'s essential. Search engines favor HTTPS sites, browsers mark HTTP sites as \\"not secure,\\" and users expect their data to be encrypted. Let\'s Encrypt has revolutionized SSL certificate provisioning by providing free, automated, and open certificates that are trusted by all major browsers.","date":"2025-10-06T00:00:00.000Z","tags":[{"inline":false,"label":"Let\'s Encrypt","permalink":"/fullstack-dev/blog/tags/lets-encrypt","description":"Let\'s Encrypt SSL certificate automation"},{"inline":false,"label":"Nginx","permalink":"/fullstack-dev/blog/tags/nginx","description":"Nginx web server and configuration"},{"inline":false,"label":"SSL","permalink":"/fullstack-dev/blog/tags/ssl","description":"SSL/TLS encryption and certificates"},{"inline":false,"label":"HTTPS","permalink":"/fullstack-dev/blog/tags/https","description":"HTTPS protocol and secure connections"},{"inline":false,"label":"Security","permalink":"/fullstack-dev/blog/tags/security","description":"Application security practices"},{"inline":false,"label":"Certbot","permalink":"/fullstack-dev/blog/tags/certbot","description":"Certbot SSL certificate management"},{"inline":false,"label":"Automation","permalink":"/fullstack-dev/blog/tags/automation","description":"Process automation and scripting"},{"inline":false,"label":"DevOps","permalink":"/fullstack-dev/blog/tags/devops","description":"DevOps practices and tools"}],"readingTime":8.26,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"lets-encrypt-nginx-ssl-setup","title":"Securing Your Website with Let\'s Encrypt and Nginx: A Complete Guide","authors":["tam"],"tags":["lets-encrypt","nginx","ssl","https","security","certbot","automation","devops"]},"unlisted":false,"prevItem":{"title":"Comprehensive Guide to Bot Prevention: Protecting Your Website from Automated Threats","permalink":"/fullstack-dev/blog/bot-prevention-mechanisms-website-security"},"nextItem":{"title":"Building Secure Microservices: Authentication & Authorization with NestJS on GCP Kubernetes","permalink":"/fullstack-dev/blog/nestjs-auth-microservices-gcp-kubernetes"}},"content":"In today\'s web landscape, HTTPS is no longer optional\u2014it\'s essential. Search engines favor HTTPS sites, browsers mark HTTP sites as \\"not secure,\\" and users expect their data to be encrypted. Let\'s Encrypt has revolutionized SSL certificate provisioning by providing free, automated, and open certificates that are trusted by all major browsers.\\n\\nIn this comprehensive guide, we\'ll walk through setting up Let\'s Encrypt SSL certificates with Nginx, from initial installation to automated renewal, ensuring your website stays secure without manual intervention.\\n\\n\x3c!-- truncate --\x3e\\n\\n## What is Let\'s Encrypt?\\n\\nLet\'s Encrypt is a free, automated, and open Certificate Authority (CA) run by the Internet Security Research Group (ISRG). It provides domain-validated SSL/TLS certificates at no cost, with the mission of creating a more secure and privacy-respecting web.\\n\\n### Key Benefits\\n\\n- **Free**: No cost for certificates\\n- **Automated**: Certificates can be issued and renewed automatically\\n- **Open**: The protocol and software are open source\\n- **Trusted**: Certificates are trusted by all major browsers\\n- **Domain Validated**: Quick verification process\\n- **90-day Validity**: Forces automation and reduces risk of compromised keys\\n\\n## Prerequisites\\n\\nBefore we begin, ensure you have:\\n\\n1. A domain name pointing to your server\\n2. Nginx installed and running\\n3. Root or sudo access to your server\\n4. Port 80 accessible from the internet\\n5. A basic Nginx configuration for your domain\\n\\n## Installing Certbot\\n\\nCertbot is the official Let\'s Encrypt client that automates certificate issuance and renewal.\\n\\n### Ubuntu/Debian\\n```bash\\nsudo apt update\\nsudo apt install snapd\\nsudo snap install core; sudo snap refresh core\\nsudo snap install --classic certbot\\nsudo ln -s /snap/bin/certbot /usr/bin/certbot\\n```\\n\\n### CentOS/RHEL 8+\\n```bash\\nsudo dnf install epel-release\\nsudo dnf install snapd\\nsudo systemctl enable --now snapd.socket\\nsudo ln -s /var/lib/snapd/snap /snap\\nsudo snap install core; sudo snap refresh core\\nsudo snap install --classic certbot\\nsudo ln -s /snap/bin/certbot /usr/bin/certbot\\n```\\n\\n### Alternative: Using Package Managers\\n```bash\\n# Ubuntu/Debian\\nsudo apt install certbot python3-certbot-nginx\\n\\n# CentOS/RHEL\\nsudo yum install certbot python3-certbot-nginx\\n```\\n\\n## Basic Nginx Configuration\\n\\nBefore obtaining SSL certificates, set up a basic HTTP configuration:\\n\\n```nginx\\n# /etc/nginx/sites-available/example.com\\nserver {\\n    listen 80;\\n    server_name example.com www.example.com;\\n    root /var/www/example.com;\\n    index index.html index.htm;\\n\\n    location / {\\n        try_files $uri $uri/ =404;\\n    }\\n\\n    # Let\'s Encrypt challenge location\\n    location /.well-known/acme-challenge/ {\\n        root /var/www/example.com;\\n    }\\n}\\n```\\n\\nEnable the site and test the configuration:\\n```bash\\nsudo ln -s /etc/nginx/sites-available/example.com /etc/nginx/sites-enabled/\\nsudo nginx -t\\nsudo systemctl reload nginx\\n```\\n\\n## Obtaining SSL Certificates\\n\\n### Method 1: Automatic Configuration (Recommended)\\n\\nThe easiest way is to let Certbot automatically configure Nginx:\\n\\n```bash\\nsudo certbot --nginx -d example.com -d www.example.com\\n```\\n\\nThis command will:\\n1. Verify domain ownership\\n2. Obtain the certificate\\n3. Automatically configure Nginx\\n4. Set up HTTP to HTTPS redirects\\n\\n### Method 2: Certificate Only (Manual Configuration)\\n\\nIf you prefer to configure Nginx manually:\\n\\n```bash\\nsudo certbot certonly --nginx -d example.com -d www.example.com\\n```\\n\\nThen manually configure Nginx with the obtained certificates.\\n\\n### Method 3: Webroot Plugin\\n\\nFor more control over the verification process:\\n\\n```bash\\nsudo certbot certonly --webroot -w /var/www/example.com -d example.com -d www.example.com\\n```\\n\\n## Manual Nginx SSL Configuration\\n\\nIf you used the certificate-only method, here\'s how to configure Nginx manually:\\n\\n```nginx\\n# /etc/nginx/sites-available/example.com\\nserver {\\n    listen 80;\\n    server_name example.com www.example.com;\\n    \\n    # Redirect all HTTP requests to HTTPS\\n    return 301 https://$server_name$request_uri;\\n}\\n\\nserver {\\n    listen 443 ssl http2;\\n    server_name example.com www.example.com;\\n    \\n    # SSL Configuration\\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\\n    \\n    # SSL Security Configuration\\n    ssl_protocols TLSv1.2 TLSv1.3;\\n    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384;\\n    ssl_prefer_server_ciphers off;\\n    ssl_session_cache shared:SSL:10m;\\n    ssl_session_timeout 10m;\\n    \\n    # OCSP Stapling\\n    ssl_stapling on;\\n    ssl_stapling_verify on;\\n    ssl_trusted_certificate /etc/letsencrypt/live/example.com/chain.pem;\\n    resolver 8.8.8.8 8.8.4.4 valid=300s;\\n    resolver_timeout 5s;\\n    \\n    # Security Headers\\n    add_header Strict-Transport-Security \\"max-age=31536000; includeSubDomains\\" always;\\n    add_header X-Frame-Options \\"SAMEORIGIN\\" always;\\n    add_header X-Content-Type-Options \\"nosniff\\" always;\\n    add_header X-XSS-Protection \\"1; mode=block\\" always;\\n    add_header Referrer-Policy \\"strict-origin-when-cross-origin\\" always;\\n    \\n    root /var/www/example.com;\\n    index index.html index.htm;\\n    \\n    location / {\\n        try_files $uri $uri/ =404;\\n    }\\n    \\n    # Let\'s Encrypt renewal\\n    location /.well-known/acme-challenge/ {\\n        root /var/www/example.com;\\n    }\\n}\\n```\\n\\nTest and reload Nginx:\\n```bash\\nsudo nginx -t\\nsudo systemctl reload nginx\\n```\\n\\n## Advanced SSL Configuration\\n\\n### Perfect Forward Secrecy\\n\\nGenerate Diffie-Hellman parameters for enhanced security:\\n\\n```bash\\nsudo openssl dhparam -out /etc/nginx/dhparam.pem 2048\\n```\\n\\nAdd to your Nginx configuration:\\n```nginx\\nssl_dhparam /etc/nginx/dhparam.pem;\\n```\\n\\n### SSL Configuration Snippet\\n\\nCreate a reusable SSL configuration:\\n\\n```nginx\\n# /etc/nginx/snippets/ssl-params.conf\\nssl_protocols TLSv1.2 TLSv1.3;\\nssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305;\\nssl_prefer_server_ciphers off;\\nssl_session_cache shared:SSL:10m;\\nssl_session_timeout 10m;\\n\\n# OCSP Stapling\\nssl_stapling on;\\nssl_stapling_verify on;\\nresolver 8.8.8.8 8.8.4.4 valid=300s;\\nresolver_timeout 5s;\\n\\n# Diffie-Hellman parameter\\nssl_dhparam /etc/nginx/dhparam.pem;\\n\\n# Security Headers\\nadd_header Strict-Transport-Security \\"max-age=31536000; includeSubDomains\\" always;\\nadd_header X-Frame-Options \\"SAMEORIGIN\\" always;\\nadd_header X-Content-Type-Options \\"nosniff\\" always;\\nadd_header X-XSS-Protection \\"1; mode=block\\" always;\\nadd_header Referrer-Policy \\"strict-origin-when-cross-origin\\" always;\\n```\\n\\nInclude it in your server blocks:\\n```nginx\\nserver {\\n    listen 443 ssl http2;\\n    server_name example.com;\\n    \\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\\n    ssl_trusted_certificate /etc/letsencrypt/live/example.com/chain.pem;\\n    \\n    include /etc/nginx/snippets/ssl-params.conf;\\n    \\n    # Your site configuration...\\n}\\n```\\n\\n## Automatic Certificate Renewal\\n\\nLet\'s Encrypt certificates expire after 90 days, so automation is crucial.\\n\\n### Setting Up Automatic Renewal\\n\\nCertbot automatically installs a systemd timer. Check if it\'s active:\\n\\n```bash\\nsudo systemctl status snap.certbot.renew.timer\\n```\\n\\nIf not using snap, create a cron job:\\n\\n```bash\\nsudo crontab -e\\n```\\n\\nAdd this line to check for renewal twice daily:\\n```bash\\n0 12 * * * /usr/bin/certbot renew --quiet\\n```\\n\\n### Testing Renewal\\n\\nTest the renewal process without actually renewing:\\n\\n```bash\\nsudo certbot renew --dry-run\\n```\\n\\n### Renewal Hooks\\n\\nAdd hooks to reload Nginx after successful renewal:\\n\\n```bash\\nsudo certbot renew --deploy-hook \\"systemctl reload nginx\\"\\n```\\n\\nOr create a renewal configuration file:\\n```bash\\n# /etc/letsencrypt/renewal-hooks/deploy/reload-nginx.sh\\n#!/bin/bash\\nsystemctl reload nginx\\n\\n# Make it executable\\nsudo chmod +x /etc/letsencrypt/renewal-hooks/deploy/reload-nginx.sh\\n```\\n\\n## Multiple Domains and Subdomains\\n\\n### Single Certificate for Multiple Domains\\n\\n```bash\\nsudo certbot --nginx -d example.com -d www.example.com -d api.example.com -d blog.example.com\\n```\\n\\n### Wildcard Certificates\\n\\nFor wildcard certificates, you need DNS challenge:\\n\\n```bash\\nsudo certbot certonly --manual --preferred-challenges dns -d example.com -d *.example.com\\n```\\n\\nYou\'ll need to add TXT records to your DNS for verification.\\n\\n### Using DNS Plugins\\n\\nFor automated wildcard certificates, use DNS plugins:\\n\\n```bash\\n# Cloudflare example\\nsudo snap install certbot-dns-cloudflare\\nsudo certbot certonly --dns-cloudflare --dns-cloudflare-credentials /etc/letsencrypt/cloudflare.ini -d example.com -d *.example.com\\n```\\n\\n## Reverse Proxy with SSL\\n\\nFor applications behind Nginx:\\n\\n```nginx\\nserver {\\n    listen 443 ssl http2;\\n    server_name api.example.com;\\n    \\n    ssl_certificate /etc/letsencrypt/live/api.example.com/fullchain.pem;\\n    ssl_certificate_key /etc/letsencrypt/live/api.example.com/privkey.pem;\\n    \\n    include /etc/nginx/snippets/ssl-params.conf;\\n    \\n    location / {\\n        proxy_pass http://localhost:3000;\\n        proxy_http_version 1.1;\\n        proxy_set_header Upgrade $http_upgrade;\\n        proxy_set_header Connection \'upgrade\';\\n        proxy_set_header Host $host;\\n        proxy_set_header X-Real-IP $remote_addr;\\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n        proxy_set_header X-Forwarded-Proto $scheme;\\n        proxy_cache_bypass $http_upgrade;\\n        \\n        # Timeouts\\n        proxy_connect_timeout 60s;\\n        proxy_send_timeout 60s;\\n        proxy_read_timeout 60s;\\n    }\\n}\\n```\\n\\n## Monitoring and Troubleshooting\\n\\n### Certificate Information\\n\\nCheck certificate details:\\n```bash\\nsudo certbot certificates\\n```\\n\\nView certificate information:\\n```bash\\nopenssl x509 -in /etc/letsencrypt/live/example.com/cert.pem -text -noout\\n```\\n\\n### Common Issues\\n\\n1. **Rate Limits**: Let\'s Encrypt has rate limits (50 certificates per domain per week)\\n2. **DNS Propagation**: Ensure DNS records have propagated\\n3. **Firewall**: Ensure ports 80 and 443 are open\\n4. **Webroot Permissions**: Ensure Nginx can write to webroot directory\\n\\n### Certificate Expiry Monitoring\\n\\nCreate a script to monitor certificate expiry:\\n\\n```bash\\n#!/bin/bash\\n# /usr/local/bin/check-ssl-expiry.sh\\n\\nDOMAIN=\\"example.com\\"\\nTHRESHOLD=30\\n\\nEXPIRY_DATE=$(echo | openssl s_client -servername $DOMAIN -connect $DOMAIN:443 2>/dev/null | openssl x509 -noout -dates | grep notAfter | cut -d= -f2)\\nEXPIRY_EPOCH=$(date -d \\"$EXPIRY_DATE\\" +%s)\\nCURRENT_EPOCH=$(date +%s)\\nDAYS_UNTIL_EXPIRY=$(( ($EXPIRY_EPOCH - $CURRENT_EPOCH) / 86400 ))\\n\\nif [ $DAYS_UNTIL_EXPIRY -lt $THRESHOLD ]; then\\n    echo \\"SSL certificate for $DOMAIN expires in $DAYS_UNTIL_EXPIRY days!\\"\\n    # Send alert (email, Slack, etc.)\\nfi\\n```\\n\\n## Security Best Practices\\n\\n### 1. Regular Updates\\n```bash\\nsudo snap refresh certbot\\n```\\n\\n### 2. Security Headers Testing\\nUse tools like:\\n- [SSL Labs SSL Test](https://www.ssllabs.com/ssltest/)\\n- [Mozilla Observatory](https://observatory.mozilla.org/)\\n- [Security Headers](https://securityheaders.com/)\\n\\n### 3. Certificate Transparency Monitoring\\nMonitor your certificates at:\\n- [crt.sh](https://crt.sh/)\\n- [Certificate Transparency logs](https://transparencyreport.google.com/https/certificates)\\n\\n### 4. HSTS Preloading\\nSubmit your domain to the [HSTS preload list](https://hstspreload.org/) for enhanced security.\\n\\n## Docker and Let\'s Encrypt\\n\\nFor containerized applications:\\n\\n```yaml\\n# docker-compose.yml\\nversion: \'3.8\'\\nservices:\\n  nginx:\\n    image: nginx:alpine\\n    ports:\\n      - \\"80:80\\"\\n      - \\"443:443\\"\\n    volumes:\\n      - ./nginx.conf:/etc/nginx/nginx.conf\\n      - /etc/letsencrypt:/etc/letsencrypt:ro\\n    \\n  certbot:\\n    image: certbot/certbot\\n    volumes:\\n      - /etc/letsencrypt:/etc/letsencrypt\\n      - /var/www/certbot:/var/www/certbot\\n    command: certonly --webroot -w /var/www/certbot -d example.com --email admin@example.com --agree-tos --no-eff-email\\n```\\n\\n## Performance Considerations\\n\\n### SSL Session Resumption\\n```nginx\\nssl_session_cache shared:SSL:10m;\\nssl_session_timeout 10m;\\nssl_session_tickets off;\\n```\\n\\n### OCSP Stapling\\n```nginx\\nssl_stapling on;\\nssl_stapling_verify on;\\nssl_trusted_certificate /etc/letsencrypt/live/example.com/chain.pem;\\n```\\n\\n### HTTP/2 Support\\n```nginx\\nlisten 443 ssl http2;\\n```\\n\\n## Conclusion\\n\\nLet\'s Encrypt with Nginx provides a robust, free solution for securing your websites with SSL/TLS certificates. The combination of automated certificate issuance, renewal, and Nginx\'s high-performance SSL handling creates a powerful security setup that scales from small personal sites to large enterprise applications.\\n\\nKey takeaways:\\n- Always use automated renewal to prevent certificate expiry\\n- Implement proper security headers for enhanced protection\\n- Monitor certificate health and expiry dates\\n- Use strong SSL configurations following current best practices\\n- Test your SSL configuration regularly\\n\\nWith this setup, you\'ll have a secure, automated SSL certificate management system that requires minimal maintenance while providing maximum security for your users.\\n\\n## Additional Resources\\n\\n- [Let\'s Encrypt Documentation](https://letsencrypt.org/docs/)\\n- [Certbot Documentation](https://certbot.eff.org/docs/)\\n- [Mozilla SSL Configuration Generator](https://ssl-config.mozilla.org/)\\n- [Nginx SSL Module Documentation](https://nginx.org/en/docs/http/ngx_http_ssl_module.html)\\n- [SSL Labs Best Practices](https://github.com/ssllabs/research/wiki/SSL-and-TLS-Deployment-Best-Practices)\\n\\n---\\n\\n*Have you implemented Let\'s Encrypt with Nginx? Share your experiences and any challenges you\'ve faced in the comments!*"},{"id":"nestjs-auth-microservices-gcp-kubernetes","metadata":{"permalink":"/fullstack-dev/blog/nestjs-auth-microservices-gcp-kubernetes","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-06-nestjs-auth-microservices-gcp-kubernetes.md","source":"@site/blog/2025-10-06-nestjs-auth-microservices-gcp-kubernetes.md","title":"Building Secure Microservices: Authentication & Authorization with NestJS on GCP Kubernetes","description":"Building secure microservices with proper authentication and authorization is one of the most critical aspects of modern application development. When deploying to Google Cloud Platform (GCP) Kubernetes, we need to consider not only the application-level security patterns but also the infrastructure and container orchestration security layers.","date":"2025-10-06T00:00:00.000Z","tags":[{"inline":false,"label":"NestJS","permalink":"/fullstack-dev/blog/tags/nestjs","description":"NestJS framework for Node.js applications"},{"inline":false,"label":"Microservices","permalink":"/fullstack-dev/blog/tags/microservices","description":"Microservices architecture and patterns"},{"inline":false,"label":"Authentication","permalink":"/fullstack-dev/blog/tags/authentication","description":"User authentication systems"},{"inline":false,"label":"Authorization","permalink":"/fullstack-dev/blog/tags/authorization","description":"Access control and permissions"},{"inline":false,"label":"Google Cloud Platform","permalink":"/fullstack-dev/blog/tags/gcp","description":"Google Cloud Platform services"},{"inline":false,"label":"Kubernetes","permalink":"/fullstack-dev/blog/tags/kubernetes","description":"Kubernetes container orchestration"},{"inline":false,"label":"JWT","permalink":"/fullstack-dev/blog/tags/jwt","description":"JSON Web Tokens for authentication"},{"inline":false,"label":"RBAC","permalink":"/fullstack-dev/blog/tags/rbac","description":"Role-based access control"},{"inline":false,"label":"Security","permalink":"/fullstack-dev/blog/tags/security","description":"Application security practices"},{"inline":false,"label":"Docker","permalink":"/fullstack-dev/blog/tags/docker","description":"Docker containerization"}],"readingTime":21.86,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"nestjs-auth-microservices-gcp-kubernetes","title":"Building Secure Microservices: Authentication & Authorization with NestJS on GCP Kubernetes","authors":["tam"],"tags":["nestjs","microservices","authentication","authorization","gcp","kubernetes","jwt","rbac","security","docker"]},"unlisted":false,"prevItem":{"title":"Securing Your Website with Let\'s Encrypt and Nginx: A Complete Guide","permalink":"/fullstack-dev/blog/lets-encrypt-nginx-ssl-setup"},"nextItem":{"title":"Nginx: The High-Performance Web Server and Reverse Proxy","permalink":"/fullstack-dev/blog/nginx-web-server-guide"}},"content":"Building secure microservices with proper authentication and authorization is one of the most critical aspects of modern application development. When deploying to Google Cloud Platform (GCP) Kubernetes, we need to consider not only the application-level security patterns but also the infrastructure and container orchestration security layers.\\n\\nThis comprehensive guide demonstrates how to implement robust authentication and authorization in a NestJS microservices architecture deployed on GCP Kubernetes, incorporating enterprise-grade security patterns including RBAC, JWT tokens, service mesh security, and cloud-native best practices.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Architecture Overview\\n\\nBefore diving into implementation, let\'s establish our target architecture based on microservices security best practices:\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502   React UI      \u2502    \u2502   Mobile App    \u2502    \u2502   Third-party   \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n          \u2502                      \u2502                      \u2502\\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                                 \u2502\\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n          \u2502             API Gateway / BFF                  \u2502\\n          \u2502         (NestJS Gateway Service)               \u2502\\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                                \u2502\\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n          \u2502              Service Mesh (Istio)              \u2502\\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                                \u2502\\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n    \u2502             \u2502             \u2502             \u2502             \u2502\\n\u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510\\n\u2502 Auth  \u2502    \u2502 User  \u2502    \u2502Product\u2502    \u2502 Order \u2502    \u2502Payment\u2502\\n\u2502Service\u2502    \u2502Service\u2502    \u2502Service\u2502    \u2502Service\u2502    \u2502Service\u2502\\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\\n    \u2502            \u2502            \u2502            \u2502            \u2502\\n\u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2510\\n\u2502Auth DB\u2502    \u2502User DB\u2502    \u2502Prod DB\u2502    \u2502Order \u2502    \u2502Pay DB \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  DB   \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n                                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\n## Core Security Concepts\\n\\n### Authentication vs Authorization\\n\\n- **Authentication**: Verifying who the user is (identity verification)\\n- **Authorization**: Determining what the authenticated user can do (access control)\\n\\n### Authorization Models We\'ll Implement\\n\\n1. **RBAC (Role-Based Access Control)**: Users have roles, roles have permissions\\n2. **ReBAC (Relationship-Based Access Control)**: Access based on user\'s relationship to resources\\n3. **ABAC (Attribute-Based Access Control)**: Access based on user, resource, and environment attributes\\n\\n## Project Setup and Structure\\n\\nLet\'s start by setting up our NestJS microservices project structure:\\n\\n```bash\\n# Create the monorepo structure\\nmkdir ecommerce-microservices\\ncd ecommerce-microservices\\n\\n# Initialize the NestJS workspace\\nnpx @nestjs/cli new . --package-manager npm\\nnpm install @nestjs/microservices @nestjs/jwt @nestjs/passport\\nnpm install passport passport-jwt passport-local bcryptjs\\nnpm install @nestjs/config @nestjs/typeorm typeorm pg\\nnpm install class-validator class-transformer\\nnpm install @google-cloud/secret-manager\\nnpm install helmet compression morgan\\n```\\n\\n### Project Structure\\n\\n```\\necommerce-microservices/\\n\u251c\u2500\u2500 apps/\\n\u2502   \u251c\u2500\u2500 api-gateway/          # BFF/API Gateway\\n\u2502   \u251c\u2500\u2500 auth-service/         # Authentication service\\n\u2502   \u251c\u2500\u2500 user-service/         # User management\\n\u2502   \u251c\u2500\u2500 product-service/      # Product catalog\\n\u2502   \u251c\u2500\u2500 order-service/        # Order management\\n\u2502   \u2514\u2500\u2500 payment-service/      # Payment processing\\n\u251c\u2500\u2500 libs/\\n\u2502   \u251c\u2500\u2500 common/              # Shared utilities\\n\u2502   \u251c\u2500\u2500 database/            # Database configurations\\n\u2502   \u251c\u2500\u2500 auth/                # Authentication guards/decorators\\n\u2502   \u2514\u2500\u2500 security/            # Security middleware\\n\u251c\u2500\u2500 k8s/                     # Kubernetes manifests\\n\u251c\u2500\u2500 docker/                  # Dockerfiles\\n\u2514\u2500\u2500 scripts/                 # Deployment scripts\\n```\\n\\n## Authentication Service Implementation\\n\\n### Core Authentication Service\\n\\n```typescript\\n// apps/auth-service/src/auth.service.ts\\nimport { Injectable, UnauthorizedException, ConflictException } from \'@nestjs/common\';\\nimport { JwtService } from \'@nestjs/jwt\';\\nimport { InjectRepository } from \'@nestjs/typeorm\';\\nimport { Repository } from \'typeorm\';\\nimport * as bcrypt from \'bcryptjs\';\\nimport { User } from \'./entities/user.entity\';\\nimport { Role } from \'./entities/role.entity\';\\nimport { Permission } from \'./entities/permission.entity\';\\n\\nexport interface JwtPayload {\\n  sub: string;\\n  email: string;\\n  roles: string[];\\n  permissions: string[];\\n  companyId?: string;\\n  departmentId?: string;\\n  iat?: number;\\n  exp?: number;\\n}\\n\\n@Injectable()\\nexport class AuthService {\\n  constructor(\\n    @InjectRepository(User)\\n    private readonly userRepository: Repository<User>,\\n    @InjectRepository(Role)\\n    private readonly roleRepository: Repository<Role>,\\n    private readonly jwtService: JwtService,\\n  ) {}\\n\\n  async register(registerDto: RegisterDto): Promise<{ user: User; tokens: TokenPair }> {\\n    // Check if user already exists\\n    const existingUser = await this.userRepository.findOne({\\n      where: { email: registerDto.email }\\n    });\\n\\n    if (existingUser) {\\n      throw new ConflictException(\'User with this email already exists\');\\n    }\\n\\n    // Hash password\\n    const saltRounds = 12;\\n    const hashedPassword = await bcrypt.hash(registerDto.password, saltRounds);\\n\\n    // Create user with default role\\n    const defaultRole = await this.roleRepository.findOne({\\n      where: { name: \'USER\' },\\n      relations: [\'permissions\']\\n    });\\n\\n    const user = this.userRepository.create({\\n      ...registerDto,\\n      password: hashedPassword,\\n      roles: defaultRole ? [defaultRole] : [],\\n      isActive: true,\\n      emailVerified: false,\\n    });\\n\\n    const savedUser = await this.userRepository.save(user);\\n    \\n    // Generate tokens\\n    const tokens = await this.generateTokens(savedUser);\\n    \\n    // Remove password from response\\n    delete savedUser.password;\\n\\n    return { user: savedUser, tokens };\\n  }\\n\\n  async login(loginDto: LoginDto): Promise<{ user: User; tokens: TokenPair }> {\\n    // Find user with roles and permissions\\n    const user = await this.userRepository.findOne({\\n      where: { email: loginDto.email },\\n      relations: [\'roles\', \'roles.permissions\', \'company\', \'department\']\\n    });\\n\\n    if (!user) {\\n      throw new UnauthorizedException(\'Invalid credentials\');\\n    }\\n\\n    // Check if user is active\\n    if (!user.isActive) {\\n      throw new UnauthorizedException(\'Account is deactivated\');\\n    }\\n\\n    // Verify password\\n    const isPasswordValid = await bcrypt.compare(loginDto.password, user.password);\\n    if (!isPasswordValid) {\\n      throw new UnauthorizedException(\'Invalid credentials\');\\n    }\\n\\n    // Update last login\\n    user.lastLoginAt = new Date();\\n    await this.userRepository.save(user);\\n\\n    // Generate tokens\\n    const tokens = await this.generateTokens(user);\\n    \\n    // Remove password from response\\n    delete user.password;\\n\\n    return { user, tokens };\\n  }\\n\\n  async generateTokens(user: User): Promise<TokenPair> {\\n    const roles = user.roles?.map(role => role.name) || [];\\n    const permissions = user.roles?.flatMap(role => \\n      role.permissions?.map(permission => permission.name) || []\\n    ) || [];\\n\\n    const payload: JwtPayload = {\\n      sub: user.id,\\n      email: user.email,\\n      roles,\\n      permissions,\\n      companyId: user.company?.id,\\n      departmentId: user.department?.id,\\n    };\\n\\n    const [accessToken, refreshToken] = await Promise.all([\\n      this.jwtService.signAsync(payload, {\\n        secret: process.env.JWT_ACCESS_SECRET,\\n        expiresIn: process.env.JWT_ACCESS_EXPIRES_IN || \'15m\',\\n      }),\\n      this.jwtService.signAsync(\\n        { sub: user.id, type: \'refresh\' }, \\n        {\\n          secret: process.env.JWT_REFRESH_SECRET,\\n          expiresIn: process.env.JWT_REFRESH_EXPIRES_IN || \'7d\',\\n        }\\n      ),\\n    ]);\\n\\n    return { accessToken, refreshToken };\\n  }\\n\\n  async refreshTokens(refreshToken: string): Promise<TokenPair> {\\n    try {\\n      const payload = await this.jwtService.verifyAsync(refreshToken, {\\n        secret: process.env.JWT_REFRESH_SECRET,\\n      });\\n\\n      if (payload.type !== \'refresh\') {\\n        throw new UnauthorizedException(\'Invalid token type\');\\n      }\\n\\n      const user = await this.userRepository.findOne({\\n        where: { id: payload.sub },\\n        relations: [\'roles\', \'roles.permissions\', \'company\', \'department\']\\n      });\\n\\n      if (!user || !user.isActive) {\\n        throw new UnauthorizedException(\'User not found or inactive\');\\n      }\\n\\n      return this.generateTokens(user);\\n    } catch (error) {\\n      throw new UnauthorizedException(\'Invalid refresh token\');\\n    }\\n  }\\n\\n  async validateUser(userId: string): Promise<User | null> {\\n    return this.userRepository.findOne({\\n      where: { id: userId },\\n      relations: [\'roles\', \'roles.permissions\', \'company\', \'department\']\\n    });\\n  }\\n\\n  async logout(userId: string): Promise<void> {\\n    // In a production environment, you might want to blacklist the JWT\\n    // or store logout events for audit purposes\\n    await this.userRepository.update(userId, { \\n      lastLogoutAt: new Date() \\n    });\\n  }\\n}\\n\\ninterface TokenPair {\\n  accessToken: string;\\n  refreshToken: string;\\n}\\n\\n// DTOs\\nexport class RegisterDto {\\n  email: string;\\n  password: string;\\n  firstName: string;\\n  lastName: string;\\n  companyId?: string;\\n  departmentId?: string;\\n}\\n\\nexport class LoginDto {\\n  email: string;\\n  password: string;\\n}\\n```\\n\\n### Database Entities\\n\\n```typescript\\n// apps/auth-service/src/entities/user.entity.ts\\nimport { Entity, PrimaryGeneratedColumn, Column, ManyToMany, ManyToOne, JoinTable, CreateDateColumn, UpdateDateColumn } from \'typeorm\';\\nimport { Role } from \'./role.entity\';\\nimport { Company } from \'./company.entity\';\\nimport { Department } from \'./department.entity\';\\n\\n@Entity(\'users\')\\nexport class User {\\n  @PrimaryGeneratedColumn(\'uuid\')\\n  id: string;\\n\\n  @Column({ unique: true })\\n  email: string;\\n\\n  @Column()\\n  password: string;\\n\\n  @Column()\\n  firstName: string;\\n\\n  @Column()\\n  lastName: string;\\n\\n  @Column({ default: true })\\n  isActive: boolean;\\n\\n  @Column({ default: false })\\n  emailVerified: boolean;\\n\\n  @Column({ nullable: true })\\n  phoneNumber: string;\\n\\n  @Column({ nullable: true })\\n  avatarUrl: string;\\n\\n  @Column({ nullable: true })\\n  lastLoginAt: Date;\\n\\n  @Column({ nullable: true })\\n  lastLogoutAt: Date;\\n\\n  @CreateDateColumn()\\n  createdAt: Date;\\n\\n  @UpdateDateColumn()\\n  updatedAt: Date;\\n\\n  @ManyToMany(() => Role, role => role.users, { eager: true })\\n  @JoinTable({\\n    name: \'user_roles\',\\n    joinColumn: { name: \'userId\', referencedColumnName: \'id\' },\\n    inverseJoinColumn: { name: \'roleId\', referencedColumnName: \'id\' }\\n  })\\n  roles: Role[];\\n\\n  @ManyToOne(() => Company, company => company.users)\\n  company: Company;\\n\\n  @ManyToOne(() => Department, department => department.users)\\n  department: Department;\\n}\\n\\n// apps/auth-service/src/entities/role.entity.ts\\n@Entity(\'roles\')\\nexport class Role {\\n  @PrimaryGeneratedColumn(\'uuid\')\\n  id: string;\\n\\n  @Column({ unique: true })\\n  name: string;\\n\\n  @Column({ nullable: true })\\n  description: string;\\n\\n  @Column({ default: true })\\n  isActive: boolean;\\n\\n  @CreateDateColumn()\\n  createdAt: Date;\\n\\n  @UpdateDateColumn()\\n  updatedAt: Date;\\n\\n  @ManyToMany(() => User, user => user.roles)\\n  users: User[];\\n\\n  @ManyToMany(() => Permission, permission => permission.roles, { eager: true })\\n  @JoinTable({\\n    name: \'role_permissions\',\\n    joinColumn: { name: \'roleId\', referencedColumnName: \'id\' },\\n    inverseJoinColumn: { name: \'permissionId\', referencedColumnName: \'id\' }\\n  })\\n  permissions: Permission[];\\n}\\n\\n// apps/auth-service/src/entities/permission.entity.ts\\n@Entity(\'permissions\')\\nexport class Permission {\\n  @PrimaryGeneratedColumn(\'uuid\')\\n  id: string;\\n\\n  @Column({ unique: true })\\n  name: string;\\n\\n  @Column({ nullable: true })\\n  description: string;\\n\\n  @Column()\\n  resource: string; // e.g., \'orders\', \'products\', \'users\'\\n\\n  @Column()\\n  action: string; // e.g., \'create\', \'read\', \'update\', \'delete\'\\n\\n  @Column({ default: true })\\n  isActive: boolean;\\n\\n  @CreateDateColumn()\\n  createdAt: Date;\\n\\n  @UpdateDateColumn()\\n  updatedAt: Date;\\n\\n  @ManyToMany(() => Role, role => role.permissions)\\n  roles: Role[];\\n}\\n```\\n\\n## Authorization Implementation\\n\\n### Guards and Decorators\\n\\n```typescript\\n// libs/auth/src/guards/jwt-auth.guard.ts\\nimport { Injectable, UnauthorizedException } from \'@nestjs/common\';\\nimport { AuthGuard } from \'@nestjs/passport\';\\nimport { ExecutionContext } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class JwtAuthGuard extends AuthGuard(\'jwt\') {\\n  canActivate(context: ExecutionContext) {\\n    return super.canActivate(context);\\n  }\\n\\n  handleRequest(err: any, user: any, info: any, context: ExecutionContext) {\\n    if (err || !user) {\\n      throw err || new UnauthorizedException(\'Invalid or expired token\');\\n    }\\n    return user;\\n  }\\n}\\n\\n// libs/auth/src/guards/roles.guard.ts\\nimport { Injectable, CanActivate, ExecutionContext, ForbiddenException } from \'@nestjs/common\';\\nimport { Reflector } from \'@nestjs/core\';\\nimport { ROLES_KEY } from \'../decorators/roles.decorator\';\\n\\n@Injectable()\\nexport class RolesGuard implements CanActivate {\\n  constructor(private reflector: Reflector) {}\\n\\n  canActivate(context: ExecutionContext): boolean {\\n    const requiredRoles = this.reflector.getAllAndOverride<string[]>(ROLES_KEY, [\\n      context.getHandler(),\\n      context.getClass(),\\n    ]);\\n\\n    if (!requiredRoles) {\\n      return true;\\n    }\\n\\n    const { user } = context.switchToHttp().getRequest();\\n    if (!user) {\\n      throw new ForbiddenException(\'User not authenticated\');\\n    }\\n\\n    const hasRole = requiredRoles.some(role => user.roles?.includes(role));\\n    \\n    if (!hasRole) {\\n      throw new ForbiddenException(`Required roles: ${requiredRoles.join(\', \')}`);\\n    }\\n\\n    return true;\\n  }\\n}\\n\\n// libs/auth/src/guards/permissions.guard.ts\\nimport { Injectable, CanActivate, ExecutionContext, ForbiddenException } from \'@nestjs/common\';\\nimport { Reflector } from \'@nestjs/core\';\\nimport { PERMISSIONS_KEY } from \'../decorators/permissions.decorator\';\\n\\n@Injectable()\\nexport class PermissionsGuard implements CanActivate {\\n  constructor(private reflector: Reflector) {}\\n\\n  canActivate(context: ExecutionContext): boolean {\\n    const requiredPermissions = this.reflector.getAllAndOverride<string[]>(PERMISSIONS_KEY, [\\n      context.getHandler(),\\n      context.getClass(),\\n    ]);\\n\\n    if (!requiredPermissions) {\\n      return true;\\n    }\\n\\n    const { user } = context.switchToHttp().getRequest();\\n    if (!user) {\\n      throw new ForbiddenException(\'User not authenticated\');\\n    }\\n\\n    const hasPermission = requiredPermissions.every(permission => \\n      user.permissions?.includes(permission)\\n    );\\n    \\n    if (!hasPermission) {\\n      throw new ForbiddenException(`Required permissions: ${requiredPermissions.join(\', \')}`);\\n    }\\n\\n    return true;\\n  }\\n}\\n\\n// libs/auth/src/decorators/roles.decorator.ts\\nimport { SetMetadata } from \'@nestjs/common\';\\n\\nexport const ROLES_KEY = \'roles\';\\nexport const Roles = (...roles: string[]) => SetMetadata(ROLES_KEY, roles);\\n\\n// libs/auth/src/decorators/permissions.decorator.ts\\nimport { SetMetadata } from \'@nestjs/common\';\\n\\nexport const PERMISSIONS_KEY = \'permissions\';\\nexport const RequirePermissions = (...permissions: string[]) => \\n  SetMetadata(PERMISSIONS_KEY, permissions);\\n\\n// libs/auth/src/decorators/current-user.decorator.ts\\nimport { createParamDecorator, ExecutionContext } from \'@nestjs/common\';\\n\\nexport const CurrentUser = createParamDecorator(\\n  (data: unknown, ctx: ExecutionContext) => {\\n    const request = ctx.switchToHttp().getRequest();\\n    return request.user;\\n  },\\n);\\n```\\n\\n### Advanced Authorization with Resource Access\\n\\n```typescript\\n// libs/auth/src/guards/resource-access.guard.ts\\nimport { Injectable, CanActivate, ExecutionContext, ForbiddenException } from \'@nestjs/common\';\\nimport { Reflector } from \'@nestjs/core\';\\nimport { ClientProxy } from \'@nestjs/microservices\';\\nimport { Inject } from \'@nestjs/common\';\\nimport { firstValueFrom } from \'rxjs\';\\n\\nexport interface ResourceAccessConfig {\\n  resource: string;\\n  action: string;\\n  ownershipField?: string;\\n  companyScoped?: boolean;\\n  departmentScoped?: boolean;\\n}\\n\\nexport const RESOURCE_ACCESS_KEY = \'resource_access\';\\nexport const ResourceAccess = (config: ResourceAccessConfig) => \\n  SetMetadata(RESOURCE_ACCESS_KEY, config);\\n\\n@Injectable()\\nexport class ResourceAccessGuard implements CanActivate {\\n  constructor(\\n    private reflector: Reflector,\\n    @Inject(\'USER_SERVICE\') private userServiceClient: ClientProxy,\\n  ) {}\\n\\n  async canActivate(context: ExecutionContext): Promise<boolean> {\\n    const config = this.reflector.getAllAndOverride<ResourceAccessConfig>(\\n      RESOURCE_ACCESS_KEY,\\n      [context.getHandler(), context.getClass()],\\n    );\\n\\n    if (!config) {\\n      return true;\\n    }\\n\\n    const request = context.switchToHttp().getRequest();\\n    const user = request.user;\\n\\n    if (!user) {\\n      throw new ForbiddenException(\'User not authenticated\');\\n    }\\n\\n    // Check basic permission\\n    const hasPermission = user.permissions?.includes(`${config.resource}:${config.action}`);\\n    if (!hasPermission) {\\n      throw new ForbiddenException(`Permission denied: ${config.resource}:${config.action}`);\\n    }\\n\\n    // Check ownership if configured\\n    if (config.ownershipField) {\\n      const resourceId = request.params.id || request.body[config.ownershipField];\\n      if (resourceId) {\\n        const hasAccess = await this.checkResourceAccess(\\n          user,\\n          config.resource,\\n          resourceId,\\n          config\\n        );\\n        if (!hasAccess) {\\n          throw new ForbiddenException(\'Access denied to this resource\');\\n        }\\n      }\\n    }\\n\\n    return true;\\n  }\\n\\n  private async checkResourceAccess(\\n    user: any,\\n    resource: string,\\n    resourceId: string,\\n    config: ResourceAccessConfig\\n  ): Promise<boolean> {\\n    try {\\n      const result = await firstValueFrom(\\n        this.userServiceClient.send(\'check_resource_access\', {\\n          userId: user.sub,\\n          resource,\\n          resourceId,\\n          config,\\n        })\\n      );\\n      return result.hasAccess;\\n    } catch (error) {\\n      console.error(\'Error checking resource access:\', error);\\n      return false;\\n    }\\n  }\\n}\\n```\\n\\n## API Gateway Implementation\\n\\n```typescript\\n// apps/api-gateway/src/main.ts\\nimport { NestFactory } from \'@nestjs/core\';\\nimport { ValidationPipe } from \'@nestjs/common\';\\nimport { DocumentBuilder, SwaggerModule } from \'@nestjs/swagger\';\\nimport helmet from \'helmet\';\\nimport * as compression from \'compression\';\\nimport * as morgan from \'morgan\';\\nimport { AppModule } from \'./app.module\';\\n\\nasync function bootstrap() {\\n  const app = await NestFactory.create(AppModule);\\n\\n  // Security middleware\\n  app.use(helmet({\\n    contentSecurityPolicy: {\\n      directives: {\\n        defaultSrc: [\\"\'self\'\\"],\\n        scriptSrc: [\\"\'self\'\\", \\"\'unsafe-inline\'\\"],\\n        styleSrc: [\\"\'self\'\\", \\"\'unsafe-inline\'\\"],\\n        imgSrc: [\\"\'self\'\\", \\"data:\\", \\"https:\\"],\\n      },\\n    },\\n    hsts: {\\n      maxAge: 31536000,\\n      includeSubDomains: true,\\n      preload: true,\\n    },\\n  }));\\n\\n  app.use(compression());\\n  app.use(morgan(\'combined\'));\\n\\n  // Enable CORS\\n  app.enableCors({\\n    origin: process.env.ALLOWED_ORIGINS?.split(\',\') || [\'http://localhost:3000\'],\\n    methods: [\'GET\', \'POST\', \'PUT\', \'DELETE\', \'PATCH\'],\\n    allowedHeaders: [\'Content-Type\', \'Authorization\'],\\n    credentials: true,\\n  });\\n\\n  // Global validation pipe\\n  app.useGlobalPipes(new ValidationPipe({\\n    whitelist: true,\\n    forbidNonWhitelisted: true,\\n    transform: true,\\n  }));\\n\\n  // Swagger documentation\\n  const config = new DocumentBuilder()\\n    .setTitle(\'E-commerce Microservices API\')\\n    .setDescription(\'Secure microservices API with authentication and authorization\')\\n    .setVersion(\'1.0\')\\n    .addBearerAuth(\\n      {\\n        type: \'http\',\\n        scheme: \'bearer\',\\n        bearerFormat: \'JWT\',\\n        name: \'JWT\',\\n        description: \'Enter JWT token\',\\n        in: \'header\',\\n      },\\n      \'JWT-auth\',\\n    )\\n    .build();\\n\\n  const document = SwaggerModule.createDocument(app, config);\\n  SwaggerModule.setup(\'api\', app, document);\\n\\n  const port = process.env.PORT || 3000;\\n  await app.listen(port, \'0.0.0.0\');\\n  console.log(`API Gateway is running on: http://localhost:${port}`);\\n}\\n\\nbootstrap();\\n\\n// apps/api-gateway/src/auth/auth.controller.ts\\nimport { Controller, Post, Body, UseGuards, Get, Req } from \'@nestjs/common\';\\nimport { ClientProxy } from \'@nestjs/microservices\';\\nimport { Inject } from \'@nestjs/common\';\\nimport { firstValueFrom } from \'rxjs\';\\nimport { JwtAuthGuard } from \'@app/auth\';\\nimport { CurrentUser } from \'@app/auth\';\\nimport { ApiTags, ApiOperation, ApiBearerAuth } from \'@nestjs/swagger\';\\n\\n@ApiTags(\'Authentication\')\\n@Controller(\'auth\')\\nexport class AuthController {\\n  constructor(\\n    @Inject(\'AUTH_SERVICE\') private authServiceClient: ClientProxy,\\n  ) {}\\n\\n  @Post(\'register\')\\n  @ApiOperation({ summary: \'Register a new user\' })\\n  async register(@Body() registerDto: any) {\\n    return firstValueFrom(\\n      this.authServiceClient.send(\'auth.register\', registerDto)\\n    );\\n  }\\n\\n  @Post(\'login\')\\n  @ApiOperation({ summary: \'Login user\' })\\n  async login(@Body() loginDto: any) {\\n    return firstValueFrom(\\n      this.authServiceClient.send(\'auth.login\', loginDto)\\n    );\\n  }\\n\\n  @Post(\'refresh\')\\n  @ApiOperation({ summary: \'Refresh access token\' })\\n  async refresh(@Body() refreshDto: { refreshToken: string }) {\\n    return firstValueFrom(\\n      this.authServiceClient.send(\'auth.refresh\', refreshDto)\\n    );\\n  }\\n\\n  @Post(\'logout\')\\n  @UseGuards(JwtAuthGuard)\\n  @ApiBearerAuth(\'JWT-auth\')\\n  @ApiOperation({ summary: \'Logout user\' })\\n  async logout(@CurrentUser() user: any) {\\n    return firstValueFrom(\\n      this.authServiceClient.send(\'auth.logout\', { userId: user.sub })\\n    );\\n  }\\n\\n  @Get(\'profile\')\\n  @UseGuards(JwtAuthGuard)\\n  @ApiBearerAuth(\'JWT-auth\')\\n  @ApiOperation({ summary: \'Get current user profile\' })\\n  async getProfile(@CurrentUser() user: any) {\\n    return firstValueFrom(\\n      this.authServiceClient.send(\'auth.profile\', { userId: user.sub })\\n    );\\n  }\\n}\\n```\\n\\n## Service Implementation Examples\\n\\n### Order Service with Authorization\\n\\n```typescript\\n// apps/order-service/src/orders.controller.ts\\nimport { Controller, Get, Post, Body, Param, UseGuards, Query } from \'@nestjs/common\';\\nimport { JwtAuthGuard, RolesGuard, PermissionsGuard, ResourceAccessGuard } from \'@app/auth\';\\nimport { Roles, RequirePermissions, ResourceAccess, CurrentUser } from \'@app/auth\';\\nimport { ApiTags, ApiBearerAuth } from \'@nestjs/swagger\';\\n\\n@ApiTags(\'Orders\')\\n@Controller(\'orders\')\\n@UseGuards(JwtAuthGuard)\\n@ApiBearerAuth(\'JWT-auth\')\\nexport class OrdersController {\\n  constructor(private readonly ordersService: OrdersService) {}\\n\\n  @Post()\\n  @UseGuards(PermissionsGuard)\\n  @RequirePermissions(\'orders:create\')\\n  async createOrder(\\n    @Body() createOrderDto: CreateOrderDto,\\n    @CurrentUser() user: any\\n  ) {\\n    return this.ordersService.create(createOrderDto, user);\\n  }\\n\\n  @Get()\\n  @UseGuards(PermissionsGuard)\\n  @RequirePermissions(\'orders:read\')\\n  async getOrders(\\n    @Query() query: GetOrdersDto,\\n    @CurrentUser() user: any\\n  ) {\\n    return this.ordersService.findAllForUser(query, user);\\n  }\\n\\n  @Get(\':id\')\\n  @UseGuards(ResourceAccessGuard)\\n  @ResourceAccess({\\n    resource: \'orders\',\\n    action: \'read\',\\n    ownershipField: \'userId\',\\n    companyScoped: true\\n  })\\n  async getOrder(@Param(\'id\') id: string) {\\n    return this.ordersService.findOne(id);\\n  }\\n\\n  @Post(\':id/cancel\')\\n  @UseGuards(ResourceAccessGuard)\\n  @ResourceAccess({\\n    resource: \'orders\',\\n    action: \'cancel\',\\n    ownershipField: \'userId\'\\n  })\\n  async cancelOrder(@Param(\'id\') id: string, @CurrentUser() user: any) {\\n    return this.ordersService.cancel(id, user);\\n  }\\n\\n  @Get(\'admin/all\')\\n  @UseGuards(RolesGuard)\\n  @Roles(\'ADMIN\', \'ORDER_MANAGER\')\\n  async getAllOrdersAdmin(@Query() query: AdminGetOrdersDto) {\\n    return this.ordersService.findAllAdmin(query);\\n  }\\n}\\n\\n// apps/order-service/src/orders.service.ts\\n@Injectable()\\nexport class OrdersService {\\n  constructor(\\n    @InjectRepository(Order)\\n    private orderRepository: Repository<Order>,\\n    @Inject(\'USER_SERVICE\')\\n    private userServiceClient: ClientProxy,\\n  ) {}\\n\\n  async create(createOrderDto: CreateOrderDto, user: any): Promise<Order> {\\n    // Verify user can create orders in their company/department\\n    const canCreate = await this.checkUserPermission(\\n      user,\\n      \'orders:create\',\\n      createOrderDto.companyId\\n    );\\n\\n    if (!canCreate) {\\n      throw new ForbiddenException(\'Cannot create orders for this company\');\\n    }\\n\\n    const order = this.orderRepository.create({\\n      ...createOrderDto,\\n      userId: user.sub,\\n      companyId: user.companyId,\\n      status: OrderStatus.PENDING,\\n    });\\n\\n    return this.orderRepository.save(order);\\n  }\\n\\n  async findAllForUser(query: GetOrdersDto, user: any): Promise<Order[]> {\\n    const queryBuilder = this.orderRepository.createQueryBuilder(\'order\');\\n\\n    // Apply user-specific filters based on roles\\n    if (user.roles.includes(\'ADMIN\')) {\\n      // Admins can see all orders\\n    } else if (user.roles.includes(\'COMPANY_MANAGER\')) {\\n      // Company managers can see company orders\\n      queryBuilder.where(\'order.companyId = :companyId\', { \\n        companyId: user.companyId \\n      });\\n    } else {\\n      // Regular users can only see their own orders\\n      queryBuilder.where(\'order.userId = :userId\', { userId: user.sub });\\n    }\\n\\n    // Apply additional filters\\n    if (query.status) {\\n      queryBuilder.andWhere(\'order.status = :status\', { status: query.status });\\n    }\\n\\n    if (query.startDate) {\\n      queryBuilder.andWhere(\'order.createdAt >= :startDate\', { \\n        startDate: query.startDate \\n      });\\n    }\\n\\n    return queryBuilder.getMany();\\n  }\\n\\n  private async checkUserPermission(\\n    user: any,\\n    permission: string,\\n    resourceId?: string\\n  ): Promise<boolean> {\\n    try {\\n      const result = await firstValueFrom(\\n        this.userServiceClient.send(\'check_permission\', {\\n          userId: user.sub,\\n          permission,\\n          resourceId,\\n          context: {\\n            companyId: user.companyId,\\n            departmentId: user.departmentId,\\n          }\\n        })\\n      );\\n      return result.hasPermission;\\n    } catch (error) {\\n      console.error(\'Error checking user permission:\', error);\\n      return false;\\n    }\\n  }\\n}\\n```\\n\\n## Kubernetes Deployment Configuration\\n\\n### Namespace and RBAC\\n\\n```yaml\\n# k8s/namespace.yaml\\napiVersion: v1\\nkind: Namespace\\nmetadata:\\n  name: ecommerce\\n  labels:\\n    name: ecommerce\\n    istio-injection: enabled\\n\\n---\\n# k8s/rbac.yaml\\napiVersion: v1\\nkind: ServiceAccount\\nmetadata:\\n  name: ecommerce-service-account\\n  namespace: ecommerce\\n\\n---\\napiVersion: rbac.authorization.k8s.io/v1\\nkind: Role\\nmetadata:\\n  namespace: ecommerce\\n  name: ecommerce-role\\nrules:\\n- apiGroups: [\\"\\"]\\n  resources: [\\"secrets\\", \\"configmaps\\"]\\n  verbs: [\\"get\\", \\"list\\"]\\n- apiGroups: [\\"\\"]\\n  resources: [\\"pods\\"]\\n  verbs: [\\"get\\", \\"list\\", \\"watch\\"]\\n\\n---\\napiVersion: rbac.authorization.k8s.io/v1\\nkind: RoleBinding\\nmetadata:\\n  name: ecommerce-role-binding\\n  namespace: ecommerce\\nsubjects:\\n- kind: ServiceAccount\\n  name: ecommerce-service-account\\n  namespace: ecommerce\\nroleRef:\\n  kind: Role\\n  name: ecommerce-role\\n  apiGroup: rbac.authorization.k8s.io\\n```\\n\\n### ConfigMaps and Secrets\\n\\n```yaml\\n# k8s/configmap.yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: ecommerce-config\\n  namespace: ecommerce\\ndata:\\n  NODE_ENV: \\"production\\"\\n  LOG_LEVEL: \\"info\\"\\n  API_VERSION: \\"v1\\"\\n  CORS_ORIGINS: \\"https://yourdomain.com,https://app.yourdomain.com\\"\\n  REDIS_HOST: \\"redis-service\\"\\n  REDIS_PORT: \\"6379\\"\\n  DB_HOST: \\"postgres-service\\"\\n  DB_PORT: \\"5432\\"\\n  DB_NAME: \\"ecommerce\\"\\n  JWT_ACCESS_EXPIRES_IN: \\"15m\\"\\n  JWT_REFRESH_EXPIRES_IN: \\"7d\\"\\n\\n---\\n# k8s/secrets.yaml\\napiVersion: v1\\nkind: Secret\\nmetadata:\\n  name: ecommerce-secrets\\n  namespace: ecommerce\\ntype: Opaque\\ndata:\\n  # Base64 encoded values\\n  DB_USERNAME: cG9zdGdyZXM= # postgres\\n  DB_PASSWORD: cGFzc3dvcmQxMjM= # password123\\n  JWT_ACCESS_SECRET: c3VwZXItc2VjcmV0LWFjY2Vzcy1rZXk= # super-secret-access-key\\n  JWT_REFRESH_SECRET: c3VwZXItc2VjcmV0LXJlZnJlc2gta2V5 # super-secret-refresh-key\\n  REDIS_PASSWORD: cmVkaXNwYXNzd29yZA== # redispassword\\n```\\n\\n### Service Deployments\\n\\n```yaml\\n# k8s/auth-service.yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: auth-service\\n  namespace: ecommerce\\n  labels:\\n    app: auth-service\\n    version: v1\\nspec:\\n  replicas: 2\\n  selector:\\n    matchLabels:\\n      app: auth-service\\n      version: v1\\n  template:\\n    metadata:\\n      labels:\\n        app: auth-service\\n        version: v1\\n    spec:\\n      serviceAccountName: ecommerce-service-account\\n      containers:\\n      - name: auth-service\\n        image: gcr.io/your-project/auth-service:latest\\n        ports:\\n        - containerPort: 3001\\n        env:\\n        - name: PORT\\n          value: \\"3001\\"\\n        - name: SERVICE_NAME\\n          value: \\"auth-service\\"\\n        envFrom:\\n        - configMapRef:\\n            name: ecommerce-config\\n        - secretRef:\\n            name: ecommerce-secrets\\n        resources:\\n          requests:\\n            memory: \\"256Mi\\"\\n            cpu: \\"250m\\"\\n          limits:\\n            memory: \\"512Mi\\"\\n            cpu: \\"500m\\"\\n        livenessProbe:\\n          httpGet:\\n            path: /health\\n            port: 3001\\n          initialDelaySeconds: 30\\n          periodSeconds: 10\\n        readinessProbe:\\n          httpGet:\\n            path: /health/ready\\n            port: 3001\\n          initialDelaySeconds: 5\\n          periodSeconds: 5\\n        securityContext:\\n          runAsNonRoot: true\\n          runAsUser: 1000\\n          allowPrivilegeEscalation: false\\n          readOnlyRootFilesystem: true\\n          capabilities:\\n            drop:\\n            - ALL\\n\\n---\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: auth-service\\n  namespace: ecommerce\\n  labels:\\n    app: auth-service\\nspec:\\n  selector:\\n    app: auth-service\\n  ports:\\n  - port: 3001\\n    targetPort: 3001\\n    name: http\\n\\n---\\n# k8s/api-gateway.yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: api-gateway\\n  namespace: ecommerce\\n  labels:\\n    app: api-gateway\\n    version: v1\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: api-gateway\\n      version: v1\\n  template:\\n    metadata:\\n      labels:\\n        app: api-gateway\\n        version: v1\\n    spec:\\n      serviceAccountName: ecommerce-service-account\\n      containers:\\n      - name: api-gateway\\n        image: gcr.io/your-project/api-gateway:latest\\n        ports:\\n        - containerPort: 3000\\n        env:\\n        - name: PORT\\n          value: \\"3000\\"\\n        - name: AUTH_SERVICE_URL\\n          value: \\"http://auth-service:3001\\"\\n        - name: USER_SERVICE_URL\\n          value: \\"http://user-service:3002\\"\\n        - name: ORDER_SERVICE_URL\\n          value: \\"http://order-service:3003\\"\\n        - name: PRODUCT_SERVICE_URL\\n          value: \\"http://product-service:3004\\"\\n        envFrom:\\n        - configMapRef:\\n            name: ecommerce-config\\n        - secretRef:\\n            name: ecommerce-secrets\\n        resources:\\n          requests:\\n            memory: \\"512Mi\\"\\n            cpu: \\"500m\\"\\n          limits:\\n            memory: \\"1Gi\\"\\n            cpu: \\"1000m\\"\\n        livenessProbe:\\n          httpGet:\\n            path: /health\\n            port: 3000\\n          initialDelaySeconds: 30\\n          periodSeconds: 10\\n        readinessProbe:\\n          httpGet:\\n            path: /health/ready\\n            port: 3000\\n          initialDelaySeconds: 5\\n          periodSeconds: 5\\n\\n---\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: api-gateway\\n  namespace: ecommerce\\n  labels:\\n    app: api-gateway\\nspec:\\n  selector:\\n    app: api-gateway\\n  ports:\\n  - port: 80\\n    targetPort: 3000\\n    name: http\\n  type: LoadBalancer\\n```\\n\\n### Istio Service Mesh Configuration\\n\\n```yaml\\n# k8s/istio/gateway.yaml\\napiVersion: networking.istio.io/v1beta1\\nkind: Gateway\\nmetadata:\\n  name: ecommerce-gateway\\n  namespace: ecommerce\\nspec:\\n  selector:\\n    istio: ingressgateway\\n  servers:\\n  - port:\\n      number: 443\\n      name: https\\n      protocol: HTTPS\\n    tls:\\n      mode: SIMPLE\\n      credentialName: ecommerce-tls-cert\\n    hosts:\\n    - api.yourdomain.com\\n  - port:\\n      number: 80\\n      name: http\\n      protocol: HTTP\\n    hosts:\\n    - api.yourdomain.com\\n    tls:\\n      httpsRedirect: true\\n\\n---\\n# k8s/istio/virtual-service.yaml\\napiVersion: networking.istio.io/v1beta1\\nkind: VirtualService\\nmetadata:\\n  name: ecommerce-vs\\n  namespace: ecommerce\\nspec:\\n  hosts:\\n  - api.yourdomain.com\\n  gateways:\\n  - ecommerce-gateway\\n  http:\\n  - match:\\n    - uri:\\n        prefix: /api/\\n    rewrite:\\n      uri: /\\n    route:\\n    - destination:\\n        host: api-gateway\\n        port:\\n          number: 80\\n    timeout: 30s\\n    retries:\\n      attempts: 3\\n      perTryTimeout: 10s\\n\\n---\\n# k8s/istio/destination-rule.yaml\\napiVersion: networking.istio.io/v1beta1\\nkind: DestinationRule\\nmetadata:\\n  name: api-gateway-dr\\n  namespace: ecommerce\\nspec:\\n  host: api-gateway\\n  trafficPolicy:\\n    connectionPool:\\n      tcp:\\n        maxConnections: 100\\n      http:\\n        http1MaxPendingRequests: 50\\n        maxRequestsPerConnection: 10\\n    loadBalancer:\\n      simple: LEAST_CONN\\n    circuitBreaker:\\n      consecutiveErrors: 3\\n      interval: 30s\\n      baseEjectionTime: 30s\\n```\\n\\n### Authorization Policies with Istio\\n\\n```yaml\\n# k8s/istio/authorization-policy.yaml\\napiVersion: security.istio.io/v1beta1\\nkind: AuthorizationPolicy\\nmetadata:\\n  name: ecommerce-authz\\n  namespace: ecommerce\\nspec:\\n  rules:\\n  - from:\\n    - source:\\n        principals: [\\"cluster.local/ns/ecommerce/sa/ecommerce-service-account\\"]\\n  - to:\\n    - operation:\\n        methods: [\\"GET\\"]\\n        paths: [\\"/health\\", \\"/health/ready\\", \\"/metrics\\"]\\n  - to:\\n    - operation:\\n        methods: [\\"POST\\"]\\n        paths: [\\"/auth/login\\", \\"/auth/register\\"]\\n  - when:\\n    - key: request.headers[authorization]\\n      values: [\\"Bearer *\\"]\\n\\n---\\n# k8s/istio/peer-authentication.yaml\\napiVersion: security.istio.io/v1beta1\\nkind: PeerAuthentication\\nmetadata:\\n  name: ecommerce-mtls\\n  namespace: ecommerce\\nspec:\\n  mtls:\\n    mode: STRICT\\n```\\n\\n## Database Migrations and Setup\\n\\n```typescript\\n// database/migrations/001_initial_schema.ts\\nimport { MigrationInterface, QueryRunner } from \'typeorm\';\\n\\nexport class InitialSchema1698765432100 implements MigrationInterface {\\n  public async up(queryRunner: QueryRunner): Promise<void> {\\n    // Create companies table\\n    await queryRunner.query(`\\n      CREATE TABLE companies (\\n        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\\n        name VARCHAR(255) NOT NULL,\\n        domain VARCHAR(255) UNIQUE,\\n        is_active BOOLEAN DEFAULT true,\\n        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n      )\\n    `);\\n\\n    // Create departments table\\n    await queryRunner.query(`\\n      CREATE TABLE departments (\\n        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\\n        name VARCHAR(255) NOT NULL,\\n        company_id UUID REFERENCES companies(id),\\n        is_active BOOLEAN DEFAULT true,\\n        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n      )\\n    `);\\n\\n    // Create permissions table\\n    await queryRunner.query(`\\n      CREATE TABLE permissions (\\n        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\\n        name VARCHAR(255) UNIQUE NOT NULL,\\n        description TEXT,\\n        resource VARCHAR(100) NOT NULL,\\n        action VARCHAR(100) NOT NULL,\\n        is_active BOOLEAN DEFAULT true,\\n        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n      )\\n    `);\\n\\n    // Create roles table\\n    await queryRunner.query(`\\n      CREATE TABLE roles (\\n        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\\n        name VARCHAR(255) UNIQUE NOT NULL,\\n        description TEXT,\\n        is_active BOOLEAN DEFAULT true,\\n        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n      )\\n    `);\\n\\n    // Create users table\\n    await queryRunner.query(`\\n      CREATE TABLE users (\\n        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\\n        email VARCHAR(255) UNIQUE NOT NULL,\\n        password VARCHAR(255) NOT NULL,\\n        first_name VARCHAR(255) NOT NULL,\\n        last_name VARCHAR(255) NOT NULL,\\n        is_active BOOLEAN DEFAULT true,\\n        email_verified BOOLEAN DEFAULT false,\\n        phone_number VARCHAR(50),\\n        avatar_url TEXT,\\n        last_login_at TIMESTAMP,\\n        last_logout_at TIMESTAMP,\\n        company_id UUID REFERENCES companies(id),\\n        department_id UUID REFERENCES departments(id),\\n        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\\n        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\\n      )\\n    `);\\n\\n    // Create junction tables\\n    await queryRunner.query(`\\n      CREATE TABLE role_permissions (\\n        role_id UUID REFERENCES roles(id) ON DELETE CASCADE,\\n        permission_id UUID REFERENCES permissions(id) ON DELETE CASCADE,\\n        PRIMARY KEY (role_id, permission_id)\\n      )\\n    `);\\n\\n    await queryRunner.query(`\\n      CREATE TABLE user_roles (\\n        user_id UUID REFERENCES users(id) ON DELETE CASCADE,\\n        role_id UUID REFERENCES roles(id) ON DELETE CASCADE,\\n        PRIMARY KEY (user_id, role_id)\\n      )\\n    `);\\n\\n    // Create indexes\\n    await queryRunner.query(`CREATE INDEX idx_users_email ON users(email)`);\\n    await queryRunner.query(`CREATE INDEX idx_users_company ON users(company_id)`);\\n    await queryRunner.query(`CREATE INDEX idx_users_department ON users(department_id)`);\\n    await queryRunner.query(`CREATE INDEX idx_permissions_resource_action ON permissions(resource, action)`);\\n  }\\n\\n  public async down(queryRunner: QueryRunner): Promise<void> {\\n    await queryRunner.query(`DROP TABLE IF EXISTS user_roles`);\\n    await queryRunner.query(`DROP TABLE IF EXISTS role_permissions`);\\n    await queryRunner.query(`DROP TABLE IF EXISTS users`);\\n    await queryRunner.query(`DROP TABLE IF EXISTS roles`);\\n    await queryRunner.query(`DROP TABLE IF EXISTS permissions`);\\n    await queryRunner.query(`DROP TABLE IF EXISTS departments`);\\n    await queryRunner.query(`DROP TABLE IF EXISTS companies`);\\n  }\\n}\\n\\n// database/seeders/default-data.seeder.ts\\nimport { DataSource } from \'typeorm\';\\nimport { Permission } from \'../entities/permission.entity\';\\nimport { Role } from \'../entities/role.entity\';\\nimport { Company } from \'../entities/company.entity\';\\n\\nexport class DefaultDataSeeder {\\n  constructor(private dataSource: DataSource) {}\\n\\n  async run(): Promise<void> {\\n    await this.seedPermissions();\\n    await this.seedRoles();\\n    await this.seedDefaultCompany();\\n  }\\n\\n  private async seedPermissions(): Promise<void> {\\n    const permissionRepository = this.dataSource.getRepository(Permission);\\n    \\n    const permissions = [\\n      // User permissions\\n      { name: \'users:create\', resource: \'users\', action: \'create\', description: \'Create new users\' },\\n      { name: \'users:read\', resource: \'users\', action: \'read\', description: \'View user information\' },\\n      { name: \'users:update\', resource: \'users\', action: \'update\', description: \'Update user information\' },\\n      { name: \'users:delete\', resource: \'users\', action: \'delete\', description: \'Delete users\' },\\n      \\n      // Order permissions\\n      { name: \'orders:create\', resource: \'orders\', action: \'create\', description: \'Create new orders\' },\\n      { name: \'orders:read\', resource: \'orders\', action: \'read\', description: \'View orders\' },\\n      { name: \'orders:update\', resource: \'orders\', action: \'update\', description: \'Update orders\' },\\n      { name: \'orders:cancel\', resource: \'orders\', action: \'cancel\', description: \'Cancel orders\' },\\n      { name: \'orders:delete\', resource: \'orders\', action: \'delete\', description: \'Delete orders\' },\\n      \\n      // Product permissions\\n      { name: \'products:create\', resource: \'products\', action: \'create\', description: \'Create new products\' },\\n      { name: \'products:read\', resource: \'products\', action: \'read\', description: \'View products\' },\\n      { name: \'products:update\', resource: \'products\', action: \'update\', description: \'Update products\' },\\n      { name: \'products:delete\', resource: \'products\', action: \'delete\', description: \'Delete products\' },\\n      \\n      // Company permissions\\n      { name: \'companies:create\', resource: \'companies\', action: \'create\', description: \'Create companies\' },\\n      { name: \'companies:read\', resource: \'companies\', action: \'read\', description: \'View companies\' },\\n      { name: \'companies:update\', resource: \'companies\', action: \'update\', description: \'Update companies\' },\\n      { name: \'companies:delete\', resource: \'companies\', action: \'delete\', description: \'Delete companies\' },\\n    ];\\n\\n    for (const permData of permissions) {\\n      const exists = await permissionRepository.findOne({ where: { name: permData.name } });\\n      if (!exists) {\\n        const permission = permissionRepository.create(permData);\\n        await permissionRepository.save(permission);\\n      }\\n    }\\n  }\\n\\n  private async seedRoles(): Promise<void> {\\n    const roleRepository = this.dataSource.getRepository(Role);\\n    const permissionRepository = this.dataSource.getRepository(Permission);\\n\\n    // Super Admin role\\n    const adminPermissions = await permissionRepository.find();\\n    let adminRole = await roleRepository.findOne({ \\n      where: { name: \'SUPER_ADMIN\' },\\n      relations: [\'permissions\']\\n    });\\n    \\n    if (!adminRole) {\\n      adminRole = roleRepository.create({\\n        name: \'SUPER_ADMIN\',\\n        description: \'Super administrator with all permissions\',\\n        permissions: adminPermissions,\\n      });\\n      await roleRepository.save(adminRole);\\n    }\\n\\n    // Regular user role\\n    const userPermissions = await permissionRepository.find({\\n      where: [\\n        { name: \'orders:create\' },\\n        { name: \'orders:read\' },\\n        { name: \'orders:cancel\' },\\n        { name: \'products:read\' },\\n      ]\\n    });\\n\\n    let userRole = await roleRepository.findOne({ \\n      where: { name: \'USER\' },\\n      relations: [\'permissions\']\\n    });\\n    \\n    if (!userRole) {\\n      userRole = roleRepository.create({\\n        name: \'USER\',\\n        description: \'Regular user with basic permissions\',\\n        permissions: userPermissions,\\n      });\\n      await roleRepository.save(userRole);\\n    }\\n  }\\n\\n  private async seedDefaultCompany(): Promise<void> {\\n    const companyRepository = this.dataSource.getRepository(Company);\\n    \\n    const exists = await companyRepository.findOne({ where: { name: \'Default Company\' } });\\n    if (!exists) {\\n      const company = companyRepository.create({\\n        name: \'Default Company\',\\n        domain: \'default.com\',\\n      });\\n      await companyRepository.save(company);\\n    }\\n  }\\n}\\n```\\n\\n## Deployment Scripts\\n\\n```bash\\n#!/bin/bash\\n# scripts/deploy.sh\\n\\nset -e\\n\\nPROJECT_ID=${1:-\\"your-gcp-project-id\\"}\\nREGION=${2:-\\"us-central1\\"}\\nCLUSTER_NAME=${3:-\\"ecommerce-cluster\\"}\\n\\necho \\"Deploying to GCP Project: $PROJECT_ID\\"\\necho \\"Region: $REGION\\"\\necho \\"Cluster: $CLUSTER_NAME\\"\\n\\n# Build and push Docker images\\necho \\"Building and pushing Docker images...\\"\\ndocker build -t gcr.io/$PROJECT_ID/auth-service:latest -f docker/auth-service.Dockerfile .\\ndocker build -t gcr.io/$PROJECT_ID/api-gateway:latest -f docker/api-gateway.Dockerfile .\\ndocker build -t gcr.io/$PROJECT_ID/user-service:latest -f docker/user-service.Dockerfile .\\ndocker build -t gcr.io/$PROJECT_ID/order-service:latest -f docker/order-service.Dockerfile .\\ndocker build -t gcr.io/$PROJECT_ID/product-service:latest -f docker/product-service.Dockerfile .\\n\\ndocker push gcr.io/$PROJECT_ID/auth-service:latest\\ndocker push gcr.io/$PROJECT_ID/api-gateway:latest\\ndocker push gcr.io/$PROJECT_ID/user-service:latest\\ndocker push gcr.io/$PROJECT_ID/order-service:latest\\ndocker push gcr.io/$PROJECT_ID/product-service:latest\\n\\n# Get GKE credentials\\necho \\"Getting GKE credentials...\\"\\ngcloud container clusters get-credentials $CLUSTER_NAME --region=$REGION --project=$PROJECT_ID\\n\\n# Apply Kubernetes manifests\\necho \\"Applying Kubernetes manifests...\\"\\nkubectl apply -f k8s/namespace.yaml\\nkubectl apply -f k8s/rbac.yaml\\nkubectl apply -f k8s/configmap.yaml\\nkubectl apply -f k8s/secrets.yaml\\n\\n# Deploy services\\nkubectl apply -f k8s/auth-service.yaml\\nkubectl apply -f k8s/api-gateway.yaml\\nkubectl apply -f k8s/user-service.yaml\\nkubectl apply -f k8s/order-service.yaml\\nkubectl apply -f k8s/product-service.yaml\\n\\n# Apply Istio configurations\\necho \\"Applying Istio configurations...\\"\\nkubectl apply -f k8s/istio/\\n\\necho \\"Waiting for deployments to be ready...\\"\\nkubectl wait --for=condition=available --timeout=600s deployment/auth-service -n ecommerce\\nkubectl wait --for=condition=available --timeout=600s deployment/api-gateway -n ecommerce\\nkubectl wait --for=condition=available --timeout=600s deployment/user-service -n ecommerce\\nkubectl wait --for=condition=available --timeout=600s deployment/order-service -n ecommerce\\nkubectl wait --for=condition=available --timeout=600s deployment/product-service -n ecommerce\\n\\necho \\"Deployment completed successfully!\\"\\necho \\"API Gateway endpoint:\\"\\nkubectl get service api-gateway -n ecommerce -o jsonpath=\'{.status.loadBalancer.ingress[0].ip}\'\\n```\\n\\n## Security Best Practices Summary\\n\\n### 1. **Authentication Security**\\n- Use strong JWT secrets stored in Kubernetes secrets\\n- Implement proper token expiration and rotation\\n- Use bcrypt with appropriate salt rounds for password hashing\\n- Implement account lockout after failed login attempts\\n\\n### 2. **Authorization Security**\\n- Implement defense in depth with multiple authorization layers\\n- Use principle of least privilege for role assignments\\n- Validate resource ownership at the service level\\n- Implement audit logging for all authorization decisions\\n\\n### 3. **Infrastructure Security**\\n- Use Kubernetes RBAC for service account permissions\\n- Implement network policies to restrict inter-service communication\\n- Use Istio service mesh for mTLS between services\\n- Store sensitive data in GCP Secret Manager or Kubernetes secrets\\n\\n### 4. **API Security**\\n- Implement rate limiting at the API gateway level\\n- Use HTTPS/TLS for all external communication\\n- Validate all input data with proper sanitization\\n- Implement proper CORS policies\\n\\n### 5. **Container Security**\\n- Run containers as non-root users\\n- Use read-only root filesystems\\n- Implement resource limits and requests\\n- Regularly scan container images for vulnerabilities\\n\\n### 6. **Monitoring and Observability**\\n- Implement comprehensive logging for security events\\n- Set up monitoring for failed authentication attempts\\n- Use distributed tracing for request flow analysis\\n- Implement alerting for suspicious activities\\n\\n## Conclusion\\n\\nThis comprehensive implementation demonstrates how to build secure, scalable microservices with NestJS on GCP Kubernetes. The architecture incorporates:\\n\\n- **Multi-layered Security**: Authentication at the gateway, authorization at the service level\\n- **Enterprise Patterns**: RBAC, ReBAC, and ABAC authorization models\\n- **Cloud-Native Features**: Kubernetes-native security, Istio service mesh, GCP integrations\\n- **Production Readiness**: Proper error handling, monitoring, and deployment automation\\n\\nKey benefits of this approach:\\n\\n1. **Scalability**: Each service can scale independently based on demand\\n2. **Security**: Multiple layers of security from infrastructure to application level\\n3. **Maintainability**: Clear separation of concerns and modular architecture\\n4. **Observability**: Comprehensive logging, monitoring, and tracing\\n5. **Reliability**: Health checks, circuit breakers, and proper error handling\\n\\nThis implementation provides a solid foundation for building enterprise-grade microservices with robust authentication and authorization mechanisms suitable for production deployment on Google Cloud Platform.\\n\\n## Further Resources\\n\\n- [NestJS Documentation](https://docs.nestjs.com/)\\n- [Kubernetes Security Best Practices](https://kubernetes.io/docs/concepts/security/)\\n- [Istio Security Documentation](https://istio.io/latest/docs/concepts/security/)\\n- [Google Cloud Security Best Practices](https://cloud.google.com/security/best-practices)\\n- [Microservices Security Patterns](https://microservices.io/patterns/security/)\\n\\n---\\n\\n*Have you implemented similar microservices architectures? Share your experiences with authentication and authorization patterns in the comments!*"},{"id":"nginx-web-server-guide","metadata":{"permalink":"/fullstack-dev/blog/nginx-web-server-guide","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-06-nginx-web-server-guide.md","source":"@site/blog/2025-10-06-nginx-web-server-guide.md","title":"Nginx: The High-Performance Web Server and Reverse Proxy","description":"Nginx (pronounced \\"engine-x\\") is one of the most popular and powerful web servers in the world, powering over 30% of all websites on the internet. Originally created by Igor Sysoev in 2004 to solve the C10K problem (handling 10,000 concurrent connections), Nginx has evolved into a versatile tool that serves as a web server, reverse proxy, load balancer, and HTTP cache.","date":"2025-10-06T00:00:00.000Z","tags":[{"inline":false,"label":"Nginx","permalink":"/fullstack-dev/blog/tags/nginx","description":"Nginx web server and configuration"},{"inline":false,"label":"Web Server","permalink":"/fullstack-dev/blog/tags/web-server","description":"Web server configuration and management"},{"inline":false,"label":"Reverse Proxy","permalink":"/fullstack-dev/blog/tags/reverse-proxy","description":"Reverse proxy configuration"},{"inline":false,"label":"Load Balancing","permalink":"/fullstack-dev/blog/tags/load-balancing","description":"Load balancing strategies"},{"inline":false,"label":"Performance","permalink":"/fullstack-dev/blog/tags/performance","description":"Performance optimization techniques"},{"inline":false,"label":"DevOps","permalink":"/fullstack-dev/blog/tags/devops","description":"DevOps practices and tools"}],"readingTime":12.85,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"nginx-web-server-guide","title":"Nginx: The High-Performance Web Server and Reverse Proxy","authors":["tam"],"tags":["nginx","web-server","reverse-proxy","load-balancing","performance","devops"]},"unlisted":false,"prevItem":{"title":"Building Secure Microservices: Authentication & Authorization with NestJS on GCP Kubernetes","permalink":"/fullstack-dev/blog/nestjs-auth-microservices-gcp-kubernetes"},"nextItem":{"title":"The Art of Prompt Engineering: How to Create Effective Prompts for AI","permalink":"/fullstack-dev/blog/how-to-create-good-prompts"}},"content":"Nginx (pronounced \\"engine-x\\") is one of the most popular and powerful web servers in the world, powering over 30% of all websites on the internet. Originally created by Igor Sysoev in 2004 to solve the C10K problem (handling 10,000 concurrent connections), Nginx has evolved into a versatile tool that serves as a web server, reverse proxy, load balancer, and HTTP cache.\\n\\nIn this comprehensive guide, we\'ll explore what makes Nginx special, its key features, common use cases, and how to get started with basic configurations.\\n\\n\x3c!-- truncate --\x3e\\n\\n## What is Nginx?\\n\\nNginx is an open-source web server that can also function as a reverse proxy, load balancer, mail proxy, and HTTP cache. Unlike traditional web servers that create a new thread or process for each request, Nginx uses an event-driven, asynchronous architecture that allows it to handle thousands of concurrent connections with minimal resource usage.\\n\\n### Key Characteristics\\n\\n- **High Performance**: Handles thousands of concurrent connections efficiently\\n- **Low Memory Usage**: Uses significantly less memory compared to Apache\\n- **Event-Driven Architecture**: Non-blocking I/O operations\\n- **Modular Design**: Extensible through modules\\n- **Configuration Flexibility**: Simple yet powerful configuration syntax\\n\\n## Core Features\\n\\n### 1. Web Server\\nNginx can serve static content (HTML, CSS, JavaScript, images) extremely efficiently. Its ability to handle static files makes it an excellent choice for serving modern web applications.\\n\\n### 2. Reverse Proxy\\nActs as an intermediary between clients and backend servers, forwarding client requests to appropriate backend services and returning responses back to clients.\\n\\n### 3. Load Balancing\\nDistributes incoming requests across multiple backend servers to ensure optimal resource utilization and prevent any single server from becoming overwhelmed.\\n\\n### 4. SSL/TLS Termination\\nHandles SSL/TLS encryption and decryption, offloading this computationally intensive task from backend servers.\\n\\n### 5. Caching\\nProvides HTTP caching capabilities to store frequently requested content, reducing load on backend servers and improving response times.\\n\\n## Common Use Cases\\n\\n### 1. Static File Serving\\n```nginx\\nserver {\\n    listen 80;\\n    server_name example.com;\\n    root /var/www/html;\\n    \\n    location / {\\n        try_files $uri $uri/ =404;\\n    }\\n    \\n    location ~* \\\\.(jpg|jpeg|png|gif|ico|css|js)$ {\\n        expires 1y;\\n        add_header Cache-Control \\"public, immutable\\";\\n    }\\n}\\n```\\n\\n### 2. Reverse Proxy for Node.js Applications\\n```nginx\\nserver {\\n    listen 80;\\n    server_name api.example.com;\\n    \\n    location / {\\n        proxy_pass http://localhost:3000;\\n        proxy_http_version 1.1;\\n        proxy_set_header Upgrade $http_upgrade;\\n        proxy_set_header Connection \'upgrade\';\\n        proxy_set_header Host $host;\\n        proxy_set_header X-Real-IP $remote_addr;\\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n        proxy_set_header X-Forwarded-Proto $scheme;\\n        proxy_cache_bypass $http_upgrade;\\n    }\\n}\\n```\\n\\n### 3. Load Balancing\\n```nginx\\nupstream backend {\\n    server backend1.example.com;\\n    server backend2.example.com;\\n    server backend3.example.com;\\n}\\n\\nserver {\\n    listen 80;\\n    server_name example.com;\\n    \\n    location / {\\n        proxy_pass http://backend;\\n    }\\n}\\n```\\n\\n### 4. SSL/HTTPS Configuration\\n```nginx\\nserver {\\n    listen 443 ssl http2;\\n    server_name example.com;\\n    \\n    ssl_certificate /path/to/certificate.crt;\\n    ssl_certificate_key /path/to/private.key;\\n    ssl_protocols TLSv1.2 TLSv1.3;\\n    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;\\n    \\n    location / {\\n        root /var/www/html;\\n        index index.html;\\n    }\\n}\\n\\n# Redirect HTTP to HTTPS\\nserver {\\n    listen 80;\\n    server_name example.com;\\n    return 301 https://$server_name$request_uri;\\n}\\n```\\n\\n## Nginx vs Apache\\n\\n| Feature | Nginx | Apache |\\n|---------|--------|--------|\\n| **Architecture** | Event-driven, asynchronous | Process/thread-based |\\n| **Memory Usage** | Lower | Higher |\\n| **Static Content** | Excellent performance | Good performance |\\n| **Configuration** | Centralized config files | .htaccess + main config |\\n| **Modules** | Dynamic loading | Both static and dynamic |\\n| **Learning Curve** | Moderate | Easier for beginners |\\n\\n## Installation and Basic Setup\\n\\n### Ubuntu/Debian\\n```bash\\nsudo apt update\\nsudo apt install nginx\\nsudo systemctl start nginx\\nsudo systemctl enable nginx\\n```\\n\\n### CentOS/RHEL\\n```bash\\nsudo yum install epel-release\\nsudo yum install nginx\\nsudo systemctl start nginx\\nsudo systemctl enable nginx\\n```\\n\\n### macOS (with Homebrew)\\n```bash\\nbrew install nginx\\nbrew services start nginx\\n```\\n\\n### macOS M4 Chip Specific Setup\\n\\nFor Apple Silicon M4 processors, you may need to install Homebrew for ARM64 architecture if not already done:\\n\\n```bash\\n# Install Homebrew (if not already installed)\\n/bin/bash -c \\"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\\"\\n\\n# Ensure you\'re using ARM64 architecture\\narch\\n# Should output: arm64\\n\\n# Install Nginx optimized for M4\\nbrew install nginx\\n\\n# Verify installation and architecture\\nfile $(brew --prefix)/bin/nginx\\n# Should show: Mach-O 64-bit executable arm64\\n\\n# Start Nginx with optimized settings for M4\\nbrew services start nginx\\n\\n# Check if running\\nbrew services list | grep nginx\\n```\\n\\n#### M4-Optimized Configuration\\n\\nFor optimal performance on M4 chips, consider these configuration adjustments:\\n\\n```nginx\\n# /opt/homebrew/etc/nginx/nginx.conf (M4 optimized)\\nuser _www;\\nworker_processes auto;  # M4 has efficient cores, auto-detection works well\\nerror_log /opt/homebrew/var/log/nginx/error.log;\\n\\nevents {\\n    worker_connections 2048;  # M4 can handle higher connections efficiently\\n    use kqueue;  # Optimal for macOS\\n    multi_accept on;\\n}\\n\\nhttp {\\n    include       mime.types;\\n    default_type  application/octet-stream;\\n    \\n    # M4 optimization settings\\n    sendfile on;\\n    tcp_nopush on;\\n    tcp_nodelay on;\\n    \\n    # Buffer sizes optimized for M4 memory bandwidth\\n    client_body_buffer_size 128k;\\n    client_max_body_size 10m;\\n    client_header_buffer_size 1k;\\n    large_client_header_buffers 4 4k;\\n    output_buffers 1 32k;\\n    postpone_output 1460;\\n    \\n    server {\\n        listen 8080;  # Default Homebrew port\\n        server_name localhost;\\n        root /opt/homebrew/var/www;\\n        index index.html index.htm;\\n        \\n        location / {\\n            try_files $uri $uri/ =404;\\n        }\\n    }\\n}\\n```\\n\\n#### Common M4 Considerations\\n\\n1. **File Paths**: Homebrew on M4 installs to `/opt/homebrew/` instead of `/usr/local/`\\n2. **Default Port**: Homebrew Nginx typically runs on port 8080 to avoid permission issues\\n3. **Process Management**: Use `brew services` for better integration with macOS\\n4. **Performance**: M4\'s efficiency cores handle Nginx\'s event-driven architecture exceptionally well\\n\\n```bash\\n# M4-specific paths\\nConfiguration: /opt/homebrew/etc/nginx/nginx.conf\\nDocument root: /opt/homebrew/var/www\\nError log: /opt/homebrew/var/log/nginx/error.log\\nAccess log: /opt/homebrew/var/log/nginx/access.log\\n```\\n\\n## Basic Configuration Structure\\n\\nNginx configuration is typically located at `/etc/nginx/nginx.conf` and follows a hierarchical structure:\\n\\n```nginx\\n# Main context\\nuser nginx;\\nworker_processes auto;\\nerror_log /var/log/nginx/error.log;\\n\\n# Events context\\nevents {\\n    worker_connections 1024;\\n}\\n\\n# HTTP context\\nhttp {\\n    include /etc/nginx/mime.types;\\n    default_type application/octet-stream;\\n    \\n    # Server context\\n    server {\\n        listen 80;\\n        server_name example.com;\\n        \\n        # Location context\\n        location / {\\n            root /var/www/html;\\n            index index.html;\\n        }\\n    }\\n}\\n```\\n\\n## Performance Optimization Tips\\n\\n### 1. Worker Processes\\nSet worker processes to match your CPU cores:\\n```nginx\\nworker_processes auto;\\n```\\n\\n### 2. Worker Connections\\nIncrease worker connections for high-traffic sites:\\n```nginx\\nevents {\\n    worker_connections 2048;\\n    use epoll; # Linux\\n    use kqueue; # macOS/BSD\\n}\\n```\\n\\n### 4. Gzip Compression\\nEnable compression to reduce bandwidth:\\n```nginx\\ngzip on;\\ngzip_vary on;\\ngzip_min_length 1024;\\ngzip_types text/plain text/css application/json application/javascript text/xml application/xml;\\n\\n# M4 optimization: Use higher compression for better CPU/bandwidth trade-off\\ngzip_comp_level 6;  # M4 can handle higher compression efficiently\\ngzip_proxied any;\\n```\\n\\n### 5. Browser Caching\\nSet appropriate cache headers:\\n```nginx\\nlocation ~* \\\\.(jpg|jpeg|png|gif|ico|css|js)$ {\\n    expires 1y;\\n    add_header Cache-Control \\"public, immutable\\";\\n}\\n```\\n\\n## Security Best Practices\\n\\n### 1. Hide Nginx Version\\n```nginx\\nserver_tokens off;\\n```\\n\\n### 2. Rate Limiting\\n```nginx\\n# Basic rate limiting by IP address\\nlimit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;\\n\\n# Rate limiting by user session (requires session ID)\\nlimit_req_zone $cookie_sessionid zone=session:10m rate=5r/s;\\n\\n# Rate limiting by server name (per domain)\\nlimit_req_zone $server_name zone=domain:10m rate=100r/s;\\n\\n# Rate limiting by request URI (specific endpoints)\\nlimit_req_zone $request_uri zone=endpoint:10m rate=2r/s;\\n\\n# Whitelist trusted IPs\\ngeo $limit {\\n    default 1;\\n    10.0.0.0/8 0;     # Internal network\\n    192.168.0.0/16 0; # Private network\\n    127.0.0.1/32 0;   # Localhost\\n}\\n\\nmap $limit $limit_key {\\n    0 \\"\\";\\n    1 $binary_remote_addr;\\n}\\n\\nlimit_req_zone $limit_key zone=trusted:10m rate=20r/s;\\n\\n# Different rate limits for different locations\\nlocation /api/ {\\n    limit_req zone=api burst=20 nodelay;\\n    limit_req_status 429;\\n    limit_req_log_level warn;\\n}\\n\\nlocation /login {\\n    # Stricter rate limiting for login attempts\\n    limit_req zone=api burst=5 nodelay;\\n    limit_req_status 429;\\n}\\n\\nlocation /search {\\n    # Higher burst for search with delay\\n    limit_req zone=api burst=50;\\n}\\n\\nlocation /upload {\\n    # Very strict rate limiting for uploads\\n    limit_req_zone $binary_remote_addr zone=upload:10m rate=1r/m;\\n    limit_req zone=upload burst=2;\\n}\\n\\nlocation /public/ {\\n    # Use trusted zone for public content\\n    limit_req zone=trusted burst=100 nodelay;\\n}\\n```\\n\\n#### Advanced Rate Limiting Configurations\\n\\n**Multiple Rate Limits**:\\n```nginx\\n# Apply multiple rate limits simultaneously\\nlocation /api/critical/ {\\n    limit_req zone=api burst=10 nodelay;\\n    limit_req zone=session burst=5 nodelay;\\n    limit_req zone=endpoint burst=2 nodelay;\\n}\\n```\\n\\n**Dynamic Rate Limiting Based on Response Status**:\\n```nginx\\n# Stricter limits after failed attempts\\nmap $status $loggable {\\n    ~^[23] 0;  # Don\'t log successful requests\\n    default 1;\\n}\\n\\nlimit_req_zone $binary_remote_addr zone=strict:10m rate=1r/s;\\n\\nlocation /api/auth {\\n    limit_req zone=api burst=10;\\n    \\n    # Apply stricter limits if previous requests failed\\n    if ($http_x_failed_attempts) {\\n        limit_req zone=strict burst=3;\\n    }\\n}\\n```\\n\\n**Rate Limiting with Custom Error Pages**:\\n```nginx\\n# Custom error page for rate limited requests\\nerror_page 429 /rate_limit.html;\\n\\nlocation = /rate_limit.html {\\n    root /var/www/error;\\n    internal;\\n    add_header Content-Type text/html;\\n    add_header Retry-After 60;\\n}\\n\\nlocation /api/ {\\n    limit_req zone=api burst=20 nodelay;\\n    limit_req_status 429;\\n}\\n```\\n\\n**Burst Control Strategies**:\\n```nginx\\n# No burst - strict limiting\\nlocation /strict-api/ {\\n    limit_req zone=api;\\n}\\n\\n# Burst with delay - smoother for users\\nlocation /smooth-api/ {\\n    limit_req zone=api burst=10;\\n}\\n\\n# Burst with nodelay - fast response but strict enforcement\\nlocation /fast-api/ {\\n    limit_req zone=api burst=10 nodelay;\\n}\\n```\\n\\n### 3. Security Headers\\n```nginx\\nadd_header X-Frame-Options \\"SAMEORIGIN\\" always;\\nadd_header X-XSS-Protection \\"1; mode=block\\" always;\\nadd_header X-Content-Type-Options \\"nosniff\\" always;\\nadd_header Referrer-Policy \\"no-referrer-when-downgrade\\" always;\\nadd_header Content-Security-Policy \\"default-src \'self\'\\" always;\\n```\\n\\n#### Comprehensive Security Headers Explained\\n\\n**X-Frame-Options** - Prevents Clickjacking Attacks:\\n```nginx\\n# DENY: Prevents any domain from framing the content\\nadd_header X-Frame-Options \\"DENY\\" always;\\n\\n# SAMEORIGIN: Only allows framing from the same origin\\nadd_header X-Frame-Options \\"SAMEORIGIN\\" always;\\n\\n# ALLOW-FROM: Allows framing from specific domains\\nadd_header X-Frame-Options \\"ALLOW-FROM https://trusted-site.com\\" always;\\n```\\n\\n**Content-Security-Policy (CSP)** - Prevents XSS and Data Injection:\\n```nginx\\n# Basic CSP - only allow resources from same origin\\nadd_header Content-Security-Policy \\"default-src \'self\'\\" always;\\n\\n# Advanced CSP for modern web applications\\nadd_header Content-Security-Policy \\"\\n    default-src \'self\';\\n    script-src \'self\' \'unsafe-inline\' https://cdn.jsdelivr.net https://ajax.googleapis.com;\\n    style-src \'self\' \'unsafe-inline\' https://fonts.googleapis.com;\\n    font-src \'self\' https://fonts.gstatic.com;\\n    img-src \'self\' data: https:;\\n    connect-src \'self\' https://api.example.com;\\n    frame-ancestors \'none\';\\n    base-uri \'self\';\\n    form-action \'self\';\\n    upgrade-insecure-requests;\\n\\" always;\\n\\n# CSP for Single Page Applications (React/Vue/Angular)\\nadd_header Content-Security-Policy \\"\\n    default-src \'self\';\\n    script-src \'self\' \'sha256-xyz123...\' \'unsafe-eval\';\\n    style-src \'self\' \'unsafe-inline\';\\n    img-src \'self\' data: blob: https:;\\n    font-src \'self\' data:;\\n    connect-src \'self\' wss: https:;\\n    worker-src \'self\' blob:;\\n\\" always;\\n```\\n\\n**Strict-Transport-Security (HSTS)** - Enforces HTTPS:\\n```nginx\\n# Basic HSTS - 1 year, include subdomains\\nadd_header Strict-Transport-Security \\"max-age=31536000; includeSubDomains\\" always;\\n\\n# HSTS with preload (for submission to browsers\' preload lists)\\nadd_header Strict-Transport-Security \\"max-age=31536000; includeSubDomains; preload\\" always;\\n\\n# Development/staging environment (shorter duration)\\nadd_header Strict-Transport-Security \\"max-age=300; includeSubDomains\\" always;\\n```\\n\\n**X-Content-Type-Options** - Prevents MIME Type Sniffing:\\n```nginx\\n# Prevents browsers from interpreting files as different MIME types\\nadd_header X-Content-Type-Options \\"nosniff\\" always;\\n```\\n\\n**Referrer-Policy** - Controls Referrer Information:\\n```nginx\\n# No referrer when protocol security is downgraded\\nadd_header Referrer-Policy \\"no-referrer-when-downgrade\\" always;\\n\\n# Strict referrer policy options\\nadd_header Referrer-Policy \\"strict-origin-when-cross-origin\\" always;\\nadd_header Referrer-Policy \\"same-origin\\" always;\\nadd_header Referrer-Policy \\"no-referrer\\" always;\\n\\n# Origin only (no path information)\\nadd_header Referrer-Policy \\"origin\\" always;\\n```\\n\\n**X-XSS-Protection** - Legacy XSS Protection:\\n```nginx\\n# Enable XSS filtering and block page rendering if attack detected\\nadd_header X-XSS-Protection \\"1; mode=block\\" always;\\n\\n# Note: This header is largely deprecated in favor of CSP\\n# Modern browsers rely on Content-Security-Policy instead\\n```\\n\\n**Permissions-Policy** - Controls Browser Features:\\n```nginx\\n# Disable potentially dangerous features\\nadd_header Permissions-Policy \\"\\n    camera=(),\\n    microphone=(),\\n    geolocation=(),\\n    payment=(),\\n    usb=(),\\n    magnetometer=(),\\n    gyroscope=(),\\n    speaker=()\\n\\" always;\\n\\n# Allow specific features for your domain only\\nadd_header Permissions-Policy \\"\\n    camera=(self),\\n    microphone=(self),\\n    geolocation=(self \'https://trusted-maps.com\'),\\n    payment=(self)\\n\\" always;\\n```\\n\\n**Cross-Origin-Embedder-Policy & Cross-Origin-Opener-Policy**:\\n```nginx\\n# Enable cross-origin isolation for advanced features\\nadd_header Cross-Origin-Embedder-Policy \\"require-corp\\" always;\\nadd_header Cross-Origin-Opener-Policy \\"same-origin\\" always;\\n\\n# More permissive options\\nadd_header Cross-Origin-Embedder-Policy \\"credentialless\\" always;\\nadd_header Cross-Origin-Opener-Policy \\"same-origin-allow-popups\\" always;\\n```\\n\\n#### Complete Security Headers Configuration\\n\\n**Production-Ready Security Headers Set**:\\n```nginx\\n# Complete security headers configuration\\nlocation / {\\n    # HSTS - Force HTTPS for 1 year\\n    add_header Strict-Transport-Security \\"max-age=31536000; includeSubDomains; preload\\" always;\\n    \\n    # Prevent clickjacking\\n    add_header X-Frame-Options \\"SAMEORIGIN\\" always;\\n    \\n    # Prevent MIME type sniffing\\n    add_header X-Content-Type-Options \\"nosniff\\" always;\\n    \\n    # Control referrer information\\n    add_header Referrer-Policy \\"strict-origin-when-cross-origin\\" always;\\n    \\n    # Comprehensive CSP\\n    add_header Content-Security-Policy \\"\\n        default-src \'self\';\\n        script-src \'self\' \'unsafe-inline\' https://cdn.jsdelivr.net;\\n        style-src \'self\' \'unsafe-inline\' https://fonts.googleapis.com;\\n        font-src \'self\' https://fonts.gstatic.com;\\n        img-src \'self\' data: https:;\\n        connect-src \'self\' https:;\\n        frame-ancestors \'none\';\\n        base-uri \'self\';\\n        form-action \'self\';\\n        upgrade-insecure-requests;\\n    \\" always;\\n    \\n    # Control browser features\\n    add_header Permissions-Policy \\"\\n        camera=(),\\n        microphone=(),\\n        geolocation=(),\\n        payment=(),\\n        usb=()\\n    \\" always;\\n    \\n    # Cross-origin policies\\n    add_header Cross-Origin-Embedder-Policy \\"credentialless\\" always;\\n    add_header Cross-Origin-Opener-Policy \\"same-origin-allow-popups\\" always;\\n    \\n    # Remove server information\\n    add_header X-Powered-By \\"\\" always;\\n    \\n    # Custom security headers\\n    add_header X-Robots-Tag \\"noindex, nofollow\\" always;  # For admin areas\\n    add_header Cache-Control \\"no-store, no-cache, must-revalidate\\" always;  # For sensitive pages\\n}\\n```\\n\\n#### Environment-Specific Configurations\\n\\n**Development Environment**:\\n```nginx\\n# Relaxed headers for development\\nadd_header Content-Security-Policy \\"\\n    default-src \'self\' \'unsafe-inline\' \'unsafe-eval\';\\n    connect-src \'self\' ws: wss: http: https:;\\n\\" always;\\n\\nadd_header Strict-Transport-Security \\"max-age=300\\" always;  # Short duration\\n```\\n\\n**API Endpoints**:\\n```nginx\\nlocation /api/ {\\n    # API-specific security headers\\n    add_header X-Content-Type-Options \\"nosniff\\" always;\\n    add_header X-Frame-Options \\"DENY\\" always;\\n    add_header Cache-Control \\"no-store\\" always;\\n    add_header Pragma \\"no-cache\\" always;\\n    \\n    # CORS headers (if needed)\\n    add_header Access-Control-Allow-Origin \\"https://yourdomain.com\\" always;\\n    add_header Access-Control-Allow-Methods \\"GET, POST, PUT, DELETE, OPTIONS\\" always;\\n    add_header Access-Control-Allow-Headers \\"Authorization, Content-Type\\" always;\\n    add_header Access-Control-Max-Age \\"86400\\" always;\\n}\\n```\\n\\n**Static Assets**:\\n```nginx\\nlocation ~* \\\\.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2)$ {\\n    # Relaxed CSP for static assets\\n    add_header Content-Security-Policy \\"default-src \'self\'\\" always;\\n    add_header Cache-Control \\"public, max-age=31536000, immutable\\" always;\\n    add_header X-Content-Type-Options \\"nosniff\\" always;\\n}\\n```\\n\\n#### Security Headers Testing and Validation\\n\\n**Tools for Testing Security Headers**:\\n- [Security Headers Scanner](https://securityheaders.com/)\\n- [Mozilla Observatory](https://observatory.mozilla.org/)\\n- [OWASP ZAP](https://owasp.org/www-project-zap/)\\n\\n**Common CSP Testing**:\\n```nginx\\n# Report-only mode for testing CSP before enforcement\\nadd_header Content-Security-Policy-Report-Only \\"\\n    default-src \'self\';\\n    report-uri /csp-report;\\n\\" always;\\n\\n# CSP violation reporting endpoint\\nlocation /csp-report {\\n    access_log /var/log/nginx/csp-violations.log;\\n    return 204;\\n}\\n```\\n\\n## Modern Web Development with Nginx\\n\\n### Microservices Architecture\\nNginx excels in microservices environments, routing requests to different services based on URL patterns:\\n\\n```nginx\\nlocation /auth/ {\\n    proxy_pass http://auth-service:3001/;\\n}\\n\\nlocation /users/ {\\n    proxy_pass http://user-service:3002/;\\n}\\n\\nlocation /orders/ {\\n    proxy_pass http://order-service:3003/;\\n}\\n```\\n\\n### API Gateway\\nUse Nginx as an API gateway for request routing, authentication, and rate limiting:\\n\\n```nginx\\nlocation /api/v1/ {\\n    auth_request /auth;\\n    proxy_pass http://api-backend/;\\n}\\n\\nlocation = /auth {\\n    internal;\\n    proxy_pass http://auth-service/verify;\\n    proxy_pass_request_body off;\\n    proxy_set_header Content-Length \\"\\";\\n    proxy_set_header X-Original-URI $request_uri;\\n}\\n```\\n\\n## Monitoring and Logging\\n\\n### Access Logs\\n```nginx\\nlog_format main \'$remote_addr - $remote_user [$time_local] \\"$request\\" \'\\n                \'$status $body_bytes_sent \\"$http_referer\\" \'\\n                \'\\"$http_user_agent\\" \\"$http_x_forwarded_for\\"\';\\n\\naccess_log /var/log/nginx/access.log main;\\n```\\n\\n### Error Logs\\n```nginx\\nerror_log /var/log/nginx/error.log warn;\\n```\\n\\n### Status Module\\nEnable the status module for monitoring:\\n```nginx\\nlocation /nginx_status {\\n    stub_status on;\\n    access_log off;\\n    allow 127.0.0.1;\\n    deny all;\\n}\\n```\\n\\n## Conclusion\\n\\nNginx has proven itself as an indispensable tool in modern web infrastructure. Its performance, flexibility, and rich feature set make it suitable for everything from simple static websites to complex, high-traffic applications. Whether you\'re serving static content, implementing a reverse proxy, or building a sophisticated load balancing solution, Nginx provides the tools and performance you need.\\n\\nAs web applications continue to evolve, Nginx remains at the forefront, adapting to new requirements while maintaining its core strengths: high performance, low resource usage, and exceptional reliability.\\n\\n## Further Reading\\n\\n- [Official Nginx Documentation](https://nginx.org/en/docs/)\\n- [Nginx Admin Guide](https://docs.nginx.com/nginx/admin-guide/)\\n- [Let\'s Encrypt with Nginx](https://certbot.eff.org/instructions?ws=nginx)\\n- [Nginx Performance Tuning](https://nginx.org/en/docs/http/ngx_http_core_module.html#optimization)\\n\\n---\\n\\n*Have you used Nginx in your projects? Share your experiences and configurations in the comments below!*"},{"id":"how-to-create-good-prompts","metadata":{"permalink":"/fullstack-dev/blog/how-to-create-good-prompts","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/prompt-engineer/2025-10-06-how-to-create-good-prompts.md","source":"@site/blog/prompt-engineer/2025-10-06-how-to-create-good-prompts.md","title":"The Art of Prompt Engineering: How to Create Effective Prompts for AI","description":"Prompt engineering has become one of the most crucial skills in the age of large language models (LLMs). Whether you\'re using ChatGPT, Gemini, Claude, or any other AI model, the quality of your prompts directly determines the quality of the responses you get. In this comprehensive guide, we\'ll explore the best practices for creating effective prompts that consistently deliver high-quality results.","date":"2025-10-06T00:00:00.000Z","tags":[{"inline":false,"label":"Prompt Engineering","permalink":"/fullstack-dev/blog/tags/prompt-engineering","description":"Prompt design and optimization"},{"inline":false,"label":"Artificial Intelligence","permalink":"/fullstack-dev/blog/tags/ai","description":"Artificial intelligence and AI applications"},{"inline":false,"label":"Large Language Models","permalink":"/fullstack-dev/blog/tags/llm","description":"Large language models and applications"},{"inline":false,"label":"Gemini","permalink":"/fullstack-dev/blog/tags/gemini","description":"Google Gemini AI model"},{"inline":false,"label":"Best Practices","permalink":"/fullstack-dev/blog/tags/best-practices","description":"Industry best practices and standards"},{"inline":false,"label":"Artificial Intelligence","permalink":"/fullstack-dev/blog/tags/artificial-intelligence","description":"AI technologies and applications"},{"inline":false,"label":"Machine Learning","permalink":"/fullstack-dev/blog/tags/machine-learning","description":"Machine learning and AI applications"}],"readingTime":8.56,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"how-to-create-good-prompts","title":"The Art of Prompt Engineering: How to Create Effective Prompts for AI","authors":["tam"],"tags":["prompt-engineering","ai","llm","gemini","best-practices","artificial-intelligence","machine-learning"]},"unlisted":false,"prevItem":{"title":"Nginx: The High-Performance Web Server and Reverse Proxy","permalink":"/fullstack-dev/blog/nginx-web-server-guide"},"nextItem":{"title":"Building an Interactive Tour Guide for New Features - Full-Stack Developer Guide","permalink":"/fullstack-dev/blog/building-interactive-tour-guide"}},"content":"Prompt engineering has become one of the most crucial skills in the age of large language models (LLMs). Whether you\'re using ChatGPT, Gemini, Claude, or any other AI model, the quality of your prompts directly determines the quality of the responses you get. In this comprehensive guide, we\'ll explore the best practices for creating effective prompts that consistently deliver high-quality results.\\n\\nUnderstanding how to craft good prompts is like learning to communicate effectively with a highly knowledgeable but literal-minded assistant. The better your instructions, the better the outcomes.\\n\\n\x3c!-- truncate --\x3e\\n\\n## What is Prompt Engineering?\\n\\nPrompt engineering is the practice of designing and optimizing text inputs (prompts) to elicit the best possible responses from AI language models. It\'s both an art and a science that involves understanding how these models interpret and respond to different types of instructions.\\n\\nThink of it as writing clear, specific instructions for a very capable but literal assistant. The assistant can perform complex tasks, but only if you communicate your needs effectively.\\n\\n## Why Good Prompts Matter\\n\\nThe difference between a poorly crafted prompt and a well-engineered one can be dramatic:\\n\\n- **Poor prompt**: \\"Tell me about Earth\\"\\n- **Good prompt**: \\"Generate a list of ways that makes Earth unique compared to other planets\\"\\n\\nThe first might give you a generic encyclopedia entry, while the second will provide focused, valuable insights tailored to your specific need.\\n\\n## Core Principles of Effective Prompt Engineering\\n\\n### 1. Be Concise\\n\\n**The Problem**: Verbose prompts introduce unnecessary noise that can confuse the model and dilute your intent.\\n\\n\u274c **Not Recommended**:\\n```\\nWhat do you think could be a good name for a flower shop that \\nspecializes in selling bouquets of dried flowers more than fresh flowers?\\n```\\n\\n\u2705 **Recommended**:\\n```\\nSuggest a name for a flower shop that sells bouquets of dried flowers\\n```\\n\\n**Why it works**: The concise version eliminates unnecessary words while preserving the core request. The model can focus on the essential task without getting distracted by conversational filler.\\n\\n### 2. Be Specific and Well-Defined\\n\\nVague prompts lead to vague responses. The more specific you are about what you want, the more targeted the response will be.\\n\\n\u274c **Too Generic**:\\n```\\nTell me about Earth\\n```\\n\\n\u2705 **Specific and Targeted**:\\n```\\nGenerate a list of ways that makes Earth unique compared to other planets\\n```\\n\\n**The difference**: The specific prompt gives the model a clear framework (comparison with other planets) and a specific output format (a list), resulting in a much more useful response.\\n\\n### 3. Ask One Task at a Time\\n\\nMulti-part questions often lead to incomplete or imbalanced responses where one part gets more attention than others.\\n\\n\u274c **Multiple Tasks**:\\n```\\nWhat\'s the best method of boiling water and why is the sky blue?\\n```\\n\\n\u2705 **Single Task**:\\n```\\nWhat\'s the best method of boiling water?\\n```\\n\\nThen separately:\\n```\\nWhy is the sky blue?\\n```\\n\\n**Benefits**: Single-task prompts ensure each question gets the full attention it deserves and produces more thorough, focused responses.\\n\\n## Advanced Techniques\\n\\n### Using System Instructions for Guardrails\\n\\nSystem instructions help prevent the AI from veering off-topic or providing inappropriate responses. They act as behavioral guidelines for the entire conversation.\\n\\n**Example Travel Chatbot System Instruction**:\\n```\\nYou are an AI chatbot for a travel website. Your mission is to provide \\nhelpful queries for travelers. Before answering any question, check if \\nit complies with your mission. If not, respond with \\"Sorry, I can\'t \\nanswer that question.\\"\\n```\\n\\nThis approach helps maintain focus and prevents the AI from responding to unrelated queries like cooking recipes when it should be helping with travel.\\n\\n### Turn Generative Tasks into Classification Tasks\\n\\nWhen you need more predictable, controlled outputs, convert open-ended questions into multiple-choice formats.\\n\\n\u274c **High Variability (Generative)**:\\n```\\nI\'m a high school student. Recommend me a programming activity to improve my skills.\\n```\\n\\n\u2705 **Lower Variability (Classification)**:\\n```\\nI\'m a high school student. Which of these activities do you suggest and why:\\na) learn Python\\nb) learn JavaScript  \\nc) learn Fortran\\n```\\n\\n**Why this works**: Classification tasks constrain the possible outputs, making responses more predictable and easier to process programmatically.\\n\\n## The Power of Examples: Zero-Shot vs Few-Shot Prompting\\n\\n### Zero-Shot Prompting\\n\\nZero-shot prompting provides no examples, relying entirely on the model\'s training to understand the task.\\n\\n**Example**:\\n```\\nDecide whether a Tweet\'s sentiment is positive, neutral, or negative.\\n\\nTweet: I loved the new YouTube video you made!\\nSentiment:\\n```\\n\\n### One-Shot Prompting\\n\\nOne-shot prompting provides a single example to guide the model\'s understanding.\\n\\n**Example**:\\n```\\nDecide whether a Tweet\'s sentiment is positive, neutral, or negative.\\n\\nTweet: I loved the new YouTube video you made!\\nSentiment: positive\\n\\nTweet: That was awful. Super boring \ud83d\ude20\\nSentiment:\\n```\\n\\n### Few-Shot Prompting\\n\\nFew-shot prompting provides multiple examples to establish a clear pattern.\\n\\n**Example**:\\n```\\nDecide whether a Tweet\'s sentiment is positive, neutral, or negative.\\n\\nTweet: I loved the new YouTube video you made!\\nSentiment: positive\\n\\nTweet: That was awful. Super boring \ud83d\ude20\\nSentiment: negative\\n\\nTweet: Something surprised me about this video - it was actually original. \\nIt was not the same old recycled stuff that I always see. Watch it - you will not regret it.\\nSentiment:\\n```\\n\\n### When to Use Each Approach\\n\\n- **Zero-shot**: When you want creative, open-ended responses\\n- **One-shot**: When you need to establish a basic pattern or format\\n- **Few-shot**: When you need consistent, predictable responses that follow a specific pattern\\n\\n## Dealing with Hallucinations\\n\\nAI models can generate confident-sounding but factually incorrect information, known as \\"hallucinations.\\" Here\'s how to minimize them:\\n\\n### 1. Be Aware of Knowledge Cutoffs\\n```\\n\u274c \\"What day is it today?\\"\\n\u2705 \\"What day of the week typically has the highest retail sales?\\"\\n```\\n\\n### 2. Ask for Uncertainty Acknowledgment\\n```\\n\u2705 \\"List the major causes of World War I. If you\'re uncertain about any point, please indicate that.\\"\\n```\\n\\n### 3. Request Sources (with caution)\\n```\\n\u2705 \\"Explain photosynthesis and indicate which parts are well-established science versus current research areas.\\"\\n```\\n\\n**Note**: Asking for citations doesn\'t eliminate hallucinations, as models can fabricate sources too.\\n\\n## Industry-Specific Prompt Patterns\\n\\n### For Code Generation\\n```\\nWrite a Python function that [specific task]. Include:\\n- Input validation\\n- Error handling  \\n- Type hints\\n- A docstring with usage examples\\n```\\n\\n### For Content Creation\\n```\\nWrite a [blog post/email/social media post] about [topic] that:\\n- Targets [specific audience]\\n- Has a [tone: professional/casual/friendly]\\n- Includes [specific elements]\\n- Is approximately [word count] words\\n```\\n\\n### For Data Analysis\\n```\\nAnalyze this data and provide:\\n1. Key trends and patterns\\n2. Notable outliers or anomalies  \\n3. Three actionable insights\\n4. Confidence level for each finding\\n\\n[Insert data]\\n```\\n\\n## Testing and Iterating Your Prompts\\n\\n### A/B Testing Approach\\n\\n1. **Create variations** of your prompt\\n2. **Test with the same input** multiple times\\n3. **Compare outputs** for consistency and quality\\n4. **Refine** based on results\\n\\n### Prompt Versioning\\n\\nKeep track of prompt variations and their performance:\\n\\n```\\nv1.0: \\"Summarize this article\\"\\nv1.1: \\"Summarize this article in 3 bullet points\\"  \\nv1.2: \\"Summarize this article in 3 bullet points, focusing on key actions and outcomes\\"\\n```\\n\\n## Common Prompt Engineering Mistakes\\n\\n### 1. Over-Engineering\\nDon\'t make prompts unnecessarily complex. Start simple and add complexity only when needed.\\n\\n### 2. Assuming Human Context\\nAI doesn\'t have access to your screen, previous conversations (unless explicitly provided), or real-time information.\\n\\n### 3. Ignoring Model Limitations\\nEach model has token limits, knowledge cutoffs, and specific strengths and weaknesses.\\n\\n### 4. Not Testing Edge Cases\\nTest your prompts with unusual inputs to understand their robustness.\\n\\n## Best Practices for Different Use Cases\\n\\n### Creative Writing\\n- Use open-ended prompts\\n- Provide style or tone guidance\\n- Include creative constraints for more interesting outputs\\n\\n### Technical Documentation\\n- Be extremely specific about format\\n- Include examples of desired output\\n- Specify technical level for the audience\\n\\n### Customer Service\\n- Use system instructions for brand voice\\n- Include escalation paths for complex issues\\n- Test with challenging customer scenarios\\n\\n### Data Processing\\n- Provide clear input/output format specifications\\n- Include error handling instructions\\n- Test with edge cases and malformed data\\n\\n## Measuring Prompt Effectiveness\\n\\n### Quantitative Metrics\\n- **Consistency**: How similar are responses to the same prompt?\\n- **Accuracy**: How often are factual claims correct?\\n- **Relevance**: How well does the output match the request?\\n- **Completeness**: Does the response address all parts of the prompt?\\n\\n### Qualitative Assessment\\n- **Usefulness**: Does the output solve your problem?\\n- **Clarity**: Is the response well-structured and understandable?\\n- **Tone**: Does it match your desired communication style?\\n\\n## Tools and Resources for Prompt Engineering\\n\\n### Prompt Libraries\\n- Keep successful prompts organized by use case\\n- Document what works and what doesn\'t\\n- Share effective prompts with your team\\n\\n### Testing Frameworks\\n- Use systematic approaches to test prompt variations\\n- Automate testing where possible\\n- Track performance over time\\n\\n### Community Resources\\n- Join prompt engineering communities\\n- Study examples from others in your field\\n- Contribute your own successful patterns\\n\\n## Future of Prompt Engineering\\n\\nAs AI models continue to evolve, prompt engineering techniques will also advance:\\n\\n### Emerging Trends\\n- **Multimodal prompts**: Combining text, images, and other media\\n- **Chain-of-thought prompting**: Breaking complex tasks into steps\\n- **Role-based prompting**: Having the AI adopt specific personas or expertise\\n- **Meta-prompting**: Using AI to help design better prompts\\n\\n### Skills to Develop\\n- Understanding model capabilities and limitations\\n- Systematic testing and evaluation methods\\n- Domain expertise to create relevant examples\\n- Communication skills for clear instruction writing\\n\\n## Conclusion\\n\\nEffective prompt engineering is a crucial skill in our AI-powered world. By following these best practices\u2014being concise, specific, and strategic about examples\u2014you can dramatically improve the quality and consistency of AI-generated responses.\\n\\nRemember that prompt engineering is both an art and a science. While these guidelines provide a solid foundation, the best prompts often come from experimentation, iteration, and deep understanding of your specific use case.\\n\\nKey takeaways:\\n- **Start simple** and add complexity gradually\\n- **Test thoroughly** with various inputs and edge cases\\n- **Use examples** strategically to guide model behavior\\n- **Be specific** about format, tone, and requirements\\n- **Consider the model\'s limitations** when designing prompts\\n- **Iterate based on results** rather than assuming first attempts are optimal\\n\\nAs AI models become more sophisticated, the ability to communicate effectively with them will only become more valuable. Master these prompt engineering fundamentals, and you\'ll be well-equipped to leverage AI tools effectively in whatever domain you work in.\\n\\n## Further Reading\\n\\n- [Google\'s Prompt Design Guidelines](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview)\\n- [OpenAI\'s Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\\n- [Anthropic\'s Prompt Engineering Guide](https://docs.anthropic.com/claude/docs/prompt-engineering)\\n- [Best Practices for Prompt Engineering with OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\\n\\n---\\n\\n*What prompt engineering techniques have worked best for you? Share your experiences and favorite patterns in the comments below!*"},{"id":"building-interactive-tour-guide","metadata":{"permalink":"/fullstack-dev/blog/building-interactive-tour-guide","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-05-interactive-tour-guide.md","source":"@site/blog/2025-10-05-interactive-tour-guide.md","title":"Building an Interactive Tour Guide for New Features - Full-Stack Developer Guide","description":"Creating an effective interactive tour guide is crucial for helping users discover and adopt new features in your application. A well-designed tour can significantly improve user onboarding, feature adoption rates, and overall user satisfaction. In this comprehensive guide, we\'ll explore how to build a flexible, accessible, and engaging tour system that can highlight new features and guide users through complex workflows.","date":"2025-10-05T00:00:00.000Z","tags":[{"inline":false,"label":"User Experience","permalink":"/fullstack-dev/blog/tags/user-experience","description":"UX design and user interaction patterns"},{"inline":false,"label":"React","permalink":"/fullstack-dev/blog/tags/react","description":"React framework and component development"},{"inline":false,"label":"TypeScript","permalink":"/fullstack-dev/blog/tags/typescript","description":"TypeScript language and type safety"},{"inline":false,"label":"Onboarding","permalink":"/fullstack-dev/blog/tags/onboarding","description":"User onboarding and introduction flows"},{"inline":false,"label":"Feature Discovery","permalink":"/fullstack-dev/blog/tags/feature-discovery","description":"Feature introduction and discovery techniques"},{"inline":false,"label":"Full Stack","permalink":"/fullstack-dev/blog/tags/full-stack","description":"Full stack development practices"}],"readingTime":27.63,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"building-interactive-tour-guide","title":"Building an Interactive Tour Guide for New Features - Full-Stack Developer Guide","authors":["tam"],"tags":["user-experience","react","typescript","onboarding","feature-discovery","full-stack"],"date":"2025-10-05T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"The Art of Prompt Engineering: How to Create Effective Prompts for AI","permalink":"/fullstack-dev/blog/how-to-create-good-prompts"},"nextItem":{"title":"Handling Rate Limiting in NestJS for Production Microservices","permalink":"/fullstack-dev/blog/nestjs-rate-limiting-microservices"}},"content":"Creating an effective interactive tour guide is crucial for helping users discover and adopt new features in your application. A well-designed tour can significantly improve user onboarding, feature adoption rates, and overall user satisfaction. In this comprehensive guide, we\'ll explore how to build a flexible, accessible, and engaging tour system that can highlight new features and guide users through complex workflows.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why Interactive Tours Matter\\n\\nBefore diving into implementation, let\'s understand why interactive tours are essential for modern applications:\\n\\n### \ud83d\udcc8 **Improved Feature Adoption**\\n- New features often go unnoticed without proper introduction\\n- Tours increase feature discovery by 40-60% on average\\n- Guided experiences reduce the learning curve for complex features\\n\\n### \ud83c\udfaf **Enhanced User Onboarding**\\n- Contextual guidance reduces user frustration\\n- Step-by-step walkthroughs improve task completion rates\\n- Personalized tours adapt to different user roles and experience levels\\n\\n### \ud83d\udca1 **Reduced Support Burden**\\n- Proactive guidance prevents common user questions\\n- Self-service learning reduces support ticket volume\\n- Interactive help is available exactly when needed\\n\\n## Tour System Architecture\\n\\nLet\'s build a tour system that\'s flexible, reusable, and easy to maintain. Our architecture will consist of several key components:\\n\\n```typescript\\n// Types for our tour system\\ninterface TourStep {\\n  id: string;\\n  target: string; // CSS selector or element ID\\n  title: string;\\n  content: string;\\n  placement?: \'top\' | \'bottom\' | \'left\' | \'right\' | \'center\';\\n  action?: \'click\' | \'hover\' | \'focus\' | \'none\';\\n  beforeShow?: () => Promise<void> | void;\\n  afterShow?: () => Promise<void> | void;\\n  beforeHide?: () => Promise<void> | void;\\n  skipable?: boolean;\\n  highlightPadding?: number;\\n  zIndex?: number;\\n}\\n\\ninterface Tour {\\n  id: string;\\n  name: string;\\n  description: string;\\n  steps: TourStep[];\\n  triggerConditions?: TriggerCondition[];\\n  userSegments?: string[];\\n  isActive: boolean;\\n  priority: number;\\n}\\n\\ninterface TourState {\\n  currentTour: Tour | null;\\n  currentStepIndex: number;\\n  isPlaying: boolean;\\n  completedTours: string[];\\n  skippedTours: string[];\\n}\\n```\\n\\n## Core Tour Engine Implementation\\n\\nLet\'s start with the main tour engine that will manage tour execution:\\n\\n```typescript\\n// hooks/useTourEngine.ts\\nimport { useState, useEffect, useCallback, useRef } from \'react\';\\nimport { useLocalStorage } from \'./useLocalStorage\';\\n\\nexport const useTourEngine = () => {\\n  const [tourState, setTourState] = useState<TourState>({\\n    currentTour: null,\\n    currentStepIndex: 0,\\n    isPlaying: false,\\n    completedTours: [],\\n    skippedTours: [],\\n  });\\n\\n  const [completedTours, setCompletedTours] = useLocalStorage<string[]>(\'tour-completed\', []);\\n  const [skippedTours, setSkippedTours] = useLocalStorage<string[]>(\'tour-skipped\', []);\\n  \\n  const overlayRef = useRef<HTMLDivElement | null>(null);\\n  const highlightRef = useRef<HTMLDivElement | null>(null);\\n\\n  // Start a tour\\n  const startTour = useCallback(async (tour: Tour) => {\\n    if (completedTours.includes(tour.id) || skippedTours.includes(tour.id)) {\\n      return;\\n    }\\n\\n    setTourState({\\n      currentTour: tour,\\n      currentStepIndex: 0,\\n      isPlaying: true,\\n      completedTours,\\n      skippedTours,\\n    });\\n\\n    // Execute beforeShow hook for first step\\n    if (tour.steps[0]?.beforeShow) {\\n      await tour.steps[0].beforeShow();\\n    }\\n  }, [completedTours, skippedTours]);\\n\\n  // Navigate to next step\\n  const nextStep = useCallback(async () => {\\n    if (!tourState.currentTour) return;\\n\\n    const currentStep = tourState.currentTour.steps[tourState.currentStepIndex];\\n    \\n    // Execute beforeHide hook\\n    if (currentStep?.beforeHide) {\\n      await currentStep.beforeHide();\\n    }\\n\\n    const nextIndex = tourState.currentStepIndex + 1;\\n    \\n    if (nextIndex >= tourState.currentTour.steps.length) {\\n      // Tour completed\\n      completeTour();\\n      return;\\n    }\\n\\n    setTourState(prev => ({\\n      ...prev,\\n      currentStepIndex: nextIndex,\\n    }));\\n\\n    // Execute beforeShow hook for next step\\n    const nextStep = tourState.currentTour.steps[nextIndex];\\n    if (nextStep?.beforeShow) {\\n      await nextStep.beforeShow();\\n    }\\n  }, [tourState]);\\n\\n  // Navigate to previous step\\n  const previousStep = useCallback(async () => {\\n    if (!tourState.currentTour || tourState.currentStepIndex === 0) return;\\n\\n    const currentStep = tourState.currentTour.steps[tourState.currentStepIndex];\\n    \\n    if (currentStep?.beforeHide) {\\n      await currentStep.beforeHide();\\n    }\\n\\n    const prevIndex = tourState.currentStepIndex - 1;\\n    setTourState(prev => ({\\n      ...prev,\\n      currentStepIndex: prevIndex,\\n    }));\\n\\n    const prevStep = tourState.currentTour.steps[prevIndex];\\n    if (prevStep?.beforeShow) {\\n      await prevStep.beforeShow();\\n    }\\n  }, [tourState]);\\n\\n  // Complete tour\\n  const completeTour = useCallback(() => {\\n    if (!tourState.currentTour) return;\\n\\n    const newCompleted = [...completedTours, tourState.currentTour.id];\\n    setCompletedTours(newCompleted);\\n    \\n    setTourState(prev => ({\\n      ...prev,\\n      currentTour: null,\\n      currentStepIndex: 0,\\n      isPlaying: false,\\n      completedTours: newCompleted,\\n    }));\\n  }, [tourState.currentTour, completedTours, setCompletedTours]);\\n\\n  // Skip tour\\n  const skipTour = useCallback(() => {\\n    if (!tourState.currentTour) return;\\n\\n    const newSkipped = [...skippedTours, tourState.currentTour.id];\\n    setSkippedTours(newSkipped);\\n    \\n    setTourState(prev => ({\\n      ...prev,\\n      currentTour: null,\\n      currentStepIndex: 0,\\n      isPlaying: false,\\n      skippedTours: newSkipped,\\n    }));\\n  }, [tourState.currentTour, skippedTours, setSkippedTours]);\\n\\n  // Get current step\\n  const getCurrentStep = useCallback((): TourStep | null => {\\n    if (!tourState.currentTour) return null;\\n    return tourState.currentTour.steps[tourState.currentStepIndex] || null;\\n  }, [tourState]);\\n\\n  return {\\n    tourState,\\n    startTour,\\n    nextStep,\\n    previousStep,\\n    completeTour,\\n    skipTour,\\n    getCurrentStep,\\n  };\\n};\\n```\\n\\n## Tour Overlay Component\\n\\nThe overlay component creates the spotlight effect and manages the visual presentation:\\n\\n```typescript\\n// components/TourOverlay/TourOverlay.tsx\\nimport React, { useEffect, useState, useRef } from \'react\';\\nimport { createPortal } from \'react-dom\';\\nimport { TourStep } from \'../../types/tour.types\';\\nimport { TourTooltip } from \'./TourTooltip\';\\n\\ninterface TourOverlayProps {\\n  step: TourStep;\\n  onNext: () => void;\\n  onPrevious: () => void;\\n  onSkip: () => void;\\n  onComplete: () => void;\\n  currentStepIndex: number;\\n  totalSteps: number;\\n  isFirstStep: boolean;\\n  isLastStep: boolean;\\n}\\n\\nexport const TourOverlay: React.FC<TourOverlayProps> = ({\\n  step,\\n  onNext,\\n  onPrevious,\\n  onSkip,\\n  onComplete,\\n  currentStepIndex,\\n  totalSteps,\\n  isFirstStep,\\n  isLastStep,\\n}) => {\\n  const [targetElement, setTargetElement] = useState<HTMLElement | null>(null);\\n  const [targetRect, setTargetRect] = useState<DOMRect | null>(null);\\n  const [tooltipPosition, setTooltipPosition] = useState({ x: 0, y: 0 });\\n  const overlayRef = useRef<HTMLDivElement>(null);\\n\\n  useEffect(() => {\\n    const element = document.querySelector(step.target) as HTMLElement;\\n    if (element) {\\n      setTargetElement(element);\\n      updatePositions(element);\\n      \\n      // Scroll element into view\\n      element.scrollIntoView({\\n        behavior: \'smooth\',\\n        block: \'center\',\\n        inline: \'center\',\\n      });\\n\\n      // Add highlight class to target element\\n      element.classList.add(\'tour-highlight\');\\n      \\n      // Execute step action\\n      if (step.action === \'click\') {\\n        element.click();\\n      } else if (step.action === \'focus\') {\\n        element.focus();\\n      } else if (step.action === \'hover\') {\\n        element.dispatchEvent(new MouseEvent(\'mouseenter\', { bubbles: true }));\\n      }\\n    }\\n\\n    return () => {\\n      if (element) {\\n        element.classList.remove(\'tour-highlight\');\\n      }\\n    };\\n  }, [step]);\\n\\n  useEffect(() => {\\n    const handleResize = () => {\\n      if (targetElement) {\\n        updatePositions(targetElement);\\n      }\\n    };\\n\\n    const handleScroll = () => {\\n      if (targetElement) {\\n        updatePositions(targetElement);\\n      }\\n    };\\n\\n    window.addEventListener(\'resize\', handleResize);\\n    window.addEventListener(\'scroll\', handleScroll, true);\\n\\n    return () => {\\n      window.removeEventListener(\'resize\', handleResize);\\n      window.removeEventListener(\'scroll\', handleScroll, true);\\n    };\\n  }, [targetElement]);\\n\\n  const updatePositions = (element: HTMLElement) => {\\n    const rect = element.getBoundingClientRect();\\n    setTargetRect(rect);\\n\\n    // Calculate tooltip position based on placement preference\\n    const placement = step.placement || \'bottom\';\\n    const padding = step.highlightPadding || 8;\\n    \\n    let tooltipX = 0;\\n    let tooltipY = 0;\\n\\n    switch (placement) {\\n      case \'top\':\\n        tooltipX = rect.left + rect.width / 2;\\n        tooltipY = rect.top - padding;\\n        break;\\n      case \'bottom\':\\n        tooltipX = rect.left + rect.width / 2;\\n        tooltipY = rect.bottom + padding;\\n        break;\\n      case \'left\':\\n        tooltipX = rect.left - padding;\\n        tooltipY = rect.top + rect.height / 2;\\n        break;\\n      case \'right\':\\n        tooltipX = rect.right + padding;\\n        tooltipY = rect.top + rect.height / 2;\\n        break;\\n      case \'center\':\\n        tooltipX = window.innerWidth / 2;\\n        tooltipY = window.innerHeight / 2;\\n        break;\\n    }\\n\\n    setTooltipPosition({ x: tooltipX, y: tooltipY });\\n  };\\n\\n  const handleKeyDown = (e: React.KeyboardEvent) => {\\n    switch (e.key) {\\n      case \'Escape\':\\n        onSkip();\\n        break;\\n      case \'ArrowRight\':\\n      case \'Enter\':\\n      case \' \':\\n        e.preventDefault();\\n        if (isLastStep) {\\n          onComplete();\\n        } else {\\n          onNext();\\n        }\\n        break;\\n      case \'ArrowLeft\':\\n        e.preventDefault();\\n        if (!isFirstStep) {\\n          onPrevious();\\n        }\\n        break;\\n    }\\n  };\\n\\n  if (!targetRect) return null;\\n\\n  const overlayStyle: React.CSSProperties = {\\n    position: \'fixed\',\\n    top: 0,\\n    left: 0,\\n    right: 0,\\n    bottom: 0,\\n    backgroundColor: \'rgba(0, 0, 0, 0.5)\',\\n    zIndex: step.zIndex || 1000,\\n    pointerEvents: \'auto\',\\n  };\\n\\n  const spotlightStyle: React.CSSProperties = {\\n    position: \'absolute\',\\n    top: targetRect.top - (step.highlightPadding || 8),\\n    left: targetRect.left - (step.highlightPadding || 8),\\n    width: targetRect.width + (step.highlightPadding || 8) * 2,\\n    height: targetRect.height + (step.highlightPadding || 8) * 2,\\n    boxShadow: `0 0 0 9999px rgba(0, 0, 0, 0.5)`,\\n    borderRadius: \'8px\',\\n    pointerEvents: \'none\',\\n  };\\n\\n  return createPortal(\\n    <div\\n      ref={overlayRef}\\n      style={overlayStyle}\\n      onKeyDown={handleKeyDown}\\n      tabIndex={-1}\\n      role=\\"dialog\\"\\n      aria-modal=\\"true\\"\\n      aria-labelledby=\\"tour-title\\"\\n      aria-describedby=\\"tour-content\\"\\n    >\\n      {/* Spotlight effect */}\\n      <div style={spotlightStyle} />\\n      \\n      {/* Tooltip */}\\n      <TourTooltip\\n        step={step}\\n        position={tooltipPosition}\\n        onNext={onNext}\\n        onPrevious={onPrevious}\\n        onSkip={onSkip}\\n        onComplete={onComplete}\\n        currentStepIndex={currentStepIndex}\\n        totalSteps={totalSteps}\\n        isFirstStep={isFirstStep}\\n        isLastStep={isLastStep}\\n        placement={step.placement || \'bottom\'}\\n      />\\n    </div>,\\n    document.body\\n  );\\n};\\n```\\n\\n## Tour Tooltip Component\\n\\nThe tooltip displays step content and navigation controls:\\n\\n```typescript\\n// components/TourOverlay/TourTooltip.tsx\\nimport React from \'react\';\\nimport { TourStep } from \'../../types/tour.types\';\\n\\ninterface TourTooltipProps {\\n  step: TourStep;\\n  position: { x: number; y: number };\\n  placement: \'top\' | \'bottom\' | \'left\' | \'right\' | \'center\';\\n  onNext: () => void;\\n  onPrevious: () => void;\\n  onSkip: () => void;\\n  onComplete: () => void;\\n  currentStepIndex: number;\\n  totalSteps: number;\\n  isFirstStep: boolean;\\n  isLastStep: boolean;\\n}\\n\\nexport const TourTooltip: React.FC<TourTooltipProps> = ({\\n  step,\\n  position,\\n  placement,\\n  onNext,\\n  onPrevious,\\n  onSkip,\\n  onComplete,\\n  currentStepIndex,\\n  totalSteps,\\n  isFirstStep,\\n  isLastStep,\\n}) => {\\n  const getTooltipStyle = (): React.CSSProperties => {\\n    const baseStyle: React.CSSProperties = {\\n      position: \'absolute\',\\n      backgroundColor: \'white\',\\n      borderRadius: \'12px\',\\n      padding: \'20px\',\\n      boxShadow: \'0 10px 40px rgba(0, 0, 0, 0.2)\',\\n      maxWidth: \'320px\',\\n      minWidth: \'280px\',\\n      zIndex: 1001,\\n      transform: getTransform(),\\n    };\\n\\n    return {\\n      ...baseStyle,\\n      left: position.x,\\n      top: position.y,\\n    };\\n  };\\n\\n  const getTransform = (): string => {\\n    switch (placement) {\\n      case \'top\':\\n        return \'translate(-50%, -100%)\';\\n      case \'bottom\':\\n        return \'translate(-50%, 0)\';\\n      case \'left\':\\n        return \'translate(-100%, -50%)\';\\n      case \'right\':\\n        return \'translate(0, -50%)\';\\n      case \'center\':\\n        return \'translate(-50%, -50%)\';\\n      default:\\n        return \'translate(-50%, 0)\';\\n    }\\n  };\\n\\n  const getArrowStyle = (): React.CSSProperties | null => {\\n    if (placement === \'center\') return null;\\n\\n    const baseArrow: React.CSSProperties = {\\n      position: \'absolute\',\\n      width: 0,\\n      height: 0,\\n      borderStyle: \'solid\',\\n    };\\n\\n    switch (placement) {\\n      case \'top\':\\n        return {\\n          ...baseArrow,\\n          bottom: \'-8px\',\\n          left: \'50%\',\\n          transform: \'translateX(-50%)\',\\n          borderWidth: \'8px 8px 0 8px\',\\n          borderColor: \'white transparent transparent transparent\',\\n        };\\n      case \'bottom\':\\n        return {\\n          ...baseArrow,\\n          top: \'-8px\',\\n          left: \'50%\',\\n          transform: \'translateX(-50%)\',\\n          borderWidth: \'0 8px 8px 8px\',\\n          borderColor: \'transparent transparent white transparent\',\\n        };\\n      case \'left\':\\n        return {\\n          ...baseArrow,\\n          right: \'-8px\',\\n          top: \'50%\',\\n          transform: \'translateY(-50%)\',\\n          borderWidth: \'8px 0 8px 8px\',\\n          borderColor: \'transparent transparent transparent white\',\\n        };\\n      case \'right\':\\n        return {\\n          ...baseArrow,\\n          left: \'-8px\',\\n          top: \'50%\',\\n          transform: \'translateY(-50%)\',\\n          borderWidth: \'8px 8px 8px 0\',\\n          borderColor: \'transparent white transparent transparent\',\\n        };\\n      default:\\n        return null;\\n    }\\n  };\\n\\n  return (\\n    <div style={getTooltipStyle()} className=\\"tour-tooltip\\">\\n      {/* Arrow */}\\n      {getArrowStyle() && <div style={getArrowStyle()!} />}\\n      \\n      {/* Header */}\\n      <div className=\\"tour-tooltip__header\\">\\n        <h3 id=\\"tour-title\\" className=\\"tour-tooltip__title\\">\\n          {step.title}\\n        </h3>\\n        <div className=\\"tour-tooltip__progress\\">\\n          <span className=\\"tour-tooltip__step-counter\\">\\n            {currentStepIndex + 1} of {totalSteps}\\n          </span>\\n          <div className=\\"tour-tooltip__progress-bar\\">\\n            <div\\n              className=\\"tour-tooltip__progress-fill\\"\\n              style={{\\n                width: `${((currentStepIndex + 1) / totalSteps) * 100}%`,\\n              }}\\n            />\\n          </div>\\n        </div>\\n      </div>\\n\\n      {/* Content */}\\n      <div\\n        id=\\"tour-content\\"\\n        className=\\"tour-tooltip__content\\"\\n        dangerouslySetInnerHTML={{ __html: step.content }}\\n      />\\n\\n      {/* Navigation */}\\n      <div className=\\"tour-tooltip__actions\\">\\n        <div className=\\"tour-tooltip__actions-left\\">\\n          {step.skipable !== false && (\\n            <button\\n              onClick={onSkip}\\n              className=\\"tour-button tour-button--secondary\\"\\n              type=\\"button\\"\\n            >\\n              Skip Tour\\n            </button>\\n          )}\\n        </div>\\n        \\n        <div className=\\"tour-tooltip__actions-right\\">\\n          {!isFirstStep && (\\n            <button\\n              onClick={onPrevious}\\n              className=\\"tour-button tour-button--secondary\\"\\n              type=\\"button\\"\\n            >\\n              Previous\\n            </button>\\n          )}\\n          \\n          <button\\n            onClick={isLastStep ? onComplete : onNext}\\n            className=\\"tour-button tour-button--primary\\"\\n            type=\\"button\\"\\n            autoFocus\\n          >\\n            {isLastStep ? \'Finish\' : \'Next\'}\\n          </button>\\n        </div>\\n      </div>\\n    </div>\\n  );\\n};\\n```\\n\\n## Tour Manager for Multiple Tours\\n\\nA tour manager handles multiple tours and their triggering conditions:\\n\\n```typescript\\n// hooks/useTourManager.ts\\nimport { useState, useEffect, useCallback } from \'react\';\\nimport { Tour, TriggerCondition } from \'../types/tour.types\';\\nimport { useTourEngine } from \'./useTourEngine\';\\n\\ninterface TourManagerConfig {\\n  tours: Tour[];\\n  autoStart?: boolean;\\n  debugMode?: boolean;\\n}\\n\\nexport const useTourManager = ({ tours, autoStart = true, debugMode = false }: TourManagerConfig) => {\\n  const [availableTours, setAvailableTours] = useState<Tour[]>([]);\\n  const tourEngine = useTourEngine();\\n\\n  // Evaluate tour trigger conditions\\n  const evaluateTriggerConditions = useCallback((conditions: TriggerCondition[]): boolean => {\\n    return conditions.every(condition => {\\n      switch (condition.type) {\\n        case \'url_match\':\\n          return window.location.pathname.includes(condition.value);\\n        \\n        case \'element_exists\':\\n          return document.querySelector(condition.value) !== null;\\n        \\n        case \'user_segment\':\\n          // This would typically check against user data from your auth system\\n          const userSegment = localStorage.getItem(\'user_segment\');\\n          return userSegment === condition.value;\\n        \\n        case \'feature_flag\':\\n          // Check if a feature flag is enabled\\n          const featureFlags = JSON.parse(localStorage.getItem(\'feature_flags\') || \'{}\');\\n          return featureFlags[condition.value] === true;\\n        \\n        case \'page_visit_count\':\\n          const visitCount = parseInt(localStorage.getItem(\'page_visit_count\') || \'0\');\\n          return visitCount >= parseInt(condition.value);\\n        \\n        case \'time_on_page\':\\n          // This would need to be implemented with a timer\\n          return true; // Simplified for example\\n        \\n        default:\\n          return false;\\n      }\\n    });\\n  }, []);\\n\\n  // Find eligible tours\\n  const findEligibleTours = useCallback((): Tour[] => {\\n    return tours.filter(tour => {\\n      // Skip if tour is not active\\n      if (!tour.isActive) return false;\\n      \\n      // Skip if already completed or skipped\\n      if (tourEngine.tourState.completedTours.includes(tour.id) || \\n          tourEngine.tourState.skippedTours.includes(tour.id)) {\\n        return false;\\n      }\\n      \\n      // Check trigger conditions\\n      if (tour.triggerConditions && tour.triggerConditions.length > 0) {\\n        return evaluateTriggerConditions(tour.triggerConditions);\\n      }\\n      \\n      return true;\\n    }).sort((a, b) => b.priority - a.priority); // Higher priority first\\n  }, [tours, tourEngine.tourState, evaluateTriggerConditions]);\\n\\n  // Auto-start eligible tours\\n  useEffect(() => {\\n    if (!autoStart || tourEngine.tourState.isPlaying) return;\\n\\n    const eligible = findEligibleTours();\\n    if (eligible.length > 0) {\\n      const nextTour = eligible[0];\\n      \\n      if (debugMode) {\\n        console.log(\'Starting tour:\', nextTour.name);\\n      }\\n      \\n      // Small delay to ensure page is fully loaded\\n      setTimeout(() => {\\n        tourEngine.startTour(nextTour);\\n      }, 500);\\n    }\\n  }, [findEligibleTours, autoStart, tourEngine, debugMode]);\\n\\n  // Manual tour starter\\n  const startTourById = useCallback((tourId: string) => {\\n    const tour = tours.find(t => t.id === tourId);\\n    if (tour) {\\n      tourEngine.startTour(tour);\\n    }\\n  }, [tours, tourEngine]);\\n\\n  // Reset tour state (useful for testing)\\n  const resetTourState = useCallback(() => {\\n    localStorage.removeItem(\'tour-completed\');\\n    localStorage.removeItem(\'tour-skipped\');\\n    window.location.reload();\\n  }, []);\\n\\n  return {\\n    ...tourEngine,\\n    availableTours: findEligibleTours(),\\n    startTourById,\\n    resetTourState,\\n  };\\n};\\n```\\n\\n## Tour Definitions and Configuration\\n\\nCreate tour definitions for your application features:\\n\\n```typescript\\n// data/tours.ts\\nexport const appTours: Tour[] = [\\n  {\\n    id: \'new-dashboard-features\',\\n    name: \'New Dashboard Features\',\\n    description: \'Discover the latest improvements to your dashboard\',\\n    priority: 10,\\n    isActive: true,\\n    triggerConditions: [\\n      { type: \'url_match\', value: \'/dashboard\' },\\n      { type: \'feature_flag\', value: \'new_dashboard_tour\' }\\n    ],\\n    steps: [\\n      {\\n        id: \'welcome\',\\n        target: \'body\',\\n        title: \'Welcome to Your Enhanced Dashboard! \ud83c\udf89\',\\n        content: `\\n          <p>We\'ve added some exciting new features to make your experience even better. \\n          Let\'s take a quick tour to show you what\'s new!</p>\\n          <p><strong>This tour will take about 2 minutes.</strong></p>\\n        `,\\n        placement: \'center\',\\n        skipable: true,\\n      },\\n      {\\n        id: \'analytics-widget\',\\n        target: \'[data-testid=\\"analytics-widget\\"]\',\\n        title: \'Enhanced Analytics Widget\',\\n        content: `\\n          <p>Your analytics widget now includes:</p>\\n          <ul>\\n            <li>\ud83d\udcca Real-time data updates</li>\\n            <li>\ud83c\udfaf Custom date range selection</li>\\n            <li>\ud83d\udcc8 Advanced filtering options</li>\\n          </ul>\\n          <p>Click on any chart to drill down into detailed metrics.</p>\\n        `,\\n        placement: \'bottom\',\\n        action: \'none\',\\n        beforeShow: async () => {\\n          // Ensure the analytics widget is visible\\n          const widget = document.querySelector(\'[data-testid=\\"analytics-widget\\"]\');\\n          if (widget) {\\n            widget.scrollIntoView({ behavior: \'smooth\', block: \'center\' });\\n          }\\n        },\\n      },\\n      {\\n        id: \'quick-actions\',\\n        target: \'[data-testid=\\"quick-actions\\"]\',\\n        title: \'New Quick Actions Bar\',\\n        content: `\\n          <p>Save time with our new quick actions bar:</p>\\n          <ul>\\n            <li>\u26a1 Create new items instantly</li>\\n            <li>\ud83d\udd0d Smart search with filters</li>\\n            <li>\ud83d\udd04 Bulk operations</li>\\n          </ul>\\n          <p>Try clicking the \\"+\\" button to see all available actions.</p>\\n        `,\\n        placement: \'bottom\',\\n        action: \'click\',\\n        beforeShow: async () => {\\n          // Highlight the quick actions area\\n          const element = document.querySelector(\'[data-testid=\\"quick-actions\\"]\');\\n          if (element) {\\n            element.classList.add(\'tour-pulse-animation\');\\n          }\\n        },\\n        afterShow: async () => {\\n          // Remove pulse animation after a delay\\n          setTimeout(() => {\\n            const element = document.querySelector(\'[data-testid=\\"quick-actions\\"]\');\\n            if (element) {\\n              element.classList.remove(\'tour-pulse-animation\');\\n            }\\n          }, 2000);\\n        },\\n      },\\n      {\\n        id: \'notification-center\',\\n        target: \'[data-testid=\\"notification-bell\\"]\',\\n        title: \'Improved Notification Center\',\\n        content: `\\n          <p>Stay updated with our enhanced notification system:</p>\\n          <ul>\\n            <li>\ud83d\udd14 Smart notification grouping</li>\\n            <li>\u2699\ufe0f Customizable notification preferences</li>\\n            <li>\ud83d\udcf1 Mobile push notifications</li>\\n          </ul>\\n          <p>Click the bell icon to see your notifications and manage your preferences.</p>\\n        `,\\n        placement: \'left\',\\n        highlightPadding: 12,\\n      },\\n      {\\n        id: \'user-menu\',\\n        target: \'[data-testid=\\"user-menu\\"]\',\\n        title: \'Enhanced User Menu\',\\n        content: `\\n          <p>We\'ve reorganized your user menu for better accessibility:</p>\\n          <ul>\\n            <li>\ud83d\udc64 Quick profile editing</li>\\n            <li>\ud83c\udfa8 Theme customization</li>\\n            <li>\ud83d\udd10 Enhanced security settings</li>\\n          </ul>\\n          <p>Access your account settings and preferences from here.</p>\\n        `,\\n        placement: \'left\',\\n      },\\n      {\\n        id: \'completion\',\\n        target: \'body\',\\n        title: \'Tour Complete! \ud83c\udf8a\',\\n        content: `\\n          <p>Congratulations! You\'ve discovered all the new features.</p>\\n          <p>Here are some helpful resources:</p>\\n          <ul>\\n            <li>\ud83d\udcda <a href=\\"/help\\" target=\\"_blank\\">Help Documentation</a></li>\\n            <li>\ud83d\udcac <a href=\\"/support\\" target=\\"_blank\\">Contact Support</a></li>\\n            <li>\ud83c\udfa5 <a href=\\"/tutorials\\" target=\\"_blank\\">Video Tutorials</a></li>\\n          </ul>\\n          <p><strong>Need to see this tour again?</strong><br>\\n          Go to Help \u2192 Feature Tours in your user menu.</p>\\n        `,\\n        placement: \'center\',\\n        skipable: false,\\n      },\\n    ],\\n  },\\n  \\n  {\\n    id: \'new-user-onboarding\',\\n    name: \'Getting Started\',\\n    description: \'Complete setup and learn the basics\',\\n    priority: 20,\\n    isActive: true,\\n    triggerConditions: [\\n      { type: \'user_segment\', value: \'new_user\' },\\n      { type: \'page_visit_count\', value: \'1\' }\\n    ],\\n    userSegments: [\'new_user\'],\\n    steps: [\\n      {\\n        id: \'welcome-new-user\',\\n        target: \'body\',\\n        title: \'Welcome to Our Platform! \ud83d\udc4b\',\\n        content: `\\n          <p>We\'re excited to have you on board! Let\'s get you set up for success.</p>\\n          <p>This quick tour will help you:</p>\\n          <ul>\\n            <li>Complete your profile setup</li>\\n            <li>Understand key features</li>\\n            <li>Know where to find help</li>\\n          </ul>\\n        `,\\n        placement: \'center\',\\n      },\\n      // Additional onboarding steps...\\n    ],\\n  },\\n];\\n\\n// Trigger conditions types\\nexport interface TriggerCondition {\\n  type: \'url_match\' | \'element_exists\' | \'user_segment\' | \'feature_flag\' | \'page_visit_count\' | \'time_on_page\';\\n  value: string;\\n  operator?: \'equals\' | \'contains\' | \'greater_than\' | \'less_than\';\\n}\\n```\\n\\n## Tour Styles and Animations\\n\\nAdd CSS for tour styling and animations:\\n\\n```css\\n/* styles/tour.css */\\n.tour-highlight {\\n  position: relative;\\n  z-index: 1001;\\n  pointer-events: auto;\\n}\\n\\n.tour-pulse-animation {\\n  animation: tourPulse 2s infinite;\\n}\\n\\n@keyframes tourPulse {\\n  0% {\\n    box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7);\\n  }\\n  70% {\\n    box-shadow: 0 0 0 10px rgba(59, 130, 246, 0);\\n  }\\n  100% {\\n    box-shadow: 0 0 0 0 rgba(59, 130, 246, 0);\\n  }\\n}\\n\\n.tour-tooltip {\\n  font-family: -apple-system, BlinkMacSystemFont, \'Segoe UI\', Roboto, sans-serif;\\n  color: #333;\\n  line-height: 1.5;\\n}\\n\\n.tour-tooltip__header {\\n  border-bottom: 1px solid #e5e7eb;\\n  padding-bottom: 16px;\\n  margin-bottom: 16px;\\n}\\n\\n.tour-tooltip__title {\\n  margin: 0 0 12px 0;\\n  font-size: 18px;\\n  font-weight: 600;\\n  color: #111827;\\n}\\n\\n.tour-tooltip__progress {\\n  display: flex;\\n  align-items: center;\\n  gap: 12px;\\n}\\n\\n.tour-tooltip__step-counter {\\n  font-size: 14px;\\n  color: #6b7280;\\n  white-space: nowrap;\\n}\\n\\n.tour-tooltip__progress-bar {\\n  flex: 1;\\n  height: 4px;\\n  background-color: #e5e7eb;\\n  border-radius: 2px;\\n  overflow: hidden;\\n}\\n\\n.tour-tooltip__progress-fill {\\n  height: 100%;\\n  background-color: #3b82f6;\\n  transition: width 0.3s ease;\\n}\\n\\n.tour-tooltip__content {\\n  margin-bottom: 20px;\\n  font-size: 14px;\\n  line-height: 1.6;\\n}\\n\\n.tour-tooltip__content ul {\\n  margin: 8px 0;\\n  padding-left: 20px;\\n}\\n\\n.tour-tooltip__content li {\\n  margin-bottom: 4px;\\n}\\n\\n.tour-tooltip__content a {\\n  color: #3b82f6;\\n  text-decoration: none;\\n}\\n\\n.tour-tooltip__content a:hover {\\n  text-decoration: underline;\\n}\\n\\n.tour-tooltip__actions {\\n  display: flex;\\n  justify-content: space-between;\\n  align-items: center;\\n  gap: 12px;\\n}\\n\\n.tour-tooltip__actions-left,\\n.tour-tooltip__actions-right {\\n  display: flex;\\n  gap: 8px;\\n}\\n\\n.tour-button {\\n  padding: 8px 16px;\\n  border-radius: 6px;\\n  font-size: 14px;\\n  font-weight: 500;\\n  cursor: pointer;\\n  transition: all 0.2s ease;\\n  border: none;\\n  outline: none;\\n}\\n\\n.tour-button:focus {\\n  outline: 2px solid #3b82f6;\\n  outline-offset: 2px;\\n}\\n\\n.tour-button--primary {\\n  background-color: #3b82f6;\\n  color: white;\\n}\\n\\n.tour-button--primary:hover {\\n  background-color: #2563eb;\\n}\\n\\n.tour-button--secondary {\\n  background-color: #f3f4f6;\\n  color: #374151;\\n  border: 1px solid #d1d5db;\\n}\\n\\n.tour-button--secondary:hover {\\n  background-color: #e5e7eb;\\n}\\n\\n/* Dark mode support */\\n@media (prefers-color-scheme: dark) {\\n  .tour-tooltip {\\n    background-color: #1f2937;\\n    color: #f9fafb;\\n  }\\n  \\n  .tour-tooltip__title {\\n    color: #f9fafb;\\n  }\\n  \\n  .tour-tooltip__header {\\n    border-color: #374151;\\n  }\\n  \\n  .tour-button--secondary {\\n    background-color: #374151;\\n    color: #f9fafb;\\n    border-color: #4b5563;\\n  }\\n  \\n  .tour-button--secondary:hover {\\n    background-color: #4b5563;\\n  }\\n}\\n\\n/* Responsive design */\\n@media (max-width: 640px) {\\n  .tour-tooltip {\\n    max-width: calc(100vw - 32px);\\n    min-width: calc(100vw - 32px);\\n    padding: 16px;\\n  }\\n  \\n  .tour-tooltip__actions {\\n    flex-direction: column;\\n  }\\n  \\n  .tour-tooltip__actions-left,\\n  .tour-tooltip__actions-right {\\n    width: 100%;\\n    justify-content: center;\\n  }\\n}\\n\\n/* Accessibility improvements */\\n.tour-overlay[role=\\"dialog\\"] {\\n  outline: none;\\n}\\n\\n.tour-button:focus-visible {\\n  outline: 2px solid #3b82f6;\\n  outline-offset: 2px;\\n}\\n\\n/* Animation for tour entrance */\\n.tour-tooltip {\\n  animation: tourTooltipEnter 0.3s ease-out;\\n}\\n\\n@keyframes tourTooltipEnter {\\n  from {\\n    opacity: 0;\\n    transform: scale(0.95) translate(-50%, 10px);\\n  }\\n  to {\\n    opacity: 1;\\n    transform: scale(1) translate(-50%, 0);\\n  }\\n}\\n```\\n\\n## Integration with Your App\\n\\nHere\'s how to integrate the tour system into your main application:\\n\\n```typescript\\n// App.tsx\\nimport React from \'react\';\\nimport { TourProvider } from \'./contexts/TourContext\';\\nimport { TourOverlay } from \'./components/TourOverlay/TourOverlay\';\\nimport { useTourManager } from \'./hooks/useTourManager\';\\nimport { appTours } from \'./data/tours\';\\nimport \'./styles/tour.css\';\\n\\nconst TourWrapper: React.FC<{ children: React.ReactNode }> = ({ children }) => {\\n  const tourManager = useTourManager({\\n    tours: appTours,\\n    autoStart: true,\\n    debugMode: process.env.NODE_ENV === \'development\',\\n  });\\n\\n  const currentStep = tourManager.getCurrentStep();\\n\\n  return (\\n    <>\\n      {children}\\n      \\n      {/* Render tour overlay when active */}\\n      {tourManager.tourState.isPlaying && currentStep && (\\n        <TourOverlay\\n          step={currentStep}\\n          onNext={tourManager.nextStep}\\n          onPrevious={tourManager.previousStep}\\n          onSkip={tourManager.skipTour}\\n          onComplete={tourManager.completeTour}\\n          currentStepIndex={tourManager.tourState.currentStepIndex}\\n          totalSteps={tourManager.tourState.currentTour?.steps.length || 0}\\n          isFirstStep={tourManager.tourState.currentStepIndex === 0}\\n          isLastStep={\\n            tourManager.tourState.currentStepIndex === \\n            (tourManager.tourState.currentTour?.steps.length || 0) - 1\\n          }\\n        />\\n      )}\\n      \\n      {/* Debug panel for development */}\\n      {process.env.NODE_ENV === \'development\' && (\\n        <TourDebugPanel tourManager={tourManager} />\\n      )}\\n    </>\\n  );\\n};\\n\\nconst App: React.FC = () => {\\n  return (\\n    <TourWrapper>\\n      <YourAppContent />\\n    </TourWrapper>\\n  );\\n};\\n\\nexport default App;\\n```\\n\\n## Open Source Solutions\\n\\nWhile building a custom tour system gives you complete control, there are excellent open source libraries that can accelerate development. Here are the most popular and well-maintained options:\\n\\n### 1. Intro.js - The Classic Choice\\n\\n**Intro.js** is one of the most popular and mature tour libraries with excellent browser support.\\n\\n```bash\\nnpm install intro.js\\nnpm install @types/intro.js  # For TypeScript support\\n```\\n\\n**Basic Implementation:**\\n```typescript\\n// components/IntroJsTour.tsx\\nimport React, { useEffect } from \'react\';\\nimport { introJs } from \'intro.js\';\\nimport \'intro.js/introjs.css\';\\nimport \'intro.js/themes/introjs-modern.css\'; // Optional theme\\n\\ninterface IntroTourProps {\\n  steps: Array<{\\n    element: string;\\n    title: string;\\n    intro: string;\\n    position?: \'top\' | \'bottom\' | \'left\' | \'right\';\\n  }>;\\n  onComplete?: () => void;\\n  onExit?: () => void;\\n  autoStart?: boolean;\\n}\\n\\nexport const IntroJsTour: React.FC<IntroTourProps> = ({\\n  steps,\\n  onComplete,\\n  onExit,\\n  autoStart = true,\\n}) => {\\n  useEffect(() => {\\n    if (!autoStart) return;\\n\\n    // Add data attributes to elements\\n    steps.forEach((step, index) => {\\n      const element = document.querySelector(step.element);\\n      if (element) {\\n        element.setAttribute(\'data-intro\', step.intro);\\n        element.setAttribute(\'data-step\', (index + 1).toString());\\n        element.setAttribute(\'data-title\', step.title);\\n        if (step.position) {\\n          element.setAttribute(\'data-position\', step.position);\\n        }\\n      }\\n    });\\n\\n    // Configure and start tour\\n    const intro = introJs();\\n    \\n    intro.setOptions({\\n      nextLabel: \'Next \u2192\',\\n      prevLabel: \'\u2190 Previous\',\\n      skipLabel: \'Skip Tour\',\\n      doneLabel: \'Finish\',\\n      showProgress: true,\\n      showBullets: false,\\n      exitOnOverlayClick: false,\\n      keyboardNavigation: true,\\n      disableInteraction: false,\\n    });\\n\\n    intro.oncomplete(() => {\\n      onComplete?.();\\n    });\\n\\n    intro.onexit(() => {\\n      onExit?.();\\n    });\\n\\n    intro.start();\\n\\n    return () => {\\n      intro.exit();\\n    };\\n  }, [steps, onComplete, onExit, autoStart]);\\n\\n  return null; // This component doesn\'t render anything\\n};\\n\\n// Usage example\\nconst DashboardWithTour = () => {\\n  const tourSteps = [\\n    {\\n      element: \'[data-testid=\\"analytics-widget\\"]\',\\n      title: \'Enhanced Analytics\',\\n      intro: \'Your new analytics dashboard with real-time updates and advanced filtering.\',\\n      position: \'bottom\' as const,\\n    },\\n    {\\n      element: \'[data-testid=\\"quick-actions\\"]\',\\n      title: \'Quick Actions\',\\n      intro: \'Access frequently used actions instantly from this new toolbar.\',\\n      position: \'bottom\' as const,\\n    },\\n    {\\n      element: \'[data-testid=\\"notification-bell\\"]\',\\n      title: \'Smart Notifications\',\\n      intro: \'Get organized notifications with smart grouping and custom preferences.\',\\n      position: \'left\' as const,\\n    },\\n  ];\\n\\n  const handleTourComplete = () => {\\n    localStorage.setItem(\'dashboard-tour-completed\', \'true\');\\n    console.log(\'Tour completed!\');\\n  };\\n\\n  return (\\n    <div>\\n      <IntroJsTour \\n        steps={tourSteps}\\n        onComplete={handleTourComplete}\\n        autoStart={!localStorage.getItem(\'dashboard-tour-completed\')}\\n      />\\n      {/* Your dashboard content */}\\n    </div>\\n  );\\n};\\n```\\n\\n**Advanced Intro.js Configuration:**\\n```typescript\\n// utils/tourConfig.ts\\nimport { introJs } from \'intro.js\';\\n\\nexport const createAdvancedTour = (config: {\\n  steps: any[];\\n  onProgress?: (stepIndex: number) => void;\\n  onBeforeChange?: (targetElement: Element) => void;\\n}) => {\\n  const intro = introJs();\\n\\n  intro.setOptions({\\n    nextLabel: \'Next \u2192\',\\n    prevLabel: \'\u2190 Previous\',\\n    skipLabel: \'Skip Tour\',\\n    doneLabel: \'Got it!\',\\n    showProgress: true,\\n    progressBarAdditionalClass: \'custom-progress\',\\n    highlightClass: \'custom-highlight\',\\n    showBullets: false,\\n    exitOnOverlayClick: false,\\n    keyboardNavigation: true,\\n    disableInteraction: false,\\n    scrollToElement: true,\\n    scrollPadding: 30,\\n    overlayOpacity: 0.7,\\n    tooltipClass: \'custom-tooltip\',\\n  });\\n\\n  // Progress tracking\\n  intro.onbeforechange((targetElement) => {\\n    config.onBeforeChange?.(targetElement);\\n    \\n    // Add custom animations\\n    targetElement.classList.add(\'tour-highlight-pulse\');\\n    setTimeout(() => {\\n      targetElement.classList.remove(\'tour-highlight-pulse\');\\n    }, 1000);\\n  });\\n\\n  intro.onchange((targetElement) => {\\n    const currentStep = intro._currentStep;\\n    config.onProgress?.(currentStep);\\n    \\n    // Track analytics\\n    if (typeof gtag !== \'undefined\') {\\n      gtag(\'event\', \'tour_step_view\', {\\n        step_number: currentStep + 1,\\n        step_element: targetElement.getAttribute(\'data-testid\') || \'unknown\',\\n      });\\n    }\\n  });\\n\\n  return intro;\\n};\\n\\n// Custom CSS for enhanced styling\\nconst customTourStyles = `\\n.custom-tooltip {\\n  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\\n  border-radius: 12px;\\n  box-shadow: 0 20px 40px rgba(0,0,0,0.1);\\n}\\n\\n.custom-progress {\\n  background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);\\n  height: 4px;\\n}\\n\\n.custom-highlight {\\n  box-shadow: 0 0 30px rgba(102, 126, 234, 0.6);\\n  border-radius: 8px;\\n}\\n\\n.tour-highlight-pulse {\\n  animation: tourPulse 1s ease-in-out;\\n}\\n\\n@keyframes tourPulse {\\n  0%, 100% { transform: scale(1); }\\n  50% { transform: scale(1.05); }\\n}\\n`;\\n```\\n\\n### 2. Reactour - React-First Approach\\n\\n**Reactour** is specifically designed for React applications with hooks and modern patterns.\\n\\n```bash\\nnpm install @reactour/tour\\nnpm install @reactour/mask\\nnpm install @reactour/popover\\n```\\n\\n**Implementation:**\\n```typescript\\n// components/ReactourTour.tsx\\nimport React from \'react\';\\nimport { TourProvider, useTour } from \'@reactour/tour\';\\nimport { Mask } from \'@reactour/mask\';\\nimport { Popover, PopoverContent } from \'@reactour/popover\';\\n\\nconst TourContent: React.FC<{\\n  currentStep: number;\\n  steps: any[];\\n  setCurrentStep: (step: number) => void;\\n  setIsOpen: (isOpen: boolean) => void;\\n}> = ({ currentStep, steps, setCurrentStep, setIsOpen }) => {\\n  const isLastStep = currentStep === steps.length - 1;\\n  const isFirstStep = currentStep === 0;\\n\\n  return (\\n    <PopoverContent>\\n      <div className=\\"tour-content\\">\\n        <div className=\\"tour-header\\">\\n          <h3>{steps[currentStep]?.title}</h3>\\n          <span className=\\"tour-progress\\">\\n            {currentStep + 1} of {steps.length}\\n          </span>\\n        </div>\\n        \\n        <div className=\\"tour-body\\">\\n          {steps[currentStep]?.content}\\n        </div>\\n        \\n        <div className=\\"tour-actions\\">\\n          <button \\n            onClick={() => setIsOpen(false)}\\n            className=\\"tour-btn tour-btn--secondary\\"\\n          >\\n            Skip\\n          </button>\\n          \\n          <div className=\\"tour-navigation\\">\\n            {!isFirstStep && (\\n              <button\\n                onClick={() => setCurrentStep(currentStep - 1)}\\n                className=\\"tour-btn tour-btn--secondary\\"\\n              >\\n                Previous\\n              </button>\\n            )}\\n            \\n            <button\\n              onClick={() => {\\n                if (isLastStep) {\\n                  setIsOpen(false);\\n                } else {\\n                  setCurrentStep(currentStep + 1);\\n                }\\n              }}\\n              className=\\"tour-btn tour-btn--primary\\"\\n            >\\n              {isLastStep ? \'Finish\' : \'Next\'}\\n            </button>\\n          </div>\\n        </div>\\n      </div>\\n    </PopoverContent>\\n  );\\n};\\n\\nexport const ReactourTourProvider: React.FC<{\\n  children: React.ReactNode;\\n  steps: Array<{\\n    selector: string;\\n    title: string;\\n    content: React.ReactNode;\\n    position?: [number, number];\\n    action?: (elem: Element) => void;\\n  }>;\\n}> = ({ children, steps }) => {\\n  return (\\n    <TourProvider\\n      steps={steps}\\n      components={{\\n        Mask: Mask,\\n        Popover: ({ children, ...props }) => (\\n          <Popover {...props}>\\n            {children}\\n          </Popover>\\n        ),\\n        Content: TourContent,\\n      }}\\n      styles={{\\n        popover: (base) => ({\\n          ...base,\\n          \'--reactour-accent\': \'#3b82f6\',\\n          borderRadius: 12,\\n          backgroundColor: \'white\',\\n          boxShadow: \'0 20px 40px rgba(0,0,0,0.15)\',\\n        }),\\n        mask: (base) => ({\\n          ...base,\\n          color: \'rgba(0, 0, 0, 0.7)\',\\n        }),\\n      }}\\n      onClickMask={({ setIsOpen }) => setIsOpen(false)}\\n      showCloseButton={false}\\n      showNavigation={false}\\n      showBadge={false}\\n    >\\n      {children}\\n    </TourProvider>\\n  );\\n};\\n\\n// Hook for controlling tour\\nexport const useTourControl = () => {\\n  const { setIsOpen, currentStep, setCurrentStep, isOpen } = useTour();\\n  \\n  const startTour = () => {\\n    setCurrentStep(0);\\n    setIsOpen(true);\\n  };\\n  \\n  const endTour = () => {\\n    setIsOpen(false);\\n  };\\n  \\n  return {\\n    startTour,\\n    endTour,\\n    isActive: isOpen,\\n    currentStep,\\n  };\\n};\\n\\n// Usage\\nconst App = () => {\\n  const tourSteps = [\\n    {\\n      selector: \'[data-tour=\\"welcome\\"]\',\\n      title: \'Welcome! \ud83d\udc4b\',\\n      content: (\\n        <div>\\n          <p>Let\'s take a quick tour of the new features!</p>\\n          <ul>\\n            <li>Enhanced analytics</li>\\n            <li>Quick actions</li>\\n            <li>Smart notifications</li>\\n          </ul>\\n        </div>\\n      ),\\n    },\\n    {\\n      selector: \'[data-tour=\\"analytics\\"]\',\\n      title: \'Analytics Dashboard\',\\n      content: (\\n        <div>\\n          <p>Your new analytics dashboard includes:</p>\\n          <ul>\\n            <li>\ud83d\udcca Real-time data</li>\\n            <li>\ud83c\udfaf Custom filters</li>\\n            <li>\ud83d\udcc8 Trend analysis</li>\\n          </ul>\\n        </div>\\n      ),\\n      action: (elem) => {\\n        // Trigger any actions when this step is reached\\n        elem.classList.add(\'highlight-pulse\');\\n      },\\n    },\\n  ];\\n\\n  return (\\n    <ReactourTourProvider steps={tourSteps}>\\n      <YourAppContent />\\n    </ReactourTourProvider>\\n  );\\n};\\n```\\n\\n### 3. Shepherd.js - Framework Agnostic\\n\\n**Shepherd.js** works with any framework and provides excellent customization options.\\n\\n```bash\\nnpm install shepherd.js\\n```\\n\\n**Implementation:**\\n```typescript\\n// utils/shepherdTour.ts\\nimport Shepherd from \'shepherd.js\';\\nimport \'shepherd.js/dist/css/shepherd.css\';\\n\\nexport class ShepherdTourManager {\\n  private tour: Shepherd.Tour;\\n  private onComplete?: () => void;\\n\\n  constructor(onComplete?: () => void) {\\n    this.onComplete = onComplete;\\n    this.tour = new Shepherd.Tour({\\n      useModalOverlay: true,\\n      defaultStepOptions: {\\n        classes: \'shepherd-theme-custom\',\\n        scrollTo: true,\\n        cancelIcon: {\\n          enabled: true,\\n        },\\n        when: {\\n          show: this.onStepShow.bind(this),\\n          hide: this.onStepHide.bind(this),\\n        },\\n      },\\n    });\\n\\n    this.tour.on(\'complete\', () => {\\n      this.onComplete?.();\\n    });\\n  }\\n\\n  private onStepShow() {\\n    // Add custom behavior when step shows\\n    const currentStep = this.tour.getCurrentStep();\\n    if (currentStep) {\\n      // Track analytics\\n      this.trackStepView(currentStep.id || \'unknown\');\\n    }\\n  }\\n\\n  private onStepHide() {\\n    // Cleanup when step hides\\n  }\\n\\n  private trackStepView(stepId: string) {\\n    if (typeof gtag !== \'undefined\') {\\n      gtag(\'event\', \'tour_step_view\', {\\n        step_id: stepId,\\n        tour_name: \'dashboard_features\',\\n      });\\n    }\\n  }\\n\\n  addStep(step: {\\n    id: string;\\n    title: string;\\n    text: string;\\n    attachTo: {\\n      element: string;\\n      on: \'top\' | \'bottom\' | \'left\' | \'right\';\\n    };\\n    buttons?: Array<{\\n      text: string;\\n      action: () => void;\\n      classes?: string;\\n    }>;\\n    beforeShowPromise?: () => Promise<void>;\\n  }) {\\n    this.tour.addStep({\\n      id: step.id,\\n      title: step.title,\\n      text: step.text,\\n      attachTo: step.attachTo,\\n      buttons: step.buttons || [\\n        {\\n          text: \'Skip\',\\n          classes: \'shepherd-button-secondary\',\\n          action: () => this.tour.complete(),\\n        },\\n        {\\n          text: \'Next\',\\n          classes: \'shepherd-button-primary\',\\n          action: () => this.tour.next(),\\n        },\\n      ],\\n      beforeShowPromise: step.beforeShowPromise,\\n    });\\n  }\\n\\n  start() {\\n    this.tour.start();\\n  }\\n\\n  complete() {\\n    this.tour.complete();\\n  }\\n}\\n\\n// React Hook wrapper\\nimport { useEffect, useRef } from \'react\';\\n\\nexport const useShepherdTour = (steps: any[], autoStart = false) => {\\n  const tourRef = useRef<ShepherdTourManager | null>(null);\\n\\n  useEffect(() => {\\n    tourRef.current = new ShepherdTourManager(() => {\\n      localStorage.setItem(\'tour-completed\', \'true\');\\n    });\\n\\n    // Add all steps\\n    steps.forEach(step => {\\n      tourRef.current!.addStep(step);\\n    });\\n\\n    if (autoStart && !localStorage.getItem(\'tour-completed\')) {\\n      tourRef.current.start();\\n    }\\n\\n    return () => {\\n      if (tourRef.current) {\\n        tourRef.current.complete();\\n      }\\n    };\\n  }, [steps, autoStart]);\\n\\n  const startTour = () => {\\n    tourRef.current?.start();\\n  };\\n\\n  const completeTour = () => {\\n    tourRef.current?.complete();\\n  };\\n\\n  return { startTour, completeTour };\\n};\\n\\n// Usage in React component\\nconst DashboardWithShepherd = () => {\\n  const tourSteps = [\\n    {\\n      id: \'welcome\',\\n      title: \'Welcome to the New Dashboard! \ud83c\udf89\',\\n      text: `\\n        <p>We\'ve added some exciting new features. Let\'s take a quick tour!</p>\\n        <div class=\\"tour-features\\">\\n          <span class=\\"feature-badge\\">\ud83d\udcca Enhanced Analytics</span>\\n          <span class=\\"feature-badge\\">\u26a1 Quick Actions</span>\\n          <span class=\\"feature-badge\\">\ud83d\udd14 Smart Notifications</span>\\n        </div>\\n      `,\\n      attachTo: {\\n        element: \'body\',\\n        on: \'top\' as const,\\n      },\\n    },\\n    {\\n      id: \'analytics\',\\n      title: \'Enhanced Analytics Widget\',\\n      text: `\\n        <p>Your analytics now include:</p>\\n        <ul>\\n          <li>\ud83d\udcca Real-time data updates</li>\\n          <li>\ud83c\udfaf Custom date range selection</li>\\n          <li>\ud83d\udcc8 Advanced filtering options</li>\\n        </ul>\\n        <p>Click any chart to drill down into detailed metrics.</p>\\n      `,\\n      attachTo: {\\n        element: \'[data-testid=\\"analytics-widget\\"]\',\\n        on: \'bottom\' as const,\\n      },\\n      beforeShowPromise: () => {\\n        return new Promise(resolve => {\\n          // Ensure element is visible before showing step\\n          const element = document.querySelector(\'[data-testid=\\"analytics-widget\\"]\');\\n          if (element) {\\n            element.scrollIntoView({ behavior: \'smooth\', block: \'center\' });\\n            setTimeout(resolve, 500);\\n          } else {\\n            resolve();\\n          }\\n        });\\n      },\\n    },\\n  ];\\n\\n  const { startTour } = useShepherdTour(tourSteps, true);\\n\\n  return (\\n    <div>\\n      <button onClick={startTour} className=\\"start-tour-btn\\">\\n        Take a Tour\\n      </button>\\n      {/* Your dashboard content */}\\n    </div>\\n  );\\n};\\n```\\n\\n### 4. Driver.js - Lightweight and Modern\\n\\n**Driver.js** is a lightweight, modern library with great performance.\\n\\n```bash\\nnpm install driver.js\\n```\\n\\n**Implementation:**\\n```typescript\\n// utils/driverTour.ts\\nimport { driver, DriveStep } from \'driver.js\';\\nimport \'driver.js/dist/driver.css\';\\n\\nexport class DriverTourManager {\\n  private driverObj: any;\\n\\n  constructor(config?: {\\n    onHighlightStarted?: (element: Element, step: DriveStep) => void;\\n    onHighlighted?: (element: Element, step: DriveStep) => void;\\n    onDeselected?: (element: Element, step: DriveStep) => void;\\n    onDestroyed?: () => void;\\n  }) {\\n    this.driverObj = driver({\\n      showProgress: true,\\n      showButtons: [\'next\', \'previous\', \'close\'],\\n      steps: [], // Will be populated later\\n      onHighlightStarted: config?.onHighlightStarted,\\n      onHighlighted: config?.onHighlighted,\\n      onDeselected: config?.onDeselected,\\n      onDestroyed: config?.onDestroyed,\\n    });\\n  }\\n\\n  setSteps(steps: DriveStep[]) {\\n    this.driverObj.setSteps(steps);\\n  }\\n\\n  start() {\\n    this.driverObj.drive();\\n  }\\n\\n  destroy() {\\n    this.driverObj.destroy();\\n  }\\n\\n  highlight(element: string) {\\n    this.driverObj.highlight({\\n      element,\\n      popover: {\\n        title: \'Highlighted Feature\',\\n        description: \'This is an important feature to note.\',\\n      },\\n    });\\n  }\\n}\\n\\n// React Hook\\nexport const useDriverTour = () => {\\n  const [tourManager] = useState(() => new DriverTourManager({\\n    onDestroyed: () => {\\n      localStorage.setItem(\'driver-tour-completed\', \'true\');\\n    },\\n    onHighlighted: (element, step) => {\\n      // Add pulse animation\\n      element.classList.add(\'driver-highlighted\');\\n      \\n      // Track step view\\n      if (typeof gtag !== \'undefined\') {\\n        gtag(\'event\', \'tour_step_view\', {\\n          step_index: step.element,\\n          tour_type: \'driver_js\',\\n        });\\n      }\\n    },\\n    onDeselected: (element) => {\\n      element.classList.remove(\'driver-highlighted\');\\n    },\\n  }));\\n\\n  const startTour = (steps: DriveStep[]) => {\\n    tourManager.setSteps(steps);\\n    tourManager.start();\\n  };\\n\\n  const highlightElement = (element: string) => {\\n    tourManager.highlight(element);\\n  };\\n\\n  return { startTour, highlightElement, destroy: () => tourManager.destroy() };\\n};\\n\\n// Component usage\\nconst FeatureTour = () => {\\n  const { startTour } = useDriverTour();\\n\\n  const tourSteps: DriveStep[] = [\\n    {\\n      element: \'body\',\\n      popover: {\\n        title: \'Welcome to the Enhanced Dashboard! \ud83d\ude80\',\\n        description: `\\n          <div class=\\"tour-welcome\\">\\n            <p>Discover our latest features that will boost your productivity:</p>\\n            <div class=\\"feature-grid\\">\\n              <div class=\\"feature-item\\">\\n                <span class=\\"feature-icon\\">\ud83d\udcca</span>\\n                <span>Real-time Analytics</span>\\n              </div>\\n              <div class=\\"feature-item\\">\\n                <span class=\\"feature-icon\\">\u26a1</span>\\n                <span>Quick Actions</span>\\n              </div>\\n              <div class=\\"feature-item\\">\\n                <span class=\\"feature-icon\\">\ud83d\udd14</span>\\n                <span>Smart Notifications</span>\\n              </div>\\n            </div>\\n          </div>\\n        `,\\n        side: \'bottom\',\\n        align: \'center\',\\n      },\\n    },\\n    {\\n      element: \'[data-testid=\\"analytics-widget\\"]\',\\n      popover: {\\n        title: \'\ud83d\udcca Enhanced Analytics\',\\n        description: `\\n          <p>Your analytics dashboard now features:</p>\\n          <ul class=\\"feature-list\\">\\n            <li>\u2728 Real-time data streaming</li>\\n            <li>\ud83c\udfaf Advanced filtering and segmentation</li>\\n            <li>\ud83d\udcc8 Predictive trend analysis</li>\\n            <li>\ud83d\udcca Custom dashboard creation</li>\\n          </ul>\\n          <div class=\\"tour-tip\\">\\n            \ud83d\udca1 <strong>Pro tip:</strong> Click any chart to drill down into detailed metrics!\\n          </div>\\n        `,\\n        side: \'bottom\',\\n        align: \'start\',\\n      },\\n    },\\n    {\\n      element: \'[data-testid=\\"quick-actions\\"]\',\\n      popover: {\\n        title: \'\u26a1 Quick Actions Toolbar\',\\n        description: `\\n          <p>Save time with instant access to common tasks:</p>\\n          <div class=\\"action-showcase\\">\\n            <div class=\\"action-item\\">\\n              <span class=\\"action-icon\\">\u2795</span>\\n              <span>Create new items</span>\\n            </div>\\n            <div class=\\"action-item\\">\\n              <span class=\\"action-icon\\">\ud83d\udd0d</span>\\n              <span>Smart search & filter</span>\\n            </div>\\n            <div class=\\"action-item\\">\\n              <span class=\\"action-icon\\">\ud83d\udd04</span>\\n              <span>Bulk operations</span>\\n            </div>\\n          </div>\\n        `,\\n        side: \'bottom\',\\n        align: \'center\',\\n      },\\n    },\\n  ];\\n\\n  useEffect(() => {\\n    // Auto-start tour for new users\\n    const hasSeenTour = localStorage.getItem(\'driver-tour-completed\');\\n    if (!hasSeenTour) {\\n      setTimeout(() => startTour(tourSteps), 1000);\\n    }\\n  }, []);\\n\\n  return (\\n    <button \\n      onClick={() => startTour(tourSteps)}\\n      className=\\"tour-trigger-btn\\"\\n    >\\n      \ud83c\udfaf Take Feature Tour\\n    </button>\\n  );\\n};\\n```\\n\\n### Library Comparison and Recommendations\\n\\n| Library | Bundle Size | React Integration | Customization | TypeScript | Best For |\\n|---------|-------------|-------------------|---------------|------------|----------|\\n| **Intro.js** | ~20KB | Good | High | Partial | Traditional web apps, maximum browser support |\\n| **Reactour** | ~15KB | Excellent | High | Excellent | React-first projects, modern styling |\\n| **Shepherd.js** | ~25KB | Good | Very High | Good | Complex tours, framework agnostic |\\n| **Driver.js** | ~12KB | Good | Medium | Good | Lightweight tours, performance-critical apps |\\n\\n### Choosing the Right Library\\n\\n**Use Intro.js when:**\\n- You need maximum browser compatibility\\n- Working with legacy codebases\\n- Want extensive documentation and community support\\n- Need proven stability in production\\n\\n**Use Reactour when:**\\n- Building React applications\\n- Want modern hooks-based API\\n- Need excellent TypeScript support\\n- Prefer component-based architecture\\n\\n**Use Shepherd.js when:**\\n- Need maximum customization flexibility\\n- Building complex, multi-step workflows\\n- Working with multiple frameworks\\n- Want advanced tour features (branching, conditionals)\\n\\n**Use Driver.js when:**\\n- Bundle size is critical\\n- Need simple, straightforward tours\\n- Want modern, clean API\\n- Performance is a priority\\n\\n### Hybrid Approach: Combining Libraries\\n\\nYou can also combine libraries for different use cases:\\n\\n```typescript\\n// tourStrategy.ts\\nimport { TourLibrary, TourStep } from \'./types\';\\n\\nexport class TourStrategy {\\n  private getOptimalLibrary(steps: TourStep[], context: any): TourLibrary {\\n    // Use lightweight library for simple tours\\n    if (steps.length <= 3 && !context.needsCustomization) {\\n      return \'driver\';\\n    }\\n    \\n    // Use React-specific library for component-heavy tours\\n    if (context.isReactApp && steps.some(s => s.hasReactContent)) {\\n      return \'reactour\';\\n    }\\n    \\n    // Use Shepherd for complex business workflows\\n    if (steps.length > 8 || context.needsBranching) {\\n      return \'shepherd\';\\n    }\\n    \\n    // Default to Intro.js for compatibility\\n    return \'introjs\';\\n  }\\n\\n  async createTour(steps: TourStep[], context: any) {\\n    const library = this.getOptimalLibrary(steps, context);\\n    \\n    switch (library) {\\n      case \'driver\':\\n        const { DriverTourManager } = await import(\'./drivers/driverTour\');\\n        return new DriverTourManager();\\n      \\n      case \'reactour\':\\n        const { ReactourManager } = await import(\'./drivers/reactourTour\');\\n        return new ReactourManager();\\n      \\n      case \'shepherd\':\\n        const { ShepherdTourManager } = await import(\'./drivers/shepherdTour\');\\n        return new ShepherdTourManager();\\n      \\n      default:\\n        const { IntroJsManager } = await import(\'./drivers/introJsTour\');\\n        return new IntroJsManager();\\n    }\\n  }\\n}\\n```\\n\\n### Quick Start Templates\\n\\nHere are ready-to-use templates for each library:\\n\\n**Intro.js Quick Start:**\\n```bash\\n# Install\\nnpm install intro.js @types/intro.js\\n\\n# Add to your component\\nimport { introJs } from \'intro.js\';\\nimport \'intro.js/introjs.css\';\\n\\n// Initialize tour\\nconst startTour = () => {\\n  introJs().setOptions({\\n    steps: [\\n      {\\n        element: \'#step1\',\\n        intro: \'This is your first feature!\',\\n        title: \'Welcome\'\\n      }\\n    ]\\n  }).start();\\n};\\n```\\n\\n**Reactour Quick Start:**\\n```bash\\n# Install\\nnpm install @reactour/tour @reactour/mask @reactour/popover\\n\\n# Wrap your app\\nimport { TourProvider } from \'@reactour/tour\';\\n\\nconst steps = [\\n  { selector: \'#step1\', content: \'Welcome to our app!\' }\\n];\\n\\n<TourProvider steps={steps}>\\n  <App />\\n</TourProvider>\\n```\\n\\n**Shepherd.js Quick Start:**\\n```bash\\n# Install\\nnpm install shepherd.js\\n\\n# Create tour\\nimport Shepherd from \'shepherd.js\';\\n\\nconst tour = new Shepherd.Tour({\\n  defaultStepOptions: { scrollTo: true }\\n});\\n\\ntour.addStep({\\n  title: \'Welcome!\',\\n  text: \'This is your first step\',\\n  attachTo: { element: \'#step1\', on: \'bottom\' }\\n});\\n\\ntour.start();\\n```\\n\\n**Driver.js Quick Start:**\\n```bash\\n# Install\\nnpm install driver.js\\n\\n# Create tour\\nimport { driver } from \'driver.js\';\\n\\nconst driverObj = driver({\\n  steps: [\\n    { element: \'#step1\', popover: { title: \'Title\', description: \'Description\' } }\\n  ]\\n});\\n\\ndriverObj.drive();\\n```\\n\\n## Advanced Features\\n\\n### Analytics Integration\\n\\nTrack tour performance and user engagement:\\n\\n```typescript\\n// utils/tourAnalytics.ts\\ninterface TourAnalyticsEvent {\\n  tourId: string;\\n  stepId: string;\\n  action: \'start\' | \'next\' | \'previous\' | \'skip\' | \'complete\';\\n  timestamp: number;\\n  userSegment?: string;\\n}\\n\\nexport class TourAnalytics {\\n  private events: TourAnalyticsEvent[] = [];\\n\\n  trackEvent(event: Omit<TourAnalyticsEvent, \'timestamp\'>) {\\n    const fullEvent: TourAnalyticsEvent = {\\n      ...event,\\n      timestamp: Date.now(),\\n    };\\n    \\n    this.events.push(fullEvent);\\n    \\n    // Send to your analytics service\\n    this.sendToAnalytics(fullEvent);\\n  }\\n\\n  private sendToAnalytics(event: TourAnalyticsEvent) {\\n    // Integration with your analytics platform\\n    if (typeof window !== \'undefined\' && (window as any).gtag) {\\n      (window as any).gtag(\'event\', \'tour_interaction\', {\\n        tour_id: event.tourId,\\n        step_id: event.stepId,\\n        action: event.action,\\n        user_segment: event.userSegment,\\n      });\\n    }\\n    \\n    // Or send to your custom analytics endpoint\\n    fetch(\'/api/analytics/tour-events\', {\\n      method: \'POST\',\\n      headers: { \'Content-Type\': \'application/json\' },\\n      body: JSON.stringify(event),\\n    }).catch(console.error);\\n  }\\n\\n  getTourMetrics(tourId: string) {\\n    const tourEvents = this.events.filter(e => e.tourId === tourId);\\n    const startEvents = tourEvents.filter(e => e.action === \'start\');\\n    const completeEvents = tourEvents.filter(e => e.action === \'complete\');\\n    const skipEvents = tourEvents.filter(e => e.action === \'skip\');\\n    \\n    return {\\n      starts: startEvents.length,\\n      completions: completeEvents.length,\\n      skips: skipEvents.length,\\n      completionRate: startEvents.length > 0 ? completeEvents.length / startEvents.length : 0,\\n      skipRate: startEvents.length > 0 ? skipEvents.length / startEvents.length : 0,\\n    };\\n  }\\n}\\n```\\n\\n### A/B Testing Support\\n\\nTest different tour variations:\\n\\n```typescript\\n// utils/tourVariants.ts\\ninterface TourVariant {\\n  id: string;\\n  name: string;\\n  tour: Tour;\\n  weight: number; // Percentage allocation\\n}\\n\\nexport class TourVariantManager {\\n  private variants: Map<string, TourVariant[]> = new Map();\\n\\n  addVariant(baseTrackId: string, variant: TourVariant) {\\n    if (!this.variants.has(baseTrackId)) {\\n      this.variants.set(baseTrackId, []);\\n    }\\n    this.variants.get(baseTrackId)!.push(variant);\\n  }\\n\\n  getVariantForUser(baseTrackId: string, userId: string): Tour | null {\\n    const variants = this.variants.get(baseTrackId);\\n    if (!variants || variants.length === 0) return null;\\n\\n    // Use consistent hash of user ID for stable variant assignment\\n    const hash = this.hashString(userId + baseTrackId);\\n    const totalWeight = variants.reduce((sum, v) => sum + v.weight, 0);\\n    const target = (hash % 100) / 100 * totalWeight;\\n    \\n    let cumulative = 0;\\n    for (const variant of variants) {\\n      cumulative += variant.weight;\\n      if (target <= cumulative) {\\n        return variant.tour;\\n      }\\n    }\\n    \\n    return variants[0].tour; // Fallback\\n  }\\n\\n  private hashString(str: string): number {\\n    let hash = 0;\\n    for (let i = 0; i < str.length; i++) {\\n      const char = str.charCodeAt(i);\\n      hash = ((hash << 5) - hash) + char;\\n      hash = hash & hash; // Convert to 32-bit integer\\n    }\\n    return Math.abs(hash);\\n  }\\n}\\n```\\n\\n## Best Practices and Tips\\n\\n### \ud83c\udfaf **Content Guidelines**\\n\\n1. **Keep it concise**: Limit steps to 5-7 for optimal engagement\\n2. **Use progressive disclosure**: Start with overview, then dive into specifics\\n3. **Include visuals**: Use emojis and bullet points for better readability\\n4. **Provide context**: Explain the \\"why\\" behind features, not just the \\"how\\"\\n\\n### \ud83d\udd27 **Technical Considerations**\\n\\n1. **Performance**: Use lazy loading for tour components\\n2. **Accessibility**: Ensure keyboard navigation and screen reader compatibility\\n3. **Mobile responsiveness**: Test tours on different screen sizes\\n4. **Error handling**: Gracefully handle missing target elements\\n\\n### \ud83d\udcca **Measurement and Optimization**\\n\\n1. **Track completion rates**: Monitor which steps cause dropoffs\\n2. **Gather feedback**: Add optional feedback collection at tour end\\n3. **A/B testing**: Test different content and flows\\n4. **Timing**: Experiment with when tours are triggered\\n\\n### \ud83c\udfa8 **Design Principles**\\n\\n1. **Non-intrusive**: Allow users to continue working while touring\\n2. **Contextual**: Show tours when users encounter relevant features\\n3. **Skippable**: Always provide an easy exit option\\n4. **Memorable**: Use consistent styling that matches your brand\\n\\n## Conclusion\\n\\nInteractive tour guides are powerful tools for improving user onboarding and feature adoption. By implementing a flexible, well-designed tour system, you can:\\n\\n- **Reduce time to value** for new users\\n- **Increase feature adoption** for existing users\\n- **Decrease support burden** through proactive guidance\\n- **Improve user satisfaction** with contextual help\\n\\nThe tour system we\'ve built provides a solid foundation that can be extended with additional features like:\\n\\n- **Multi-step forms guidance**\\n- **Video integration**\\n- **Branching tour paths**\\n- **Personalized content based on user behavior**\\n- **Integration with help desk systems**\\n\\nRemember to continuously gather user feedback and iterate on your tour content and timing. The best tours feel helpful rather than intrusive, and they evolve based on real user needs and behaviors.\\n\\nStart with simple tours for your most important features, measure their effectiveness, and gradually expand your tour system as you learn what works best for your users and application.\\n\\n---\\n\\n*Want to learn more about user experience optimization? This guide provides a solid foundation for building interactive user experiences that enhance feature discovery and adoption.*"},{"id":"nestjs-rate-limiting-microservices","metadata":{"permalink":"/fullstack-dev/blog/nestjs-rate-limiting-microservices","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-05-nestjs-rate-limiting-microservices.md","source":"@site/blog/2025-10-05-nestjs-rate-limiting-microservices.md","title":"Handling Rate Limiting in NestJS for Production Microservices","description":"Rate limiting is a critical security and performance mechanism in production microservice architectures. It protects your services from abuse, ensures fair resource allocation, and maintains system stability under high load. In this comprehensive guide, we\'ll explore how to implement robust, scalable rate limiting in NestJS applications designed for microservice environments.","date":"2025-10-05T00:00:00.000Z","tags":[{"inline":false,"label":"NestJS","permalink":"/fullstack-dev/blog/tags/nestjs","description":"NestJS framework for Node.js applications"},{"inline":false,"label":"Microservices","permalink":"/fullstack-dev/blog/tags/microservices","description":"Microservices architecture and patterns"},{"inline":false,"label":"Rate Limiting","permalink":"/fullstack-dev/blog/tags/rate-limiting","description":"Rate limiting and throttling techniques"},{"inline":false,"label":"Security","permalink":"/fullstack-dev/blog/tags/security","description":"Application security practices"},{"inline":false,"label":"Performance","permalink":"/fullstack-dev/blog/tags/performance","description":"Performance optimization techniques"},{"inline":false,"label":"Redis","permalink":"/fullstack-dev/blog/tags/redis","description":"Redis caching and data storage"},{"inline":false,"label":"Production","permalink":"/fullstack-dev/blog/tags/production","description":"Production-ready development and deployment"}],"readingTime":25.63,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"nestjs-rate-limiting-microservices","title":"Handling Rate Limiting in NestJS for Production Microservices","authors":["tam"],"tags":["nestjs","microservices","rate-limiting","security","performance","redis","production"],"date":"2025-10-05T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Building an Interactive Tour Guide for New Features - Full-Stack Developer Guide","permalink":"/fullstack-dev/blog/building-interactive-tour-guide"},"nextItem":{"title":"Elasticsearch Full-Text Search Setup","permalink":"/fullstack-dev/blog/ELASTICSEARCH_SETUP"}},"content":"Rate limiting is a critical security and performance mechanism in production microservice architectures. It protects your services from abuse, ensures fair resource allocation, and maintains system stability under high load. In this comprehensive guide, we\'ll explore how to implement robust, scalable rate limiting in NestJS applications designed for microservice environments.\\n\\n\x3c!--truncate--\x3e\\n\\n## Why Rate Limiting is Critical in Microservices\\n\\n### \ud83d\udee1\ufe0f **Security Benefits**\\n- **DDoS Protection**: Prevents overwhelming individual services with excessive requests\\n- **API Abuse Prevention**: Stops malicious actors from exhausting system resources\\n- **Brute Force Attack Mitigation**: Limits login attempts and sensitive operations\\n- **Resource Protection**: Ensures no single client can monopolize service capacity\\n\\n### \u26a1 **Performance Benefits**\\n- **Fair Resource Allocation**: Ensures all users get equitable access to services\\n- **Cascade Failure Prevention**: Prevents one overloaded service from affecting others\\n- **Cost Control**: Manages computational and bandwidth costs in cloud environments\\n- **SLA Compliance**: Helps maintain service level agreements under varying loads\\n\\n### \ud83c\udfd7\ufe0f **Microservice-Specific Challenges**\\n- **Distributed State Management**: Rate limits must work across multiple service instances\\n- **Service-to-Service Communication**: Internal APIs need different limits than public ones\\n- **Dynamic Scaling**: Rate limits must adapt to auto-scaling scenarios\\n- **Cross-Service Coordination**: Shared limits across multiple related services\\n\\n## Popular Open Source Rate Limiting Libraries\\n\\nBefore implementing custom rate limiting solutions, consider these battle-tested libraries that can significantly speed up development:\\n\\n### \ud83d\ude80 **@nestjs/throttler**\\n\\nThe official NestJS throttling library provides simple, decorator-based rate limiting.\\n\\n```typescript\\n// Installation\\nnpm install @nestjs/throttler\\n\\n// Basic setup\\nimport { ThrottlerModule, ThrottlerGuard } from \'@nestjs/throttler\';\\nimport { APP_GUARD } from \'@nestjs/core\';\\n\\n@Module({\\n  imports: [\\n    ThrottlerModule.forRoot([\\n      {\\n        name: \'short\',\\n        ttl: 1000,  // 1 second\\n        limit: 3,   // 3 requests per second\\n      },\\n      {\\n        name: \'medium\',\\n        ttl: 10000, // 10 seconds\\n        limit: 20,  // 20 requests per 10 seconds\\n      },\\n      {\\n        name: \'long\',\\n        ttl: 60000, // 1 minute\\n        limit: 100, // 100 requests per minute\\n      },\\n    ]),\\n  ],\\n  providers: [\\n    {\\n      provide: APP_GUARD,\\n      useClass: ThrottlerGuard,\\n    },\\n  ],\\n})\\nexport class AppModule {}\\n\\n// Usage in controllers\\nimport { Throttle } from \'@nestjs/throttler\';\\n\\n@Controller(\'api\')\\nexport class ApiController {\\n  @Get(\'public\')\\n  @Throttle({ default: { limit: 10, ttl: 60000 } })\\n  getPublicData() {\\n    return { data: \'Limited to 10 requests per minute\' };\\n  }\\n\\n  @Post(\'auth/login\')\\n  @Throttle({ default: { limit: 5, ttl: 300000 } }) // 5 attempts per 5 minutes\\n  login(@Body() credentials: any) {\\n    return { token: \'jwt-token\' };\\n  }\\n}\\n```\\n\\n### \u26a1 **express-rate-limit**\\n\\nA mature Express.js rate limiting middleware that works seamlessly with NestJS.\\n\\n```typescript\\n// Installation\\nnpm install express-rate-limit\\n\\n// Global setup\\nimport rateLimit from \'express-rate-limit\';\\n\\nconst app = await NestFactory.create(AppModule);\\n\\n// Global rate limiting\\napp.use(\\n  rateLimit({\\n    windowMs: 15 * 60 * 1000, // 15 minutes\\n    max: 100, // Limit each IP to 100 requests per windowMs\\n    message: {\\n      error: \'Too many requests, please try again later.\',\\n      retryAfter: \'15 minutes\',\\n    },\\n    standardHeaders: true, // Return rate limit info in headers\\n    legacyHeaders: false,\\n    // Redis store for distributed rate limiting\\n    store: new RedisStore({\\n      sendCommand: (...args: string[]) => redisClient.call(...args),\\n    }),\\n  })\\n);\\n\\n// Route-specific limiting\\nimport { Request, Response, NextFunction } from \'express\';\\n\\nconst loginLimiter = rateLimit({\\n  windowMs: 15 * 60 * 1000, // 15 minutes\\n  max: 5, // Limit each IP to 5 login requests per windowMs\\n  message: \'Too many login attempts, please try again later.\',\\n  skipSuccessfulRequests: true, // Don\'t count successful requests\\n});\\n\\n@Controller(\'auth\')\\nexport class AuthController {\\n  @Post(\'login\')\\n  @UseInterceptors(\\n    // Apply rate limiting middleware as interceptor\\n    (req: Request, res: Response, next: NextFunction) => \\n      loginLimiter(req, res, next)\\n  )\\n  login(@Body() credentials: any) {\\n    return { token: \'jwt-token\' };\\n  }\\n}\\n```\\n\\n### \ud83d\udd04 **bottleneck**\\n\\nAdvanced rate limiting with queuing, clustering, and Redis support.\\n\\n```typescript\\n// Installation\\nnpm install bottleneck\\n\\n// Service implementation\\nimport Bottleneck from \'bottleneck\';\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class AdvancedRateLimitService {\\n  private limiters = new Map<string, Bottleneck>();\\n\\n  constructor() {\\n    // Create different limiters for different use cases\\n    this.setupLimiters();\\n  }\\n\\n  private setupLimiters() {\\n    // API rate limiter with Redis clustering\\n    this.limiters.set(\'api\', new Bottleneck({\\n      reservoir: 100,           // Initial capacity\\n      reservoirRefreshAmount: 100, // Tokens to add\\n      reservoirRefreshInterval: 60 * 1000, // Every minute\\n      maxConcurrent: 10,        // Max concurrent requests\\n      minTime: 100,             // Min time between requests (100ms)\\n      \\n      // Redis clustering for distributed rate limiting\\n      datastore: \'redis\',\\n      clearDatastore: false,\\n      clientOptions: {\\n        host: \'localhost\',\\n        port: 6379,\\n      },\\n      clusterNodes: [\\n        { host: \'redis-1\', port: 6379 },\\n        { host: \'redis-2\', port: 6379 },\\n      ],\\n    }));\\n\\n    // Premium API with higher limits\\n    this.limiters.set(\'premium\', new Bottleneck({\\n      reservoir: 1000,\\n      reservoirRefreshAmount: 1000,\\n      reservoirRefreshInterval: 60 * 1000,\\n      maxConcurrent: 50,\\n      minTime: 20,\\n    }));\\n\\n    // Heavy processing limiter\\n    this.limiters.set(\'processing\', new Bottleneck({\\n      maxConcurrent: 3,         // Only 3 heavy operations at once\\n      minTime: 2000,            // 2 seconds between operations\\n    }));\\n  }\\n\\n  async executeWithRateLimit<T>(\\n    limiterType: string,\\n    operation: () => Promise<T>,\\n    priority?: number\\n  ): Promise<T> {\\n    const limiter = this.limiters.get(limiterType);\\n    if (!limiter) {\\n      throw new Error(`Unknown limiter type: ${limiterType}`);\\n    }\\n\\n    return limiter.schedule({ priority }, operation);\\n  }\\n\\n  async checkRateLimit(\\n    limiterType: string,\\n    weight: number = 1\\n  ): Promise<{ allowed: boolean; msBeforeNext: number }> {\\n    const limiter = this.limiters.get(limiterType);\\n    if (!limiter) {\\n      return { allowed: false, msBeforeNext: 0 };\\n    }\\n\\n    try {\\n      const result = await limiter.check(weight);\\n      return {\\n        allowed: result >= 0,\\n        msBeforeNext: result < 0 ? Math.abs(result) : 0,\\n      };\\n    } catch (error) {\\n      return { allowed: false, msBeforeNext: 1000 };\\n    }\\n  }\\n\\n  // Get limiter statistics\\n  getStats(limiterType: string) {\\n    const limiter = this.limiters.get(limiterType);\\n    if (!limiter) return null;\\n\\n    return {\\n      running: limiter.running(),\\n      queued: limiter.queued(),\\n      reservoir: limiter.reservoir(),\\n      capacity: limiter.capacity,\\n    };\\n  }\\n}\\n\\n// Usage in controllers\\n@Controller(\'api\')\\nexport class ApiController {\\n  constructor(\\n    private readonly rateLimitService: AdvancedRateLimitService\\n  ) {}\\n\\n  @Get(\'data\')\\n  async getData() {\\n    return this.rateLimitService.executeWithRateLimit(\\n      \'api\',\\n      async () => {\\n        // Your API logic here\\n        return { data: \'API response\' };\\n      }\\n    );\\n  }\\n\\n  @Post(\'heavy-process\')\\n  async heavyProcess(@Body() data: any) {\\n    const check = await this.rateLimitService.checkRateLimit(\'processing\');\\n    \\n    if (!check.allowed) {\\n      throw new HttpException(\\n        {\\n          message: \'Processing queue full\',\\n          retryAfter: Math.ceil(check.msBeforeNext / 1000),\\n        },\\n        HttpStatus.TOO_MANY_REQUESTS\\n      );\\n    }\\n\\n    return this.rateLimitService.executeWithRateLimit(\\n      \'processing\',\\n      async () => {\\n        // Heavy processing logic\\n        await this.performHeavyOperation(data);\\n        return { status: \'completed\' };\\n      },\\n      5 // High priority\\n    );\\n  }\\n\\n  @Get(\'stats\')\\n  getSystemStats() {\\n    return {\\n      api: this.rateLimitService.getStats(\'api\'),\\n      premium: this.rateLimitService.getStats(\'premium\'),\\n      processing: this.rateLimitService.getStats(\'processing\'),\\n    };\\n  }\\n}\\n```\\n\\n### \ud83c\udfea **ioredis-rate-limiter**\\n\\nRedis-based rate limiting with sliding window implementation.\\n\\n```typescript\\n// Installation\\nnpm install ioredis-rate-limiter ioredis\\n\\n// Service implementation\\nimport RateLimiter from \'ioredis-rate-limiter\';\\nimport Redis from \'ioredis\';\\nimport { Injectable } from \'@nestjs/common\';\\n\\n@Injectable()\\nexport class RedisRateLimitService {\\n  private redis: Redis;\\n  private limiters = new Map<string, RateLimiter>();\\n\\n  constructor() {\\n    this.redis = new Redis({\\n      host: \'localhost\',\\n      port: 6379,\\n      retryDelayOnFailover: 100,\\n    });\\n\\n    this.setupLimiters();\\n  }\\n\\n  private setupLimiters() {\\n    // API rate limiter - 100 requests per minute\\n    this.limiters.set(\'api\', new RateLimiter({\\n      redis: this.redis,\\n      key: (id: string) => `rate_limit:api:${id}`,\\n      window: 60000,        // 1 minute window\\n      limit: 100,           // 100 requests per window\\n    }));\\n\\n    // Login rate limiter - 5 attempts per 15 minutes\\n    this.limiters.set(\'login\', new RateLimiter({\\n      redis: this.redis,\\n      key: (id: string) => `rate_limit:login:${id}`,\\n      window: 15 * 60000,   // 15 minutes\\n      limit: 5,             // 5 attempts\\n    }));\\n\\n    // Premium API - 1000 requests per minute\\n    this.limiters.set(\'premium\', new RateLimiter({\\n      redis: this.redis,\\n      key: (id: string) => `rate_limit:premium:${id}`,\\n      window: 60000,\\n      limit: 1000,\\n    }));\\n  }\\n\\n  async checkLimit(\\n    type: string,\\n    identifier: string,\\n    cost: number = 1\\n  ): Promise<{\\n    allowed: boolean;\\n    remaining: number;\\n    resetTime: Date;\\n    totalHits: number;\\n  }> {\\n    const limiter = this.limiters.get(type);\\n    if (!limiter) {\\n      throw new Error(`Unknown rate limiter type: ${type}`);\\n    }\\n\\n    try {\\n      const result = await limiter.check(identifier, cost);\\n      \\n      return {\\n        allowed: result.allowed,\\n        remaining: result.remaining,\\n        resetTime: new Date(result.resetTime),\\n        totalHits: result.totalHits,\\n      };\\n    } catch (error) {\\n      // Fallback in case of Redis issues\\n      console.error(\'Rate limit check failed:\', error);\\n      return {\\n        allowed: true, // Fail open for availability\\n        remaining: 0,\\n        resetTime: new Date(Date.now() + 60000),\\n        totalHits: 0,\\n      };\\n    }\\n  }\\n\\n  async getRemainingQuota(type: string, identifier: string): Promise<number> {\\n    const result = await this.checkLimit(type, identifier, 0); // Cost 0 for check only\\n    return result.remaining;\\n  }\\n}\\n\\n// Guard implementation\\n@Injectable()\\nexport class RedisRateLimitGuard implements CanActivate {\\n  constructor(\\n    private readonly rateLimitService: RedisRateLimitService,\\n    private readonly reflector: Reflector\\n  ) {}\\n\\n  async canActivate(context: ExecutionContext): Promise<boolean> {\\n    const request = context.switchToHttp().getRequest();\\n    const response = context.switchToHttp().getResponse();\\n    \\n    // Get rate limit configuration from decorator\\n    const config = this.reflector.get<{\\n      type: string;\\n      identifier?: (req: any) => string;\\n      cost?: number;\\n    }>(\'REDIS_RATE_LIMIT\', context.getHandler());\\n\\n    if (!config) {\\n      return true; // No rate limiting configured\\n    }\\n\\n    // Generate identifier\\n    const identifier = config.identifier \\n      ? config.identifier(request)\\n      : request.ip;\\n\\n    // Check rate limit\\n    const result = await this.rateLimitService.checkLimit(\\n      config.type,\\n      identifier,\\n      config.cost || 1\\n    );\\n\\n    // Set headers\\n    response.setHeader(\'X-RateLimit-Remaining\', result.remaining);\\n    response.setHeader(\'X-RateLimit-Reset\', result.resetTime.toISOString());\\n    response.setHeader(\'X-RateLimit-Total\', result.totalHits);\\n\\n    if (!result.allowed) {\\n      response.setHeader(\'Retry-After\', Math.ceil((result.resetTime.getTime() - Date.now()) / 1000));\\n      \\n      throw new HttpException(\\n        {\\n          statusCode: HttpStatus.TOO_MANY_REQUESTS,\\n          message: \'Rate limit exceeded\',\\n          retryAfter: result.resetTime.toISOString(),\\n        },\\n        HttpStatus.TOO_MANY_REQUESTS\\n      );\\n    }\\n\\n    return true;\\n  }\\n}\\n\\n// Decorator for easy usage\\nexport const RedisRateLimit = (config: {\\n  type: string;\\n  identifier?: (req: any) => string;\\n  cost?: number;\\n}) => SetMetadata(\'REDIS_RATE_LIMIT\', config);\\n\\n// Usage example\\n@Controller(\'api\')\\n@UseGuards(RedisRateLimitGuard)\\nexport class ApiController {\\n  @Get(\'data\')\\n  @RedisRateLimit({\\n    type: \'api\',\\n    identifier: (req) => req.ip,\\n  })\\n  getData() {\\n    return { data: \'API response\' };\\n  }\\n\\n  @Post(\'login\')\\n  @RedisRateLimit({\\n    type: \'login\',\\n    identifier: (req) => `${req.ip}:${req.body.email}`,\\n  })\\n  login(@Body() credentials: any) {\\n    return { token: \'jwt-token\' };\\n  }\\n\\n  @Get(\'premium\')\\n  @RedisRateLimit({\\n    type: \'premium\',\\n    identifier: (req) => req.user?.id || req.ip,\\n    cost: 5, // This endpoint costs 5 \\"points\\"\\n  })\\n  getPremiumData() {\\n    return { data: \'Premium API response\' };\\n  }\\n}\\n```\\n\\n### \ud83d\udcca **Library Comparison**\\n\\n| Library | Pros | Cons | Best For |\\n|---------|------|------|----------|\\n| **@nestjs/throttler** | \u2705 Official NestJS support<br/>\u2705 Decorator-based<br/>\u2705 Multiple rate limits<br/>\u2705 Redis support | \u274c Limited algorithms<br/>\u274c Basic queuing | Simple rate limiting, Getting started |\\n| **express-rate-limit** | \u2705 Mature & stable<br/>\u2705 Extensive middleware<br/>\u2705 Good documentation<br/>\u2705 Flexible configuration | \u274c Express-specific<br/>\u274c Limited queue management | General web applications, Migration from Express |\\n| **bottleneck** | \u2705 Advanced queuing<br/>\u2705 Clustering support<br/>\u2705 Priority queues<br/>\u2705 Multiple algorithms | \u274c Complex configuration<br/>\u274c Learning curve | Complex rate limiting, Job queues, Distributed systems |\\n| **ioredis-rate-limiter** | \u2705 Sliding window<br/>\u2705 High performance<br/>\u2705 Simple API<br/>\u2705 Redis-native | \u274c Redis dependency<br/>\u274c Limited to sliding window | High-performance APIs, Redis-based infrastructure |\\n\\n### \ud83d\udd04 **Quick Migration Guide**\\n\\nIf you\'re using custom rate limiting and want to migrate to a library:\\n\\n```typescript\\n// From custom implementation\\n@RateLimit({\\n  algorithm: \'sliding-window\',\\n  limit: 100,\\n  windowMs: 60000,\\n})\\n\\n// To @nestjs/throttler\\n@Throttle({ default: { limit: 100, ttl: 60000 } })\\n\\n// To bottleneck\\nasync method() {\\n  return this.rateLimitService.executeWithRateLimit(\'api\', async () => {\\n    // Your logic here\\n  });\\n}\\n\\n// To ioredis-rate-limiter\\n@RedisRateLimit({\\n  type: \'api\',\\n  identifier: (req) => req.ip,\\n})\\n```\\n\\n## Rate Limiting Strategies for Microservices\\n\\n### 1. Token Bucket Algorithm\\n\\nThe token bucket algorithm is ideal for allowing bursts while maintaining average rate limits.\\n\\n```typescript\\n// rate-limiting/token-bucket.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { RedisService } from \'@nestjs-modules/ioredis\';\\n\\ninterface TokenBucketConfig {\\n  capacity: number;      // Maximum tokens in bucket\\n  refillRate: number;    // Tokens added per second\\n  windowSize: number;    // Time window in seconds\\n}\\n\\n@Injectable()\\nexport class TokenBucketService {\\n  constructor(private readonly redis: RedisService) {}\\n\\n  async checkRateLimit(\\n    key: string,\\n    config: TokenBucketConfig,\\n    tokensRequested: number = 1\\n  ): Promise<{\\n    allowed: boolean;\\n    remainingTokens: number;\\n    resetTime: number;\\n    retryAfter?: number;\\n  }> {\\n    const script = `\\n      local key = KEYS[1]\\n      local capacity = tonumber(ARGV[1])\\n      local refillRate = tonumber(ARGV[2])\\n      local windowSize = tonumber(ARGV[3])\\n      local tokensRequested = tonumber(ARGV[4])\\n      local now = tonumber(ARGV[5])\\n      \\n      -- Get current bucket state\\n      local bucket = redis.call(\'HMGET\', key, \'tokens\', \'lastRefill\')\\n      local tokens = tonumber(bucket[1]) or capacity\\n      local lastRefill = tonumber(bucket[2]) or now\\n      \\n      -- Calculate tokens to add based on time elapsed\\n      local elapsed = math.max(0, now - lastRefill)\\n      local tokensToAdd = math.floor(elapsed * refillRate)\\n      tokens = math.min(capacity, tokens + tokensToAdd)\\n      \\n      -- Check if request can be fulfilled\\n      local allowed = tokens >= tokensRequested\\n      local remainingTokens = tokens\\n      local retryAfter = 0\\n      \\n      if allowed then\\n        remainingTokens = tokens - tokensRequested\\n        -- Update bucket state\\n        redis.call(\'HMSET\', key, \'tokens\', remainingTokens, \'lastRefill\', now)\\n        redis.call(\'EXPIRE\', key, windowSize * 2)\\n      else\\n        -- Calculate retry after time\\n        local tokensNeeded = tokensRequested - tokens\\n        retryAfter = math.ceil(tokensNeeded / refillRate)\\n      end\\n      \\n      return {\\n        allowed and 1 or 0,\\n        remainingTokens,\\n        now + (capacity - remainingTokens) / refillRate,\\n        retryAfter\\n      }\\n    `;\\n\\n    const now = Math.floor(Date.now() / 1000);\\n    const result = await this.redis.eval(\\n      script,\\n      1,\\n      key,\\n      config.capacity,\\n      config.refillRate,\\n      config.windowSize,\\n      tokensRequested,\\n      now\\n    ) as [number, number, number, number];\\n\\n    return {\\n      allowed: result[0] === 1,\\n      remainingTokens: result[1],\\n      resetTime: result[2],\\n      retryAfter: result[3] > 0 ? result[3] : undefined,\\n    };\\n  }\\n}\\n```\\n\\n### 2. Sliding Window Algorithm\\n\\nSliding window provides more accurate rate limiting by tracking requests in a rolling time window.\\n\\n```typescript\\n// rate-limiting/sliding-window.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { RedisService } from \'@nestjs-modules/ioredis\';\\n\\ninterface SlidingWindowConfig {\\n  limit: number;         // Maximum requests per window\\n  windowMs: number;      // Window size in milliseconds\\n  precision: number;     // Sub-window precision (e.g., 10 for 10 sub-windows)\\n}\\n\\n@Injectable()\\nexport class SlidingWindowService {\\n  constructor(private readonly redis: RedisService) {}\\n\\n  async checkRateLimit(\\n    key: string,\\n    config: SlidingWindowConfig\\n  ): Promise<{\\n    allowed: boolean;\\n    remaining: number;\\n    resetTime: number;\\n    currentUsage: number;\\n  }> {\\n    const script = `\\n      local key = KEYS[1]\\n      local limit = tonumber(ARGV[1])\\n      local windowMs = tonumber(ARGV[2])\\n      local precision = tonumber(ARGV[3])\\n      local now = tonumber(ARGV[4])\\n      \\n      -- Calculate sub-window size\\n      local subWindowMs = windowMs / precision\\n      local currentWindow = math.floor(now / subWindowMs)\\n      local windowStart = currentWindow - precision + 1\\n      \\n      -- Clean old sub-windows\\n      redis.call(\'ZREMRANGEBYSCORE\', key, 0, windowStart - 1)\\n      \\n      -- Count current requests in the sliding window\\n      local currentCount = 0\\n      local subWindows = redis.call(\'ZRANGE\', key, 0, -1, \'WITHSCORES\')\\n      \\n      for i = 1, #subWindows, 2 do\\n        local subWindow = tonumber(subWindows[i + 1])\\n        local count = tonumber(subWindows[i])\\n        \\n        if subWindow >= windowStart then\\n          -- Calculate overlap percentage for partial windows\\n          local overlap = 1\\n          if subWindow == windowStart then\\n            local subWindowTime = subWindow * subWindowMs\\n            local windowTime = now - windowMs\\n            overlap = math.max(0, (subWindowTime + subWindowMs - windowTime) / subWindowMs)\\n          end\\n          currentCount = currentCount + (count * overlap)\\n        end\\n      end\\n      \\n      local allowed = currentCount < limit\\n      local remaining = math.max(0, limit - currentCount - 1)\\n      \\n      if allowed then\\n        -- Increment counter for current sub-window\\n        redis.call(\'ZINCRBY\', key, 1, currentWindow)\\n        redis.call(\'EXPIRE\', key, math.ceil(windowMs / 1000) * 2)\\n      end\\n      \\n      local resetTime = (currentWindow + 1) * subWindowMs\\n      \\n      return {\\n        allowed and 1 or 0,\\n        remaining,\\n        resetTime,\\n        currentCount + (allowed and 1 or 0)\\n      }\\n    `;\\n\\n    const now = Date.now();\\n    const result = await this.redis.eval(\\n      script,\\n      1,\\n      key,\\n      config.limit,\\n      config.windowMs,\\n      config.precision,\\n      now\\n    ) as [number, number, number, number];\\n\\n    return {\\n      allowed: result[0] === 1,\\n      remaining: result[1],\\n      resetTime: result[2],\\n      currentUsage: result[3],\\n    };\\n  }\\n}\\n```\\n\\n## Advanced Rate Limiting Guard\\n\\nCreate a flexible, configurable rate limiting guard that supports multiple algorithms and strategies.\\n\\n```typescript\\n// guards/rate-limit.guard.ts\\nimport {\\n  Injectable,\\n  CanActivate,\\n  ExecutionContext,\\n  HttpException,\\n  HttpStatus,\\n  Inject,\\n} from \'@nestjs/common\';\\nimport { Reflector } from \'@nestjs/core\';\\nimport { Request, Response } from \'express\';\\nimport { TokenBucketService } from \'../rate-limiting/token-bucket.service\';\\nimport { SlidingWindowService } from \'../rate-limiting/sliding-window.service\';\\nimport { RATE_LIMIT_OPTIONS } from \'../decorators/rate-limit.decorator\';\\n\\nexport interface RateLimitOptions {\\n  algorithm: \'token-bucket\' | \'sliding-window\' | \'fixed-window\';\\n  keyGenerator?: (req: Request) => string;\\n  skipIf?: (req: Request) => boolean;\\n  onLimitReached?: (req: Request, res: Response) => void;\\n  \\n  // Token bucket specific\\n  capacity?: number;\\n  refillRate?: number;\\n  \\n  // Sliding/Fixed window specific\\n  limit?: number;\\n  windowMs?: number;\\n  precision?: number; // For sliding window\\n  \\n  // Common options\\n  message?: string;\\n  standardHeaders?: boolean;\\n  legacyHeaders?: boolean;\\n  skipSuccessfulRequests?: boolean;\\n  skipFailedRequests?: boolean;\\n}\\n\\n@Injectable()\\nexport class RateLimitGuard implements CanActivate {\\n  constructor(\\n    private readonly reflector: Reflector,\\n    private readonly tokenBucket: TokenBucketService,\\n    private readonly slidingWindow: SlidingWindowService,\\n    @Inject(\'CONFIG_SERVICE\') private readonly config: any\\n  ) {}\\n\\n  async canActivate(context: ExecutionContext): Promise<boolean> {\\n    const request = context.switchToHttp().getRequest<Request>();\\n    const response = context.switchToHttp().getResponse<Response>();\\n    \\n    // Get rate limit options from decorator or global config\\n    const options = this.getRateLimitOptions(context);\\n    \\n    if (!options) {\\n      return true; // No rate limiting configured\\n    }\\n\\n    // Check if request should be skipped\\n    if (options.skipIf && options.skipIf(request)) {\\n      return true;\\n    }\\n\\n    // Generate rate limit key\\n    const key = this.generateKey(request, options);\\n    \\n    // Apply rate limiting based on algorithm\\n    const result = await this.applyRateLimit(key, options);\\n    \\n    // Set response headers\\n    this.setHeaders(response, result, options);\\n    \\n    if (!result.allowed) {\\n      // Execute custom handler if provided\\n      if (options.onLimitReached) {\\n        options.onLimitReached(request, response);\\n      }\\n      \\n      // Throw rate limit exceeded exception\\n      throw new HttpException(\\n        {\\n          statusCode: HttpStatus.TOO_MANY_REQUESTS,\\n          message: options.message || \'Rate limit exceeded\',\\n          error: \'Too Many Requests\',\\n          retryAfter: result.retryAfter,\\n        },\\n        HttpStatus.TOO_MANY_REQUESTS\\n      );\\n    }\\n\\n    return true;\\n  }\\n\\n  private getRateLimitOptions(context: ExecutionContext): RateLimitOptions | null {\\n    // Check method-level decorator first\\n    const methodOptions = this.reflector.get<RateLimitOptions>(\\n      RATE_LIMIT_OPTIONS,\\n      context.getHandler()\\n    );\\n    \\n    if (methodOptions) {\\n      return methodOptions;\\n    }\\n\\n    // Check class-level decorator\\n    const classOptions = this.reflector.get<RateLimitOptions>(\\n      RATE_LIMIT_OPTIONS,\\n      context.getClass()\\n    );\\n    \\n    if (classOptions) {\\n      return classOptions;\\n    }\\n\\n    // Return global default options if configured\\n    return this.config.get(\'rateLimit.default\');\\n  }\\n\\n  private generateKey(request: Request, options: RateLimitOptions): string {\\n    if (options.keyGenerator) {\\n      return options.keyGenerator(request);\\n    }\\n\\n    // Default key generation strategy\\n    const ip = request.ip || request.connection.remoteAddress;\\n    const userId = (request as any).user?.id || \'anonymous\';\\n    const route = `${request.method}:${request.route?.path || request.path}`;\\n    \\n    return `rate_limit:${ip}:${userId}:${route}`;\\n  }\\n\\n  private async applyRateLimit(\\n    key: string,\\n    options: RateLimitOptions\\n  ): Promise<{\\n    allowed: boolean;\\n    remaining?: number;\\n    resetTime?: number;\\n    retryAfter?: number;\\n    currentUsage?: number;\\n  }> {\\n    switch (options.algorithm) {\\n      case \'token-bucket\':\\n        return this.tokenBucket.checkRateLimit(key, {\\n          capacity: options.capacity || 10,\\n          refillRate: options.refillRate || 1,\\n          windowSize: Math.floor((options.windowMs || 60000) / 1000),\\n        });\\n\\n      case \'sliding-window\':\\n        return this.slidingWindow.checkRateLimit(key, {\\n          limit: options.limit || 100,\\n          windowMs: options.windowMs || 60000,\\n          precision: options.precision || 10,\\n        });\\n\\n      case \'fixed-window\':\\n        return this.applyFixedWindow(key, {\\n          limit: options.limit || 100,\\n          windowMs: options.windowMs || 60000,\\n        });\\n\\n      default:\\n        throw new Error(`Unknown rate limiting algorithm: ${options.algorithm}`);\\n    }\\n  }\\n\\n  private async applyFixedWindow(\\n    key: string,\\n    config: { limit: number; windowMs: number }\\n  ): Promise<any> {\\n    // Simple fixed window implementation using Redis\\n    const window = Math.floor(Date.now() / config.windowMs);\\n    const windowKey = `${key}:${window}`;\\n    \\n    const current = await this.tokenBucket[\'redis\'].incr(windowKey);\\n    await this.tokenBucket[\'redis\'].expire(windowKey, Math.ceil(config.windowMs / 1000));\\n    \\n    const allowed = current <= config.limit;\\n    const remaining = Math.max(0, config.limit - current);\\n    const resetTime = (window + 1) * config.windowMs;\\n    \\n    return {\\n      allowed,\\n      remaining,\\n      resetTime,\\n      currentUsage: current,\\n    };\\n  }\\n\\n  private setHeaders(response: Response, result: any, options: RateLimitOptions): void {\\n    if (options.standardHeaders !== false) {\\n      // Standard rate limit headers (draft RFC)\\n      response.setHeader(\'RateLimit-Limit\', options.limit || options.capacity);\\n      response.setHeader(\'RateLimit-Remaining\', result.remaining || 0);\\n      response.setHeader(\'RateLimit-Reset\', result.resetTime);\\n      \\n      if (result.retryAfter) {\\n        response.setHeader(\'Retry-After\', result.retryAfter);\\n      }\\n    }\\n\\n    if (options.legacyHeaders) {\\n      // Legacy X-RateLimit headers for compatibility\\n      response.setHeader(\'X-RateLimit-Limit\', options.limit || options.capacity);\\n      response.setHeader(\'X-RateLimit-Remaining\', result.remaining || 0);\\n      response.setHeader(\'X-RateLimit-Reset\', result.resetTime);\\n    }\\n  }\\n}\\n```\\n\\n## Rate Limiting Decorators\\n\\nCreate flexible decorators for easy application of rate limits.\\n\\n```typescript\\n// decorators/rate-limit.decorator.ts\\nimport { SetMetadata } from \'@nestjs/common\';\\nimport { RateLimitOptions } from \'../guards/rate-limit.guard\';\\n\\nexport const RATE_LIMIT_OPTIONS = \'RATE_LIMIT_OPTIONS\';\\n\\nexport const RateLimit = (options: RateLimitOptions) => \\n  SetMetadata(RATE_LIMIT_OPTIONS, options);\\n\\n// Convenience decorators for common patterns\\nexport const PublicApiRateLimit = () => \\n  RateLimit({\\n    algorithm: \'sliding-window\',\\n    limit: 1000,\\n    windowMs: 60000, // 1 minute\\n    message: \'Too many requests from this IP, please try again later\',\\n    standardHeaders: true,\\n  });\\n\\nexport const AuthRateLimit = () => \\n  RateLimit({\\n    algorithm: \'token-bucket\',\\n    capacity: 5,\\n    refillRate: 1/60, // 1 token per minute\\n    windowMs: 300000, // 5 minutes\\n    message: \'Too many authentication attempts, please try again later\',\\n    keyGenerator: (req) => `auth:${req.ip}:${req.body?.email || \'unknown\'}`,\\n  });\\n\\nexport const PremiumApiRateLimit = () => \\n  RateLimit({\\n    algorithm: \'sliding-window\',\\n    limit: 10000,\\n    windowMs: 60000,\\n    skipIf: (req) => (req as any).user?.plan === \'enterprise\',\\n    keyGenerator: (req) => `premium:${(req as any).user?.id || req.ip}`,\\n  });\\n\\nexport const InternalServiceRateLimit = () => \\n  RateLimit({\\n    algorithm: \'token-bucket\',\\n    capacity: 1000,\\n    refillRate: 10,\\n    windowMs: 60000,\\n    skipIf: (req) => req.headers[\'x-service-token\'] === process.env.INTERNAL_SERVICE_TOKEN,\\n    keyGenerator: (req) => `internal:${req.headers[\'x-service-name\'] || \'unknown\'}`,\\n  });\\n\\n// Dynamic rate limiting based on user tier\\nexport const TieredRateLimit = () => \\n  RateLimit({\\n    algorithm: \'sliding-window\',\\n    windowMs: 60000,\\n    keyGenerator: (req) => {\\n      const user = (req as any).user;\\n      const tier = user?.plan || \'free\';\\n      return `tiered:${tier}:${user?.id || req.ip}`;\\n    },\\n    limit: 0, // Will be dynamically set\\n  });\\n```\\n\\n## Microservice-Aware Rate Limiting\\n\\nImplement service-specific rate limiting strategies that work across distributed systems.\\n\\n```typescript\\n// services/distributed-rate-limit.service.ts\\nimport { Injectable, Inject } from \'@nestjs/common\';\\nimport { ClientProxy } from \'@nestjs/microservices\';\\nimport { RedisService } from \'@nestjs-modules/ioredis\';\\n\\ninterface ServiceRateLimitConfig {\\n  serviceName: string;\\n  globalLimit: number;\\n  perInstanceLimit: number;\\n  windowMs: number;\\n  coordinationStrategy: \'redis\' | \'gossip\' | \'leader-election\';\\n}\\n\\n@Injectable()\\nexport class DistributedRateLimitService {\\n  private instanceId: string;\\n  \\n  constructor(\\n    private readonly redis: RedisService,\\n    @Inject(\'MESSAGE_BROKER\') private readonly messageBroker: ClientProxy\\n  ) {\\n    this.instanceId = `${process.env.POD_NAME || \'local\'}-${Date.now()}`;\\n  }\\n\\n  async checkServiceRateLimit(\\n    config: ServiceRateLimitConfig,\\n    clientKey: string\\n  ): Promise<{\\n    allowed: boolean;\\n    globalUsage: number;\\n    instanceUsage: number;\\n    recommendation: \'allow\' | \'deny\' | \'throttle\';\\n  }> {\\n    const script = `\\n      local globalKey = KEYS[1]\\n      local instanceKey = KEYS[2]\\n      local globalLimit = tonumber(ARGV[1])\\n      local perInstanceLimit = tonumber(ARGV[2])\\n      local windowMs = tonumber(ARGV[3])\\n      local now = tonumber(ARGV[4])\\n      local instanceId = ARGV[5]\\n      \\n      -- Clean expired entries\\n      local cutoff = now - windowMs\\n      redis.call(\'ZREMRANGEBYSCORE\', globalKey, 0, cutoff)\\n      redis.call(\'ZREMRANGEBYSCORE\', instanceKey, 0, cutoff)\\n      \\n      -- Get current usage\\n      local globalUsage = redis.call(\'ZCARD\', globalKey)\\n      local instanceUsage = redis.call(\'ZCARD\', instanceKey)\\n      \\n      -- Calculate available capacity\\n      local globalAvailable = globalLimit - globalUsage\\n      local instanceAvailable = perInstanceLimit - instanceUsage\\n      \\n      -- Determine if request should be allowed\\n      local allowed = globalAvailable > 0 and instanceAvailable > 0\\n      local recommendation = \'allow\'\\n      \\n      if not allowed then\\n        recommendation = \'deny\'\\n      elseif globalAvailable < globalLimit * 0.1 then\\n        recommendation = \'throttle\'\\n      end\\n      \\n      if allowed then\\n        -- Record the request\\n        local requestId = instanceId .. \':\' .. now .. \':\' .. math.random(1000000)\\n        redis.call(\'ZADD\', globalKey, now, requestId)\\n        redis.call(\'ZADD\', instanceKey, now, requestId)\\n        redis.call(\'EXPIRE\', globalKey, math.ceil(windowMs / 1000) * 2)\\n        redis.call(\'EXPIRE\', instanceKey, math.ceil(windowMs / 1000) * 2)\\n        \\n        globalUsage = globalUsage + 1\\n        instanceUsage = instanceUsage + 1\\n      end\\n      \\n      return {\\n        allowed and 1 or 0,\\n        globalUsage,\\n        instanceUsage,\\n        recommendation\\n      }\\n    `;\\n\\n    const now = Date.now();\\n    const globalKey = `service_rate_limit:${config.serviceName}:global:${clientKey}`;\\n    const instanceKey = `service_rate_limit:${config.serviceName}:${this.instanceId}:${clientKey}`;\\n\\n    const result = await this.redis.eval(\\n      script,\\n      2,\\n      globalKey,\\n      instanceKey,\\n      config.globalLimit,\\n      config.perInstanceLimit,\\n      config.windowMs,\\n      now,\\n      this.instanceId\\n    ) as [number, number, number, string];\\n\\n    // Publish metrics for monitoring\\n    await this.publishMetrics(config.serviceName, {\\n      globalUsage: result[1],\\n      instanceUsage: result[2],\\n      recommendation: result[3],\\n      timestamp: now,\\n    });\\n\\n    return {\\n      allowed: result[0] === 1,\\n      globalUsage: result[1],\\n      instanceUsage: result[2],\\n      recommendation: result[3] as any,\\n    };\\n  }\\n\\n  private async publishMetrics(serviceName: string, metrics: any): Promise<void> {\\n    try {\\n      await this.messageBroker.emit(\'rate_limit.metrics\', {\\n        serviceName,\\n        instanceId: this.instanceId,\\n        ...metrics,\\n      });\\n    } catch (error) {\\n      // Metrics publishing failure shouldn\'t affect rate limiting\\n      console.warn(\'Failed to publish rate limit metrics:\', error);\\n    }\\n  }\\n\\n  async getServiceHealth(serviceName: string): Promise<{\\n    totalInstances: number;\\n    healthyInstances: number;\\n    globalUsage: number;\\n    averageInstanceUsage: number;\\n  }> {\\n    const healthKey = `service_health:${serviceName}`;\\n    const instances = await this.redis.hgetall(healthKey);\\n    \\n    const now = Date.now();\\n    const healthyThreshold = 30000; // 30 seconds\\n    \\n    let healthyCount = 0;\\n    let totalUsage = 0;\\n    \\n    for (const [instanceId, lastSeen] of Object.entries(instances)) {\\n      if (now - parseInt(lastSeen) < healthyThreshold) {\\n        healthyCount++;\\n        \\n        // Get instance usage\\n        const usageKey = `service_rate_limit:${serviceName}:${instanceId}:*`;\\n        const usageKeys = await this.redis.keys(usageKey);\\n        for (const key of usageKeys) {\\n          const usage = await this.redis.zcard(key);\\n          totalUsage += usage;\\n        }\\n      }\\n    }\\n    \\n    return {\\n      totalInstances: Object.keys(instances).length,\\n      healthyInstances: healthyCount,\\n      globalUsage: totalUsage,\\n      averageInstanceUsage: healthyCount > 0 ? totalUsage / healthyCount : 0,\\n    };\\n  }\\n}\\n```\\n\\n## Production-Ready Controller Implementation\\n\\nHere\'s how to apply rate limiting in real microservice controllers:\\n\\n```typescript\\n// controllers/api.controller.ts\\nimport {\\n  Controller,\\n  Get,\\n  Post,\\n  Body,\\n  UseGuards,\\n  Req,\\n  HttpStatus,\\n  HttpException,\\n} from \'@nestjs/common\';\\nimport { Request } from \'express\';\\nimport { RateLimitGuard } from \'../guards/rate-limit.guard\';\\nimport {\\n  PublicApiRateLimit,\\n  AuthRateLimit,\\n  TieredRateLimit,\\n  InternalServiceRateLimit,\\n} from \'../decorators/rate-limit.decorator\';\\n\\n@Controller(\'api/v1\')\\n@UseGuards(RateLimitGuard)\\nexport class ApiController {\\n  \\n  @Get(\'public/data\')\\n  @PublicApiRateLimit()\\n  async getPublicData() {\\n    return { data: \'This is public data with standard rate limiting\' };\\n  }\\n\\n  @Post(\'auth/login\')\\n  @AuthRateLimit()\\n  async login(@Body() credentials: any, @Req() request: Request) {\\n    // Implement authentication logic\\n    return { token: \'jwt-token\' };\\n  }\\n\\n  @Get(\'user/profile\')\\n  @TieredRateLimit()\\n  async getUserProfile(@Req() request: Request) {\\n    // Dynamic rate limiting based on user tier\\n    const user = (request as any).user;\\n    \\n    // This would be handled by a custom guard that sets limits based on user tier\\n    return { profile: user.profile };\\n  }\\n\\n  @Post(\'internal/sync\')\\n  @InternalServiceRateLimit()\\n  async internalSync(@Body() data: any, @Req() request: Request) {\\n    // Internal service communication with special rate limiting\\n    return { status: \'synced\' };\\n  }\\n\\n  @Get(\'premium/analytics\')\\n  @RateLimit({\\n    algorithm: \'sliding-window\',\\n    limit: 1000,\\n    windowMs: 60000,\\n    keyGenerator: (req) => {\\n      const user = (req as any).user;\\n      const tier = user?.plan || \'free\';\\n      \\n      // Different limits for different tiers\\n      const limits = {\\n        free: 10,\\n        pro: 100,\\n        enterprise: 1000,\\n      };\\n      \\n      return `analytics:${tier}:${user?.id || req.ip}`;\\n    },\\n    onLimitReached: (req, res) => {\\n      // Custom handling for limit exceeded\\n      const user = (req as any).user;\\n      if (user?.plan === \'free\') {\\n        // Suggest upgrade for free users\\n        res.setHeader(\'X-Upgrade-Suggestion\', \'Consider upgrading to Pro for higher limits\');\\n      }\\n    },\\n  })\\n  async getPremiumAnalytics(@Req() request: Request) {\\n    const user = (request as any).user;\\n    const tierLimits = {\\n      free: 10,\\n      pro: 100,\\n      enterprise: 1000,\\n    };\\n    \\n    const userLimit = tierLimits[user?.plan] || tierLimits.free;\\n    \\n    return {\\n      analytics: \'Advanced analytics data\',\\n      currentPlan: user?.plan || \'free\',\\n      apiLimit: userLimit,\\n    };\\n  }\\n}\\n```\\n\\n## Middleware for Global Rate Limiting\\n\\nImplement middleware for application-wide rate limiting with exemptions.\\n\\n```typescript\\n// middleware/global-rate-limit.middleware.ts\\nimport { Injectable, NestMiddleware, HttpException, HttpStatus } from \'@nestjs/common\';\\nimport { Request, Response, NextFunction } from \'express\';\\nimport { TokenBucketService } from \'../rate-limiting/token-bucket.service\';\\n\\n@Injectable()\\nexport class GlobalRateLimitMiddleware implements NestMiddleware {\\n  constructor(private readonly tokenBucket: TokenBucketService) {}\\n\\n  async use(req: Request, res: Response, next: NextFunction) {\\n    // Skip rate limiting for certain paths\\n    const exemptPaths = [\\n      \'/health\',\\n      \'/metrics\',\\n      \'/api/v1/internal\',\\n    ];\\n\\n    if (exemptPaths.some(path => req.path.startsWith(path))) {\\n      return next();\\n    }\\n\\n    // Skip for internal service calls\\n    if (req.headers[\'x-service-token\'] === process.env.INTERNAL_SERVICE_TOKEN) {\\n      return next();\\n    }\\n\\n    // Apply global rate limiting\\n    const clientKey = this.generateClientKey(req);\\n    const result = await this.tokenBucket.checkRateLimit(clientKey, {\\n      capacity: 10000,     // 10k requests\\n      refillRate: 100,     // 100 requests per second\\n      windowSize: 3600,    // 1 hour window\\n    });\\n\\n    // Set rate limit headers\\n    res.setHeader(\'X-Global-RateLimit-Limit\', \'10000\');\\n    res.setHeader(\'X-Global-RateLimit-Remaining\', result.remainingTokens);\\n    res.setHeader(\'X-Global-RateLimit-Reset\', result.resetTime);\\n\\n    if (!result.allowed) {\\n      throw new HttpException(\\n        {\\n          statusCode: HttpStatus.TOO_MANY_REQUESTS,\\n          message: \'Global rate limit exceeded\',\\n          error: \'Too Many Requests\',\\n          retryAfter: result.retryAfter,\\n        },\\n        HttpStatus.TOO_MANY_REQUESTS\\n      );\\n    }\\n\\n    next();\\n  }\\n\\n  private generateClientKey(req: Request): string {\\n    // Prioritize API key, then user ID, then IP\\n    const apiKey = req.headers[\'x-api-key\'] as string;\\n    const userId = (req as any).user?.id;\\n    const ip = req.ip || req.connection.remoteAddress;\\n\\n    if (apiKey) {\\n      return `global:api:${apiKey}`;\\n    }\\n    if (userId) {\\n      return `global:user:${userId}`;\\n    }\\n    return `global:ip:${ip}`;\\n  }\\n}\\n```\\n\\n## Configuration and Module Setup\\n\\nSet up the rate limiting module with proper configuration management.\\n\\n```typescript\\n// modules/rate-limit.module.ts\\nimport { Module, Global } from \'@nestjs/common\';\\nimport { ConfigModule, ConfigService } from \'@nestjs/config\';\\nimport { RedisModule } from \'@nestjs-modules/ioredis\';\\nimport { TokenBucketService } from \'../rate-limiting/token-bucket.service\';\\nimport { SlidingWindowService } from \'../rate-limiting/sliding-window.service\';\\nimport { DistributedRateLimitService } from \'../services/distributed-rate-limit.service\';\\nimport { RateLimitGuard } from \'../guards/rate-limit.guard\';\\n\\n@Global()\\n@Module({\\n  imports: [\\n    ConfigModule,\\n    RedisModule.forRootAsync({\\n      imports: [ConfigModule],\\n      useFactory: (configService: ConfigService) => ({\\n        config: {\\n          host: configService.get(\'REDIS_HOST\', \'localhost\'),\\n          port: configService.get(\'REDIS_PORT\', 6379),\\n          password: configService.get(\'REDIS_PASSWORD\'),\\n          db: configService.get(\'REDIS_DB\', 0),\\n          keyPrefix: configService.get(\'REDIS_KEY_PREFIX\', \'rate_limit:\'),\\n          retryDelayOnFailover: 100,\\n          enableReadyCheck: true,\\n          maxRetriesPerRequest: 3,\\n        },\\n      }),\\n      inject: [ConfigService],\\n    }),\\n  ],\\n  providers: [\\n    TokenBucketService,\\n    SlidingWindowService,\\n    DistributedRateLimitService,\\n    RateLimitGuard,\\n    {\\n      provide: \'CONFIG_SERVICE\',\\n      useFactory: (configService: ConfigService) => configService,\\n      inject: [ConfigService],\\n    },\\n  ],\\n  exports: [\\n    TokenBucketService,\\n    SlidingWindowService,\\n    DistributedRateLimitService,\\n    RateLimitGuard,\\n  ],\\n})\\nexport class RateLimitModule {}\\n\\n// config/rate-limit.config.ts\\nexport const rateLimitConfig = () => ({\\n  rateLimit: {\\n    default: {\\n      algorithm: \'sliding-window\',\\n      limit: 100,\\n      windowMs: 60000,\\n      standardHeaders: true,\\n      legacyHeaders: false,\\n    },\\n    redis: {\\n      host: process.env.REDIS_HOST || \'localhost\',\\n      port: parseInt(process.env.REDIS_PORT) || 6379,\\n      password: process.env.REDIS_PASSWORD,\\n      db: parseInt(process.env.REDIS_DB) || 0,\\n      keyPrefix: process.env.REDIS_KEY_PREFIX || \'rate_limit:\',\\n    },\\n    microservice: {\\n      instanceId: process.env.POD_NAME || `local-${Date.now()}`,\\n      serviceName: process.env.SERVICE_NAME || \'unknown-service\',\\n      coordinationStrategy: process.env.RATE_LIMIT_COORDINATION || \'redis\',\\n    },\\n  },\\n});\\n```\\n\\n## Monitoring and Observability\\n\\nImplement comprehensive monitoring for rate limiting performance.\\n\\n```typescript\\n// monitoring/rate-limit-metrics.service.ts\\nimport { Injectable } from \'@nestjs/common\';\\nimport { Gauge, Counter, Histogram, register } from \'prom-client\';\\n\\n@Injectable()\\nexport class RateLimitMetricsService {\\n  private readonly requestsTotal: Counter<string>;\\n  private readonly requestsBlocked: Counter<string>;\\n  private readonly rateLimitUsage: Gauge<string>;\\n  private readonly rateLimitLatency: Histogram<string>;\\n\\n  constructor() {\\n    this.requestsTotal = new Counter({\\n      name: \'rate_limit_requests_total\',\\n      help: \'Total number of requests processed by rate limiter\',\\n      labelNames: [\'service\', \'algorithm\', \'key_type\'],\\n      registers: [register],\\n    });\\n\\n    this.requestsBlocked = new Counter({\\n      name: \'rate_limit_requests_blocked_total\',\\n      help: \'Total number of requests blocked by rate limiter\',\\n      labelNames: [\'service\', \'algorithm\', \'key_type\', \'reason\'],\\n      registers: [register],\\n    });\\n\\n    this.rateLimitUsage = new Gauge({\\n      name: \'rate_limit_usage_ratio\',\\n      help: \'Current usage ratio of rate limits (0-1)\',\\n      labelNames: [\'service\', \'algorithm\', \'key_type\'],\\n      registers: [register],\\n    });\\n\\n    this.rateLimitLatency = new Histogram({\\n      name: \'rate_limit_check_duration_seconds\',\\n      help: \'Time spent checking rate limits\',\\n      labelNames: [\'service\', \'algorithm\'],\\n      buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0],\\n      registers: [register],\\n    });\\n  }\\n\\n  recordRequest(service: string, algorithm: string, keyType: string): void {\\n    this.requestsTotal.inc({ service, algorithm, key_type: keyType });\\n  }\\n\\n  recordBlocked(\\n    service: string, \\n    algorithm: string, \\n    keyType: string, \\n    reason: string\\n  ): void {\\n    this.requestsBlocked.inc({ service, algorithm, key_type: keyType, reason });\\n  }\\n\\n  recordUsage(\\n    service: string, \\n    algorithm: string, \\n    keyType: string, \\n    ratio: number\\n  ): void {\\n    this.rateLimitUsage.set({ service, algorithm, key_type: keyType }, ratio);\\n  }\\n\\n  recordLatency(service: string, algorithm: string, duration: number): void {\\n    this.rateLimitLatency.observe({ service, algorithm }, duration);\\n  }\\n\\n  async getMetrics(): Promise<string> {\\n    return register.metrics();\\n  }\\n}\\n\\n// Health check for rate limiting system\\nimport { Injectable } from \'@nestjs/common\';\\nimport { HealthIndicator, HealthIndicatorResult, HealthCheckError } from \'@nestjs/terminus\';\\nimport { RedisService } from \'@nestjs-modules/ioredis\';\\n\\n@Injectable()\\nexport class RateLimitHealthIndicator extends HealthIndicator {\\n  constructor(private readonly redis: RedisService) {\\n    super();\\n  }\\n\\n  async isHealthy(key: string): Promise<HealthIndicatorResult> {\\n    try {\\n      // Test Redis connectivity\\n      const start = Date.now();\\n      await this.redis.ping();\\n      const latency = Date.now() - start;\\n\\n      // Test rate limiting functionality\\n      const testKey = `health_check:${Date.now()}`;\\n      await this.redis.incr(testKey);\\n      await this.redis.expire(testKey, 60);\\n\\n      const isHealthy = latency < 100; // Consider healthy if latency < 100ms\\n\\n      const result = this.getStatus(key, isHealthy, {\\n        redis_latency: latency,\\n        redis_status: \'connected\',\\n      });\\n\\n      if (isHealthy) {\\n        return result;\\n      }\\n\\n      throw new HealthCheckError(\'Rate limiting is unhealthy\', result);\\n    } catch (error) {\\n      throw new HealthCheckError(\'Rate limiting check failed\', {\\n        [key]: {\\n          status: \'down\',\\n          error: error.message,\\n        },\\n      });\\n    }\\n  }\\n}\\n```\\n\\n## Testing Rate Limiting\\n\\nComprehensive testing strategies for rate limiting functionality.\\n\\n```typescript\\n// tests/rate-limit.integration.spec.ts\\nimport { Test, TestingModule } from \'@nestjs/testing\';\\nimport { INestApplication } from \'@nestjs/common\';\\nimport { RedisService } from \'@nestjs-modules/ioredis\';\\nimport * as request from \'supertest\';\\nimport { AppModule } from \'../src/app.module\';\\n\\ndescribe(\'Rate Limiting Integration\', () => {\\n  let app: INestApplication;\\n  let redis: RedisService;\\n\\n  beforeEach(async () => {\\n    const moduleFixture: TestingModule = await Test.createTestingModule({\\n      imports: [AppModule],\\n    }).compile();\\n\\n    app = moduleFixture.createNestApplication();\\n    redis = moduleFixture.get<RedisService>(RedisService);\\n    \\n    await app.init();\\n    \\n    // Clear Redis before each test\\n    await redis.flushdb();\\n  });\\n\\n  afterEach(async () => {\\n    await app.close();\\n  });\\n\\n  describe(\'Token Bucket Rate Limiting\', () => {\\n    it(\'should allow requests within capacity\', async () => {\\n      const endpoint = \'/api/v1/auth/login\';\\n      \\n      // Should allow first 5 requests (capacity)\\n      for (let i = 0; i < 5; i++) {\\n        const response = await request(app.getHttpServer())\\n          .post(endpoint)\\n          .send({ email: \'test@example.com\', password: \'password\' })\\n          .expect(200);\\n          \\n        expect(response.headers[\'ratelimit-remaining\']).toBeDefined();\\n      }\\n    });\\n\\n    it(\'should block requests exceeding capacity\', async () => {\\n      const endpoint = \'/api/v1/auth/login\';\\n      const email = \'test@example.com\';\\n      \\n      // Exhaust the token bucket\\n      for (let i = 0; i < 5; i++) {\\n        await request(app.getHttpServer())\\n          .post(endpoint)\\n          .send({ email, password: \'password\' });\\n      }\\n      \\n      // Next request should be blocked\\n      const response = await request(app.getHttpServer())\\n        .post(endpoint)\\n        .send({ email, password: \'password\' })\\n        .expect(429);\\n        \\n      expect(response.body.message).toContain(\'Too many authentication attempts\');\\n      expect(response.headers[\'retry-after\']).toBeDefined();\\n    });\\n\\n    it(\'should refill tokens over time\', async () => {\\n      const endpoint = \'/api/v1/auth/login\';\\n      \\n      // Exhaust capacity\\n      for (let i = 0; i < 5; i++) {\\n        await request(app.getHttpServer())\\n          .post(endpoint)\\n          .send({ email: \'test@example.com\', password: \'password\' });\\n      }\\n      \\n      // Wait for token refill (mock time or use actual delay)\\n      await new Promise(resolve => setTimeout(resolve, 60000)); // 1 minute\\n      \\n      // Should allow request after refill\\n      await request(app.getHttpServer())\\n        .post(endpoint)\\n        .send({ email: \'test@example.com\', password: \'password\' })\\n        .expect(200);\\n    });\\n  });\\n\\n  describe(\'Sliding Window Rate Limiting\', () => {\\n    it(\'should track requests in sliding window\', async () => {\\n      const endpoint = \'/api/v1/public/data\';\\n      \\n      // Make requests at different times within window\\n      const responses = [];\\n      for (let i = 0; i < 10; i++) {\\n        const response = await request(app.getHttpServer())\\n          .get(endpoint)\\n          .expect(200);\\n        responses.push(response);\\n        \\n        // Small delay between requests\\n        await new Promise(resolve => setTimeout(resolve, 100));\\n      }\\n      \\n      // Check that remaining count decreases properly\\n      responses.forEach((response, index) => {\\n        const remaining = parseInt(response.headers[\'ratelimit-remaining\']);\\n        expect(remaining).toBe(1000 - index - 1); // Assuming limit of 1000\\n      });\\n    });\\n  });\\n\\n  describe(\'Distributed Rate Limiting\', () => {\\n    it(\'should coordinate limits across service instances\', async () => {\\n      // This would require multiple app instances for proper testing\\n      // Mock multiple instances using different instance IDs\\n      \\n      const endpoint = \'/api/v1/premium/analytics\';\\n      const userId = \'test-user-123\';\\n      \\n      // Simulate requests from different instances\\n      for (let instance = 0; instance < 3; instance++) {\\n        // Mock different instance IDs\\n        process.env.POD_NAME = `test-pod-${instance}`;\\n        \\n        const response = await request(app.getHttpServer())\\n          .get(endpoint)\\n          .set(\'Authorization\', `Bearer ${generateJWT({ id: userId })}`)\\n          .expect(200);\\n          \\n        expect(response.headers[\'x-global-usage\']).toBeDefined();\\n      }\\n    });\\n  });\\n\\n  describe(\'Rate Limit Headers\', () => {\\n    it(\'should return correct rate limit headers\', async () => {\\n      const response = await request(app.getHttpServer())\\n        .get(\'/api/v1/public/data\')\\n        .expect(200);\\n        \\n      expect(response.headers[\'ratelimit-limit\']).toBeDefined();\\n      expect(response.headers[\'ratelimit-remaining\']).toBeDefined();\\n      expect(response.headers[\'ratelimit-reset\']).toBeDefined();\\n    });\\n\\n    it(\'should return retry-after header when rate limited\', async () => {\\n      const endpoint = \'/api/v1/auth/login\';\\n      \\n      // Exhaust rate limit\\n      for (let i = 0; i < 5; i++) {\\n        await request(app.getHttpServer())\\n          .post(endpoint)\\n          .send({ email: \'test@example.com\', password: \'password\' });\\n      }\\n      \\n      const response = await request(app.getHttpServer())\\n        .post(endpoint)\\n        .send({ email: \'test@example.com\', password: \'password\' })\\n        .expect(429);\\n        \\n      expect(response.headers[\'retry-after\']).toBeDefined();\\n      expect(parseInt(response.headers[\'retry-after\'])).toBeGreaterThan(0);\\n    });\\n  });\\n});\\n\\n// Load testing for rate limiting\\ndescribe(\'Rate Limiting Load Tests\', () => {\\n  it(\'should handle high concurrent load\', async () => {\\n    const concurrentRequests = 100;\\n    const endpoint = \'/api/v1/public/data\';\\n    \\n    const promises = Array(concurrentRequests)\\n      .fill(null)\\n      .map(() => \\n        request(app.getHttpServer())\\n          .get(endpoint)\\n      );\\n    \\n    const results = await Promise.allSettled(promises);\\n    \\n    const successful = results.filter(r => \\n      r.status === \'fulfilled\' && r.value.status === 200\\n    ).length;\\n    \\n    const rateLimited = results.filter(r => \\n      r.status === \'fulfilled\' && r.value.status === 429\\n    ).length;\\n    \\n    expect(successful + rateLimited).toBe(concurrentRequests);\\n    expect(successful).toBeLessThanOrEqual(1000); // Assuming limit of 1000\\n  });\\n});\\n\\nfunction generateJWT(payload: any): string {\\n  // Mock JWT generation for testing\\n  return \'mock.jwt.token\';\\n}\\n```\\n\\n## Best Practices and Production Considerations\\n\\n### \ud83d\udd27 **Configuration Management**\\n\\n1. **Environment-Specific Limits**: Use different rate limits for development, staging, and production\\n2. **Dynamic Configuration**: Allow runtime adjustment of rate limits without deployment\\n3. **Graceful Degradation**: Fall back to in-memory limiting if Redis is unavailable\\n4. **Circuit Breakers**: Implement circuit breakers for rate limiting services\\n\\n### \ud83d\udcca **Monitoring and Alerting**\\n\\n1. **Metrics Collection**: Track rate limit usage, blocked requests, and system health\\n2. **Alerting**: Set up alerts for high block rates or system failures\\n3. **Dashboard**: Create monitoring dashboards for real-time rate limit visibility\\n4. **Log Analysis**: Analyze logs to identify patterns and potential abuse\\n\\n### \u26a1 **Performance Optimization**\\n\\n1. **Redis Optimization**: Use Redis clusters for high availability and performance\\n2. **Lua Scripts**: Leverage atomic Lua scripts for consistent rate limiting\\n3. **Connection Pooling**: Optimize Redis connection management\\n4. **Caching**: Cache rate limit decisions for frequently accessed keys\\n\\n### \ud83d\udee1\ufe0f **Security Considerations**\\n\\n1. **Key Generation**: Use secure, unpredictable key generation strategies\\n2. **API Key Management**: Implement proper API key validation and rotation\\n3. **Bypass Protection**: Secure internal service communication channels\\n4. **Audit Logging**: Log all rate limit decisions for security auditing\\n\\n## Conclusion\\n\\nImplementing robust rate limiting in NestJS microservices requires careful consideration of algorithms, distribution strategies, and production requirements. The solutions presented here provide:\\n\\n- **Multiple Rate Limiting Algorithms**: Token bucket, sliding window, and fixed window implementations\\n- **Distributed Coordination**: Service-aware rate limiting across multiple instances  \\n- **Flexible Configuration**: Decorator-based and middleware approaches for different use cases\\n- **Production Readiness**: Monitoring, health checks, and comprehensive testing\\n- **Performance Optimization**: Redis-based storage with efficient Lua scripts\\n\\nStart with simple rate limiting for critical endpoints, gradually expanding to more sophisticated distributed strategies as your microservice architecture grows. Always monitor rate limiting effectiveness and adjust limits based on actual usage patterns and business requirements.\\n\\nRemember that rate limiting is just one part of a comprehensive security and performance strategy. Combine it with other techniques like authentication, authorization, caching, and circuit breakers for maximum effectiveness in production environments.\\n\\n---\\n\\n*Ready to implement rate limiting? This comprehensive guide provides everything you need to build robust rate limiting for your NestJS microservices architecture.*"},{"id":"/ELASTICSEARCH_SETUP","metadata":{"permalink":"/fullstack-dev/blog/ELASTICSEARCH_SETUP","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/ELASTICSEARCH_SETUP.md","source":"@site/blog/ELASTICSEARCH_SETUP.md","title":"Elasticsearch Full-Text Search Setup","description":"This guide will help you set up Elasticsearch for full-text search functionality in your Next.js application.","date":"2025-10-01T16:11:37.000Z","tags":[],"readingTime":4.37,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Handling Rate Limiting in NestJS for Production Microservices","permalink":"/fullstack-dev/blog/nestjs-rate-limiting-microservices"},"nextItem":{"title":"SEO Implementation Guide","permalink":"/fullstack-dev/blog/SEO_IMPLEMENTATION"}},"content":"This guide will help you set up Elasticsearch for full-text search functionality in your Next.js application.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Prerequisites\\n\\n- Node.js and npm/yarn installed\\n- Next.js application running\\n- Supabase database with posts\\n\\n## 1. Install Elasticsearch\\n\\n### Option A: Using Docker (Recommended for development)\\n\\n```bash\\n# Start Elasticsearch with Docker\\ndocker run -d \\\\\\n  --name elasticsearch \\\\\\n  -p 9200:9200 \\\\\\n  -e \\"discovery.type=single-node\\" \\\\\\n  -e \\"xpack.security.enabled=false\\" \\\\\\n  elasticsearch:8.11.0\\n\\n# Verify Elasticsearch is running\\ncurl http://localhost:9200\\n```\\n\\n### Option B: Local Installation\\n\\n1. Download Elasticsearch from [elastic.co](https://www.elastic.co/downloads/elasticsearch)\\n2. Follow the installation guide for your operating system\\n3. Start Elasticsearch service\\n\\n## 2. Environment Variables\\n\\nAdd these environment variables to your `.env.local` file:\\n\\n```env\\n# Elasticsearch Configuration\\nELASTICSEARCH_URL=http://localhost:9200\\nELASTICSEARCH_POSTS_INDEX=posts\\n\\n# Optional: Authentication (if your Elasticsearch requires auth)\\n# ELASTICSEARCH_USERNAME=your_username\\n# ELASTICSEARCH_PASSWORD=your_password\\n# ELASTICSEARCH_APIKEY=your_api_key\\n```\\n\\n## 3. Initialize the Index\\n\\n### Option A: Using the Web Interface (Development)\\n\\n1. Go to your posts page (`/posts`)\\n2. In the debug section, click \\"Check Status\\" to verify Elasticsearch connection\\n3. Click \\"Initialize Index\\" to create the index and bulk import existing posts\\n\\n### Option B: Using the Setup Script\\n\\n```bash\\n# Run the setup script\\nnpx tsx scripts/setup-elasticsearch.ts\\n\\n# Or add to package.json scripts:\\n# \\"setup:elasticsearch\\": \\"tsx scripts/setup-elasticsearch.ts\\"\\n# Then run: npm run setup:elasticsearch\\n```\\n\\n### Option C: Using the API Endpoint\\n\\n```bash\\n# Check Elasticsearch status\\ncurl http://localhost:3000/api/elasticsearch/init\\n\\n# Initialize the index\\ncurl -X POST http://localhost:3000/api/elasticsearch/init\\n```\\n\\n## 4. Features\\n\\n### Search Functionality\\n\\n- **Full-text search**: Search across post titles and content\\n- **Fuzzy matching**: Handles typos and similar words\\n- **Highlighting**: Search terms are highlighted in results\\n- **Fallback**: Falls back to database search if Elasticsearch is unavailable\\n- **Responsive**: Search bar available in navbar on desktop and mobile\\n\\n### Search Features\\n\\n- **Keyboard shortcut**: Press `Cmd+K` (Mac) or `Ctrl+K` (Windows/Linux) to focus search\\n- **Real-time results**: Search results update as you type\\n- **Pagination**: Large result sets are paginated\\n- **Sorting**: Results sorted by relevance score and creation date\\n\\n## 5. API Endpoints\\n\\n### Search Posts\\n```\\nGET /api/posts/search?q=search_term&page=1&limit=10\\n```\\n\\n### Initialize Elasticsearch\\n```\\nGET /api/elasticsearch/init    # Check status\\nPOST /api/elasticsearch/init   # Initialize index\\n```\\n\\n### Sync Posts to Elasticsearch\\n```\\nGET /api/elasticsearch/sync     # Health check and endpoints info\\nPOST /api/elasticsearch/sync?action=sync   # Sync all posts\\nPOST /api/elasticsearch/sync?action=health # Health check only\\n```\\n\\n## 6. Automatic Indexing\\n\\nPosts are automatically indexed in Elasticsearch when:\\n- **Creating a post**: New posts are indexed immediately after successful creation\\n- **Updating a post**: Modified posts are re-indexed with the latest content\\n- **Deleting a post**: Posts are removed from the Elasticsearch index\\n\\nThe indexing happens automatically in the background and won\'t affect the user experience. If Elasticsearch is unavailable, the database operations will still succeed, and only a warning will be logged.\\n\\n### Manual Sync\\n\\nIf you need to sync existing posts or re-index everything:\\n\\n#### Using the API\\n```bash\\n# Check Elasticsearch health\\ncurl http://localhost:3000/api/elasticsearch/sync\\n\\n# Sync all posts to Elasticsearch\\ncurl -X POST \\"http://localhost:3000/api/elasticsearch/sync?action=sync\\"\\n\\n# Health check only\\ncurl -X POST \\"http://localhost:3000/api/elasticsearch/sync?action=health\\"\\n```\\n\\n#### Using the Sync Service\\n```typescript\\nimport { syncPostsToElasticsearch } from \'@/shared/services/sync\';\\n\\nconst result = await syncPostsToElasticsearch();\\nconsole.log(`Synced ${result.syncedCount} posts`);\\n```\\n\\n### Monitoring Indexing\\n\\nDuring development, you can monitor indexing in the browser console:\\n- \u2705 `Post indexed in Elasticsearch: 123`\\n- \u2705 `Post updated in Elasticsearch: 123`\\n- \u2705 `Post deleted from Elasticsearch: 123`\\n- \u26a0\ufe0f `Failed to index post in Elasticsearch: [error details]`\\n\\n## 7. Troubleshooting\\n\\n### Elasticsearch not connecting\\n\\n1. Verify Elasticsearch is running: `curl http://localhost:9200`\\n2. Check environment variables in `.env.local`\\n3. Check Docker container status: `docker ps`\\n4. View Docker logs: `docker logs elasticsearch`\\n\\n### Search not working\\n\\n1. Check if index exists: Use the debug panel in `/posts`\\n2. Verify posts are indexed: Look for \\"posts indexed\\" message\\n3. Check browser console for JavaScript errors\\n4. Verify API endpoints are working\\n\\n### Performance Issues\\n\\n1. Increase Elasticsearch memory: Add `-e \\"ES_JAVA_OPTS=-Xms512m -Xmx512m\\"` to Docker command\\n2. Optimize search queries in `elasticsearch.ts`\\n3. Implement caching for frequently searched terms\\n\\n## 8. Production Deployment\\n\\n### Elasticsearch Service\\n\\nFor production, consider using:\\n- **Elastic Cloud**: Managed Elasticsearch service\\n- **AWS OpenSearch**: Amazon\'s Elasticsearch service\\n- **Self-hosted**: Deploy Elasticsearch on your own infrastructure\\n\\n### Environment Variables for Production\\n\\n```env\\nELASTICSEARCH_URL=https://your-production-elasticsearch-url\\nELASTICSEARCH_APIKEY=your-production-api-key\\nELASTICSEARCH_POSTS_INDEX=production_posts\\n```\\n\\n### Security Considerations\\n\\n1. Enable authentication on Elasticsearch\\n2. Use HTTPS for Elasticsearch connections\\n3. Restrict network access to Elasticsearch\\n4. Regularly update Elasticsearch version\\n\\n## 9. Monitoring and Maintenance\\n\\n### Health Checks\\n\\nThe application includes health checks:\\n- Elasticsearch availability check in search API\\n- Fallback to database search if Elasticsearch is down\\n- Status indicators in development debug panel\\n\\n### Index Maintenance\\n\\n- **Reindexing**: Use the initialize endpoint to rebuild the index\\n- **Mapping updates**: Update the mapping in `elasticsearch.ts` and reinitialize\\n- **Performance monitoring**: Monitor query performance and optimize as needed\\n\\n## 10. Customization\\n\\n### Search Configuration\\n\\nEdit `src/shared/services/elasticsearch.ts` to customize:\\n- Search fields and boost values\\n- Highlighting settings\\n- Fuzzy matching sensitivity\\n- Result sorting criteria\\n\\n### UI Customization\\n\\nEdit components to customize:\\n- `src/shared/ui/search-bar/index.tsx`: Search bar appearance\\n- `src/features/posts/list/ui.tsx`: Results display\\n- `src/app/[locale]/components/Navbar.tsx`: Navbar integration\\n\\n## Support\\n\\nIf you encounter issues:\\n1. Check the troubleshooting section above\\n2. Review Elasticsearch logs\\n3. Check browser console for errors\\n4. Verify environment variables are set correctly"},{"id":"/SEO_IMPLEMENTATION","metadata":{"permalink":"/fullstack-dev/blog/SEO_IMPLEMENTATION","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/SEO_IMPLEMENTATION.md","source":"@site/blog/SEO_IMPLEMENTATION.md","title":"SEO Implementation Guide","description":"This document outlines the comprehensive SEO implementation added to the Next.js application using next-sitemap and next-seo packages.","date":"2025-10-01T16:11:37.000Z","tags":[],"readingTime":4.3,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"Elasticsearch Full-Text Search Setup","permalink":"/fullstack-dev/blog/ELASTICSEARCH_SETUP"},"nextItem":{"title":"SEO Setup with next-sitemap","permalink":"/fullstack-dev/blog/SEO_SETUP"}},"content":"This document outlines the comprehensive SEO implementation added to the Next.js application using `next-sitemap` and `next-seo` packages.\\n\\n\x3c!-- truncate --\x3e\\n\\n## \ud83d\udccb Overview\\n\\nThe SEO implementation includes:\\n- **Sitemap Generation** with `next-sitemap`\\n- **Meta Tags Management** with `next-seo`\\n- **Structured Data** (JSON-LD) support\\n- **Multilingual SEO** for English and Vietnamese\\n- **Social Media Optimization** (OpenGraph, Twitter Cards)\\n- **SEO Health Monitoring** tools\\n\\n## \ud83d\uddc2\ufe0f File Structure\\n\\n```\\nsrc/\\n\u251c\u2500\u2500 config/\\n\u2502   \u251c\u2500\u2500 seo.ts              # Default SEO configuration\\n\u2502   \u2514\u2500\u2500 seo-pages.ts        # Page-specific SEO configurations\\n\u251c\u2500\u2500 components/\\n\u2502   \u251c\u2500\u2500 SEOWrapper.tsx      # Global SEO wrapper component\\n\u2502   \u2514\u2500\u2500 PageSEO.tsx         # Page-specific SEO components\\n\u251c\u2500\u2500 hooks/\\n\u2502   \u2514\u2500\u2500 useSEO.ts          # SEO utility hooks\\n\u2514\u2500\u2500 app/\\n    \u2514\u2500\u2500 [locale]/\\n        \u2514\u2500\u2500 layout.tsx      # Updated with SEO integration\\n\\nConfiguration Files:\\n\u251c\u2500\u2500 next-sitemap.config.js  # Sitemap generation configuration\\n\u2514\u2500\u2500 scripts/\\n    \u2514\u2500\u2500 seo-health-check.js # SEO monitoring script\\n```\\n\\n## \ud83d\udd27 Core Components\\n\\n### 1. Default SEO Configuration (`src/config/seo.ts`)\\n\\n```typescript\\nexport const defaultSEO: DefaultSeoProps = {\\n  titleTemplate: \'%s | Next.js Production App\',\\n  defaultTitle: \'Next.js Production App\',\\n  description: \'A production-ready Next.js application with modern features...\',\\n  openGraph: {\\n    type: \'website\',\\n    locale: \'en_US\',\\n    url: \'https://next-for-prod.com/\',\\n    siteName: \'Next.js Production App\',\\n    images: [{ url: \'/og-default.jpg\', width: 1200, height: 630 }]\\n  },\\n  twitter: {\\n    handle: \'@nextjsprod\',\\n    site: \'@nextjsprod\',\\n    cardType: \'summary_large_image\'\\n  }\\n};\\n```\\n\\n### 2. Page-Specific SEO (`src/config/seo-pages.ts`)\\n\\nProvides localized SEO configurations for all major pages:\\n- Home, About, Libraries, Tools, Calendar, Posts, Feedback\\n- Authentication pages (Login, Signup)\\n- Multilingual support (English/Vietnamese)\\n- Canonical URLs and language alternates\\n\\n### 3. SEO Components (`src/components/PageSEO.tsx`)\\n\\n```typescript\\n// Specialized components for each page type\\n<HomeSEO />\\n<AboutSEO />\\n<LibsSEO />\\n<ArticleSEO \\n  title=\\"Article Title\\"\\n  description=\\"Article description\\"\\n  url=\\"https://example.com/article\\"\\n  datePublished=\\"2024-01-01\\"\\n  image=\\"/article-image.jpg\\"\\n/>\\n```\\n\\n### 4. SEO Hooks (`src/hooks/useSEO.ts`)\\n\\n```typescript\\n// Automatic SEO based on current route\\nconst seoConfig = useSEO();\\n\\n// Manual page specification\\nconst seoConfig = useSEO(\'home\');\\n\\n// Get canonical URL\\nconst canonicalUrl = useCanonicalUrl();\\n\\n// Generate structured data\\nconst organizationData = useStructuredData(\'organization\');\\n```\\n\\n## \ud83d\uddfa\ufe0f Sitemap Configuration\\n\\n### next-sitemap.config.js\\n\\n```javascript\\nmodule.exports = {\\n  siteUrl: process.env.SITE_URL || \'https://yourdomain.com\',\\n  generateRobotstxt: true,\\n  sitemapSize: 7000,\\n  changefreq: \'daily\',\\n  priority: 0.7,\\n  additionalPaths: async (config) => {\\n    // 29 URLs total with multilingual support\\n    // Static pages, dynamic routes, auth pages\\n  },\\n  robotsTxtOptions: {\\n    policies: [\\n      { userAgent: \'*\', allow: \'/\' },\\n      { userAgent: \'GPTBot\', disallow: [\'/\'] },\\n      { userAgent: \'ChatGPT-User\', disallow: [\'/\'] },\\n      { userAgent: \'CCBot\', disallow: [\'/\'] }\\n    ]\\n  }\\n};\\n```\\n\\n### Generated Files\\n- **`public/sitemap.xml`**: 29 URLs with proper priorities and change frequencies\\n- **`public/robots.txt`**: AI crawler blocking and sitemap references\\n\\n## \ud83c\udf10 Multilingual SEO\\n\\nEach page supports both English and Vietnamese with:\\n- Localized titles and descriptions\\n- Proper `hreflang` attributes\\n- Language-specific OpenGraph images\\n- Canonical URLs for each locale\\n\\n```typescript\\n// English\\ncanonical: `${BASE_URL}/en/about`\\nhreflang: [\\n  { hrefLang: \'en\', href: `${BASE_URL}/en/about` },\\n  { hrefLang: \'vi\', href: `${BASE_URL}/vi/about` },\\n  { hrefLang: \'x-default\', href: `${BASE_URL}/en/about` }\\n]\\n\\n// Vietnamese  \\ncanonical: `${BASE_URL}/vi/about`\\nlocale: \'vi_VN\'\\n```\\n\\n## \ud83d\udcca Structured Data Support\\n\\n### Organization Schema\\n```json\\n{\\n  \\"@context\\": \\"https://schema.org\\",\\n  \\"@type\\": \\"Organization\\",\\n  \\"name\\": \\"Next.js Production App\\",\\n  \\"url\\": \\"https://next-for-prod.com\\",\\n  \\"logo\\": \\"https://next-for-prod.com/logo.png\\"\\n}\\n```\\n\\n### Article Schema\\n```json\\n{\\n  \\"@context\\": \\"https://schema.org\\",\\n  \\"@type\\": \\"Article\\",\\n  \\"headline\\": \\"Article Title\\",\\n  \\"datePublished\\": \\"2024-01-01\\",\\n  \\"author\\": { \\"@type\\": \\"Person\\", \\"name\\": \\"Author Name\\" }\\n}\\n```\\n\\n### Breadcrumb Schema\\n```json\\n{\\n  \\"@context\\": \\"https://schema.org\\",\\n  \\"@type\\": \\"BreadcrumbList\\",\\n  \\"itemListElement\\": [...]\\n}\\n```\\n\\n## \ud83d\ude80 Usage Examples\\n\\n### 1. Basic Page SEO\\n```tsx\\nimport { HomeSEO } from \'@/components/PageSEO\';\\n\\nexport default function HomePage() {\\n  return (\\n    <>\\n      <HomeSEO />\\n      <main>\\n        {/* Page content */}\\n      </main>\\n    </>\\n  );\\n}\\n```\\n\\n### 2. Custom SEO Override\\n```tsx\\nimport { PageSEO } from \'@/components/PageSEO\';\\n\\nexport default function CustomPage() {\\n  return (\\n    <>\\n      <PageSEO \\n        pageKey=\\"home\\"\\n        customSEO={{\\n          title: \'Custom Title\',\\n          description: \'Custom description\'\\n        }}\\n      />\\n      <main>\\n        {/* Page content */}\\n      </main>\\n    </>\\n  );\\n}\\n```\\n\\n### 3. Article with Structured Data\\n```tsx\\nimport { ArticleSEO } from \'@/components/PageSEO\';\\n\\nexport default function BlogPost() {\\n  return (\\n    <>\\n      <ArticleSEO\\n        title=\\"How to Build Production-Ready Next.js Apps\\"\\n        description=\\"Complete guide to building scalable Next.js applications\\"\\n        url=\\"https://next-for-prod.com/en/posts/production-nextjs\\"\\n        datePublished=\\"2024-01-15\\"\\n        authorName=\\"Development Team\\"\\n        image=\\"/posts/production-nextjs-og.jpg\\"\\n      />\\n      <article>\\n        {/* Article content */}\\n      </article>\\n    </>\\n  );\\n}\\n```\\n\\n## \ud83d\udd0d SEO Health Monitoring\\n\\n### Health Check Script (`scripts/seo-health-check.js`)\\n\\n```bash\\nnode scripts/seo-health-check.js\\n```\\n\\nValidates:\\n- \u2705 Sitemap accessibility\\n- \u2705 Robots.txt functionality  \\n- \u2705 Page response codes\\n- \u2705 Meta tag presence\\n- \u2705 OpenGraph data\\n- \u2705 Structured data validation\\n\\n## \ud83d\udee0\ufe0f Build Integration\\n\\nThe sitemap automatically regenerates on every build:\\n\\n```json\\n{\\n  \\"scripts\\": {\\n    \\"build\\": \\"next build\\",\\n    \\"postbuild\\": \\"next-sitemap\\"\\n  }\\n}\\n```\\n\\n## \ud83d\udcc8 SEO Features Summary\\n\\n| Feature | Status | Description |\\n|---------|--------|-------------|\\n| **Sitemap Generation** | \u2705 | 29 URLs with multilingual support |\\n| **Robots.txt** | \u2705 | AI crawler blocking, sitemap references |\\n| **Meta Tags** | \u2705 | Title, description, viewport, theme-color |\\n| **OpenGraph** | \u2705 | Facebook, LinkedIn sharing optimization |\\n| **Twitter Cards** | \u2705 | Twitter sharing optimization |\\n| **Structured Data** | \u2705 | Organization, Article, Breadcrumb schemas |\\n| **Multilingual** | \u2705 | English/Vietnamese with hreflang |\\n| **Canonical URLs** | \u2705 | Proper URL canonicalization |\\n| **Health Monitoring** | \u2705 | Automated SEO validation |\\n\\n## \ud83c\udfaf Best Practices Implemented\\n\\n1. **Title Templates**: Consistent branding across all pages\\n2. **Unique Descriptions**: Each page has specific, descriptive meta descriptions\\n3. **Image Optimization**: 1200x630 OpenGraph images for optimal sharing\\n4. **Mobile Optimization**: Proper viewport and mobile meta tags\\n5. **Accessibility**: Alt text for images, proper heading structure\\n6. **Performance**: Minimal SEO overhead, efficient component structure\\n7. **Internationalization**: Proper language declarations and alternates\\n\\n## \ud83d\udd2e Future Enhancements\\n\\n- [ ] **Video Structured Data** for video content\\n- [ ] **FAQ Schema** for help pages\\n- [ ] **Local Business Schema** if applicable\\n- [ ] **Product Schema** for e-commerce features\\n- [ ] **Review Schema** for user-generated content\\n- [ ] **Event Schema** for calendar integration\\n- [ ] **Advanced Analytics** integration\\n- [ ] **Core Web Vitals** monitoring\\n\\n## \ud83d\udcda References\\n\\n- [next-seo Documentation](https://github.com/garmeeh/next-seo)\\n- [next-sitemap Documentation](https://github.com/iamvishnusankar/next-sitemap)\\n- [Google Search Console Guidelines](https://developers.google.com/search/docs)\\n- [Schema.org Documentation](https://schema.org/)\\n- [OpenGraph Protocol](https://ogp.me/)\\n- [Twitter Card Validator](https://cards-dev.twitter.com/validator)\\n\\n---\\n\\n**\ud83c\udf89 Your Next.js application now has enterprise-grade SEO implementation!**\\n\\nThe setup includes comprehensive sitemap generation, meta tag management, structured data, and multilingual support. All major search engines can now properly index and display your content in search results and social media platforms."},{"id":"/SEO_SETUP","metadata":{"permalink":"/fullstack-dev/blog/SEO_SETUP","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/SEO_SETUP.md","source":"@site/blog/SEO_SETUP.md","title":"SEO Setup with next-sitemap","description":"This project uses next-sitemap to generate SEO-optimized sitemaps and robots.txt files.","date":"2025-10-01T16:11:37.000Z","tags":[],"readingTime":2.08,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"SEO Implementation Guide","permalink":"/fullstack-dev/blog/SEO_IMPLEMENTATION"},"nextItem":{"title":"Social Login Setup (Google & GitHub)","permalink":"/fullstack-dev/blog/SOCIAL_LOGIN_SETUP"}},"content":"This project uses `next-sitemap` to generate SEO-optimized sitemaps and robots.txt files.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Features\\n\\n\u2705 **Automatic Sitemap Generation**: Generates comprehensive sitemaps for all public routes  \\n\u2705 **Multi-language Support**: Full support for English (`en`) and Vietnamese (`vi`) locales  \\n\u2705 **Robots.txt Generation**: Automatic robots.txt with AI crawler blocking  \\n\u2705 **SEO Optimization**: Proper priorities, change frequencies, and hreflang attributes  \\n\u2705 **Build Integration**: Automatically runs after each build  \\n\\n## Configuration\\n\\n### Environment Variables\\n\\nSet your production domain in your environment:\\n\\n```bash\\n# .env.local or .env.production\\nNEXT_PUBLIC_APP_URL=https://next-for-prod.com\\n```\\n\\n### Routes Included\\n\\nThe sitemap includes these public routes for both locales:\\n\\n- **Homepage**: `/en`, `/vi` (Priority: 1.0, Daily updates)\\n- **Content Pages**: `/about`, `/libs`, `/posts`, `/calendar` (High priority)\\n- **Tools**: `/tools`, `/search-*`, `/roadmap/*` (Medium priority)\\n- **Auth Pages**: `/login`, `/signup` (Lower priority)\\n- **Utility Pages**: `/feedback` (Medium priority)\\n\\n### Routes Excluded\\n\\nThese routes are excluded from search engines:\\n\\n- Admin pages (`/admin/*`)\\n- User profiles (`/profile/*`, `/me/*`)\\n- Private settings (`/settings`)\\n- API routes (`/api/*`)\\n- Test pages (`/test-*`)\\n- Authentication callbacks (`/auth/*`)\\n- Edit/create forms\\n\\n## Usage\\n\\n### Generate Sitemap\\n\\n```bash\\n# Manual generation\\npnpm sitemap:generate\\n\\n# Automatic generation after build\\npnpm build  # Runs next-sitemap via postbuild script\\n```\\n\\n### Generated Files\\n\\n- `public/sitemap.xml` - Main sitemap with all URLs\\n- `public/robots.txt` - Search engine directives\\n\\n### SEO Utilities\\n\\nThe project includes SEO utilities in `src/utils/seo.ts`:\\n\\n```typescript\\nimport { generatePageSEO } from \'@/utils/seo\';\\n\\nexport const metadata = generatePageSEO(\'home\', \'en\');\\n```\\n\\nAvailable functions:\\n- `generateSEOMetadata()` - Comprehensive metadata generation\\n- `generatePageSEO()` - Page-specific SEO metadata\\n- `generateStructuredData()` - JSON-LD structured data\\n\\n## AI Crawler Blocking\\n\\nThe robots.txt automatically blocks these AI crawlers:\\n- GPTBot\\n- ChatGPT-User  \\n- CCBot\\n- anthropic-ai\\n- Claude-Web\\n\\n## Monitoring\\n\\n### Google Search Console\\n\\n1. Submit your sitemap: `https://yourdomain.com/sitemap.xml`\\n2. Monitor indexing status\\n3. Check for crawl errors\\n\\n### Validation Tools\\n\\n- [Google Rich Results Test](https://search.google.com/test/rich-results)\\n- [Bing Webmaster Tools](https://www.bing.com/webmasters)\\n- [XML Sitemap Validator](https://www.xml-sitemaps.com/validate-xml-sitemap.html)\\n\\n## Configuration File\\n\\nEdit `next-sitemap.config.js` to:\\n- Add new routes\\n- Modify priorities and change frequencies\\n- Update hreflang mappings\\n- Exclude additional paths\\n\\n## Best Practices\\n\\n1. **Update sitemap after major changes**: Run `pnpm sitemap:generate`\\n2. **Monitor crawl budget**: Use robots.txt to guide crawlers to important pages\\n3. **Regular audits**: Check for 404s and crawl errors\\n4. **Performance**: Exclude dynamic/user-specific pages from sitemap\\n5. **Localization**: Ensure hreflang attributes are correct for international SEO\\n\\n## Troubleshooting\\n\\n### Sitemap not updating\\n- Run `pnpm build` to regenerate\\n- Check `next-sitemap.config.js` for syntax errors\\n- Verify environment variables\\n\\n### Routes missing from sitemap\\n- Add to `additionalPaths` in config\\n- Check exclusion rules\\n- Ensure pages are statically accessible\\n\\n### robots.txt issues  \\n- Verify `generateRobotsTxt: true` in config\\n- Check policy rules for conflicts\\n- Test with robots.txt validators"},{"id":"/SOCIAL_LOGIN_SETUP","metadata":{"permalink":"/fullstack-dev/blog/SOCIAL_LOGIN_SETUP","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/SOCIAL_LOGIN_SETUP.md","source":"@site/blog/SOCIAL_LOGIN_SETUP.md","title":"Social Login Setup (Google & GitHub)","description":"This document explains how to set up Google and GitHub OAuth providers in your Supabase project.","date":"2025-10-01T16:11:37.000Z","tags":[],"readingTime":2.04,"hasTruncateMarker":true,"authors":[],"frontMatter":{},"unlisted":false,"prevItem":{"title":"SEO Setup with next-sitemap","permalink":"/fullstack-dev/blog/SEO_SETUP"},"nextItem":{"title":"Introducing Next.js for Production","permalink":"/fullstack-dev/blog/introducing-fullstack-devuction"}},"content":"This document explains how to set up Google and GitHub OAuth providers in your Supabase project.\\n\\n\x3c!-- truncate --\x3e\\n\\n## \ud83d\udd27 Supabase Configuration\\n\\n### 1. Google OAuth Setup\\n\\n1. **Create Google OAuth App**:\\n   - Go to [Google Cloud Console](https://console.cloud.google.com/)\\n   - Create a new project or select existing one\\n   - Enable Google+ API\\n   - Go to \\"Credentials\\" \u2192 \\"Create Credentials\\" \u2192 \\"OAuth 2.0 Client IDs\\"\\n   - Choose \\"Web application\\"\\n   - Add authorized redirect URIs:\\n     ```\\n     https://your-project-ref.supabase.co/auth/v1/callback\\n     ```\\n\\n2. **Configure in Supabase**:\\n   - Go to your Supabase project dashboard\\n   - Navigate to \\"Authentication\\" \u2192 \\"Providers\\"\\n   - Enable \\"Google\\"\\n   - Add your Google Client ID and Client Secret\\n   - Save configuration\\n\\n### 2. GitHub OAuth Setup\\n\\n1. **Create GitHub OAuth App**:\\n   - Go to GitHub Settings \u2192 Developer settings \u2192 OAuth Apps\\n   - Click \\"New OAuth App\\"\\n   - Fill in the details:\\n     - Application name: Your app name\\n     - Homepage URL: Your app URL\\n     - Authorization callback URL:\\n       ```\\n       https://your-project-ref.supabase.co/auth/v1/callback\\n       ```\\n\\n2. **Configure in Supabase**:\\n   - Go to your Supabase project dashboard\\n   - Navigate to \\"Authentication\\" \u2192 \\"Providers\\"\\n   - Enable \\"GitHub\\"\\n   - Add your GitHub Client ID and Client Secret\\n   - Save configuration\\n\\n## \ud83d\ude80 Implementation Features\\n\\n### Frontend Components\\n\\n- **Login Form** (`src/features/auth/login-form/ui.tsx`):\\n  - Google login button with brand colors\\n  - GitHub login button\\n  - Loading states and error handling\\n  - Disabled state during authentication\\n\\n- **OAuth Callback** (`src/app/[locale]/auth/callback/route.ts`):\\n  - Handles OAuth redirects from providers\\n  - Exchanges authorization codes for sessions\\n  - Redirects with success/error messages\\n\\n### User Experience\\n\\n1. **Login Flow**:\\n   - User clicks Google/GitHub button\\n   - Redirected to provider\'s authorization page\\n   - After approval, redirected back to `/auth/callback`\\n   - Session established and redirected to home page\\n\\n2. **Error Handling**:\\n   - Provider authentication failures\\n   - Network errors\\n   - Invalid callback requests\\n   - User-friendly error messages\\n\\n## \ud83d\udd12 Security Features\\n\\n- **PKCE Flow**: Uses Proof Key for Code Exchange for security\\n- **State Validation**: Prevents CSRF attacks\\n- **Secure Redirects**: Only allows authorized redirect URLs\\n- **Session Management**: Proper cookie handling and session storage\\n\\n## \ud83c\udfa8 UI/UX Improvements\\n\\n- **Brand Colors**: Google (red) and GitHub (gray) themed buttons\\n- **Loading States**: Buttons disabled during authentication\\n- **Clear Messaging**: Success and error feedback\\n- **Responsive Design**: Works on mobile and desktop\\n\\n## \ud83d\udcdd Usage Notes\\n\\n- Make sure to configure your OAuth apps with the correct callback URLs\\n- Test both providers in development and production environments\\n- The callback route handles both success and error cases\\n- Users will be redirected to the home page after successful login\\n\\n## \ud83d\udc1b Troubleshooting\\n\\n1. **\\"Invalid redirect URI\\"**: Check your OAuth app callback URLs\\n2. **\\"Client ID not found\\"**: Verify Supabase provider configuration\\n3. **\\"Authentication failed\\"**: Check provider app permissions and status\\n4. **Session not persisting**: Verify cookie settings and domain configuration"},{"id":"introducing-fullstack-devuction","metadata":{"permalink":"/fullstack-dev/blog/introducing-fullstack-devuction","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2024-01-01-introducing-nextjs-for-production.md","source":"@site/blog/2024-01-01-introducing-nextjs-for-production.md","title":"Introducing Next.js for Production","description":"We\'re excited to introduce Next.js for Production - a comprehensive, enterprise-grade Next.js application that demonstrates best practices, modern architecture, and production-ready features.","date":"2024-01-01T00:00:00.000Z","tags":[{"inline":false,"label":"Next.js","permalink":"/fullstack-dev/blog/tags/nextjs","description":"Next.js framework and related topics"},{"inline":false,"label":"TypeScript","permalink":"/fullstack-dev/blog/tags/typescript","description":"TypeScript language and type safety"},{"inline":false,"label":"Production","permalink":"/fullstack-dev/blog/tags/production","description":"Production-ready development and deployment"},{"inline":false,"label":"Architecture","permalink":"/fullstack-dev/blog/tags/architecture","description":"Software architecture and design patterns"}],"readingTime":2.08,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"introducing-fullstack-devuction","title":"Introducing Next.js for Production","authors":["tam"],"tags":["nextjs","typescript","production","architecture"]},"unlisted":false,"prevItem":{"title":"Social Login Setup (Google & GitHub)","permalink":"/fullstack-dev/blog/SOCIAL_LOGIN_SETUP"},"nextItem":{"title":"Welcome","permalink":"/fullstack-dev/blog/welcome"}},"content":"We\'re excited to introduce **Next.js for Production** - a comprehensive, enterprise-grade Next.js application that demonstrates best practices, modern architecture, and production-ready features.\\n\\n\x3c!-- truncate --\x3e\\n\\n## What Makes This Project Special?\\n\\n### \ud83c\udfd7\ufe0f Modern Architecture\\n\\nOur project follows a clean, scalable architecture based on:\\n\\n- **Atomic Design**: Components are organized into atoms, molecules, organisms, and templates\\n- **Feature-Based Structure**: Each major feature is self-contained with its own components, hooks, and services\\n- **TypeScript First**: Complete type safety across the entire application\\n- **Domain-Driven Design**: Clear separation of business logic and presentation layers\\n\\n### \ud83d\udd10 Enterprise Security\\n\\nSecurity is built into every layer:\\n\\n- **Authentication**: Multi-provider auth with Supabase\\n- **Authorization**: Role-based access control (RBAC) with row-level security\\n- **Input Validation**: Zod schemas for runtime type checking\\n- **Rate Limiting**: API protection with Arcjet\\n- **Security Headers**: Comprehensive security headers configuration\\n\\n### \ud83d\udcca Real-World Features\\n\\nThe application includes features you\'d find in production applications:\\n\\n- **Calendar System**: Advanced calendar with recurring events and real-time updates\\n- **Library Management**: Elasticsearch-powered search with faceted filtering\\n- **User Management**: Complete user lifecycle with profiles and preferences\\n- **Internationalization**: Multi-language support with next-intl\\n- **Real-time Updates**: WebSocket integration for live data synchronization\\n\\n## Technical Highlights\\n\\n### Performance First\\n\\n- **Core Web Vitals**: Optimized for all performance metrics\\n- **Image Optimization**: Next.js Image component with CDN integration\\n- **Code Splitting**: Automatic route-based and component-based splitting\\n- **Caching Strategy**: Multi-layer caching with Redis and CDN\\n\\n### Developer Experience\\n\\n- **Hot Reload**: Instant feedback during development\\n- **Type Safety**: End-to-end TypeScript coverage\\n- **Testing**: Comprehensive test suite with Vitest and Playwright\\n- **Linting**: ESLint and Prettier for code quality\\n- **Git Hooks**: Automated quality checks with Husky\\n\\n### Production Ready\\n\\n- **Docker**: Multi-stage builds for optimization\\n- **CI/CD**: GitHub Actions for automated testing and deployment\\n- **Monitoring**: Health checks and error tracking\\n- **Scalability**: Horizontal scaling with load balancers\\n\\n## Getting Started\\n\\nGetting started is simple:\\n\\n```bash\\ngit clone https://github.com/tamnk74/fullstack-dev.git\\ncd fullstack-dev\\npnpm install\\npnpm dev\\n```\\n\\nVisit our [Setup Guide](/docs/setup) for detailed installation instructions.\\n\\n## What\'s Next?\\n\\nWe\'re continuously improving the project with:\\n\\n- **Mobile App**: React Native companion app\\n- **Advanced Analytics**: Enhanced reporting dashboard  \\n- **AI Integration**: Smart content recommendations\\n- **Workflow Automation**: Custom workflow builder\\n\\n## Contributing\\n\\nWe welcome contributions! Check out our [Contributing Guide](/docs/contributing) to get started.\\n\\n## Learn More\\n\\n- [Documentation](/docs/intro)\\n- [Architecture Practices](/docs/architecture-practices)\\n- [API Reference](/docs/api-reference)\\n- [GitHub Repository](https://github.com/tamnk74/fullstack-dev)\\n\\n---\\n\\n*This project represents months of research, development, and refinement to create a truly production-ready Next.js application. We hope it serves as a valuable reference for your own projects.*"},{"id":"welcome","metadata":{"permalink":"/fullstack-dev/blog/welcome","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","tags":[{"inline":false,"label":"Facebook","permalink":"/fullstack-dev/blog/tags/facebook","description":"Facebook-related development and integration"},{"inline":false,"label":"Hello","permalink":"/fullstack-dev/blog/tags/hello","description":"Introduction and welcome posts"},{"inline":false,"label":"Docusaurus","permalink":"/fullstack-dev/blog/tags/docusaurus","description":"Docusaurus documentation platform"}],"readingTime":0.56,"hasTruncateMarker":true,"authors":[{"name":"S\xe9bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/fullstack-dev/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/fullstack-dev/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"unlisted":false,"prevItem":{"title":"Introducing Next.js for Production","permalink":"/fullstack-dev/blog/introducing-fullstack-devuction"},"nextItem":{"title":"MDX Blog Post","permalink":"/fullstack-dev/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\\n\\nHere are a few tips you might find useful.\\n\\n\x3c!-- truncate --\x3e\\n\\nSimply add Markdown files (or folders) to the `blog` directory.\\n\\nRegular blog authors can be added to `authors.yml`.\\n\\nThe blog post date can be extracted from filenames, such as:\\n\\n- `2019-05-30-welcome.md`\\n- `2019-05-30-welcome/index.md`\\n\\nA blog post folder can be convenient to co-locate blog post images:\\n\\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\\n\\nThe blog supports tags as well!\\n\\n**And if you don\'t want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/fullstack-dev/blog/mdx-blog-post","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2021-08-01-mdx-blog-post.mdx","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","tags":[{"inline":false,"label":"Docusaurus","permalink":"/fullstack-dev/blog/tags/docusaurus","description":"Docusaurus documentation platform"}],"readingTime":0.27,"hasTruncateMarker":true,"authors":[{"name":"S\xe9bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/fullstack-dev/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"unlisted":false,"prevItem":{"title":"Welcome","permalink":"/fullstack-dev/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/fullstack-dev/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\\n\\n:::tip\\n\\nUse the power of React to create interactive blog posts.\\n\\n:::\\n\\n{/* truncate */}\\n\\nFor example, use JSX to create an interactive button:\\n\\n```js\\n<button onClick={() => alert(\'button clicked!\')}>Click me!</button>\\n```\\n\\n<button onClick={() => alert(\'button clicked!\')}>Click me!</button>"},{"id":"long-blog-post","metadata":{"permalink":"/fullstack-dev/blog/long-blog-post","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2019-05-29-long-blog-post.md","source":"@site/blog/2019-05-29-long-blog-post.md","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","tags":[{"inline":false,"label":"Hello","permalink":"/fullstack-dev/blog/tags/hello","description":"Introduction and welcome posts"},{"inline":false,"label":"Docusaurus","permalink":"/fullstack-dev/blog/tags/docusaurus","description":"Docusaurus documentation platform"}],"readingTime":2.04,"hasTruncateMarker":true,"authors":[{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/fullstack-dev/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"yangshun","tags":["hello","docusaurus"]},"unlisted":false,"prevItem":{"title":"MDX Blog Post","permalink":"/fullstack-dev/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/fullstack-dev/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\\n\\nUse a `\x3c!--` `truncate` `--\x3e` comment to limit blog post size in the list view.\\n\\n\x3c!-- truncate --\x3e\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/fullstack-dev/blog/first-blog-post","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2019-05-28-first-blog-post.md","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet...","date":"2019-05-28T00:00:00.000Z","tags":[{"inline":false,"label":"Hola","permalink":"/fullstack-dev/blog/tags/hola","description":"Spanish greeting and introductory content"},{"inline":false,"label":"Docusaurus","permalink":"/fullstack-dev/blog/tags/docusaurus","description":"Docusaurus documentation platform"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"S\xe9bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","page":{"permalink":"/fullstack-dev/blog/authors/all-sebastien-lorber-articles"},"socials":{"x":"https://x.com/sebastienlorber","linkedin":"https://www.linkedin.com/in/sebastienlorber/","github":"https://github.com/slorber","newsletter":"https://thisweekinreact.com"},"imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Ex-Meta Staff Engineer, Co-founder GreatFrontEnd","url":"https://linkedin.com/in/yangshun","page":{"permalink":"/fullstack-dev/blog/authors/yangshun"},"socials":{"x":"https://x.com/yangshunz","linkedin":"https://www.linkedin.com/in/yangshun/","github":"https://github.com/yangshun","newsletter":"https://www.greatfrontend.com"},"imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":["slorber","yangshun"],"tags":["hola","docusaurus"]},"unlisted":false,"prevItem":{"title":"Long Blog Post","permalink":"/fullstack-dev/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet...\\n\\n\x3c!-- truncate --\x3e\\n\\n...consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}]}}')}}]);