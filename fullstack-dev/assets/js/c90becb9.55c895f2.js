"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[9834],{4323:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>a,metadata:()=>r,toc:()=>l});var r=t(9213),s=t(5813),i=t(5741);const a={slug:"rag-ecommerce-recommendations-part3-retrieval-system",title:"Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation",authors:["tam"],tags:["rag","ecommerce","recommendations","vector-search","qdrant","pinecone","hybrid-search","retrieval"],date:new Date("2025-10-08T00:00:00.000Z")},o="Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation",c={authorsImageUrls:[void 0]},l=[{value:"Retrieval System Architecture",id:"retrieval-system-architecture",level:2},{value:"Vector Database Implementation",id:"vector-database-implementation",level:2},{value:"1. Qdrant Implementation",id:"1-qdrant-implementation",level:3},{value:"2. Pinecone Implementation",id:"2-pinecone-implementation",level:3},{value:"3. Hybrid Search Implementation",id:"3-hybrid-search-implementation",level:3},{value:"Advanced Search Strategies",id:"advanced-search-strategies",level:2},{value:"1. Contextual Search Implementation",id:"1-contextual-search-implementation",level:3},{value:"2. Performance Optimization",id:"2-performance-optimization",level:3},{value:"Testing and Evaluation",id:"testing-and-evaluation",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"<strong>What We&#39;ve Accomplished</strong>",id:"what-weve-accomplished",level:3},{value:"<strong>Before Part 4</strong>",id:"before-part-4",level:3}];function _(e){const n={code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Welcome to Part 3 of our RAG-powered e-commerce recommendation series! We've built our data pipeline and generated high-quality embeddings. Now comes the exciting part: implementing a sophisticated retrieval system that can find the most relevant products using multiple search strategies."}),"\n",(0,s.jsx)(n.p,{children:"The retrieval system is the heart of our RAG architecture, responsible for efficiently finding relevant products from millions of items using semantic search, keyword matching, and hybrid approaches. We'll implement production-ready solutions using popular vector databases and explore advanced optimization techniques."}),"\n",(0,s.jsx)(n.h2,{id:"retrieval-system-architecture",children:"Retrieval System Architecture"}),"\n",(0,s.jsx)(n.p,{children:"Our retrieval system combines multiple search strategies to maximize relevance and coverage:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Query Processing Layer                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Query     \u2502  \u2502  Context    \u2502  \u2502   Intent    \u2502  \u2502  Filter     \u2502 \u2502\n\u2502  \u2502 Embedding   \u2502  \u2502 Enhancement \u2502  \u2502 Detection   \u2502  \u2502 Extraction  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Retrieval Strategies                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Semantic   \u2502  \u2502  Keyword    \u2502  \u2502Collaborative\u2502  \u2502   Hybrid    \u2502 \u2502\n\u2502  \u2502   Search    \u2502  \u2502   Search    \u2502  \u2502  Filtering  \u2502  \u2502   Fusion    \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Storage Layer                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Vector    \u2502  \u2502  Full-Text  \u2502  \u2502   Graph     \u2502  \u2502   Cache     \u2502 \u2502\n\u2502  \u2502  Database   \u2502  \u2502   Search    \u2502  \u2502  Database   \u2502  \u2502   Layer     \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"vector-database-implementation",children:"Vector Database Implementation"}),"\n",(0,s.jsx)(n.p,{children:"Let's implement retrieval systems for the three most popular vector databases:"}),"\n",(0,s.jsx)(n.h3,{id:"1-qdrant-implementation",children:"1. Qdrant Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# retrieval/qdrant_retriever.py\nimport asyncio\nfrom typing import List, Dict, Any, Optional, Tuple\nimport numpy as np\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http import models\nfrom qdrant_client.http.models import (\n    Distance, VectorParams, CreateCollection, PointStruct,\n    Filter, FieldCondition, PayloadSchemaType\n)\nimport logging\nfrom abc import ABC, abstractmethod\n\nlogger = logging.getLogger(__name__)\n\nclass BaseVectorRetriever(ABC):\n    """Abstract base class for vector retrievers"""\n    \n    @abstractmethod\n    async def create_collection(self, collection_name: str, vector_dimension: int) -> bool:\n        pass\n    \n    @abstractmethod\n    async def upsert_vectors(self, collection_name: str, vectors: List[Dict[str, Any]]) -> bool:\n        pass\n    \n    @abstractmethod\n    async def search(self, collection_name: str, query_vector: np.ndarray, \n                    limit: int = 10, filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\n        pass\n\nclass QdrantRetriever(BaseVectorRetriever):\n    """Qdrant vector database retriever implementation"""\n    \n    def __init__(self, host: str = "localhost", port: int = 6333, api_key: Optional[str] = None):\n        self.client = QdrantClient(\n            host=host,\n            port=port,\n            api_key=api_key,\n            timeout=30\n        )\n        self.collection_configs = {}\n        logger.info(f"Connected to Qdrant at {host}:{port}")\n    \n    async def create_collection(self, collection_name: str, vector_dimension: int, \n                               distance_metric: Distance = Distance.COSINE) -> bool:\n        """Create a new collection in Qdrant"""\n        try:\n            # Check if collection already exists\n            collections = self.client.get_collections()\n            existing_names = [col.name for col in collections.collections]\n            \n            if collection_name in existing_names:\n                logger.info(f"Collection {collection_name} already exists")\n                return True\n            \n            # Create collection\n            self.client.create_collection(\n                collection_name=collection_name,\n                vectors_config=VectorParams(\n                    size=vector_dimension,\n                    distance=distance_metric\n                ),\n                optimizers_config=models.OptimizersConfig(\n                    default_segment_number=2,\n                    max_segment_size=20000,\n                    memmap_threshold=20000,\n                    indexing_threshold=20000,\n                ),\n                replication_factor=1,\n                write_consistency_factor=1,\n            )\n            \n            # Create payload schema for better performance\n            self.client.create_payload_index(\n                collection_name=collection_name,\n                field_name="category",\n                field_schema=PayloadSchemaType.KEYWORD\n            )\n            \n            self.client.create_payload_index(\n                collection_name=collection_name,\n                field_name="brand",\n                field_schema=PayloadSchemaType.KEYWORD\n            )\n            \n            self.client.create_payload_index(\n                collection_name=collection_name,\n                field_name="price",\n                field_schema=PayloadSchemaType.FLOAT\n            )\n            \n            self.client.create_payload_index(\n                collection_name=collection_name,\n                field_name="rating",\n                field_schema=PayloadSchemaType.FLOAT\n            )\n            \n            logger.info(f"Created collection {collection_name} with dimension {vector_dimension}")\n            return True\n            \n        except Exception as e:\n            logger.error(f"Failed to create collection {collection_name}: {e}")\n            return False\n    \n    async def upsert_vectors(self, collection_name: str, vectors: List[Dict[str, Any]]) -> bool:\n        """Insert or update vectors in the collection"""\n        try:\n            points = []\n            for i, vector_data in enumerate(vectors):\n                point = PointStruct(\n                    id=vector_data.get(\'id\', i),\n                    vector=vector_data[\'vector\'].tolist() if isinstance(vector_data[\'vector\'], np.ndarray) \n                           else vector_data[\'vector\'],\n                    payload=vector_data.get(\'payload\', {})\n                )\n                points.append(point)\n            \n            # Batch upsert\n            batch_size = 100\n            for i in range(0, len(points), batch_size):\n                batch = points[i:i + batch_size]\n                operation_info = self.client.upsert(\n                    collection_name=collection_name,\n                    wait=True,\n                    points=batch\n                )\n                logger.debug(f"Upserted batch {i//batch_size + 1}: {operation_info}")\n            \n            logger.info(f"Successfully upserted {len(vectors)} vectors to {collection_name}")\n            return True\n            \n        except Exception as e:\n            logger.error(f"Failed to upsert vectors to {collection_name}: {e}")\n            return False\n    \n    async def search(self, collection_name: str, query_vector: np.ndarray, \n                    limit: int = 10, filters: Optional[Dict] = None,\n                    score_threshold: Optional[float] = None) -> List[Dict[str, Any]]:\n        """Search for similar vectors"""\n        try:\n            # Convert numpy array to list\n            query_vector_list = query_vector.tolist() if isinstance(query_vector, np.ndarray) else query_vector\n            \n            # Build filters\n            qdrant_filter = self._build_qdrant_filter(filters) if filters else None\n            \n            # Perform search\n            search_result = self.client.search(\n                collection_name=collection_name,\n                query_vector=query_vector_list,\n                limit=limit,\n                query_filter=qdrant_filter,\n                score_threshold=score_threshold,\n                with_payload=True,\n                with_vectors=False\n            )\n            \n            # Format results\n            results = []\n            for scored_point in search_result:\n                result = {\n                    \'id\': scored_point.id,\n                    \'score\': scored_point.score,\n                    \'payload\': scored_point.payload\n                }\n                results.append(result)\n            \n            logger.debug(f"Found {len(results)} results for query in {collection_name}")\n            return results\n            \n        except Exception as e:\n            logger.error(f"Search failed in {collection_name}: {e}")\n            return []\n    \n    async def hybrid_search(self, collection_name: str, query_vector: np.ndarray,\n                           text_query: str, limit: int = 10, \n                           alpha: float = 0.7) -> List[Dict[str, Any]]:\n        """Hybrid search combining vector and text search"""\n        try:\n            # Vector search\n            vector_results = await self.search(\n                collection_name=collection_name,\n                query_vector=query_vector,\n                limit=limit * 2  # Get more candidates\n            )\n            \n            # Text-based filtering/scoring\n            text_scored_results = self._score_text_relevance(vector_results, text_query)\n            \n            # Combine scores\n            final_results = []\n            for result in text_scored_results:\n                vector_score = result[\'score\']\n                text_score = result.get(\'text_score\', 0.0)\n                \n                # Weighted combination\n                combined_score = alpha * vector_score + (1 - alpha) * text_score\n                \n                result[\'combined_score\'] = combined_score\n                result[\'vector_score\'] = vector_score\n                result[\'text_score\'] = text_score\n                \n                final_results.append(result)\n            \n            # Sort by combined score and limit results\n            final_results.sort(key=lambda x: x[\'combined_score\'], reverse=True)\n            return final_results[:limit]\n            \n        except Exception as e:\n            logger.error(f"Hybrid search failed: {e}")\n            return []\n    \n    def _build_qdrant_filter(self, filters: Dict[str, Any]) -> Filter:\n        """Build Qdrant filter from dictionary"""\n        conditions = []\n        \n        for field, value in filters.items():\n            if isinstance(value, dict):\n                # Range filter\n                if \'gte\' in value or \'lte\' in value or \'gt\' in value or \'lt\' in value:\n                    condition = FieldCondition(\n                        key=field,\n                        range=models.Range(**value)\n                    )\n                # Match any filter\n                elif \'any\' in value:\n                    condition = FieldCondition(\n                        key=field,\n                        match=models.MatchAny(any=value[\'any\'])\n                    )\n                else:\n                    continue\n            else:\n                # Exact match\n                condition = FieldCondition(\n                    key=field,\n                    match=models.MatchValue(value=value)\n                )\n            \n            conditions.append(condition)\n        \n        return Filter(must=conditions) if conditions else None\n    \n    def _score_text_relevance(self, results: List[Dict[str, Any]], \n                             text_query: str) -> List[Dict[str, Any]]:\n        """Score results based on text relevance"""\n        query_terms = set(text_query.lower().split())\n        \n        for result in results:\n            text_score = 0.0\n            payload = result.get(\'payload\', {})\n            \n            # Score based on title match\n            title = payload.get(\'title\', \'\').lower()\n            title_words = set(title.split())\n            title_overlap = len(query_terms & title_words) / max(len(query_terms), 1)\n            text_score += title_overlap * 0.6\n            \n            # Score based on description match\n            description = payload.get(\'description\', \'\').lower()\n            desc_words = set(description.split())\n            desc_overlap = len(query_terms & desc_words) / max(len(query_terms), 1)\n            text_score += desc_overlap * 0.3\n            \n            # Score based on category/brand match\n            category = payload.get(\'category\', \'\').lower()\n            brand = payload.get(\'brand\', \'\').lower()\n            \n            if any(term in category for term in query_terms):\n                text_score += 0.1\n            if any(term in brand for term in query_terms):\n                text_score += 0.1\n            \n            result[\'text_score\'] = text_score\n        \n        return results\n    \n    async def get_collection_info(self, collection_name: str) -> Dict[str, Any]:\n        """Get information about a collection"""\n        try:\n            info = self.client.get_collection(collection_name)\n            return {\n                \'status\': info.status,\n                \'vectors_count\': info.vectors_count,\n                \'points_count\': info.points_count,\n                \'config\': info.config\n            }\n        except Exception as e:\n            logger.error(f"Failed to get collection info: {e}")\n            return {}\n    \n    async def delete_collection(self, collection_name: str) -> bool:\n        """Delete a collection"""\n        try:\n            self.client.delete_collection(collection_name)\n            logger.info(f"Deleted collection {collection_name}")\n            return True\n        except Exception as e:\n            logger.error(f"Failed to delete collection {collection_name}: {e}")\n            return False\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-pinecone-implementation",children:"2. Pinecone Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# retrieval/pinecone_retriever.py\nimport pinecone\nimport numpy as np\nfrom typing import List, Dict, Any, Optional\nimport logging\nimport asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\nlogger = logging.getLogger(__name__)\n\nclass PineconeRetriever(BaseVectorRetriever):\n    """Pinecone vector database retriever implementation"""\n    \n    def __init__(self, api_key: str, environment: str):\n        pinecone.init(api_key=api_key, environment=environment)\n        self.api_key = api_key\n        self.environment = environment\n        self.indexes = {}\n        self.executor = ThreadPoolExecutor(max_workers=10)\n        logger.info(f"Initialized Pinecone in environment: {environment}")\n    \n    async def create_collection(self, collection_name: str, vector_dimension: int,\n                               metric: str = "cosine", pods: int = 1,\n                               pod_type: str = "p1.x1") -> bool:\n        """Create a new index in Pinecone"""\n        try:\n            # Check if index exists\n            if collection_name in pinecone.list_indexes():\n                logger.info(f"Index {collection_name} already exists")\n                self.indexes[collection_name] = pinecone.Index(collection_name)\n                return True\n            \n            # Create index\n            pinecone.create_index(\n                name=collection_name,\n                dimension=vector_dimension,\n                metric=metric,\n                pods=pods,\n                pod_type=pod_type\n            )\n            \n            # Wait for index to be ready\n            await asyncio.sleep(10)  # Pinecone needs time to initialize\n            \n            self.indexes[collection_name] = pinecone.Index(collection_name)\n            logger.info(f"Created Pinecone index {collection_name}")\n            return True\n            \n        except Exception as e:\n            logger.error(f"Failed to create Pinecone index {collection_name}: {e}")\n            return False\n    \n    async def upsert_vectors(self, collection_name: str, vectors: List[Dict[str, Any]]) -> bool:\n        """Insert or update vectors in Pinecone"""\n        try:\n            if collection_name not in self.indexes:\n                self.indexes[collection_name] = pinecone.Index(collection_name)\n            \n            index = self.indexes[collection_name]\n            \n            # Prepare vectors for Pinecone format\n            pinecone_vectors = []\n            for vector_data in vectors:\n                vector_id = str(vector_data.get(\'id\'))\n                vector_values = vector_data[\'vector\'].tolist() if isinstance(vector_data[\'vector\'], np.ndarray) else vector_data[\'vector\']\n                metadata = vector_data.get(\'payload\', {})\n                \n                pinecone_vectors.append((vector_id, vector_values, metadata))\n            \n            # Batch upsert\n            batch_size = 100\n            for i in range(0, len(pinecone_vectors), batch_size):\n                batch = pinecone_vectors[i:i + batch_size]\n                \n                # Run in executor to avoid blocking\n                await asyncio.get_event_loop().run_in_executor(\n                    self.executor, \n                    lambda: index.upsert(vectors=batch)\n                )\n            \n            logger.info(f"Upserted {len(vectors)} vectors to Pinecone index {collection_name}")\n            return True\n            \n        except Exception as e:\n            logger.error(f"Failed to upsert vectors to Pinecone: {e}")\n            return False\n    \n    async def search(self, collection_name: str, query_vector: np.ndarray,\n                    limit: int = 10, filters: Optional[Dict] = None,\n                    include_metadata: bool = True) -> List[Dict[str, Any]]:\n        """Search for similar vectors in Pinecone"""\n        try:\n            if collection_name not in self.indexes:\n                self.indexes[collection_name] = pinecone.Index(collection_name)\n            \n            index = self.indexes[collection_name]\n            \n            # Convert numpy array to list\n            query_vector_list = query_vector.tolist() if isinstance(query_vector, np.ndarray) else query_vector\n            \n            # Perform search\n            search_response = await asyncio.get_event_loop().run_in_executor(\n                self.executor,\n                lambda: index.query(\n                    vector=query_vector_list,\n                    top_k=limit,\n                    filter=filters,\n                    include_metadata=include_metadata\n                )\n            )\n            \n            # Format results\n            results = []\n            for match in search_response.matches:\n                result = {\n                    \'id\': match.id,\n                    \'score\': match.score,\n                    \'payload\': match.metadata if include_metadata else {}\n                }\n                results.append(result)\n            \n            logger.debug(f"Found {len(results)} results in Pinecone index {collection_name}")\n            return results\n            \n        except Exception as e:\n            logger.error(f"Pinecone search failed: {e}")\n            return []\n    \n    async def delete_collection(self, collection_name: str) -> bool:\n        """Delete a Pinecone index"""\n        try:\n            pinecone.delete_index(collection_name)\n            if collection_name in self.indexes:\n                del self.indexes[collection_name]\n            logger.info(f"Deleted Pinecone index {collection_name}")\n            return True\n        except Exception as e:\n            logger.error(f"Failed to delete Pinecone index {collection_name}: {e}")\n            return False\n    \n    async def get_collection_info(self, collection_name: str) -> Dict[str, Any]:\n        """Get information about a Pinecone index"""\n        try:\n            index_stats = await asyncio.get_event_loop().run_in_executor(\n                self.executor,\n                lambda: pinecone.Index(collection_name).describe_index_stats()\n            )\n            return {\n                \'total_vector_count\': index_stats.total_vector_count,\n                \'dimension\': index_stats.dimension,\n                \'index_fullness\': index_stats.index_fullness\n            }\n        except Exception as e:\n            logger.error(f"Failed to get Pinecone index info: {e}")\n            return {}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-hybrid-search-implementation",children:"3. Hybrid Search Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# retrieval/hybrid_retriever.py\nimport asyncio\nfrom typing import List, Dict, Any, Optional, Tuple\nimport numpy as np\nfrom elasticsearch import AsyncElasticsearch\nimport logging\nfrom collections import defaultdict\n\nlogger = logging.getLogger(__name__)\n\nclass HybridRetriever:\n    \"\"\"Combines vector search with traditional text search\"\"\"\n    \n    def __init__(self, vector_retriever: BaseVectorRetriever, \n                 elasticsearch_client: Optional[AsyncElasticsearch] = None):\n        self.vector_retriever = vector_retriever\n        self.elasticsearch_client = elasticsearch_client\n        self.fusion_methods = {\n            'rrf': self._reciprocal_rank_fusion,\n            'weighted': self._weighted_fusion,\n            'linear': self._linear_combination\n        }\n    \n    async def hybrid_search(self, collection_name: str, query_vector: np.ndarray,\n                           text_query: str, limit: int = 10,\n                           vector_weight: float = 0.7,\n                           fusion_method: str = 'rrf',\n                           filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\n        \"\"\"Perform hybrid search combining vector and text search\"\"\"\n        \n        # Run searches in parallel\n        vector_task = self._vector_search(collection_name, query_vector, limit * 2, filters)\n        text_task = self._text_search(collection_name, text_query, limit * 2, filters)\n        \n        vector_results, text_results = await asyncio.gather(vector_task, text_task)\n        \n        # Fuse results\n        fusion_func = self.fusion_methods.get(fusion_method, self._reciprocal_rank_fusion)\n        fused_results = fusion_func(vector_results, text_results, vector_weight)\n        \n        # Limit and return results\n        return fused_results[:limit]\n    \n    async def _vector_search(self, collection_name: str, query_vector: np.ndarray,\n                            limit: int, filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\n        \"\"\"Perform vector similarity search\"\"\"\n        try:\n            results = await self.vector_retriever.search(\n                collection_name=collection_name,\n                query_vector=query_vector,\n                limit=limit,\n                filters=filters\n            )\n            \n            # Add search type and normalize scores\n            for i, result in enumerate(results):\n                result['search_type'] = 'vector'\n                result['rank'] = i + 1\n                result['normalized_score'] = result['score']  # Assumes cosine similarity [0,1]\n            \n            return results\n            \n        except Exception as e:\n            logger.error(f\"Vector search failed: {e}\")\n            return []\n    \n    async def _text_search(self, collection_name: str, text_query: str,\n                          limit: int, filters: Optional[Dict] = None) -> List[Dict[str, Any]]:\n        \"\"\"Perform full-text search using Elasticsearch\"\"\"\n        if not self.elasticsearch_client:\n            logger.warning(\"Elasticsearch client not configured, skipping text search\")\n            return []\n        \n        try:\n            # Build Elasticsearch query\n            es_query = {\n                \"query\": {\n                    \"bool\": {\n                        \"must\": [\n                            {\n                                \"multi_match\": {\n                                    \"query\": text_query,\n                                    \"fields\": [\"title^3\", \"description^2\", \"category\", \"brand\"],\n                                    \"type\": \"best_fields\",\n                                    \"fuzziness\": \"AUTO\"\n                                }\n                            }\n                        ]\n                    }\n                },\n                \"size\": limit\n            }\n            \n            # Add filters if provided\n            if filters:\n                es_filters = self._build_elasticsearch_filters(filters)\n                es_query[\"query\"][\"bool\"][\"filter\"] = es_filters\n            \n            # Execute search\n            response = await self.elasticsearch_client.search(\n                index=collection_name,\n                body=es_query\n            )\n            \n            # Format results\n            results = []\n            for i, hit in enumerate(response['hits']['hits']):\n                result = {\n                    'id': hit['_id'],\n                    'score': hit['_score'],\n                    'payload': hit['_source'],\n                    'search_type': 'text',\n                    'rank': i + 1,\n                    'normalized_score': hit['_score'] / response['hits']['max_score'] if response['hits']['max_score'] > 0 else 0\n                }\n                results.append(result)\n            \n            return results\n            \n        except Exception as e:\n            logger.error(f\"Text search failed: {e}\")\n            return []\n    \n    def _reciprocal_rank_fusion(self, vector_results: List[Dict[str, Any]],\n                               text_results: List[Dict[str, Any]],\n                               vector_weight: float = 0.7,\n                               k: int = 60) -> List[Dict[str, Any]]:\n        \"\"\"Combine results using Reciprocal Rank Fusion\"\"\"\n        # Create score maps\n        vector_scores = {result['id']: 1 / (k + result['rank']) for result in vector_results}\n        text_scores = {result['id']: 1 / (k + result['rank']) for result in text_results}\n        \n        # Get all unique IDs\n        all_ids = set(vector_scores.keys()) | set(text_scores.keys())\n        \n        # Calculate combined scores\n        combined_results = []\n        item_map = {}\n        \n        # Create item lookup\n        for result in vector_results + text_results:\n            if result['id'] not in item_map:\n                item_map[result['id']] = result\n        \n        for item_id in all_ids:\n            vector_score = vector_scores.get(item_id, 0)\n            text_score = text_scores.get(item_id, 0)\n            \n            # Weighted RRF score\n            combined_score = (vector_weight * vector_score + \n                            (1 - vector_weight) * text_score)\n            \n            if item_id in item_map:\n                result = item_map[item_id].copy()\n                result['rrf_score'] = combined_score\n                result['vector_rrf'] = vector_score\n                result['text_rrf'] = text_score\n                combined_results.append(result)\n        \n        # Sort by combined score\n        combined_results.sort(key=lambda x: x['rrf_score'], reverse=True)\n        return combined_results\n    \n    def _weighted_fusion(self, vector_results: List[Dict[str, Any]],\n                        text_results: List[Dict[str, Any]],\n                        vector_weight: float = 0.7) -> List[Dict[str, Any]]:\n        \"\"\"Combine results using weighted score fusion\"\"\"\n        # Create score maps\n        vector_scores = {result['id']: result['normalized_score'] for result in vector_results}\n        text_scores = {result['id']: result['normalized_score'] for result in text_results}\n        \n        # Get all unique IDs\n        all_ids = set(vector_scores.keys()) | set(text_scores.keys())\n        \n        # Calculate combined scores\n        combined_results = []\n        item_map = {}\n        \n        # Create item lookup\n        for result in vector_results + text_results:\n            if result['id'] not in item_map:\n                item_map[result['id']] = result\n        \n        for item_id in all_ids:\n            vector_score = vector_scores.get(item_id, 0)\n            text_score = text_scores.get(item_id, 0)\n            \n            # Weighted combination\n            combined_score = (vector_weight * vector_score + \n                            (1 - vector_weight) * text_score)\n            \n            if item_id in item_map:\n                result = item_map[item_id].copy()\n                result['combined_score'] = combined_score\n                result['vector_score'] = vector_score\n                result['text_score'] = text_score\n                combined_results.append(result)\n        \n        # Sort by combined score\n        combined_results.sort(key=lambda x: x['combined_score'], reverse=True)\n        return combined_results\n    \n    def _linear_combination(self, vector_results: List[Dict[str, Any]],\n                           text_results: List[Dict[str, Any]],\n                           vector_weight: float = 0.7) -> List[Dict[str, Any]]:\n        \"\"\"Simple linear combination of normalized scores\"\"\"\n        return self._weighted_fusion(vector_results, text_results, vector_weight)\n    \n    def _build_elasticsearch_filters(self, filters: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Convert filters to Elasticsearch format\"\"\"\n        es_filters = []\n        \n        for field, value in filters.items():\n            if isinstance(value, dict):\n                if 'gte' in value or 'lte' in value:\n                    es_filters.append({\n                        \"range\": {\n                            field: value\n                        }\n                    })\n                elif 'any' in value:\n                    es_filters.append({\n                        \"terms\": {\n                            field: value['any']\n                        }\n                    })\n            else:\n                es_filters.append({\n                    \"term\": {\n                        field: value\n                    }\n                })\n        \n        return es_filters\n"})}),"\n",(0,s.jsx)(n.h2,{id:"advanced-search-strategies",children:"Advanced Search Strategies"}),"\n",(0,s.jsx)(n.h3,{id:"1-contextual-search-implementation",children:"1. Contextual Search Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# retrieval/contextual_search.py\nfrom typing import List, Dict, Any, Optional\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass ContextualSearchEngine:\n    \"\"\"Advanced search engine with context awareness\"\"\"\n    \n    def __init__(self, retriever: BaseVectorRetriever):\n        self.retriever = retriever\n        self.context_weights = {\n            'seasonal': 0.1,\n            'trending': 0.15,\n            'personal': 0.3,\n            'behavioral': 0.25,\n            'collaborative': 0.2\n        }\n    \n    async def contextual_search(self, collection_name: str, query_vector: np.ndarray,\n                               user_context: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:\n        \"\"\"Perform context-aware search\"\"\"\n        \n        # Get base search results\n        base_results = await self.retriever.search(\n            collection_name=collection_name,\n            query_vector=query_vector,\n            limit=limit * 3  # Get more candidates for reranking\n        )\n        \n        # Apply contextual reranking\n        reranked_results = await self._apply_contextual_reranking(\n            base_results, user_context\n        )\n        \n        # Apply diversity filtering\n        diverse_results = self._apply_diversity_filtering(reranked_results, limit)\n        \n        return diverse_results\n    \n    async def _apply_contextual_reranking(self, results: List[Dict[str, Any]], \n                                         context: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Rerank results based on context\"\"\"\n        \n        for result in results:\n            payload = result.get('payload', {})\n            base_score = result['score']\n            \n            # Calculate context-based adjustments\n            seasonal_boost = self._calculate_seasonal_boost(payload, context)\n            trending_boost = self._calculate_trending_boost(payload, context)\n            personal_boost = self._calculate_personal_boost(payload, context)\n            behavioral_boost = self._calculate_behavioral_boost(payload, context)\n            collaborative_boost = self._calculate_collaborative_boost(payload, context)\n            \n            # Apply weighted boosts\n            context_score = (\n                self.context_weights['seasonal'] * seasonal_boost +\n                self.context_weights['trending'] * trending_boost +\n                self.context_weights['personal'] * personal_boost +\n                self.context_weights['behavioral'] * behavioral_boost +\n                self.context_weights['collaborative'] * collaborative_boost\n            )\n            \n            # Combine base score with context score\n            result['contextual_score'] = base_score * (1 + context_score)\n            result['context_breakdown'] = {\n                'seasonal': seasonal_boost,\n                'trending': trending_boost,\n                'personal': personal_boost,\n                'behavioral': behavioral_boost,\n                'collaborative': collaborative_boost\n            }\n        \n        # Sort by contextual score\n        results.sort(key=lambda x: x['contextual_score'], reverse=True)\n        return results\n    \n    def _calculate_seasonal_boost(self, product: Dict[str, Any], \n                                 context: Dict[str, Any]) -> float:\n        \"\"\"Calculate seasonal relevance boost\"\"\"\n        current_month = datetime.now().month\n        product_category = product.get('category', '').lower()\n        \n        # Define seasonal categories\n        seasonal_categories = {\n            'winter': ['coats', 'sweaters', 'boots', 'heating'],\n            'spring': ['flowers', 'gardening', 'light_clothing'],\n            'summer': ['swimwear', 'shorts', 'cooling', 'outdoor'],\n            'fall': ['jackets', 'school_supplies', 'warm_drinks']\n        }\n        \n        # Determine current season\n        season_map = {\n            12: 'winter', 1: 'winter', 2: 'winter',\n            3: 'spring', 4: 'spring', 5: 'spring',\n            6: 'summer', 7: 'summer', 8: 'summer',\n            9: 'fall', 10: 'fall', 11: 'fall'\n        }\n        \n        current_season = season_map.get(current_month, 'spring')\n        seasonal_items = seasonal_categories.get(current_season, [])\n        \n        # Check if product matches current season\n        for item in seasonal_items:\n            if item in product_category or item in product.get('title', '').lower():\n                return 0.2  # 20% boost for seasonal items\n        \n        return 0.0\n    \n    def _calculate_trending_boost(self, product: Dict[str, Any], \n                                 context: Dict[str, Any]) -> float:\n        \"\"\"Calculate trending boost based on recent popularity\"\"\"\n        popularity_score = product.get('popularity_score', 0)\n        recent_views = product.get('recent_views', 0)\n        \n        # Boost based on popularity and recent activity\n        trending_score = 0.0\n        \n        if popularity_score > 0.8:\n            trending_score += 0.15\n        elif popularity_score > 0.6:\n            trending_score += 0.1\n        \n        if recent_views > 1000:  # High recent activity\n            trending_score += 0.1\n        \n        return trending_score\n    \n    def _calculate_personal_boost(self, product: Dict[str, Any], \n                                 context: Dict[str, Any]) -> float:\n        \"\"\"Calculate personal preference boost\"\"\"\n        user_preferences = context.get('preferences', {})\n        personal_score = 0.0\n        \n        # Category preference\n        preferred_categories = user_preferences.get('preferred_categories', [])\n        if product.get('category') in preferred_categories:\n            personal_score += 0.3\n        \n        # Brand preference\n        preferred_brands = user_preferences.get('preferred_brands', [])\n        if product.get('brand') in preferred_brands:\n            personal_score += 0.2\n        \n        # Price preference\n        price_sensitivity = user_preferences.get('price_sensitivity', 0.5)\n        product_price = product.get('price', 0)\n        user_avg_price = context.get('avg_order_value', 100)\n        \n        if price_sensitivity < 0.3:  # Price-conscious user\n            if product_price <= user_avg_price * 0.8:\n                personal_score += 0.1\n        elif price_sensitivity > 0.7:  # Premium-oriented user\n            if product_price >= user_avg_price * 1.2:\n                personal_score += 0.1\n        \n        return personal_score\n    \n    def _calculate_behavioral_boost(self, product: Dict[str, Any], \n                                   context: Dict[str, Any]) -> float:\n        \"\"\"Calculate behavioral pattern boost\"\"\"\n        user_behavior = context.get('behavioral_features', {})\n        behavioral_score = 0.0\n        \n        # Time-based patterns\n        current_hour = datetime.now().hour\n        user_peak_hour = context.get('peak_hour', 12)\n        \n        # Boost items typically purchased at current time\n        if abs(current_hour - user_peak_hour) <= 2:\n            behavioral_score += 0.1\n        \n        # Purchase frequency patterns\n        purchase_frequency = user_behavior.get('purchase_frequency', 0)\n        if purchase_frequency > 10:  # Frequent buyer\n            # Boost consumable/replenishable items\n            if any(keyword in product.get('title', '').lower() \n                   for keyword in ['refill', 'pack', 'bulk']):\n                behavioral_score += 0.15\n        \n        return behavioral_score\n    \n    def _calculate_collaborative_boost(self, product: Dict[str, Any], \n                                      context: Dict[str, Any]) -> float:\n        \"\"\"Calculate collaborative filtering boost\"\"\"\n        # This would typically use precomputed user similarity scores\n        # For now, we'll use simplified logic\n        \n        similar_users_preferences = context.get('similar_users_bought', [])\n        if product.get('id') in similar_users_preferences:\n            return 0.2\n        \n        return 0.0\n    \n    def _apply_diversity_filtering(self, results: List[Dict[str, Any]], \n                                  limit: int, diversity_threshold: float = 0.3) -> List[Dict[str, Any]]:\n        \"\"\"Apply diversity filtering to avoid too similar items\"\"\"\n        if not results:\n            return results\n        \n        diverse_results = [results[0]]  # Always include top result\n        \n        for result in results[1:]:\n            if len(diverse_results) >= limit:\n                break\n            \n            # Check diversity against already selected items\n            is_diverse = True\n            result_category = result.get('payload', {}).get('category', '')\n            result_brand = result.get('payload', {}).get('brand', '')\n            \n            category_count = sum(1 for r in diverse_results \n                               if r.get('payload', {}).get('category', '') == result_category)\n            brand_count = sum(1 for r in diverse_results \n                            if r.get('payload', {}).get('brand', '') == result_brand)\n            \n            # Avoid too many items from same category/brand\n            if (category_count >= limit * diversity_threshold or \n                brand_count >= limit * diversity_threshold):\n                is_diverse = False\n            \n            if is_diverse:\n                diverse_results.append(result)\n        \n        return diverse_results\n"})}),"\n",(0,s.jsx)(n.h3,{id:"2-performance-optimization",children:"2. Performance Optimization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# retrieval/performance_optimizer.py\nimport asyncio\nfrom typing import List, Dict, Any, Optional\nimport numpy as np\nimport redis\nimport json\nimport hashlib\nfrom datetime import datetime, timedelta\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass SearchPerformanceOptimizer:\n    """Optimize search performance through caching and query optimization"""\n    \n    def __init__(self, redis_client: Optional[redis.Redis] = None):\n        self.redis_client = redis_client\n        self.cache_ttl = {\n            \'search_results\': 3600,    # 1 hour\n            \'user_embeddings\': 86400,  # 24 hours\n            \'popular_queries\': 7200,   # 2 hours\n        }\n        self.query_stats = {}\n    \n    async def optimized_search(self, search_func, cache_key: str, \n                              ttl: int = 3600, *args, **kwargs) -> List[Dict[str, Any]]:\n        """Wrapper for optimized search with caching"""\n        \n        # Try cache first\n        cached_result = await self._get_cached_result(cache_key)\n        if cached_result is not None:\n            logger.debug(f"Cache hit for key: {cache_key}")\n            return cached_result\n        \n        # Execute search\n        start_time = datetime.now()\n        results = await search_func(*args, **kwargs)\n        execution_time = (datetime.now() - start_time).total_seconds()\n        \n        # Cache results\n        await self._cache_result(cache_key, results, ttl)\n        \n        # Update query statistics\n        self._update_query_stats(cache_key, execution_time, len(results))\n        \n        logger.debug(f"Search executed in {execution_time:.3f}s, {len(results)} results")\n        return results\n    \n    async def _get_cached_result(self, cache_key: str) -> Optional[List[Dict[str, Any]]]:\n        """Retrieve cached search results"""\n        if not self.redis_client:\n            return None\n        \n        try:\n            cached_data = self.redis_client.get(cache_key)\n            if cached_data:\n                return json.loads(cached_data)\n        except Exception as e:\n            logger.warning(f"Cache retrieval failed: {e}")\n        \n        return None\n    \n    async def _cache_result(self, cache_key: str, results: List[Dict[str, Any]], \n                           ttl: int) -> None:\n        """Cache search results"""\n        if not self.redis_client:\n            return\n        \n        try:\n            # Serialize results (handle numpy arrays)\n            serializable_results = self._make_serializable(results)\n            cached_data = json.dumps(serializable_results)\n            \n            self.redis_client.setex(cache_key, ttl, cached_data)\n            logger.debug(f"Cached results for key: {cache_key}")\n        except Exception as e:\n            logger.warning(f"Caching failed: {e}")\n    \n    def _make_serializable(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n        """Convert results to JSON-serializable format"""\n        serializable_results = []\n        \n        for result in results:\n            serializable_result = {}\n            for key, value in result.items():\n                if isinstance(value, np.ndarray):\n                    serializable_result[key] = value.tolist()\n                elif isinstance(value, (np.int64, np.int32)):\n                    serializable_result[key] = int(value)\n                elif isinstance(value, (np.float64, np.float32)):\n                    serializable_result[key] = float(value)\n                else:\n                    serializable_result[key] = value\n            \n            serializable_results.append(serializable_result)\n        \n        return serializable_results\n    \n    def _update_query_stats(self, cache_key: str, execution_time: float, \n                           result_count: int) -> None:\n        """Update query performance statistics"""\n        if cache_key not in self.query_stats:\n            self.query_stats[cache_key] = {\n                \'count\': 0,\n                \'total_time\': 0.0,\n                \'total_results\': 0,\n                \'avg_time\': 0.0,\n                \'avg_results\': 0.0\n            }\n        \n        stats = self.query_stats[cache_key]\n        stats[\'count\'] += 1\n        stats[\'total_time\'] += execution_time\n        stats[\'total_results\'] += result_count\n        stats[\'avg_time\'] = stats[\'total_time\'] / stats[\'count\']\n        stats[\'avg_results\'] = stats[\'total_results\'] / stats[\'count\']\n    \n    def generate_cache_key(self, *args, **kwargs) -> str:\n        """Generate cache key from search parameters"""\n        # Create deterministic key from parameters\n        key_data = {\n            \'args\': args,\n            \'kwargs\': kwargs\n        }\n        \n        key_string = json.dumps(key_data, sort_keys=True, default=str)\n        return hashlib.md5(key_string.encode()).hexdigest()\n    \n    async def warm_cache(self, collection_name: str, popular_queries: List[str],\n                        retriever: BaseVectorRetriever, \n                        embedding_generator) -> None:\n        """Pre-warm cache with popular queries"""\n        logger.info(f"Warming cache with {len(popular_queries)} popular queries")\n        \n        for query in popular_queries:\n            try:\n                # Generate query embedding\n                query_embedding = await embedding_generator.generate_query_embedding(query)\n                \n                # Generate cache key\n                cache_key = self.generate_cache_key(\n                    \'search\', collection_name, query, limit=20\n                )\n                \n                # Execute search if not cached\n                cached_result = await self._get_cached_result(cache_key)\n                if cached_result is None:\n                    results = await retriever.search(\n                        collection_name=collection_name,\n                        query_vector=query_embedding,\n                        limit=20\n                    )\n                    await self._cache_result(cache_key, results, \n                                           self.cache_ttl[\'search_results\'])\n                \n                # Rate limiting to avoid overwhelming the system\n                await asyncio.sleep(0.1)\n                \n            except Exception as e:\n                logger.warning(f"Failed to warm cache for query \'{query}\': {e}")\n        \n        logger.info("Cache warming completed")\n    \n    def get_performance_stats(self) -> Dict[str, Any]:\n        """Get performance statistics"""\n        total_queries = sum(stats[\'count\'] for stats in self.query_stats.values())\n        avg_execution_time = np.mean([stats[\'avg_time\'] for stats in self.query_stats.values()]) if self.query_stats else 0\n        \n        return {\n            \'total_queries\': total_queries,\n            \'unique_query_patterns\': len(self.query_stats),\n            \'avg_execution_time\': avg_execution_time,\n            \'query_breakdown\': self.query_stats\n        }\n'})}),"\n",(0,s.jsx)(n.h2,{id:"testing-and-evaluation",children:"Testing and Evaluation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# tests/test_retrieval_system.py\nimport pytest\nimport numpy as np\nfrom typing import List, Dict, Any\nimport asyncio\nimport time\nfrom retrieval.qdrant_retriever import QdrantRetriever\nfrom retrieval.hybrid_retriever import HybridRetriever\n\nclass RetrievalSystemTester:\n    \"\"\"Comprehensive testing for retrieval system\"\"\"\n    \n    def __init__(self, retriever: BaseVectorRetriever):\n        self.retriever = retriever\n        self.test_collection = \"test_products\"\n        self.test_data = self._generate_test_data()\n    \n    async def run_all_tests(self) -> Dict[str, Any]:\n        \"\"\"Run comprehensive test suite\"\"\"\n        results = {\n            'accuracy_tests': await self._test_search_accuracy(),\n            'performance_tests': await self._test_search_performance(),\n            'scalability_tests': await self._test_scalability(),\n            'relevance_tests': await self._test_relevance_ranking()\n        }\n        \n        return results\n    \n    async def _test_search_accuracy(self) -> Dict[str, float]:\n        \"\"\"Test search accuracy using ground truth data\"\"\"\n        # Set up test collection\n        await self.retriever.create_collection(self.test_collection, 384)\n        await self.retriever.upsert_vectors(self.test_collection, self.test_data)\n        \n        accuracy_scores = []\n        \n        # Test with known similar items\n        for test_case in self._get_accuracy_test_cases():\n            query_vector = test_case['query_vector']\n            expected_ids = set(test_case['expected_ids'])\n            \n            results = await self.retriever.search(\n                collection_name=self.test_collection,\n                query_vector=query_vector,\n                limit=len(expected_ids) * 2\n            )\n            \n            # Calculate accuracy metrics\n            retrieved_ids = set([r['id'] for r in results[:len(expected_ids)]])\n            precision = len(retrieved_ids & expected_ids) / len(retrieved_ids) if retrieved_ids else 0\n            recall = len(retrieved_ids & expected_ids) / len(expected_ids) if expected_ids else 0\n            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n            \n            accuracy_scores.append({\n                'precision': precision,\n                'recall': recall,\n                'f1_score': f1_score\n            })\n        \n        # Calculate average metrics\n        avg_precision = np.mean([s['precision'] for s in accuracy_scores])\n        avg_recall = np.mean([s['recall'] for s in accuracy_scores])\n        avg_f1 = np.mean([s['f1_score'] for s in accuracy_scores])\n        \n        return {\n            'precision': avg_precision,\n            'recall': avg_recall,\n            'f1_score': avg_f1\n        }\n    \n    async def _test_search_performance(self) -> Dict[str, float]:\n        \"\"\"Test search performance and latency\"\"\"\n        query_vector = np.random.rand(384)\n        \n        # Warm up\n        await self.retriever.search(self.test_collection, query_vector, limit=10)\n        \n        # Performance test\n        latencies = []\n        for _ in range(50):\n            start_time = time.time()\n            await self.retriever.search(self.test_collection, query_vector, limit=10)\n            latency = time.time() - start_time\n            latencies.append(latency)\n        \n        return {\n            'avg_latency': np.mean(latencies),\n            'p95_latency': np.percentile(latencies, 95),\n            'p99_latency': np.percentile(latencies, 99),\n            'min_latency': np.min(latencies),\n            'max_latency': np.max(latencies)\n        }\n    \n    async def _test_scalability(self) -> Dict[str, Any]:\n        \"\"\"Test system scalability with increasing load\"\"\"\n        results = {}\n        \n        # Test concurrent queries\n        for concurrency in [1, 5, 10, 20]:\n            query_vector = np.random.rand(384)\n            \n            start_time = time.time()\n            tasks = []\n            for _ in range(concurrency):\n                task = self.retriever.search(self.test_collection, query_vector, limit=10)\n                tasks.append(task)\n            \n            await asyncio.gather(*tasks)\n            total_time = time.time() - start_time\n            \n            results[f'concurrency_{concurrency}'] = {\n                'total_time': total_time,\n                'avg_time_per_query': total_time / concurrency,\n                'queries_per_second': concurrency / total_time\n            }\n        \n        return results\n    \n    async def _test_relevance_ranking(self) -> Dict[str, float]:\n        \"\"\"Test relevance ranking quality\"\"\"\n        # This would test if more relevant items appear higher in results\n        # For now, we'll implement a simplified version\n        \n        relevance_scores = []\n        \n        for test_case in self._get_relevance_test_cases():\n            query_vector = test_case['query_vector']\n            relevance_map = test_case['relevance_map']  # id -> relevance_score\n            \n            results = await self.retriever.search(\n                collection_name=self.test_collection,\n                query_vector=query_vector,\n                limit=10\n            )\n            \n            # Calculate NDCG (Normalized Discounted Cumulative Gain)\n            dcg = 0.0\n            ideal_dcg = 0.0\n            \n            # Calculate DCG for retrieved results\n            for i, result in enumerate(results):\n                relevance = relevance_map.get(result['id'], 0)\n                dcg += relevance / np.log2(i + 2)\n            \n            # Calculate ideal DCG\n            ideal_relevances = sorted(relevance_map.values(), reverse=True)\n            for i, relevance in enumerate(ideal_relevances[:len(results)]):\n                ideal_dcg += relevance / np.log2(i + 2)\n            \n            ndcg = dcg / ideal_dcg if ideal_dcg > 0 else 0\n            relevance_scores.append(ndcg)\n        \n        return {\n            'avg_ndcg': np.mean(relevance_scores),\n            'min_ndcg': np.min(relevance_scores),\n            'max_ndcg': np.max(relevance_scores)\n        }\n    \n    def _generate_test_data(self) -> List[Dict[str, Any]]:\n        \"\"\"Generate test data for evaluation\"\"\"\n        test_data = []\n        \n        # Generate synthetic product vectors and metadata\n        for i in range(1000):\n            vector = np.random.rand(384)\n            payload = {\n                'id': f'product_{i}',\n                'title': f'Test Product {i}',\n                'category': ['electronics', 'clothing', 'books'][i % 3],\n                'brand': ['BrandA', 'BrandB', 'BrandC'][i % 3],\n                'price': 10 + (i % 200),\n                'rating': 3.0 + (i % 3)\n            }\n            \n            test_data.append({\n                'id': f'product_{i}',\n                'vector': vector,\n                'payload': payload\n            })\n        \n        return test_data\n    \n    def _get_accuracy_test_cases(self) -> List[Dict[str, Any]]:\n        \"\"\"Get test cases for accuracy evaluation\"\"\"\n        # Create test cases where we know which items should be similar\n        test_cases = []\n        \n        # Electronics category test\n        electronics_vector = np.random.rand(384)\n        electronics_ids = [f'product_{i}' for i in range(0, 334, 3)]  # Every 3rd electronics item\n        \n        test_cases.append({\n            'query_vector': electronics_vector,\n            'expected_ids': electronics_ids[:10]  # Top 10 expected\n        })\n        \n        return test_cases\n    \n    def _get_relevance_test_cases(self) -> List[Dict[str, Any]]:\n        \"\"\"Get test cases for relevance evaluation\"\"\"\n        test_cases = []\n        \n        # Create relevance maps for test queries\n        query_vector = np.random.rand(384)\n        relevance_map = {}\n        \n        # Assign higher relevance to certain products\n        for i in range(100):\n            if i % 10 == 0:  # High relevance\n                relevance_map[f'product_{i}'] = 3\n            elif i % 5 == 0:  # Medium relevance\n                relevance_map[f'product_{i}'] = 2\n            else:  # Low relevance\n                relevance_map[f'product_{i}'] = 1\n        \n        test_cases.append({\n            'query_vector': query_vector,\n            'relevance_map': relevance_map\n        })\n        \n        return test_cases\n"})}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.p,{children:["In ",(0,s.jsx)(n.strong,{children:"Part 4"})," of this series, we'll implement the generation and personalization engine that transforms retrieved products into intelligent, personalized recommendations. We'll cover:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"LLM Integration"}),": Connecting with OpenAI, Anthropic, and local models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Prompt Engineering"}),": Crafting effective prompts for recommendation generation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Personalization Algorithms"}),": Advanced techniques for user-specific recommendations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"A/B Testing Framework"}),": Measuring and optimizing recommendation quality"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"what-weve-accomplished",children:(0,s.jsx)(n.strong,{children:"What We've Accomplished"})}),"\n",(0,s.jsx)(n.p,{children:"In this post, we've built a sophisticated retrieval system:"}),"\n",(0,s.jsxs)(n.p,{children:["\u2705 ",(0,s.jsx)(n.strong,{children:"Multi-Database Support"}),": Implementations for Qdrant, Pinecone, and hybrid approaches\n\u2705 ",(0,s.jsx)(n.strong,{children:"Advanced Search Strategies"}),": Semantic, keyword, and hybrid search with fusion algorithms\n\u2705 ",(0,s.jsx)(n.strong,{children:"Contextual Intelligence"}),": Context-aware search with seasonal, behavioral, and collaborative signals\n\u2705 ",(0,s.jsx)(n.strong,{children:"Performance Optimization"}),": Caching, query optimization, and scalability testing\n\u2705 ",(0,s.jsx)(n.strong,{children:"Comprehensive Testing"}),": Accuracy, performance, and relevance evaluation frameworks"]}),"\n",(0,s.jsx)(n.h3,{id:"before-part-4",children:(0,s.jsx)(n.strong,{children:"Before Part 4"})}),"\n",(0,s.jsx)(n.p,{children:"Ensure you have:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Set up your chosen vector database"}),"\n",(0,s.jsx)(n.li,{children:"Indexed your product catalog with embeddings"}),"\n",(0,s.jsx)(n.li,{children:"Implemented and tested basic search functionality"}),"\n",(0,s.jsx)(n.li,{children:"Prepared for LLM integration (API keys, model selection)"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"The retrieval system is the engine that finds relevant products. Next, we'll build the intelligence layer that transforms these results into personalized recommendations!"})})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(_,{...e})}):_(e)}},5741:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var r=t(9729);const s={},i=r.createContext(s);function a(e){const n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(i.Provider,{value:n},e.children)}},9213:e=>{e.exports=JSON.parse('{"permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part3-retrieval-system","editUrl":"https://github.com/tamnk74/fullstack-dev/tree/main/docs-site/blog/2025-10-08-rag-ecommerce-recommendations-part3-retrieval-system.md","source":"@site/blog/2025-10-08-rag-ecommerce-recommendations-part3-retrieval-system.md","title":"Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation","description":"Welcome to Part 3 of our RAG-powered e-commerce recommendation series! We\'ve built our data pipeline and generated high-quality embeddings. Now comes the exciting part: implementing a sophisticated retrieval system that can find the most relevant products using multiple search strategies.","date":"2025-10-08T00:00:00.000Z","tags":[{"inline":false,"label":"RAG","permalink":"/fullstack-dev/blog/tags/rag","description":"Retrieval-Augmented Generation"},{"inline":false,"label":"E-commerce","permalink":"/fullstack-dev/blog/tags/ecommerce","description":"E-commerce development and strategies"},{"inline":false,"label":"Recommendations","permalink":"/fullstack-dev/blog/tags/recommendations","description":"Recommendation systems and algorithms"},{"inline":false,"label":"Vector Search","permalink":"/fullstack-dev/blog/tags/vector-search","description":"Vector similarity search"},{"inline":false,"label":"Qdrant","permalink":"/fullstack-dev/blog/tags/qdrant","description":"Qdrant vector database"},{"inline":false,"label":"Pinecone","permalink":"/fullstack-dev/blog/tags/pinecone","description":"Pinecone vector database"},{"inline":false,"label":"Hybrid Search","permalink":"/fullstack-dev/blog/tags/hybrid-search","description":"Hybrid search combining multiple techniques"},{"inline":false,"label":"Retrieval","permalink":"/fullstack-dev/blog/tags/retrieval","description":"Information retrieval systems"}],"readingTime":21.69,"hasTruncateMarker":true,"authors":[{"name":"Tam Nguyen","title":"Full Stack Developer, Next.js for Production Creator","url":"https://github.com/tamnk74","page":{"permalink":"/fullstack-dev/blog/authors/tam"},"socials":{"github":"https://github.com/tamnk74"},"imageURL":"https://github.com/tamnk74.png","key":"tam"}],"frontMatter":{"slug":"rag-ecommerce-recommendations-part3-retrieval-system","title":"Building Intelligent E-commerce Recommendations with RAG: Part 3 - Retrieval System Implementation","authors":["tam"],"tags":["rag","ecommerce","recommendations","vector-search","qdrant","pinecone","hybrid-search","retrieval"],"date":"2025-10-08T00:00:00.000Z"},"unlisted":false,"prevItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 2 - Data Pipeline and Vector Embeddings","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part2-data-pipeline-embeddings"},"nextItem":{"title":"Building Intelligent E-commerce Recommendations with RAG: Part 4 - Generation and Personalization Engine","permalink":"/fullstack-dev/blog/rag-ecommerce-recommendations-part4-generation-personalization"}}')}}]);